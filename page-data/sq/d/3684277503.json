{"data":{"allMdx":{"nodes":[{"id":"102f164c-f107-5b16-a52a-bd713037c481","body":"Join the Meshery project office hours at KubeCon North America 2023 from 6th to 9th November, 2023 and get introduced to the cloud native management plane and to its open source maintainers.\n\n","frontmatter":{"title":"KubeCon + CloudNativeCon North America Chicago 2023","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmoAAABXRUJQVlA4IF4AAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQAAKVUVi2o0E/RBAAAD+6OwHbusRM21Xmi3Wvp1u+KBhKwaJ72MhQ8JdpkdPj/natj5Lrx3vKRjldF9kuVsEqLvPgAAA"},"images":{"fallback":{"src":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp","srcSet":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/7513b/kubeconNA2023.webp 750w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/317ed/kubeconNA2023.webp 1080w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/kubeconNA2023.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmoAAABXRUJQVlA4IF4AAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQAAKVUVi2o0E/RBAAAD+6OwHbusRM21Xmi3Wvp1u+KBhKwaJ72MhQ8JdpkdPj/natj5Lrx3vKRjldF9kuVsEqLvPgAAA"},"images":{"fallback":{"src":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp","srcSet":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/7513b/kubeconNA2023.webp 750w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/317ed/kubeconNA2023.webp 1080w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/kubeconNA2023.webp"}},"fields":{"slug":"/community/events/kubecon-cloudnativecon-north-america-chicago-2023"}},{"id":"6858b2dc-8746-5b50-a350-8fa8b5fdabdc","body":"\n\n<h2>Multiplayer Kubernetes: GitOps with Friends</h2>\n<p>Join Pranav Singh at KCD Chennai 2023 to witness firsthand how Meshery revolutionizes Kubernetes operations, enabling seamless orchestration across multiple environments made possible by GitOps principles and multi-user collaboration..</p>","frontmatter":{"title":"KCD Chennai 2023","type":"Event","technology":null,"product":"MeshMap, Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACQAwCdASoUAAkAPtFUo0uoJKMhsAgBABoJYgCdACHXTgtO3n/AAP70I0R6RU15i/FPhc6hLVo4kuVo0wbzDyEuQ2l7ExJWwAfqQAAA"},"images":{"fallback":{"src":"/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png","srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/89ef0/kcd_chennai.png 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png 962w","sizes":"100vw"},"sources":[{"srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/4cace/kcd_chennai.webp 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/dc547/kcd_chennai.webp 962w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4563409563409564}},"extension":"webp","publicURL":"/static/f2a4ec0abd2656caffece99a892e808a/kcd_chennai.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACQAwCdASoUAAkAPtFUo0uoJKMhsAgBABoJYgCdACHXTgtO3n/AAP70I0R6RU15i/FPhc6hLVo4kuVo0wbzDyEuQ2l7ExJWwAfqQAAA"},"images":{"fallback":{"src":"/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png","srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/89ef0/kcd_chennai.png 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png 962w","sizes":"100vw"},"sources":[{"srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/4cace/kcd_chennai.webp 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/dc547/kcd_chennai.webp 962w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4563409563409564}},"extension":"webp","publicURL":"/static/f2a4ec0abd2656caffece99a892e808a/kcd_chennai.webp"}},"fields":{"slug":"/community/events/kcd-chennai-2023"}},{"id":"87dbbb33-fabe-538f-8478-09aa6b36c6de","body":"\nJoin Lee Calcote and Nate Waddington in the upcoming Maintainer’s Circle special session and explore their insights, and experiences from their mentorship journey within the CNCF.","frontmatter":{"title":"May Maintainer's Circle 2023","type":"Event","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC8ElEQVQozx2P22/bZByGfYUEQmNrkzg+fZ/9OYlzauKc7Byc2EnsFLqmMK10GwOpDEEBbQJEVQZsSGWV0KQOqSAhFVgRpxVuuBkXaP/F/qD9XpRePVev3ueRqv+eQDr+is4dfw3t423I2RTK1SKCYQ/9oIdhGKDX76Ljt9HuNDEc9dEfdJF3bGh6FjpToTEVuZxJ6/M1SIMnf9MLp0cwfjgg3qzANBRySnn43Q7closw8PDKrIck9tFsVdFouvC7bRQcG6bFYAoOyzZJUWVMpmOSWj8dUvaNDWKDDrihErMY2XkbrU4Dg34XJd+FYilw8gbcRhWVagk1twqnWAA3GSzBYQoTipZFnEwhTV9OoKSWYDHt7G2RUG/Usb5xEa9vXkbn4gzZgoVquYhJPEE0iRCNQ6zUKzC4AUsYELYJVVeQJBNIcTwlxVBJ5AW4xSCEAWYZKDk27r23hZ5bAeMGuOAoODlcinsoFvNgXD0TMC0DVs6EaqiIV2NI8WwKRZNhCgYuGIQmQ44CBNev4dGXe1idz7EsOJS1GerdNu60bdQ6DcilAiyun0ksqKWXKIlCkuIkhqqrsGwOvtBXZVxYi2E++AbvPDii3M0dOlfO0dKbW1TZ/4Le374CZWsD51eKsE0dTDAYKw4tzbro7X0AKU6mpOpZCJuTaXOylAwym3N68dExpQ9u4/ndnbNx+vomLf/1My3fv4vzn9+itOfCUmXkywXih7eReXhAgz+PSBpPI0rLKTCukW4o0HUFajFHqdUQF25uk/zhW6S9lpBxdQ7tox1Sb9xAym9BEQzlRfbbl+m53+6T9Ms9DB6fkHT12hUMhj2qu1XUGnXU3BXUKyWqNesQ+59S7WCXandukbv7LrzPPqHu3j7cVgetWhn99VVkvr+LzOl3eOn3b8n/7w9I40n0dDyOMAqHz0ZhiFE4wigaLUih7yPwPAw9D4HvU+B7GPY8DMMRJpMIa5deReXkEOV/fnzmPP4VxSenT/8HweVwClNqlj8AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png","srcSet":"/static/2a4da6359a86759259487a68a8831202/0dee1/Maintainer-Circle.png 750w,\n/static/2a4da6359a86759259487a68a8831202/8beaa/Maintainer-Circle.png 1080w,\n/static/2a4da6359a86759259487a68a8831202/d079a/Maintainer-Circle.png 1366w,\n/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/2a4da6359a86759259487a68a8831202/a66aa/Maintainer-Circle.webp 750w,\n/static/2a4da6359a86759259487a68a8831202/65dd5/Maintainer-Circle.webp 1080w,\n/static/2a4da6359a86759259487a68a8831202/4fad6/Maintainer-Circle.webp 1366w,\n/static/2a4da6359a86759259487a68a8831202/c512e/Maintainer-Circle.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/2a4da6359a86759259487a68a8831202/Maintainer-Circle.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC8ElEQVQozx2P22/bZByGfYUEQmNrkzg+fZ/9OYlzauKc7Byc2EnsFLqmMK10GwOpDEEBbQJEVQZsSGWV0KQOqSAhFVgRpxVuuBkXaP/F/qD9XpRePVev3ueRqv+eQDr+is4dfw3t423I2RTK1SKCYQ/9oIdhGKDX76Ljt9HuNDEc9dEfdJF3bGh6FjpToTEVuZxJ6/M1SIMnf9MLp0cwfjgg3qzANBRySnn43Q7closw8PDKrIck9tFsVdFouvC7bRQcG6bFYAoOyzZJUWVMpmOSWj8dUvaNDWKDDrihErMY2XkbrU4Dg34XJd+FYilw8gbcRhWVagk1twqnWAA3GSzBYQoTipZFnEwhTV9OoKSWYDHt7G2RUG/Usb5xEa9vXkbn4gzZgoVquYhJPEE0iRCNQ6zUKzC4AUsYELYJVVeQJBNIcTwlxVBJ5AW4xSCEAWYZKDk27r23hZ5bAeMGuOAoODlcinsoFvNgXD0TMC0DVs6EaqiIV2NI8WwKRZNhCgYuGIQmQ44CBNev4dGXe1idz7EsOJS1GerdNu60bdQ6DcilAiyun0ksqKWXKIlCkuIkhqqrsGwOvtBXZVxYi2E++AbvPDii3M0dOlfO0dKbW1TZ/4Le374CZWsD51eKsE0dTDAYKw4tzbro7X0AKU6mpOpZCJuTaXOylAwym3N68dExpQ9u4/ndnbNx+vomLf/1My3fv4vzn9+itOfCUmXkywXih7eReXhAgz+PSBpPI0rLKTCukW4o0HUFajFHqdUQF25uk/zhW6S9lpBxdQ7tox1Sb9xAym9BEQzlRfbbl+m53+6T9Ms9DB6fkHT12hUMhj2qu1XUGnXU3BXUKyWqNesQ+59S7WCXandukbv7LrzPPqHu3j7cVgetWhn99VVkvr+LzOl3eOn3b8n/7w9I40n0dDyOMAqHz0ZhiFE4wigaLUih7yPwPAw9D4HvU+B7GPY8DMMRJpMIa5deReXkEOV/fnzmPP4VxSenT/8HweVwClNqlj8AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png","srcSet":"/static/2a4da6359a86759259487a68a8831202/0dee1/Maintainer-Circle.png 750w,\n/static/2a4da6359a86759259487a68a8831202/8beaa/Maintainer-Circle.png 1080w,\n/static/2a4da6359a86759259487a68a8831202/d079a/Maintainer-Circle.png 1366w,\n/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/2a4da6359a86759259487a68a8831202/a66aa/Maintainer-Circle.webp 750w,\n/static/2a4da6359a86759259487a68a8831202/65dd5/Maintainer-Circle.webp 1080w,\n/static/2a4da6359a86759259487a68a8831202/4fad6/Maintainer-Circle.webp 1366w,\n/static/2a4da6359a86759259487a68a8831202/c512e/Maintainer-Circle.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/2a4da6359a86759259487a68a8831202/Maintainer-Circle.png"}},"fields":{"slug":"/community/events/may-maintainers-circle-2023"}},{"id":"4c1fe13b-9122-5393-ab74-397c3f250ce5","body":"\n\n\n<p>\n  Join Layer5 in-person at <a href=\"https://www.meetup.com/docker-bangalore/events/288597531/\">Docker Community Meetup - Bengaluru</a> as\n  we share on the Meshery Docker Extension and how you can manage your cloud native applications using it.\n</p>\n\n\n<h2>Take the Blinders off with Meshery Docker Extension</h2>\n\n\n<p>\nManaging cloud native infrastructure becomes a nightmare with hundreds of distributed systems. Vectors like performance, and metrics are game changers but not precisely interpreted. <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> is here to empower engineers so they can extract more value from their infrastructure.\n</p>\n<p>What will you learn?</p>\n<ul>\n<li>An introduction to basic concepts, architecture diagrams, and general ideas about the functioning of different components of <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link></li>\n<li>Performance Management and Metrics Intro, how to run performance tests, interpret the results, and metrics from Grafana and Prometheus.</li>\n<li>An introduction to service meshes, the concept of meshery adapters, provisioning of service meshes, sample applications and <Link to=\"/projects/service-mesh-interface-conformance\">SMI</Link> conformance tests.</li>\n<li><Link to=\"/cloud-native-management/meshery\">Meshery</Link> Configurations: Application, Patterns, Filters, Pattern configurator, ingestion of K8s YAMLs, Docker-Compose apps, helm charts.</li>\n<li>Introduction to <Link to=\"/cloud-native-management/meshmap\">MeshMap</Link>, the visual topology for your cloud native infrastructure.</li>\n<li><Link to=\"/programs/hacktoberfest\">Hacktoberfest</Link> participation for newcomers in the community, how to get started, open issues and how to engage in the community.</li>\n</ul>\n\n<b>Speakers:</b>\n\n<ul>\n  <li>\n    <Link to=\"/community/members/pranav-singh\">Pranav Singh</Link>\n  </li>\n</ul>\n\n<br />\n","frontmatter":{"title":"Hacktoberfest 2022: Docker Extensions Show-n-Tell","type":"Meetups","technology":null,"product":"Meshery Extensions","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZACsAB7HDon77geC0gAA/rPm3sGheniZTrUvmVzONKE9xhunSUPDjDF4UXsgsZpwmE0xL0R3lr138jrEu5bGEHDhQ9f7pqXCDz97Op2WX3py0n+n3N5aM7wSOsbepml7aIzIqrUGkivmMfIAAA=="},"images":{"fallback":{"src":"/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp","srcSet":"/static/208954253f8b2b5c47ccbe13a4d98acc/fdac4/dockerBengaluru.webp 750w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/0f929/dockerBengaluru.webp 1080w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/fc20e/dockerBengaluru.webp 1366w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5567708333333333}},"extension":"webp","publicURL":"/static/208954253f8b2b5c47ccbe13a4d98acc/dockerBengaluru.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZACsAB7HDon77geC0gAA/rPm3sGheniZTrUvmVzONKE9xhunSUPDjDF4UXsgsZpwmE0xL0R3lr138jrEu5bGEHDhQ9f7pqXCDz97Op2WX3py0n+n3N5aM7wSOsbepml7aIzIqrUGkivmMfIAAA=="},"images":{"fallback":{"src":"/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp","srcSet":"/static/208954253f8b2b5c47ccbe13a4d98acc/fdac4/dockerBengaluru.webp 750w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/0f929/dockerBengaluru.webp 1080w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/fc20e/dockerBengaluru.webp 1366w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5567708333333333}},"extension":"webp","publicURL":"/static/208954253f8b2b5c47ccbe13a4d98acc/dockerBengaluru.webp"}},"fields":{"slug":"/community/events/hacktoberfest-2022-docker-extensions-show-n-tell"}},{"id":"f3a6db1e-0f3d-5750-aa96-8984d759fd27","body":"\n\n\nJoin host Bret Fisher and guests <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> from Layer5 and <Link to=\"/community/members/nic-jackson\">Nic Jackson</Link> from HashiCorp at <a href=\"https://www.linkedin.com/events/servicemeshfordocker-withmesher6977705316406730752/about/\">DevOps and Docker Live Show</a> to see the <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> in-action! Design and deploy your Docker Compose and Kubernetes apps on Docker Desktop or any remote cluster.\n\nThe Meshery extension transforms Docker Desktop into powerful cloud native infrastructure development environment in a box with Kubernetes and service mesh. Learn how to discover and model your cloud native deployments with <Link to=\"/cloud-native-management/meshmap\">MeshMap</Link>. MeshMap enables GitOps integrated, visual composition of your cloud native infrastructure. \n\nCan’t wait to get your hands on Docker Desktop for Meshery in the meantime? Sign up and learn all about the <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> to make the most out of it.\n","frontmatter":{"title":"DevOps and Docker Live Show","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoAAAABXRUJQVlA4IHQAAABwAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJbAC7ABDQ3t6Pi0AA/rp9YKc2gqcg9rSeyinFhrntul+JsT2ClPzd5n1yupRrp4H+db6W3NB/OTUCcgNqiKE6hBlzd7cDJLFpP5N4KJvn6F5PC5cx+o7jogAAAA=="},"images":{"fallback":{"src":"/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp","srcSet":"/static/7cb9216652c98031d9a83ec6805fbec8/a66aa/docker-and-meshery-live-show.webp 750w,\n/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/7cb9216652c98031d9a83ec6805fbec8/docker-and-meshery-live-show.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoAAAABXRUJQVlA4IHQAAABwAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJbAC7ABDQ3t6Pi0AA/rp9YKc2gqcg9rSeyinFhrntul+JsT2ClPzd5n1yupRrp4H+db6W3NB/OTUCcgNqiKE6hBlzd7cDJLFpP5N4KJvn6F5PC5cx+o7jogAAAA=="},"images":{"fallback":{"src":"/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp","srcSet":"/static/7cb9216652c98031d9a83ec6805fbec8/a66aa/docker-and-meshery-live-show.webp 750w,\n/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/7cb9216652c98031d9a83ec6805fbec8/docker-and-meshery-live-show.webp"}},"fields":{"slug":"/community/events/devops-and-docker-live-show"}},{"id":"7362064c-b1c9-5316-8c31-c78d86d3a80f","body":"\n\n\n<p>\n  Join Layer5 in-person at <a href=\"https://www.meetup.com/Docker-Bangalore/events/285342797/\">Docker Developer Community Meetup - Bengaluru</a> as\n  we share on the Meshery Docker Extension and how you can manage your cloud native applications using it.\n</p>\n\n\n<h2>Composing Cloud Native Infrastructure with Docker Desktop and Meshery</h2>\n\n\n<p>\n\nThe Meshery Docker Extension’s ability to import Docker Compose apps, convert them to Kubernetes applications, and deploy them on any service mesh is a powerful enabler for microservices developers, who need to develop, test, and deploy their modern applications in the context of and compatibility with any service mesh. Along with this, the extension can help you to,\n\n<ul>\n<li>Get service mesh support for your Docker Compose apps: Import your Docker Compose apps. Configure and deploy them to Kubernetes and any service mesh.</li>\n<li>Help you with single-click deployment of any service mesh: Supports 10 different service meshes to the fingertips of developers in connection with Docker Desktop’s ability to deliver Kubernetes locally.</li>\n<li>Detection of Kubernetes environments: Scan your kubeconfigs and select your current Kubernetes environment. Switch from one environment to another.</li>\n</ul>\n\nThis talk can help the attendees to improve upon their K8s or Docker deployments as well as help them in managing different service meshes simultaneously. I have a pretty basic knowledge of cloud native stuff having worked with Kubernetes, Docker, Helm, and using some of the service meshes, trying them out for different stuff or applications. I have been using Docker Desktop for the past year and a half. I’m also a maintainer of Meshery and have contributed to several other open source projects.\n\n</p>\n\nSpeakers:\n\n<ul>\n  <li>\n    <Link to=\"/community/members/adithya-krishna\">Aditya Krishna Sharma</Link>\n  </li>\n  <li>Karthik Ravishankar</li>\n</ul>\n\n<br />\n","frontmatter":{"title":"Composing Cloud Native Infrastructure with Docker Desktop and Meshery","type":"Meetups","technology":null,"product":"Meshery Extensions","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRowAAABXRUJQVlA4IIAAAACwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBOgBCdX0ZZKDRXGgAD+kVVK+cYYGtSI2eVCoXTN6L8uXdp3bjwue79NZyzTm55fEyGTpK2kP7BTnsGl/E/IBPURHWhjV7gq3rMFHQKd6+wjuuDGhioNhvLyKngQcQg853NbgAAAAA=="},"images":{"fallback":{"src":"/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp","srcSet":"/static/b7199140cfc400f93faf5c264b9dbcb4/45f0d/dockerBengaluru.webp 750w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/3c63c/dockerBengaluru.webp 1080w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/04e2f/dockerBengaluru.webp 1366w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5583333333333333}},"extension":"webp","publicURL":"/static/b7199140cfc400f93faf5c264b9dbcb4/dockerBengaluru.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRowAAABXRUJQVlA4IIAAAACwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBOgBCdX0ZZKDRXGgAD+kVVK+cYYGtSI2eVCoXTN6L8uXdp3bjwue79NZyzTm55fEyGTpK2kP7BTnsGl/E/IBPURHWhjV7gq3rMFHQKd6+wjuuDGhioNhvLyKngQcQg853NbgAAAAA=="},"images":{"fallback":{"src":"/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp","srcSet":"/static/b7199140cfc400f93faf5c264b9dbcb4/45f0d/dockerBengaluru.webp 750w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/3c63c/dockerBengaluru.webp 1080w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/04e2f/dockerBengaluru.webp 1366w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5583333333333333}},"extension":"webp","publicURL":"/static/b7199140cfc400f93faf5c264b9dbcb4/dockerBengaluru.webp"}},"fields":{"slug":"/community/events/composing-cloud-native-infrastructure-with-docker-desktop-and-meshery"}},{"id":"9930a6c0-5d32-5059-8c2e-d7dbf8185f1d","body":"\n\n\nWith a goal to bring workload identity and attestation to all service meshes, HPE Security Engineering uses the Docker Desktop Extension for Meshery to deploy their service mesh of choice and test the performance of their SPIFFE and SPIRE-based identity solution.\n\nThe Meshery extension transforms Docker Desktop into powerful load generation utility, conveniently enables HPE engineers with the ability to deploy and configure any service mesh with a click of the button and invoke and control load-based performance tests from their desktop.\n\nCan’t wait to get your hands on Docker Desktop for Meshery in the meantime? Sign up for our <Link to=\"/docker-extension-meshery\">beta program</Link> to get early access!\n\n<p>\nRead the recap <Link to=\"/blog/docker/extending-docker-with-meshery-spire-and-istio\">blog</Link> post and find out more about <a href=\"https://layer5.io/docker-extension-meshery\">Docker Extension for Meshery</a>. \n</p>","frontmatter":{"title":"DockerCon 2022: Lighting Talk in a dedicated community room","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnoAAABXRUJQVlA4IG4AAADQBACdASoUAAsAPtFWo0uoJKMhsAgBABoJaACdMoMYPX+z/4DzP8uhaTjalamYAAD+39z6kXh4RPs5dqtegOv3ZmBs7PK8A9ZCXZg/9Xqtx03qAbZmNZB1J3JyoGi/Gv/WFe+f4Vmcup7378AAAA=="},"images":{"fallback":{"src":"/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp","srcSet":"/static/2ca6501625e8174ab27c9f55d9c0cd08/8d8ff/HPE.webp 750w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/fc98a/HPE.webp 1080w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/1ab6d/HPE.webp 1366w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5604166666666667}},"extension":"webp","publicURL":"/static/2ca6501625e8174ab27c9f55d9c0cd08/HPE.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnoAAABXRUJQVlA4IG4AAADQBACdASoUAAsAPtFWo0uoJKMhsAgBABoJaACdMoMYPX+z/4DzP8uhaTjalamYAAD+39z6kXh4RPs5dqtegOv3ZmBs7PK8A9ZCXZg/9Xqtx03qAbZmNZB1J3JyoGi/Gv/WFe+f4Vmcup7378AAAA=="},"images":{"fallback":{"src":"/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp","srcSet":"/static/2ca6501625e8174ab27c9f55d9c0cd08/8d8ff/HPE.webp 750w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/fc98a/HPE.webp 1080w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/1ab6d/HPE.webp 1366w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5604166666666667}},"extension":"webp","publicURL":"/static/2ca6501625e8174ab27c9f55d9c0cd08/HPE.webp"}},"fields":{"slug":"/community/events/dockercon-2022-lighting-talk-in-a-dedicated-community-room"}},{"id":"09db083d-79c0-59f3-8b79-8cb0c25d7633","body":"\n\n\nHashiCorp’s Consul service mesh offers unique functionality offered to its users. Using its visual designer, MeshMap, Meshery facilitates the developers full understanding of Consul’s differientiated capabilities, allowing developer’s to visually configure and deploy Consul-based deployments and their workloads.\n\nThe Meshery extension’s ability to import Docker Compose apps, convert them to Kubernetes applications, and deploy them on Consult service meshes is a powerful enabler for microservices developers, who need to dev, test, and deploy their modern applications in context of and compatibility with Consul service mesh.\n\nCan’t wait to get your hands on Docker Desktop for Meshery in the meantime? Sign up for our <Link to=\"/docker-extension-meshery\">beta program</Link> to get early access!\n\n<p>\nRead the recap <Link to=\"/blog/docker/extending-the-docker-compose-experience-to-service-mesh\">blog</Link> post and find out more about <a href=\"https://layer5.io/docker-extension-meshery\">Docker Extension for Meshery</a>. \n</p>","frontmatter":{"title":"DockerCon 2022: Lighting Talk on the main stage","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJaACdMoGv/gPM//6mqk4rNoAA/t/c+pF4gihmJJjlXBAZp3OCNsjjwXe6L1Kqtd5U9nHotvGQPEXE2M6ZjjMqBgRk4K3H2CE06QlcORybs1mjQAA="},"images":{"fallback":{"src":"/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp","srcSet":"/static/bd9364ba124a438c72a181924156cb71/b9516/Hashicorp.webp 750w,\n/static/bd9364ba124a438c72a181924156cb71/c4814/Hashicorp.webp 1080w,\n/static/bd9364ba124a438c72a181924156cb71/1ab6d/Hashicorp.webp 1366w,\n/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5609375}},"extension":"webp","publicURL":"/static/bd9364ba124a438c72a181924156cb71/Hashicorp.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJaACdMoGv/gPM//6mqk4rNoAA/t/c+pF4gihmJJjlXBAZp3OCNsjjwXe6L1Kqtd5U9nHotvGQPEXE2M6ZjjMqBgRk4K3H2CE06QlcORybs1mjQAA="},"images":{"fallback":{"src":"/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp","srcSet":"/static/bd9364ba124a438c72a181924156cb71/b9516/Hashicorp.webp 750w,\n/static/bd9364ba124a438c72a181924156cb71/c4814/Hashicorp.webp 1080w,\n/static/bd9364ba124a438c72a181924156cb71/1ab6d/Hashicorp.webp 1366w,\n/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5609375}},"extension":"webp","publicURL":"/static/bd9364ba124a438c72a181924156cb71/Hashicorp.webp"}},"fields":{"slug":"/community/events/dockercon-2022-lighting-talk-on-the-main-stage"}},{"id":"65e5d763-2c13-5297-97e0-abf55149b0e2","body":"\n\n\n<p>\n  Join Layer5 at <a href=\"https://www.devconf.info/cz/\">DevConf.cz 2022</a> as\n  we share on our CNCF projects Meshery and Service Mesh Performance. Bring\n  your questions. We have answers. Engage with us in our talks!\n</p>\n\n<br />\n\n<h2>\n  Talk:{\" \"}\n  <a href=\"https://sched.co/siKF\">Measuring Service Mesh Performance 101</a>\n</h2>\n\n<br />\n\n<p>\n\nBenchmarking a service mesh and your workload’s performance is no simple task. Questions arise like:\n\n<ul>\n<li>Which load generator should you use and what signals should you measure?</li>\n<li>How long should I run a test?</li>\n<li>How has the performance of service meshes evolved over time?</li>\n<li>Should I run tests from outside or within my cluster?</li>\n<li>How does the configuration of my service mesh affect performance?</li>\n\n</ul>\n\nThis talk answers these questions by empowering attendees with at-hand tooling for continual evaluation of their service mesh environment and a reflection of how service mesh deployment models affect performance.\n\n</p>\n\nSpeakers:\n\n<ul>\n  <li>\n    Navendu Pottekkat\n  </li>\n</ul>\n\n<br />\n<hr />\n<br />\n\n<h2>\n  Talk:{\" \"}\n  <a href=\"https://sched.co/siEs\">\n    {\" \"}\n    Journey Into the World of Service Meshes and Meshery\n  </a>\n</h2>\n\n<br />\n\n<p>\n\nEngineers adopting microservice architectures are quickly faced with distributed systems challenges and in need of implementing rate limiting, circuit breaking, timeouts, retries, and implementing metrics, logging and tracing into each service is no simple task. Enter the service mesh.\n\n</p>\n\n<h3>Let’s talk about:</h3>\n\n<p>\n\nWhat is a service mesh? Why do you need one?\nWhat types of service meshes are available? How do they contrast?\n\nLearn how Meshery, a CNCF Project, multi-service mesh management plane implements the service mesh specifications, Service Mesh Performance (SMP) and Service Mesh Interface (SMI), to empower users to manage more than 10 service meshes simultaneously.\n\nUnderstand how Meshery uses a catalog of Service Mesh Patterns to provide templates for best practice configurations and how you can design new patterns with the visual topology designer, MeshMap\n\n</p>\n\n<h3>Benefits to the ecosystem:</h3>\n\n<p>\n  Attendees will be empowered with the ability to quickly deploy different\n  service meshes in which they may learn how service meshes function and how\n  each differs from the next, so that they may select the best-fit-for-purpose\n  service mesh for their workloads and their environment. It will be very\n  helpful for experienced service mesh operators seeking to learn best practices\n  through service mesh design patterns.\n</p>\n\nSpeakers:\n\n<ul>\n  <li>\n    <Link to=\"/community/members/adithya-krishna\">Aditya Krishna Sharma</Link>\n  </li>\n  <li>\n    <Link to=\"/community/members/nithish-karthik\">Nithish Karthik</Link>\n  </li>\n</ul>\n","frontmatter":{"title":"DEVCONF 2022","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAADQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJYgAD5GoN60GsAsrRAAAA9mjfMimnxwQT5/XIr5WhMTx1nL1rFzbw4qgN/FpH/xIFT02JUgs/3+TvSpoNGcwIrASVmhV5B05AxI+qwAA="},"images":{"fallback":{"src":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp","srcSet":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp 551w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5862068965517242}},"extension":"webp","publicURL":"/static/9902d5f121e1bb06352939e21ee50f90/devConf22.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAADQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJYgAD5GoN60GsAsrRAAAA9mjfMimnxwQT5/XIr5WhMTx1nL1rFzbw4qgN/FpH/xIFT02JUgs/3+TvSpoNGcwIrASVmhV5B05AxI+qwAA="},"images":{"fallback":{"src":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp","srcSet":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp 551w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5862068965517242}},"extension":"webp","publicURL":"/static/9902d5f121e1bb06352939e21ee50f90/devConf22.webp"}},"fields":{"slug":"/community/events/devconf-2022"}},{"id":"8896e373-f631-58c3-a48a-5c1c5c2f4c9c","body":"\nimport slidesTAG from \"./cncf-tag-network-and-service-mesh-working-group-kubecon-china-2021-lee-calcote-ken-owens_compressed.pdf\";\nimport slidesAdopt from \"./solving-the-service-mesh-adopters-dilemma-anita-ihuman-kubecon-china-2021_compressed.pdf\";\n\n\n<div style={{backgroundColor: \"#E6E6E6\", borderTop: \"1px #D3D3D3 solid\", borderBottom: \"1px #D3D3D3 solid\", padding: \"1rem\", align: \"center\", color: \"#666\", marginBottom: \"1rem\"}}>ENGLISH</div>\n\n<h2>\n  <a href=\"https://kccncosschn21.sched.com/event/pcbq/ji-jie-zhi-ke-zha-mu-solving-the-service-mesh-adopters-dilemma-anita-ihuman-layer5?iframe=no\">\n    Solving the Service Mesh Adopter’s Dilemma\n  </a>\n</h2>\n\n<p>\n  Which service mesh should I use and how do I get started? What are the\n  different service meshes, and how do they contrast? Learn about the\n  functionality of different service meshes and visually manipulate mesh\n  configuration.{\" \"}\n</p>\n\n<p>\n  This talk introduces Meshery, an open source, multi-service mesh management\n  plane that provisions (ten and counting) different service meshes, their\n  sample applications and how it benchmarks the performance of service mesh\n  deployments. Meshery facilitates benchmarking various configuration scenarios\n  of any service mesh, comparison of performance of services (applications) on\n  and off the mesh and across different meshes. It vets mesh and service\n  configurations against deployment best practices. Some of the service mesh\n  projects use Meshery as their performance benchmark tool for each release.\n</p>\n\nSpeakers:\n\n<ul>\n  <li>\n    MeshMate <Link to=\"/community/members/anita-ihuman\">Anita Ihuman</Link>\n  </li>\n</ul>\n\n- <Link to={slidesAdopt}>Presentation Slides</Link>\n\n<h2>\n  <a href=\"https://kccncosschn21.sched.com/event/pcYk/cncf-tag-jie-zhang-re-jie-yuan-cncf-tag-network-and-service-mesh-working-group-lee-calcote-layer5-ed-warnicke-cisco-ken-owens-fiserv?iframe=no\">\n    CNCF TAG Network and Service Mesh Working Group\n  </a>\n</h2>\n\n<p>\n  With the increasing prevalence of microservice-based distributed systems, this\n  is true: the network, as a discipline, has never been so critical in the\n  efficient operation of cloud-native deployments. Network primitives including\n  load balancing, observability, authentication, authorization, policies, rate\n  limiting, QoS, mesh networks, traditional infrastructure bridging, and so on\n  are now being developed and invested by the entire industry, and are the focus\n  of the Service Mesh Working Group withing the CNCF TAG Network.{\" \"}\n</p>\n<p>\n  Listen to our introduction and get an in-depth understanding of the service\n  mesh projects being managed within the working group.\n</p>\n<ul>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Ed Warnicke</li>\n<li>Ken Owens</li>\n</ul>\n\n- <Link to={slidesTAG}>Presentation Slides</Link>\n\n<h2>Meshery Project Office Hours</h2>\n\n<p>Join the Meshery Project Office Hours at KubeCon China 2021 to learn more about the CNCF's latest service mesh project and its maintainers.</p>\n<p>Come and discover why Meshery is the easiest way to get started with 10+ service meshes!</p>\n\nSpeakers:\n<ul>\n<li><Link to=\"/community/members/aisuko-li\">Aisuko Lee</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Navendu Pottekkat</li>\n<li>All Meshery project maintainers</li>\n</ul>\n\n<iframe width=\"50%\" height=\"360px\" style={{marginBottom: \"3rem\"}} loading=\"lazy\" src=\"https://www.youtube.com/embed/GTZamP6r74A\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen>\n</iframe>\n\n<h2>Service Mesh Performance Project Office Hours</h2>\n\n<p>Join the Service Mesh Performance Project Office Hours at KubeCon China 2021 and get introduced to the new standard of cloud native performance characterisation and to its open source maintainers.</p>\n<p>Learn what Service Mesh Performance is and how Meshery's implementation uses it to measure the performance of any service mesh available.</p>\n\n\nSpeakers:\n<ul>\n<li><Link to=\"/community/members/sunku-ranganath\">Sunku Ranganath</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li><Link to=\"/community/members/otto-van-der-schaaf\">Otto Van der Schaaf</Link></li>\n<li><Link to=\"/community/members/nic-jackson\">Nic Jackson</Link></li>\n<li>Xin Huang</li>\n<li>Mrittika Ganguli</li>\n<li>All SMP project maintainers</li>\n</ul>\n\n<iframe width=\"50%\" height=\"360px\" style={{marginBottom: \"3rem\"}} loading=\"lazy\" src=\"https://www.youtube.com/embed/WEu6MorFtM0\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen>\n</iframe>\n\n<div style={{backgroundColor: \"#E6E6E6\", borderTop: \"1px #D3D3D3 solid\", borderBottom: \"1px #D3D3D3 solid\", padding: \"1rem\", align: \"center\", color: \"#666\", marginBottom: \"1rem\"}}>CHINESE</div>\n\n<h2><a href=\"https://kccncosschn21.sched.com/event/pcbq/ji-jie-zhi-ke-zha-mu-solving-the-service-mesh-adopters-dilemma-anita-ihuman-layer5?iframe=no\">致力于解决服务网格使用中碰到的棘手问题</a></h2>\n\n<p>例如：我们应该如何选择并使用服务网格技术以及如何上手？目前存在哪些不同的服务网格产品，互相之间如何进行对比？了解不同的服务网格产品的功能并且可以直观地对服务网格进行配置。 </p>\n<p>本次演讲旨在介绍 Meshery， 一款开源的多服务网格管理平面，它提供了市面上（至少10个）不同的服务网格产品的生命周期管理，示例应用程序以及开箱即用的服务网格的性能基准测试功能。 Meshery有能力在各种不同的场景下对任意的服务网格进行性能基准测试的能力，比较不同应用程序在服务网格内外以及不同服务网格之间的性能。它可以根据服务网格的最佳实践来审查网络和服务配置。越来越多的服务网格项目使用Meshery作为每个版本的性能基准测试工具。 </p>\n\n演讲者：\n<ul>\n<li>MeshMate <Link to=\"/community/members/anita-ihuman\">Anita Ihuman</Link></li>\n</ul>\n\n- <Link to={slidesAdopt}>Presentation Slides</Link>\n\n\n<h2><a href=\"https://kccncosschn21.sched.com/event/pcYk/cncf-tag-jie-zhang-re-jie-yuan-cncf-tag-network-and-service-mesh-working-group-lee-calcote-layer5-ed-warnicke-cisco-ken-owens-fiserv?iframe=no\">CNCF TAG Network and Service Mesh Working Group</a></h2>\n\n<p>随着基于微服务的分布式系统越来越流行，网络作为一门学科，在云原生的高效部署和运行中变得越来越重要已然成为了不可动摇的事实。包括负载均衡，可观察性，鉴权，授权，策略，限速，QoS，Mesh网络，传统基础设施桥接等，正在被整个行业大力发展和投资，这些也是CNCF TAG Network的Service Mesh Working Group的重点。 </p>\n<p>欢迎参加我们的介绍来深入的了解工作组内管理的服务网格项目。 </p>\n\n演讲者:\n<ul>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Ed Warnicke</li>\n<li>Ken Owens</li>\n</ul>\n\n- <Link to={slidesTAG}>Presentation Slides</Link>\n\n\n<h2>Meshery Project Office Hours</h2>\n\n<p>欢迎大家加入到KubeCon 2021 中国站 Meshery office hours，来了解CNCF服务网格项目的最新进展，以及与项目维护者进行在线互动。 </p>\n<p>快来了解为什么Meshery是开始使用10+个服务网格的最简单方法！</p>\n\n\n演讲者:\n<ul>\n<li><Link to=\"/community/members/aisuko-li\">Aisuko Lee</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Navendu Pottekkat</li>\n<li>All Meshery project maintainers</li>\n</ul>\n\n<h2>Service Mesh Performance Project Office Hours</h2>\n\n<p>欢迎大家加入到KubeCon 2021 中国站 Service Mesh Performance Project Office Hours，来了解云原生性能表征的新标准的资讯，以及与项目维护者进行在线互动。 </p>\n<p>欢迎大家来了解什么是服务网格性能以及Meshery如何实现衡量任何可用服务网格的性能。 </p>\n\n\nSpeakers:\n<ul>\n<li><Link to=\"/community/members/sunku-ranganath\">Sunku Ranganath</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li><Link to=\"/community/members/otto-van-der-schaaf\">Otto Van der Schaaf</Link></li>\n<li><Link to=\"/community/members/nic-jackson\">Nic Jackson</Link></li>\n<li>Xin Huang</li>\n<li>Mrittika Ganguli</li>\n<li>All SMP project maintainers</li>\n</ul>\n<br />\n","frontmatter":{"title":"KubeCon China 2021","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAACQAwCdASoUAAcAPtFUo0uoJKMhsAgBABoJQBdgA6Z8ZYa79/cAAP6g7l8sttdWABhvdu7bcIgenjoppWS3AkrVm23k1zOAokP6eFgz3VFPHAWsoo9qAAAA"},"images":{"fallback":{"src":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp","srcSet":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/1aa35/kubeconchina2021.webp 750w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/f13f2/kubeconchina2021.webp 1080w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/146ff/kubeconchina2021.webp 1366w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.33854166666666663}},"extension":"webp","publicURL":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/kubeconchina2021.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAACQAwCdASoUAAcAPtFUo0uoJKMhsAgBABoJQBdgA6Z8ZYa79/cAAP6g7l8sttdWABhvdu7bcIgenjoppWS3AkrVm23k1zOAokP6eFgz3VFPHAWsoo9qAAAA"},"images":{"fallback":{"src":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp","srcSet":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/1aa35/kubeconchina2021.webp 750w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/f13f2/kubeconchina2021.webp 1080w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/146ff/kubeconchina2021.webp 1366w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.33854166666666663}},"extension":"webp","publicURL":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/kubeconchina2021.webp"}},"fields":{"slug":"/community/events/kubecon-china-2021"}},{"id":"a2ffc3d6-0e4c-5913-b01c-9d7c340fd1bc","body":"\nimport slidesAdopt from \"./layer5- solving-the-service-mesh-adopters-dilemma_compressed.pdf\";\n\nJoin the Service Mesh Performance project office hours at KubeCon North America 2021 and get introduced to the new standard of cloud native performance charaterization and to its open source maintainers.\n\nLearn what Service Mesh Performance is and how Meshery's implementation uses it to measure the performance of any service mesh available.\n<ul><li><Link to={slidesAdopt}>Presentation Slides</Link></li></ul>\n","frontmatter":{"title":"Project Office Hours: Service Mesh Performance at KubeCon NA 2021","type":"Event","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZAC7ACB1gxjlB4J8kAD+12/uoBV3jnVQwKZeFvGBFjyuL9VL0oeYfflbUHdMO54lVt9n+TfniOK4/k26cgblHyNG3Ag+PGU5IQosw1Lm4U1YePmgS738A92zgAAA"},"images":{"fallback":{"src":"/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp","srcSet":"/static/e4154fb9ffdc18d732c957f93c64f070/7513b/KubeCon-2021.webp 750w,\n/static/e4154fb9ffdc18d732c957f93c64f070/317ed/KubeCon-2021.webp 1080w,\n/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/e4154fb9ffdc18d732c957f93c64f070/KubeCon-2021.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZAC7ACB1gxjlB4J8kAD+12/uoBV3jnVQwKZeFvGBFjyuL9VL0oeYfflbUHdMO54lVt9n+TfniOK4/k26cgblHyNG3Ag+PGU5IQosw1Lm4U1YePmgS738A92zgAAA"},"images":{"fallback":{"src":"/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp","srcSet":"/static/e4154fb9ffdc18d732c957f93c64f070/7513b/KubeCon-2021.webp 750w,\n/static/e4154fb9ffdc18d732c957f93c64f070/317ed/KubeCon-2021.webp 1080w,\n/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/e4154fb9ffdc18d732c957f93c64f070/KubeCon-2021.webp"}},"fields":{"slug":"/community/events/project-office-hours-service-mesh-performance-at-kubecon-na-2021"}},{"id":"bab37a47-b96f-5533-8edc-afc709ade99d","body":"Join the Meshery project office hours at KubeCon North America 2021 and get introduced to the cloud native management plane and to its open source maintainers.\n\nCome see why Meshery is one of the CNCF's hottest, new projects!\n","frontmatter":{"title":"Meet the Meshery Maintainers at KubeCon NA 2021","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZAC7ACB1gxjlB4J8kAD+12/uoBV3jnVQwKZeFvGBFjyuL9VL0oeYfflbUHdMO54lVt9n+TfniOK4/k26cgblHyNG3Ag+PGU5IQosw1Lm4U1YePmgS738A92zgAAA"},"images":{"fallback":{"src":"/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp","srcSet":"/static/e4154fb9ffdc18d732c957f93c64f070/7513b/KubeCon-2021.webp 750w,\n/static/e4154fb9ffdc18d732c957f93c64f070/317ed/KubeCon-2021.webp 1080w,\n/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/e4154fb9ffdc18d732c957f93c64f070/KubeCon-2021.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZAC7ACB1gxjlB4J8kAD+12/uoBV3jnVQwKZeFvGBFjyuL9VL0oeYfflbUHdMO54lVt9n+TfniOK4/k26cgblHyNG3Ag+PGU5IQosw1Lm4U1YePmgS738A92zgAAA"},"images":{"fallback":{"src":"/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp","srcSet":"/static/e4154fb9ffdc18d732c957f93c64f070/7513b/KubeCon-2021.webp 750w,\n/static/e4154fb9ffdc18d732c957f93c64f070/317ed/KubeCon-2021.webp 1080w,\n/static/e4154fb9ffdc18d732c957f93c64f070/31cc3/KubeCon-2021.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/e4154fb9ffdc18d732c957f93c64f070/KubeCon-2021.webp"}},"fields":{"slug":"/community/events/meet-the-meshery-maintainers-at-kubecon-na-2021"}},{"id":"d350304d-fb07-5152-8688-987b4e324b2f","body":"\nJoin Layer5 at ServiceMeshCon North America 2021. <a href=\"https://events.linuxfoundation.org/servicemeshcon-north-america\">ServiceMeshCon</a> is a vendor-neutral conference on service mesh technologies. Topics include getting started with and adopting a mesh, lessons learned from production deployments, and technical sessions from service mesh maintainers.\n\n<h3>Service Mesh Patterns by the Book</h3>\n<p>\n  Infrastructure diversity is a reality for many organizations. It’s predicted\n  that by 2022, 90% of all apps will feature microservices architectures. A huge\n  range of microservice patterns drives a world of multiple service meshes. As\n  various service meshes have proliferated infrastructures, service mesh\n  patterns and abstractions have emerged. We will break down 60 service mesh\n  patterns into different categories of use, demonstrating and examining a\n  select few using Meshery for deeper review of their problems they solve,\n  discussing caveats, and highlighting anti-patterns.{\" \"}\n</p>\n\n<p>\n  The patterns discussed are being published in{\" \"}\n  <a href=\"/books/service-mesh-patterns\">Service Mesh Patterns</a> (O’Reilly) by\n  Lee Calcote and Nic Jackson.\n</p>\n","frontmatter":{"title":"ServiceMeshCon NA 2021","type":"Event","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIAAABXRUJQVlA4IFYAAACQAwCdASoUAAYAPtFUo0uoJKMhsAgBABoJZACsLwAA3n4enuVAAP7LblyW6N0HCCw2ET3vDcCQgIIUI2XrO/rD7bX4TWB6eKEBbMPuBIJqUiUQFgAAAA=="},"images":{"fallback":{"src":"/static/194251e6e380682e04028df900dacd5f/20e39/servicemeshcon.webp","srcSet":"/static/194251e6e380682e04028df900dacd5f/14783/servicemeshcon.webp 750w,\n/static/194251e6e380682e04028df900dacd5f/0a188/servicemeshcon.webp 1080w,\n/static/194251e6e380682e04028df900dacd5f/a508b/servicemeshcon.webp 1366w,\n/static/194251e6e380682e04028df900dacd5f/20e39/servicemeshcon.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.31875}},"extension":"webp","publicURL":"/static/194251e6e380682e04028df900dacd5f/servicemeshcon.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIAAABXRUJQVlA4IFYAAACQAwCdASoUAAYAPtFUo0uoJKMhsAgBABoJZACsLwAA3n4enuVAAP7LblyW6N0HCCw2ET3vDcCQgIIUI2XrO/rD7bX4TWB6eKEBbMPuBIJqUiUQFgAAAA=="},"images":{"fallback":{"src":"/static/194251e6e380682e04028df900dacd5f/20e39/servicemeshcon.webp","srcSet":"/static/194251e6e380682e04028df900dacd5f/14783/servicemeshcon.webp 750w,\n/static/194251e6e380682e04028df900dacd5f/0a188/servicemeshcon.webp 1080w,\n/static/194251e6e380682e04028df900dacd5f/a508b/servicemeshcon.webp 1366w,\n/static/194251e6e380682e04028df900dacd5f/20e39/servicemeshcon.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.31875}},"extension":"webp","publicURL":"/static/194251e6e380682e04028df900dacd5f/servicemeshcon.webp"}},"fields":{"slug":"/community/events/servicemeshcon-na-2021"}},{"id":"d866c476-ba85-5624-931f-5e49a4c8a790","body":"<p>In this workshop an introduction to Meshery and what a Service Mesh is will be addressed. Then the entire flow will be shown to contribute to various Meshery repositories such as CI workflows, e2e Testing with Cypress, Documentation, Translations, among others.</p>\n","frontmatter":{"title":"CCOSS Meshery Workshop 2021","type":"Workshop","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAe3G7RGAY//EABoQAAICAwAAAAAAAAAAAAAAAAABAhEDEzH/2gAIAQEAAQUCtRITKQuGVvZ//8QAGBEAAgMAAAAAAAAAAAAAAAAAAAEREyH/2gAIAQMBAT8Ba0sg/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAES/9oACAECAQE/AWY//8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEgISL/2gAIAQEABj8CNQdn/8QAHBABAAEEAwAAAAAAAAAAAAAAAQAQESExQWGR/9oACAEBAAE/IUYaOLETNz1iLN0mqggF7P/aAAwDAQACAAMAAAAQFP8A/8QAFxEBAQEBAAAAAAAAAAAAAAAAEQEAwf/aAAgBAwEBPxBE63R3f//EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQIBAT8QTqLbD//EABsQAQACAgMAAAAAAAAAAAAAAAEAETFRQZHR/9oACAEBAAE/EGOOAIh1LgVfB+YlSK7iV1bqW7hQIVQLRP/Z"},"images":{"fallback":{"src":"/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg","srcSet":"/static/efaab4bb63b1958f85345953b12601b4/5f965/ccoss.jpg 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg 800w","sizes":"100vw"},"sources":[{"srcSet":"/static/efaab4bb63b1958f85345953b12601b4/ee7ce/ccoss.webp 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e7773/ccoss.webp 800w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}},"extension":"jpeg","publicURL":"/static/efaab4bb63b1958f85345953b12601b4/ccoss.jpeg"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAe3G7RGAY//EABoQAAICAwAAAAAAAAAAAAAAAAABAhEDEzH/2gAIAQEAAQUCtRITKQuGVvZ//8QAGBEAAgMAAAAAAAAAAAAAAAAAAAEREyH/2gAIAQMBAT8Ba0sg/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAES/9oACAECAQE/AWY//8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEgISL/2gAIAQEABj8CNQdn/8QAHBABAAEEAwAAAAAAAAAAAAAAAQAQESExQWGR/9oACAEBAAE/IUYaOLETNz1iLN0mqggF7P/aAAwDAQACAAMAAAAQFP8A/8QAFxEBAQEBAAAAAAAAAAAAAAAAEQEAwf/aAAgBAwEBPxBE63R3f//EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQIBAT8QTqLbD//EABsQAQACAgMAAAAAAAAAAAAAAAEAETFRQZHR/9oACAEBAAE/EGOOAIh1LgVfB+YlSK7iV1bqW7hQIVQLRP/Z"},"images":{"fallback":{"src":"/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg","srcSet":"/static/efaab4bb63b1958f85345953b12601b4/5f965/ccoss.jpg 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg 800w","sizes":"100vw"},"sources":[{"srcSet":"/static/efaab4bb63b1958f85345953b12601b4/ee7ce/ccoss.webp 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e7773/ccoss.webp 800w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}},"extension":"jpeg","publicURL":"/static/efaab4bb63b1958f85345953b12601b4/ccoss.jpeg"}},"fields":{"slug":"/community/events/ccoss-meshery-workshop-2021"}},{"id":"4c56628f-1269-5240-b562-8abc0bdabe53","body":"\n\nimport { BufProtocol } from \"./BufProtocol.style\";\n\nimport Problems from \"./problems.webp\";\n\n<BlogWrapper>\n<BufProtocol>\n\n\n<div className=\"intro\" style={{textAlign: \"center\", margin: \"2rem 4rem\"}}><p>At Layer5, we are continuously evaluating new technologies and incorporating them into our open source projects. Buf is one of those projects. This post presents an overview of Buf.</p></div>\n\n\n## What is Buf?\n\n<p>A tool to make Protobuf reliable and easy to use for service owners and clients, while keeping it the obvious choice on the technical merits.\nOur organization should not have to reinvent the wheel to create, maintain, and consume Protobuf APIs efficiently and effectively. It will handle our Protobuf management strategy for us, so we can focus on what matters.</p>\n\n<div className=\"fact\">Learn more about Buf Protocol, visit <a href=\"https://buf.build\" rel=\"nofollow\">Buf Protocol</a> or their documentation at <a href=\"https://docs.buf.build/\" rel=\"nofollow\">Buf Protocol Docs</a></div>\n\n<img className=\"problem-image\" src={Problems} />\n\n## Features \n\n- Automatic file discovery. \n- Selectable configuration - 40 lint checkers and 54 breaking checkers\n- Selectable error output - `file:line:col:message`\n- Check anything from anywhere - proto files, tar, git, pre-built images or file descriptors.\n- [Speed](https://docs.buf.build/tour-8/) - Its internal compiler is super fast (approx. 4x then Protoc)\n- Can use buf as a protoc plugin instead of using it as a standalone tool.\n\n## Buf CLI\n\nBuf attempts to simplify your Protocol Buffers workflow using the Buf CLI and protoc plugins. The Buf CLI currently provides:\n\n- A linter that enforces good API design choices and structure.\n- A breaking change detector that enforces compatibility at the source code level or wire level.\n- A generator that invokes your protoc plugins based on a configurable template. A protoc replacement that uses Buf's newly-developed high performance Protobuf compiler.\n- A configurable file builder that produces Images, our extension of FileDescriptorSets.\n\n## Comparison Between Protobuf and Buf\nLayer5 projects currently use protoc as the tool for building their protobuf defintions. The following are some considerations made while determining whether to use Buf.\n\n- Protobuf is not as widely adopted as JSON.\n- API Structure \n  - No standards enforcement\n  - Inconsistency can arise across an organization's Protobuf APIs,   \n  - Design decisions can be made that can affect your API's future iterability.\n- Backward Compatibility\n- Stub distribution\n- Tooling\n\n<p>Buf aims to solve the above problems and it's long-term goal is to enable schema-driven development: A future where APIs are defined consistently, in a way that service owners and us can depend on</p>\n\n## Roadmap to Adopting Buf\nIn consideration of the use of Buf, we would adopt it in phases, starting with the following ares of integration.\n\n- **API Structure  Enforcements**\n  - Linter solves this issue by enforcing standards. \n  - Also, we don’t need to use Buf as a standalone tool we can just use linter as plugins.\n\n\n- **Backward Compatibility**\n  - It will check for different things that can cause breaking change.\n  - For example, type change.\n\n<div className=\"intro\"><p>If these topics excite you and you want to explore more <a href=\"/resources\">cloud native technolgies</a>, come and say \"Hi\" on the community <a href=\"http://slack.layer5.io\">Slack</a> and you are sure to be warmly welcomed. <span>😀</span></p></div>\n\n</BufProtocol>\n</BlogWrapper>","frontmatter":{"title":"Rethinking Protocol Buffers with Buf","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnAAAABXRUJQVlA4IGQAAACQAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJQBOgA+Tk8aehcycAAP7ATvlxq/O19EhA9XrL+2Tj+Q03SbYzgyfckaPxQws5+ikk5FoYgfquExjejLHTZGOL/rxz2A413CEfQgAA"},"images":{"fallback":{"src":"/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp","srcSet":"/static/f9bfdf0ed6d91ee82471bb9f41472183/b9516/buf-protocol.webp 750w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a327/buf-protocol.webp 1080w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a401/buf-protocol.webp 1366w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5619791666666667}},"extension":"webp","publicURL":"/static/f9bfdf0ed6d91ee82471bb9f41472183/buf-protocol.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnAAAABXRUJQVlA4IGQAAACQAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJQBOgA+Tk8aehcycAAP7ATvlxq/O19EhA9XrL+2Tj+Q03SbYzgyfckaPxQws5+ikk5FoYgfquExjejLHTZGOL/rxz2A413CEfQgAA"},"images":{"fallback":{"src":"/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp","srcSet":"/static/f9bfdf0ed6d91ee82471bb9f41472183/b9516/buf-protocol.webp 750w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a327/buf-protocol.webp 1080w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a401/buf-protocol.webp 1366w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5619791666666667}},"extension":"webp","publicURL":"/static/f9bfdf0ed6d91ee82471bb9f41472183/buf-protocol.webp"}},"fields":{"slug":"/blog/cloud-native/rethinking-protocol-buffers-with-buf"}},{"id":"1a43ad33-34a1-5314-b643-eb8266dfcd3b","body":"Join Layer5 at the inaugural Istio conference on Monday, Feb. 22nd to Friday, Feb. 26th. <a href=\"https://events.istio.io/istiocon-2021/about/\">IstioCon</a> is a 100% virtual event that is designed to connect community members across the globe with Istio and the Istio ecosystem.\n\nLayer5 will kickoff the event with our renowned service mesh workshop, featuring <a href=\"/cloud-native-management/meshery\">Meshery</a>, the service mesh manager. Attend our workshop to help you get started with managing your own service mesh!\n\n<h4>Using Istio</h4>\n<br />\n<p>\nAs the third phase in your microservices journey, service meshes provide a substrate of secure connectivity, uniform visibility and granular control over service requests. Service meshes have quickly entered the cloud native landscape filling unmet service-level needs. Organizations that have adopted containers and who are running a handful or more of microservices find tools to provide observability, control and security lacking. Operating at layer 5, service meshes promise much value. This live training walks you through a series of hands-on labs, introducing you to each and every aspect of the popular service mesh - Istio. During this workshop you will gain hands-on experience as we walk through deploying Istio alongside microservices running in Kubernetes.\n</p>\nYou will learn to:\n\n<ul>\n<li>Configure and operate Istio in context of an example workloads and their common use cases</li>\n<li>Manage traffic through load balancing and resilient communications</li>\n<li>Enforce policies and rate limiting</li>\n<li>Be confident with ongoing management of Istio</li>\n<li>Understand WebAssembly filters for Envoy and deploy a custom filter</li>\n</ul>\n<h4 style={{marginBottom: \"1.25rem\"}}><a href=\"https://github.com/layer5io/advanced-istio-service-mesh-workshop\">Workshop Labs</a></h4>\n\nSee link for self-paced study.\n\n<h4 style={{marginBottom: \"1.25rem\"}}><a href=\"https://calcotestudios.com/talks/decks/slides-istiocon-2021-using-istio.html\">Workshop Slides</a></h4>\n\n<iframe width=\"50%\" height=\"400px;\" src=\"https://calcotestudios.com/talks/decks/slides-istiocon-2021-using-istio.html\"></iframe>\n<br />\n<br />\n<h4 style={{marginBottom: \"1.25rem\"}}>Workshop Recording</h4>\n\n<iframe width=\"50%\" src=\"https://www.youtube.com/embed/T1Kwh3SRAXQ\" loading=\"lazy\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" style={{minHeight: \"315px\", minWidth: \"280px\", margin: \"auto\", textAlign: \"center\"}} allowFullScreen></iframe>\n<br />\n<br />","frontmatter":{"title":"IstioCon 2021","type":"Event","technology":"WebAssembly","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/88e79f3aa90a7116b0cc0fe4bf81160a/istiocon-logo.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/88e79f3aa90a7116b0cc0fe4bf81160a/istiocon-logo.svg"}},"fields":{"slug":"/community/events/istiocon-2021"}},{"id":"76416647-ddf0-5d96-89f4-74fd2427ea25","body":"Organizations that have adopted containers and are running a handful (or more) of microservices often find tools to provide observability, control, and security lacking. Service meshes—the third phase in the microservices journey—have quickly entered the cloud native landscape, filling unmet service-level needs and providing a substrate of secure connectivity, uniform visibility, and granular control over service requests. Operating at layer 5, service meshes offer great value.\n\nLee Calcote walks you through advanced service mesh concepts and each and every aspect of the open source service mesh Istio. Over three hours, you’ll gain hands-on experience with this popular tool as you learn how to deploy Istio alongside microservices running in Kubernetes.\n\n### What you'll learn-and how you can apply it\n\n#### By the end of this live online course, you’ll understand:\n\n- How to manage traffic through load balancing and resilient communications\n- How to enforce policies and rate limiting\n- Istio's methods for managing telemetry, monitoring, and reporting\n- Approaches to canary deployments and securing communication with Istio\n\n### And you’ll be able to:\n\n- Configure and operate Istio in context of an example workloads and their common use cases\n- Take the third step in your cloud native journey with an initial deployment of a service mesh\n\n### This training course is for you because...\n\n- You’re an operator who wants uniform observability irrespective of the different languages and libraries that run your services.\n- You’re a developer who wants to affect application behavior without code changes.\n- You want to become a cloud native architect or level up as one.\n\n#### Prerequisites\n\n- Working knowledge of Docker, Kubernetes, and kubectl.\n\n#### A locally running instance of:\n\n- Docker (Docker Desktop for Mac or Windows, or Docker for Linux)\n- Kubernetes (using Docker Desktop or Minikube for Mac, Windows, or Linux)\n- [Meshery](/cloud-native-management/meshery) (Mac, Windows or Linux)\n\n#### Recommended preparation:\n\n- Take Introduction to Kubernetes (live online training course with Sébastien Goasguen)\n- If you need help installing Kubernetes, read “Installing Kubernetes Locally Using Minikube” (short section in “Chapter 3: Deploying a Kubernetes Cluster” in Kubernetes: Up and Running)\n\n#### Recommended follow-up:\n\n- Read [The Enterprise Path to Service Mesh Architectures](/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures) (report)\n- Read [Istio: Up and Running](/learn/service-mesh-books/istio-up-and-running)\n","frontmatter":{"title":"Introduction to Istio","type":"Workshop","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABwAwCdASoUAAUAPtFUpEuoJKOhsAgBABoJYwCdABXtBUsf90QA9r4yXDIkZSS4/98YaUNRVuJ1ibcvxJnpUM9NKvQmXrHHCXnv/ERTtZ/U8JmEi7E0yC0qUWTh3cNkYAA="},"images":{"fallback":{"src":"/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp","srcSet":"/static/57f2e0891f16e4a8c3d4cb537c154452/5f043/istio-intro.webp 750w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/d488d/istio-intro.webp 1080w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/57f2e0891f16e4a8c3d4cb537c154452/istio-intro.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABwAwCdASoUAAUAPtFUpEuoJKOhsAgBABoJYwCdABXtBUsf90QA9r4yXDIkZSS4/98YaUNRVuJ1ibcvxJnpUM9NKvQmXrHHCXnv/ERTtZ/U8JmEi7E0yC0qUWTh3cNkYAA="},"images":{"fallback":{"src":"/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp","srcSet":"/static/57f2e0891f16e4a8c3d4cb537c154452/5f043/istio-intro.webp 750w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/d488d/istio-intro.webp 1080w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/57f2e0891f16e4a8c3d4cb537c154452/istio-intro.webp"}},"fields":{"slug":"/community/events/introduction-to-istio"}},{"id":"f773d288-9c5e-5457-a811-44f458f33c3f","body":"Organizations that have adopted containers and are running a handful (or more) of microservices often find tools to provide observability, control, and security lacking. Service meshes—the third phase in the microservices journey—have quickly entered the cloud native landscape, filling unmet service-level needs and providing a substrate of secure connectivity, uniform visibility, and granular control over service requests. Operating at layer 5, service meshes offer great value.\n\nLee Calcote walks you through advanced service mesh concepts and each and every aspect of the open source service mesh Istio. Over three hours, you’ll gain hands-on experience with this popular tool as you learn how to deploy Istio alongside microservices running in Kubernetes.\n\n### What you'll learn-and how you can apply it\n\n#### By the end of this live online course, you’ll understand:\n\n- Istio's methods for managing telemetry, monitoring, and reporting\n- Advanced traffic management scenarios\n- Approaches to canary deployments and securing communication with Istio\n\n#### And you’ll be able to:\n\n- Configure and operate Istio in context of an example workloads and their common use cases\n- Manage traffic through load balancing and resilient communications\n- Enforce policies and rate limiting\n- Be confident in the third step of your cloud native journey with ongoing management of your service mesh\n\n### This training course is for you because...\n\n- You’re an operator who wants uniform observability irrespective of the different languages and libraries that run your services.\n- You’re a developer who wants to affect application behavior without code changes.\n- You want to become a cloud native architect or level up as one.\n\n#### Prerequisites\n\n- A working knowledge of Istio and Kubernetes\n- Familiarity with Docker Desktop, Minikube, or kind\n- A computer with Docker and Meshery installed locally\n- Access to local or remote Kubernetes cluster of any size, with cluster admin privileges (Either of these two local single-node clusters will work: Docker Desktop or Minikube.)\n\n#### Recommended preparation\n\n- Take Introduction to Istio (live online training course with Lee Calcote)\n- If you need to brush up on Kubernetes, take Introduction to Kubernetes (live online training course with Sébastien Goasguen) or read Kubernetes Cookbook (book) or Kubernetes: Up and Running (book)\n\n#### Recommended follow-up\n\n- Read The Enterprise Path to Service Mesh Architectures (report)\n- Read Istio: Up and Running (early release book)\n","frontmatter":{"title":"Advanced Istio","type":"Workshop","technology":null,"product":null,"mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmgAAABXRUJQVlA4IFwAAADQAwCdASoUAAUAPtFUo0uoJKMhsAgBABoJZACdMoADTFB/LrchbKgA/tuDjRifiEyjK7blIB54Z22YjegTggP9B94px3symZbFfM+eWLNXXz01P+gnrmrZsIAAAA=="},"images":{"fallback":{"src":"/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp","srcSet":"/static/0b49520092152a93c81799540f1a1dd8/5f043/istio.webp 750w,\n/static/0b49520092152a93c81799540f1a1dd8/d488d/istio.webp 1080w,\n/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/0b49520092152a93c81799540f1a1dd8/istio.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmgAAABXRUJQVlA4IFwAAADQAwCdASoUAAUAPtFUo0uoJKMhsAgBABoJZACdMoADTFB/LrchbKgA/tuDjRifiEyjK7blIB54Z22YjegTggP9B94px3symZbFfM+eWLNXXz01P+gnrmrZsIAAAA=="},"images":{"fallback":{"src":"/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp","srcSet":"/static/0b49520092152a93c81799540f1a1dd8/5f043/istio.webp 750w,\n/static/0b49520092152a93c81799540f1a1dd8/d488d/istio.webp 1080w,\n/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/0b49520092152a93c81799540f1a1dd8/istio.webp"}},"fields":{"slug":"/community/events/advanced-istio"}},{"id":"6994d091-d275-5efc-8b71-7b9ef114d9aa","body":"","frontmatter":{"title":"CCOSS 2020","type":"Workshop","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/307ef318ef302830a3d992ad903e95e0/ccoss-logo.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/307ef318ef302830a3d992ad903e95e0/ccoss-logo.svg"}},"fields":{"slug":"/community/events/ccoss-2020"}},{"id":"a3067699-bf45-580d-88f0-3c5da00e522e","body":"","frontmatter":{"title":"O'Reilly OSCON 2020","type":"Workshop","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRqgAAABXRUJQVlA4IJwAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoADQn9+voPUk/5eAAD+n0Lrn1eo/SOFlETnXHT8EM8ECIsMVg/ZpgyvP3zhijTAvsAQhf7L3/COxUwKDNv/yW32Gia9CSw/4bMi5cnt/dpZ/ob+qp5VK6U/VQWpbaS0odt9AQiJNZGUIR+DE/JKoNOG4rcwZ4HT8TVhtFQAAAA="},"images":{"fallback":{"src":"/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp","srcSet":"/static/eb1bb6900c1b8d30dd4f66c821c31500/06f57/oscon.webp 750w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b5fe1/oscon.webp 1080w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/8cf68/oscon.webp 1366w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.37604166666666666}},"extension":"webp","publicURL":"/static/eb1bb6900c1b8d30dd4f66c821c31500/oscon.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRqgAAABXRUJQVlA4IJwAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoADQn9+voPUk/5eAAD+n0Lrn1eo/SOFlETnXHT8EM8ECIsMVg/ZpgyvP3zhijTAvsAQhf7L3/COxUwKDNv/yW32Gia9CSw/4bMi5cnt/dpZ/ob+qp5VK6U/VQWpbaS0odt9AQiJNZGUIR+DE/JKoNOG4rcwZ4HT8TVhtFQAAAA="},"images":{"fallback":{"src":"/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp","srcSet":"/static/eb1bb6900c1b8d30dd4f66c821c31500/06f57/oscon.webp 750w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b5fe1/oscon.webp 1080w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/8cf68/oscon.webp 1366w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.37604166666666666}},"extension":"webp","publicURL":"/static/eb1bb6900c1b8d30dd4f66c821c31500/oscon.webp"}},"fields":{"slug":"/community/events/oreilly-oscon-2020"}},{"id":"9cb48195-603d-5b01-849a-4ffc7518c1dc","body":"","frontmatter":{"title":"O'Reilly Infrastructure & Ops","type":"Workshop","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAABQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoRwGQAAblgzKfUnzAnAAP7j0LFfp+Dxs1Fkmx6VbWq5XYGM85oRqhXgtUJ7d+4hf2tMgUgqu8nuk2e7a0cbIH68Lgj+Kp1AzQif21wKFpUZmIQCYLUliqATtiP1Dc29JHogAAAA"},"images":{"fallback":{"src":"/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp","srcSet":"/static/168951be11a3367dbe384088996f4c66/93b8c/infra-ops.webp 750w,\n/static/168951be11a3367dbe384088996f4c66/58fe6/infra-ops.webp 1080w,\n/static/168951be11a3367dbe384088996f4c66/da0ea/infra-ops.webp 1366w,\n/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3776041666666667}},"extension":"webp","publicURL":"/static/168951be11a3367dbe384088996f4c66/infra-ops.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAABQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoRwGQAAblgzKfUnzAnAAP7j0LFfp+Dxs1Fkmx6VbWq5XYGM85oRqhXgtUJ7d+4hf2tMgUgqu8nuk2e7a0cbIH68Lgj+Kp1AzQif21wKFpUZmIQCYLUliqATtiP1Dc29JHogAAAA"},"images":{"fallback":{"src":"/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp","srcSet":"/static/168951be11a3367dbe384088996f4c66/93b8c/infra-ops.webp 750w,\n/static/168951be11a3367dbe384088996f4c66/58fe6/infra-ops.webp 1080w,\n/static/168951be11a3367dbe384088996f4c66/da0ea/infra-ops.webp 1366w,\n/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3776041666666667}},"extension":"webp","publicURL":"/static/168951be11a3367dbe384088996f4c66/infra-ops.webp"}},"fields":{"slug":"/community/events/oreilly-infrastructure-ops"}},{"id":"20288afa-9686-554d-a063-482a02e70cc4","body":"Too lazy to implement multi-tenancy? Don't have time to implement per user rate limiting in your application's endpoints? In this talk, we will examine how to let application infrastructure concerns melt off your Dockerized workloads and have your infrastructure implement multi-tenancy on your behalf.\n\nLearn how to use Docker Desktop and Kubernetes as your development platforms of choice in combination with Meshery, the cloud native management plane, to easily deploy a service mesh. Using Consul and Envoy's latest capabilities, see how WASM can be used to move user authentication and authorization from your application to the infrastructure.","frontmatter":{"title":"DockerCon LIVE","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoQAAABXRUJQVlA4IHgAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdH8GJ/gPNEbtVx2W1tm4OgAD+8YB+o/JPMBUszhbX2XgfyYa480xd/nGXIU7QxsbxU+kloDLJf6a9ZPl5uX0PNims/4PMDglbDuYeHIVMNVVNctCcxMDaj6npYAA="},"images":{"fallback":{"src":"/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp","srcSet":"/static/9497b4aad63f55a6d041b550a7c9b01a/a66aa/dockerCon2020.webp 750w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/65dd5/dockerCon2020.webp 1080w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/4fad6/dockerCon2020.webp 1366w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/9497b4aad63f55a6d041b550a7c9b01a/dockerCon2020.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoQAAABXRUJQVlA4IHgAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdH8GJ/gPNEbtVx2W1tm4OgAD+8YB+o/JPMBUszhbX2XgfyYa480xd/nGXIU7QxsbxU+kloDLJf6a9ZPl5uX0PNims/4PMDglbDuYeHIVMNVVNctCcxMDaj6npYAA="},"images":{"fallback":{"src":"/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp","srcSet":"/static/9497b4aad63f55a6d041b550a7c9b01a/a66aa/dockerCon2020.webp 750w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/65dd5/dockerCon2020.webp 1080w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/4fad6/dockerCon2020.webp 1366w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/9497b4aad63f55a6d041b550a7c9b01a/dockerCon2020.webp"}},"fields":{"slug":"/community/events/dockercon-live"}},{"id":"415e407f-720e-5552-85f3-0271a2d45c6e","body":"\nimport { HPEfacts, HPEintro, HPEbenefits } from \"./hpe.style.js\";\nimport GlobeIcon from \"./globe.svg\";\nimport UsersIcon from \"./users.svg\";\nimport NetworkIcon from \"./network.svg\";\nimport LayersIcon from \"./layers.svg\";\nimport MesheryIntegration from \"./meshery-integrations.svg\";\nimport Maxi from \"../../../../collections/members/maximiliano-churichi/Maximiliano-Churichi.webp\";\nimport Yogi from \"./yogi.webp\"\n\n<ResourcesWrapper>\n\n<HPEintro>\nHPE's adoption of Meshery was driven by the need to simplify Kubernetes cluster management and monitoring. Meshery is an open source cloud native management tool that provides a self-service platform for designing, visualizing, deploying, testing, and operating cloud native infrastructure.\n</HPEintro>\n\n<p>\n   HPE, a leading technology company specializing in enterprise infrastructure, adopted Meshery Extension to enhance their Kubernetes deployments. HPE uses Kubernetes as a primary platform to build and deploy their containerized applications. The company has a large and complex Kubernetes environment, which requires robust networking solutions for efficient communication between services.\n</p>\n\n\n\n<HPEfacts>\n   <tr><td colSpan=\"2\"><h4>HPE FAST FACTS</h4></td></tr>\n   <tr>\n      <td>\n      <img src={UsersIcon} />\n      Full Time Employees: 60,000+\n      </td>\n      <td>\n      <img src={GlobeIcon} />\n      Market Presence: HPE is one of the largest technology companies globally, serving customers in over 150 countries.\n      </td>\n   </tr>\n   <tr>\n      <td>\n      <img src={LayersIcon} />\n      HPE GreenLake: HPE GreenLake is a key offering by the company, providing a flexible and scalable IT infrastructure model known as \"everything-as-a-service.\"\n      </td>\n      <td>\n      <img src={NetworkIcon} />\n      Research and Development: HPE invests significantly in research and development to drive innovation. It operates HPE Labs, which focuses on developing cutting-edge technologies and solutions for the future.\n      </td>\n   </tr>\n</HPEfacts>\n\n<p>\nSPIRE is a toolchain of APIs for establishing trust between software systems across a wide variety of hosting platforms. SPIRE exposes the SPIFFE Workload API, which can attest running software systems and issue SPIFFE IDs and SVIDs to them. <br/><br/>\n</p>\n\n<HPEbenefits>\n    <b>Meshery offers several benefits to HPE, including:</b>\n    <br/>\n    ✔️ Consistent service mesh management: HPE can now manage all their service meshes consistently, regardless of the underlying infrastructure or cloud provider.\n    <br/>\n    ✔️ Improved observability: With Meshery's built-in visualization and observability tools, HPE can gain insights into the behavior of their service meshes, detect anomalies, and troubleshoot issues in real-time.\n    <br/>\n    ✔️ Simplified testing and validation: Meshery's service mesh validation capabilities enable HPE to easily test and validate their service meshes, ensuring that they meet their performance, security, and compliance requirements.\n    <br/>\n    ✔️ Enhanced security: With Meshery's security features, HPE can ensure that their service meshes are secure and compliant with their organization's security policies.\n</HPEbenefits>\n<br/>\n\n<p>\n    Overall, Meshery has helped HPE to streamline their integration of the identity management control plane to reduce complexity, and improve the overall reliability and performance of their Kubernetes environment. SPIFFE is a set of open-source specifications for a framework capable of bootstrapping and issuing identity to services across heterogeneous environments and organizational boundaries. The lifecycle of SPIFFE identities, SVIDs, is managed by SPIRE, a production-ready implementation of the SPIFFE APIs that performs node and workload attestation in order to securely issue SVIDs to workloads, and verify the SVIDs of other workloads, based on a predefined set of conditions.\n</p>\n\n<p>\n    <b>HPE's adoption of Meshery has also been enhanced by the platform's ability to integrate with other popular technologies, such as SPIRE and Istio</b>\n</p>\n<p style={{display: \"flex\", justifyContent: \"center\", alignItem: \"center\", padding: \"2%\"}}>\n<img src={MesheryIntegration}></img>\n</p>\n<p>\n   SPIRE is an open-source project that provides a secure and scalable solution for service identity and authentication in distributed systems. HPE uses SPIRE to authenticate and authorize services in their Kubernetes environment, which ensures that only authorized services can communicate with each other.\n</p>\n\n<p>\n   Meshery's integration with SPIRE enables HPE to manage SPIRE instances, issue and revoke service certificates, and automate the management of SPIRE agents across their Kubernetes clusters. This integration ensures that HPE's service meshes are secure, and only authorized services can communicate with each other.\n</p>\n  <InlineQuotes\n          quote=\"With a goal to bring workload identity and attestation to all service meshes, HPE Security Engineering uses the Meshery's Extension to deploy their cloud native infrastructure of choice and test the performance of our SPIFFE and SPIRE-based identity solution.\"\n          person=\"Maximiliano Churichi\"\n          title=\"Software Engineer at HPE\"\n          image={Maxi} />\n\n<p>\n   In addition, HPE's use of Meshery has been enhanced by its integration with Istio, an open-source service mesh that provides a comprehensive solution for traffic management, security, and observability in Kubernetes environments.\n</p>\n\n<p>\n   Meshery's integration with Istio enables HPE to manage Istio service meshes and configurations, automate the deployment of Istio components, and monitor and visualize Istio metrics and traces. This integration enables HPE to simplify the management of their Istio service meshes, ensure their security and compliance, and gain insights into their behavior for better decision-making.\n</p>\n\n<p>\n   Overall, HPE's adoption of Meshery, along with its integration with SPIRE and Istio, has enabled the company to streamline their service mesh management, ensure the security and compliance of their Kubernetes environment, and gain valuable insights into the behavior of their service meshes for improved performance and reliability.\n</p>\n\n<p>\n   <b>Meshery also implements the Service Mesh Performance (SMP) specification</b>\n</p>\n\n<p>\n   SMP is a community-driven effort that provides a standard for measuring and comparing the performance of different service meshes. It is designed to help users select the best service mesh for their needs by providing a common framework for benchmarking.\n</p>\n <InlineQuotes\n          quote=\"The Layer5 team has been amazing. Our project wouldn’t have been successful with out Meshery.\"\n          person=\"Yogi Porla\"\n          title=\"Engineering Manager, HPE\"\n          image={Yogi} />\n<p>\n   Meshery implements SMP by providing a simple and easy-to-use interface for running performance tests against different service meshes. Users can select the service mesh they want to test, configure the test parameters (such as the number of requests per second and the number of concurrent clients), and run the test. Meshery will then generate a report that shows the performance metrics for each service mesh, such as latency, throughput, and error rates.\n</p>\n\n<p>\n   By implementing SMP, Meshery provides a valuable tool for developers and operators who are evaluating different service meshes. Instead of having to create their own benchmarks, they can use SMP to get an objective and standardized view of each service mesh's performance characteristics. This can save a significant amount of time and effort, and help users make more informed decisions when choosing a service mesh.\n</p>\n\n<p>\nOverall, HPE's use of Meshery and the Docker Extension for Meshery demonstrates the power of cloud native technologies and the importance of open source collaboration. By leveraging these tools, HPE has been able to streamline its development and deployment processes, improve performance and security, and stay at the forefront of the cloud native movement.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"HPE's adoption of Meshery and Meshmap","type":"Case Study","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/91d038ef73208e4f202eecb42cb08c1f/meshery-and-hpe.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/91d038ef73208e4f202eecb42cb08c1f/meshery-and-hpe.svg"}},"fields":{"slug":"/resources/case-study/hpes-adoption-of-meshery-and-meshmap"}},{"id":"515bf6db-37bb-5a06-9892-326ee784c2f6","body":"\n\nimport MesheryVersion from \"./meshery-version.png\";\n\n<BlogWrapper>\n\n<p>\n  Meshery is constantly evolving and improving, with new features and bug fixes being added regularly. To stay up to date with the latest Meshery features and updates, you can switch between different release channels.\n</p>\n<p>\n  Artifacts of the builds for Meshery and its components are published under two different release channels, so that improved controls may be provided to both  Meshery users and Meshery developers. The two release channels are edge and stable release channels. Relative to stable releases, edge releases occur much more frequently. Edge releases are made with each merge to master, unless that merge to master is for a stable release. Stable releases are made with each\n  merge to master when a GitHub release tag is also present in the workflow.\n</p>\n\n<h2> How release channels offer subscription </h2>\n<p>\n  Release Channels offers a subsciption where user can subscribe to a specific  release channel and get notified when a new release is available. This is  useful for users who want to stay up to date with the latest Meshery features, while also also providing flexibility for users who want to stay on a specific version of Meshery.\n  However, this approach can be risky because some updates may introduce bugs or compatibility issues that could break your existing installation. Depending upon your risk aversion and the nature of your deployment environment, having a subscription means that you will automatically receive these updates that you might not be ready incorporate. On the other hand, release channels also offer the ability to pin to a specific release which is a  good thing as it allows users to maintain stability and predictability of their environment by preventing unexpected changes from being introduced into their system. However, doing so cancels out any future subscription-based benefits such as receiving security patches or bug fixes that were added after that version was released.\n\nTherefore, it's important for you to weigh the pros and cons of each option before making decisions on how you want to manage your Meshery deployment. It's recommended you and your organizations have a well-defined upgrade strategy based on testing and validation procedures prior to applying new releases in production environments whether via subscriptions or manual upgrades to ensure that system availability is maintained and risks are minimized.\n\n</p>\n<p>\nTo subscribe to a specific release channel or version using mesheryctl you can use \n<pre><code className=\"language-bash\">mesheryctl system channel set [stable|stable-version|edge|edge-version] </code></pre>\nThis command will update your local Meshery configuration to use the selected channel for future updates. To set the channel to a specific version, replace Version with the desired version number. Example: <code className=\"language-bash\">mesheryctl system channel set stable</code> or <code className=\"language-bash\">mesheryctl system channel set stable-v0.5.56</code>\n</p>\n<h2> Switching between Release Channels</h2>\n<p>There are two ways to switch between Meshery release channels: using mesheryctl or by editing your meshconfig file. In this blog post, we'll cover both methods.</p>\n\n<h3>What is Meshconfig?</h3>\n<p>\n  Meshconfig is a configuration file that is used to configure Meshery. It is typically located in the <code>~/.meshery/config.yaml</code> directory. It contains information about the current release channel, the version of Meshery that is installed, and other configuration options that are specific to your Meshery installation. \n  Meshconfig is automatically generated when you run Meshery for the first time. It is also automatically updated when you update Meshery\n</p>\n\n<ol>\n<h3>Switching between Meshery release channels using meshconfig file.</h3>\n<p>Open your terminal and confirm that you have mesheryctl installed by running  <code>mesheryctl version</code>. If you don't have mesheryctl installed, you can install it by following the instructions in the  <a href=\"https://docs.meshery.io/installation/mesheryctl\">Meshery documentation</a>.</p>\n<li>\nCreate new Meshery config.yaml file <pre><code className=\"language=bash\">mesheryctl system context create [context-name]</code></pre>\n</li>\nExample: <br/> <code className=\"language-bash\">mesheryctl system context create new-context --components meshery-istio meshery-osm meshery-linkerd --platform docker --url http://localhost:9081 --set --yes </code>\n<li> To view the newly created meshery context use <pre><code className=\"language-bash\">mesheryctl system context view [context-name]</code></pre></li>\n<li>After making these changes, you can switch between different context by using <pre><code className=\"language-bash\">mesheryctl system context switch</code></pre></li>\n</ol>\n\n<h3>Switching between Meshery release channels using mesheryctl.</h3>\n<p>mesheryctl is a command-line tool for managing Meshery. You can use it to switch between different release channels. Here's how:</p>\n\n<ul>\n<li>Run the following command to see the current configuration for Meshery:</li>\n<pre>\n<code className=\"language-bash\">mesheryctl system context view</code>\n</pre>\n<img src={MesheryVersion} className=\"image-center\"  style={{width: \"50%\"}}></img>\n<p>This will show you the currently channels ,<b>stable</b> or <b>edge</b>, along with the version number and other information.</p>\n<li>Run the following command to switch to a different release channel:</li>\n<pre><code className=\"language-bash\">mesheryctl system channel switch</code></pre>\nThis command will update your meshconfig file to switch release channel and version of context in focus. To switch the channel to a specific version, replace <b>Version</b> with the desired version number.\n<li> To confirm that the channel has been changed, run the following command again: <pre><code className=\"language-bash\">mesheryctl system channel view</code></pre></li>\n</ul>\n\n<h2>Conclusion </h2>\n\n<p>\n  Switching between Meshery release channels is a simple and straightforward process. You can do it using mesheryctl or by switching between your meshconfig file. Whether you want stable updates or bleeding-edge features, Meshery has a release channel that suits your needs. Just remember to carefully consider your use case and needs before making any changes to ensure that you have the best Meshery experience.\n</p>\n\n</BlogWrapper>\n","frontmatter":{"title":"Changing Meshery Release Channels","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACD0lEQVQoz22S3WvTUBiHj+uGMLeuS85HknNyzkl6kjRt0iRN2g02KzjdyqyuE4TdiFe781LvRr3xRqEVvHXSzo9bRawM/OukTtGhLw+/u4ffC+8Lag1nv39r5/b2bu9GVtRNtk4FpFy3JeQOth3MBGSS2Mba6vER+PC6dPqyNBmBL2/BbAIo17mD/ZBXfaoCFqd+lHhxolTAmERSkHooDMuwqGV4VaxcyG1NuQtnr8D5O2BL2Giquwe7D44G/cPenYO9/mBvcH+/mfpU6FzgLLLSuBo1ajU/4NREmqYbZGEyBufvAXcwd3CxEXe77U4edlJ/sxNtbrccZdoSc4k2muU0YkHgK8+TjpRC2Kpamo7nzXPZJYzrpmeRolZ5eA9vNZlZ5i7hLmYc56mXt+IwrMOL0XXdNP5qdokQkKUKH+7ojwZWN5O2diFTjpMka7c7QghN0yBCULss2w626ZqxUb/29Bj2tsxUMbbOJBIuoRQmSZrnuRCCEKL/21z1aRAKvyFV5nkh90Luh0IFjDsYdYus0yzaRT2KsWFAjCFCOrX+yK5nhZHbKupZK0zyWqvdiFJfcUhuFssnj5viauy7DrW1lRVUqaDVMoRwYTL6vbZETMB5SnSRTCJOK8vPn4DPp4svTkqj4eJ4uDQeLo1+Mn525dMbMJv+OtUlXCLYunE9m7/RtzPw/eN/mE3B18kPG1Z/7RBYIsMAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png","srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/0dee1/change-meshery-release-channels.png 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/8beaa/change-meshery-release-channels.png 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/d079a/change-meshery-release-channels.png 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/a66aa/change-meshery-release-channels.webp 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/65dd5/change-meshery-release-channels.webp 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/4fad6/change-meshery-release-channels.webp 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/c512e/change-meshery-release-channels.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/60fe9ee92d711b8b6d591e00535d18ef/change-meshery-release-channels.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACD0lEQVQoz22S3WvTUBiHj+uGMLeuS85HknNyzkl6kjRt0iRN2g02KzjdyqyuE4TdiFe781LvRr3xRqEVvHXSzo9bRawM/OukTtGhLw+/u4ffC+8Lag1nv39r5/b2bu9GVtRNtk4FpFy3JeQOth3MBGSS2Mba6vER+PC6dPqyNBmBL2/BbAIo17mD/ZBXfaoCFqd+lHhxolTAmERSkHooDMuwqGV4VaxcyG1NuQtnr8D5O2BL2Giquwe7D44G/cPenYO9/mBvcH+/mfpU6FzgLLLSuBo1ajU/4NREmqYbZGEyBufvAXcwd3CxEXe77U4edlJ/sxNtbrccZdoSc4k2muU0YkHgK8+TjpRC2Kpamo7nzXPZJYzrpmeRolZ5eA9vNZlZ5i7hLmYc56mXt+IwrMOL0XXdNP5qdokQkKUKH+7ojwZWN5O2diFTjpMka7c7QghN0yBCULss2w626ZqxUb/29Bj2tsxUMbbOJBIuoRQmSZrnuRCCEKL/21z1aRAKvyFV5nkh90Luh0IFjDsYdYus0yzaRT2KsWFAjCFCOrX+yK5nhZHbKupZK0zyWqvdiFJfcUhuFssnj5viauy7DrW1lRVUqaDVMoRwYTL6vbZETMB5SnSRTCJOK8vPn4DPp4svTkqj4eJ4uDQeLo1+Mn525dMbMJv+OtUlXCLYunE9m7/RtzPw/eN/mE3B18kPG1Z/7RBYIsMAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png","srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/0dee1/change-meshery-release-channels.png 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/8beaa/change-meshery-release-channels.png 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/d079a/change-meshery-release-channels.png 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/a66aa/change-meshery-release-channels.webp 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/65dd5/change-meshery-release-channels.webp 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/4fad6/change-meshery-release-channels.webp 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/c512e/change-meshery-release-channels.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/60fe9ee92d711b8b6d591e00535d18ef/change-meshery-release-channels.png"}},"fields":{"slug":"/blog/meshery/changing-meshery-release-channels"}},{"id":"322a9220-3d64-5c7e-bc41-c0021e2cba60","body":"\nimport DockerExtensionCTA from \"../../../../sections/Docker-Meshery/docker-extension-CTA.js\"\n\n<ResourcesWrapper>\n<p>\nDocker Swarm is a{\" \"}\n<Link to=\"../../articles/kubernetes/management-of-kubernetes\">container orchestration</Link>{\" \"}\ntool that makes it easy to manage and scale your existing Docker\ninfrastructure. It consists of a pool of Docker hosts that run in Swarm\nmode with some nodes acting as managers, workers, or both. Using Docker\nSwarm mode to manage your Docker containers brings the following\nbenefits:\n</p>\n<ul>\n<li>It allows you to incrementally apply updates with zero downtime.</li>\n<li>\nIt increases application resilience to outages by reconciling any\ndifferences between the actual state and your expressed desired state.\n</li>\n<li>\nIt eases the process of scaling your applications since you only need to\ndefine the desired number of replicas in the cluster.\n</li>\n<li>\nIt is built into the <code>docker</code> CLI, so you don't need\nadditional software to get up and running.\n</li>\n<li>\nIt enables multi-host networking such that containers deployed on\ndifferent nodes can communicate with each other easily.\n</li>\n</ul>\n<p>\nIn this tutorial, you will learn key concepts in Docker Swarm and set up a\nhighly available Swarm cluster that is resilient to failures. You will\nalso learn some best practices and recommendations to ensure that your\nSwarm setup is fault tolerant.\n</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>\nBefore proceeding with this tutorial, ensure that you have access to five\nUbuntu 22.04 servers. This is necessary to demonstrate a highly available\nset up, although it is also possible to run Docker Swarm on a single\nmachine. You also need to configure each server with a user that has\nadministrative privileges.\n</p>\n<p>\nThe following ports must also be available on each server for communication\npurposes between the nodes. On Ubuntu 22.04, they are open by default:\n</p>\n<ul>\n<li>TCP port 2377 for cluster management communications,</li>\n<li>TCP and UDP port 7946 for communication among nodes,</li>\n<li>TCP and UDP port 4789 for overlay network traffic.</li>\n</ul>\n<h2 id=\"explaining-docker-swarm-terminology\">Explaining Docker Swarm terminology</h2>\n<p>\nBefore proceeding with this tutorial, let's examine some terms and\ndefinitions in Docker Swarm so that you have enough understanding of what\neach one means when they are used in this article and in other Docker Swarm\nresources.\n</p>\n\n<div>\n    <ul>\n    <li>\n        <strong>Node</strong>: refers to an instance of the Docker engine in the Swarm cluster.\n    </li>\n    <li>\n        <strong>Manager nodes</strong>: they are tasked with handling orchestration and cluster management functions, and dispatching incoming tasks to worker nodes. They can also act as worker nodes unless placed in Drain mode (recommended).\n    </li>\n    <li>\n        <strong>Leader</strong>: this is a specific manager node that is elected to perform orchestration tasks and management/maintenance operations by all the manager nodes in the cluster using the <a rel=\"noreferrer\" target=\"_blank\" className=\"whitespace-nowrap\" href=\"https://raft.github.io/\">Raft Consensus Algorithm</a>.\n    </li>\n    <li>\n        <strong>Worker nodes</strong>: are Docker instances whose sole purpose is to receive and execute Swarm tasks from manager nodes.\n    </li>\n    <li>\n        <strong>Swarm task</strong>: refers to a Docker container and the commands that run inside the container. Once a task is assigned to a node, it can run or fail but it cannot be transferred to a different node.\n    </li>\n    <li>\n        <strong>Swarm service</strong>: this is the mechanism for defining tasks that should be executed on a node. It involves specifying the container image and commands that should run inside the container.\n    </li>\n    <li>\n        <strong>Drain</strong>: means that new tasks are no longer assigned to a node, and existing tasks are reassigned to other available nodes.\n    </li>\n    </ul>\n    \n    <h2 id=\"docker-swarm-requirements-for-high-availability\">Docker Swarm requirements for high availability</h2>\n    <p>A highly available Docker Swarm setup ensures that if a node fails, services on the failed node are re-provisioned and assigned to other available nodes in the cluster. A Docker Swarm setup that consists of one or two manager nodes is not considered highly available because any incident will cause operations on the cluster to be interrupted. Therefore the minimum number of manager nodes in a highly available Swarm cluster should be three.</p>\n    <p>The table below shows the number of failures a Swarm cluster can tolerate depending on the number of manager nodes in the cluster:</p>\n    <div>\n    <table>\n        <thead>\n        <tr>\n            <th>Manager Nodes</th>\n            <th>Failures tolerated</th>\n        </tr>\n        </thead>\n        <tbody>\n        <tr>\n            <td>1</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>2</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>3</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>4</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>5</td>\n            <td>2</td>\n        </tr>\n        <tr>\n            <td>6</td>\n            <td>2</td>\n        </tr>\n        <tr>\n            <td>7</td>\n            <td>3</td>\n        </tr>\n        </tbody>\n    </table>\n    </div>\n    <p>As you can see, having an even number of manager nodes does not help with failure tolerance, so you should always maintain an odd number of manager nodes. Fault tolerance improves as you add more manager nodes, but Docker recommends no more than seven managers so that performance is not negatively impacted since each node must acknowledge proposals to update the state of the cluster.</p>\n    <p>You should also distribute your manager nodes in separate locations so they are not affected by the same outage. If they run on the same server, a hardware problem could cause them all to go down. The high availability Swarm cluster that you will be set up in this tutorial will therefore exhibit the following characteristics:</p>\n    <ul>\n    <li>5 total nodes (2 workers and 3 managers) with each one running on a separate server.</li>\n    <li>2 worker nodes (<code>worker-1</code> and <code>worker-2</code>).</li>\n    <li>3 manager nodes (<code>manager-1</code>, <code>manager-2</code>, and <code>manager-3</code>).</li>\n    </ul>\n    <DockerExtensionCTA/>\n    <h2 id=\"step-1-installing-docker\">Step 1 — Installing Docker</h2>\n    <p>In this step, you will install Docker on all five Ubuntu servers. Therefore, execute all the commands below (and in step 2) on all five servers. If your host offers a snapshot feature, you may be able to run the commands on a single server and use that server as a base for the other four instances.</p>\n    <p>Let's start by installing the latest version of the Docker Engine (20.10.18 at the time of writing). Go ahead and update the package information list from all configured sources on your system:</p>\n    <pre>\n    <code>\n        sudo apt update\n    </code>\n    </pre>\n    <p>Afterward, install the following packages to allow <code>apt</code> to use packages over HTTPS:</p>\n    <pre>\n    <code>\n        sudo apt install apt-transport-https ca-certificates curl software-properties-common\n    </code>\n    </pre>\n    <p>Next, add the GPG key for the official Docker repository to the server:</p>\n    <pre>\n    <code>\n        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n    </code>\n    </pre>\n    <p>Once the GPG key is added, include the official Docker repository in the server's apt sources list:</p>\n    <pre>\n    <code>\n        echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n    </code>\n    </pre>\n    <p>Finally, update apt once again and install the Docker Engine:</p>\n    <pre>\n    <code>\n        sudo apt update\n    </code>\n    </pre>\n    <pre>\n    <code>\n        sudo apt install docker-ce\n    </code>\n    </pre>\n    <p>Once the relevant packages are installed, you can check the status of the <code>docker</code> service using the command below:</p>\n    <pre>\n    <code>\n        sudo systemctl status docker\n    </code>\n    </pre>\n    <p>If everything goes well, you should observe that the container engine is active and running on your server.</p>\n    \n    <h2 id=\"step-2-executing-the-docker-command-without-sudo\">Step 2 — Executing the Docker command without sudo</h2>\n    <p>By default, the <code>docker</code> command can only be executed by the root user or any user in the <code>docker</code> group (auto created on installation). If you execute a <code>docker</code> command without prefixing it with <code>sudo</code> or running it through a user that belongs to the <code>docker</code> group, you will get a permission error that looks like this:</p>\n    <pre>\n    <code>\n        Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get \"http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json\": dial unix /var/run/docker.sock: connect: permission denied\n    </code>\n    </pre>\n    <p>As mentioned earlier, using <code>sudo</code> with <code>docker</code> is a security risk, so the solution to the above error is to add the relevant user to the <code>docker</code> group. This can be achieved through the command below:</p>\n    <pre>\n    <code>\n        sudo usermod -aG docker $USER\n    </code>\n    </pre>\n    <p>Next, run the following command and enter the user's password when prompted for the changes to take effect:</p>\n    <pre>\n    <code>\n        su - $USER\n    </code>\n    </pre>\n    <p>You should now be able to run <code>docker</code> commands without prefixing them with <code>sudo</code>. For example, when you run the command <code>docker ps</code>, you should observe the output.</p>\n    <p>Before proceeding to the next step, ensure that all the commands in step 1 and step 2 have been executed on all five servers.</p>\n    \n    <h2>Step 3 — Initializing the Swarm Cluster</h2>\n    <p>At this point, each of your five Docker instances are acting as separate hosts and not as part of a Swarm cluster. Therefore, in this step, we will initialize the Swarm cluster on the <code>manager-1</code> server and add the hosts to the cluster accordingly.</p>\n    <p>Start by logging into one of the Ubuntu servers (<code>manager-1</code>) and retrieve the private IP address of the machine using the following command:</p>\n    <pre>\n    <code>hostname -I | awk '&#123;print $1&#125;'</code>\n    </pre>\n    <p>Copy the IP address to your clipboard and replace the <code>&lt;manager_1_server_ip&gt;</code> placeholder in the command below to initialize Swarm mode:</p>\n    <pre>\n    <code>\n        docker swarm init --advertise-addr &lt;manager_1_server_ip&gt;\n    </code>\n    </pre>\n    <p>If the command is successful, you will see output indicating that the Swarm has been initialized and that the current node is now a manager. It will also provide a command to join worker nodes to the cluster. Copy the command for later use.</p>\n    \n    <p>Next, SSH into each of the other four Ubuntu servers (manager-2, manager-3, worker-1, and worker-2) and run the command you copied earlier to join them to the Swarm cluster. The command should look like this:</p>\n    <pre>\n    <code>\n        docker swarm join --token &lt;token&gt; &lt;manager_1_server_ip&gt;:&lt;port&gt;\n    </code>\n    </pre>\n    \n    <p>After running the command on each server, you should see output indicating that the node has joined the Swarm as either a manager or a worker. To verify the status of the Swarm cluster, you can run the command <code>docker node ls</code> on the manager node:</p>\n    <pre>\n    <code>\n        docker node ls\n    </code>\n    </pre>\n    \n    <p>You should see a list of all the nodes in the Swarm cluster, including their IDs, hostname, status, availability, and whether they are a manager or a worker.</p>\n    \n    <h2>Step 4 — Deploying the Application Stack</h2>\n    <p>Now that you have a functioning Docker Swarm cluster, you can deploy your application stack. In this tutorial, we will use a simple example of a web application stack consisting of a front-end service and a back-end service.</p>\n    \n    <p>Start by creating a new directory for your application stack on the manager node:</p>\n    <pre>\n    <code>\n        mkdir app-stack\n        cd app-stack\n    </code>\n    </pre>\n    \n    <p>Next, create a file called <code>docker-compose.yml</code> in the <code>app-stack</code> directory and open it in a text editor:</p>\n    <pre>\n    <code>\n        nano docker-compose.yml\n    </code>\n    </pre>\n    \n    <p>Copy and paste the following YAML code into the <code>docker-compose.yml</code> file:</p>\n    <pre>\n    <code>\n        version: '3.8'\n        \n        services:\n        frontend:\n            image: nginx:latest\n            ports:\n            - 80:80\n            deploy:\n            replicas: 2\n            restart_policy:\n                condition: on-failure\n        \n        backend:\n            image: httpd:latest\n            ports:\n            - 8080:80\n            deploy:\n            replicas: 2\n            restart_policy:\n                condition: on-failure\n    </code>\n    </pre>\n    \n    <p>This Docker Compose file defines two services: <code>frontend</code> and <code>backend</code>. The <code>frontend</code> service uses the <code>nginx:latest</code> image and maps port 80 of the host to port 80 of the container. It is configured to have 2 replicas and to restart on failure. The <code>backend</code> service uses the <code>httpd:latest</code> image and maps port 8080 of the host to port 80 of the container. It is also configured to have 2 replicas and to restart on failure.</p>\n    \n    <p>Save and close the <code>docker-compose.yml</code> file.</p>\n    \n    <p>To deploy the application stack, run the following command:</p>\n    <pre>\n    <code>\n        docker stack deploy -c docker-compose.yml app-stack\n    </code>\n    </pre>\n    \n    <p>If the command is successful, you should see output indicating that the services are being deployed. You can check the status of the services by running the command <code>docker service ls</code>:</p>\n    <pre>\n    <code>\n        docker service ls\n    </code>\n    </pre>\n    \n    <p>You should see a list of the services in the stack, including their names, mode, replicas, and ports.</p>\n    \n    <h2>Conclusion</h2>\n    <p>In this tutorial, you learned how to set up a highly available Docker Swarm cluster and deploy a simple application stack. This setup provides fault tolerance and load balancing for your applications, allowing you to scale them easily as your needs grow.</p>\n    \n    <p>Next steps:</p>\n    <ul>\n    <li>Explore more Docker Swarm features, such as service updates and rolling updates.</li>\n    <li>Deploy your own application stack using Docker Compose.</li>\n    <li>Learn about Docker networking and how to create overlay networks.</li>\n    </ul>\n</div>\n\n</ResourcesWrapper>","frontmatter":{"title":"Configuring Highly Available Docker Swarm","type":"Tutorial","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEAAAQUxQSJQAAAABgGJt2zLlGU+eXav7TJqBSPTOYQW6BDqHaIkN2BogujtEd30f7NcVRMQEwOyTr893V5ebBTW1rmX+m1FzQMXoYPq/4PS90tnCRPZPcJxqr1Z7AQxQ6zGAIU1rAFqk/FWaA+B9IUWEf0XIPgCYJ4WKwm3Xn/Q9VcpHJ/5tXqq474ZiYHjljeTnxVQMai3uVLUUdMJIVlA4IJgAAACQAwCdASoUABEAPtFgqE+oJSOiKAgBABoJbACxG68ARBlm6uAAANS2tWZeMGxmi1qLnh5LjlIo4xIsTbq4p4hCKxJzxrDHwZu1xhyZ41Gz3YoQA/G0bZzOYnmzs7xPjdFxkzyc7a2RtoIDHkb+G1LvgYf//E+1Wr8D10Xopi//C4s/72CdFz/pXwPt+CHUPPeTizNi0zgAAA=="},"images":{"fallback":{"src":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp","srcSet":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp 512w","sizes":"100vw"},"sources":[]},"width":1,"height":0.83203125}},"extension":"webp","publicURL":"/static/5b72df1802df0608ac6ee6e6bff70c9d/docker-swarm.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEAAAQUxQSJQAAAABgGJt2zLlGU+eXav7TJqBSPTOYQW6BDqHaIkN2BogujtEd30f7NcVRMQEwOyTr893V5ebBTW1rmX+m1FzQMXoYPq/4PS90tnCRPZPcJxqr1Z7AQxQ6zGAIU1rAFqk/FWaA+B9IUWEf0XIPgCYJ4WKwm3Xn/Q9VcpHJ/5tXqq474ZiYHjljeTnxVQMai3uVLUUdMJIVlA4IJgAAACQAwCdASoUABEAPtFgqE+oJSOiKAgBABoJbACxG68ARBlm6uAAANS2tWZeMGxmi1qLnh5LjlIo4xIsTbq4p4hCKxJzxrDHwZu1xhyZ41Gz3YoQA/G0bZzOYnmzs7xPjdFxkzyc7a2RtoIDHkb+G1LvgYf//E+1Wr8D10Xopi//C4s/72CdFz/pXwPt+CHUPPeTizNi0zgAAA=="},"images":{"fallback":{"src":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp","srcSet":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp 512w","sizes":"100vw"},"sources":[]},"width":1,"height":0.83203125}},"extension":"webp","publicURL":"/static/5b72df1802df0608ac6ee6e6bff70c9d/docker-swarm.webp"}},"fields":{"slug":"/resources/docker/configuring-highly-available-docker-swarm"}},{"id":"ea7f10cc-a66d-5ebe-9167-6bf3e9bc136b","body":"\n\n\n\n\n<ResourcesWrapper>\n<p>\n    Terraform is a powerful tool that helps users manage and provision infrastructure resources in a consistent and efficient manner. With Terraform, you can define your infrastructure as code, using human-readable configuration files that can be versioned, shared, and reused. This makes it easy to create, modify, and manage your infrastructure resources, whether they are cloud-based or on-premises.\n</p>\n<div className=\"intro\">\n  <p>\n     It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.\n  </p>\n</div>\n\n<p>\n  One way to further enhance your use of Terraform is by integrating it with Meshery. Meshery is a cloud-native management platform that provides a unified interface for managing and monitoring your infrastructure resources, including those managed by Terraform. By integrating Terraform with Meshery, you can leverage the power and flexibility of both tools to streamline your infrastructure management process.\n</p>\n\n<p>\n  One of the key benefits of using Terraform with Meshery is the ability to manage and monitor infrastructure resources in a consistent and centralized manner. With Meshery, you can view and manage all of your infrastructure resources, whether they are managed by Terraform or other tools, from a single dashboard. This allows you to quickly identify any issues or potential problems with your infrastructure, and take action to resolve them in a timely manner.\n</p>\n\n<p>\n  Another benefit of using Terraform with Meshery is the ability to automate your infrastructure management process. With Meshery, you can create and manage automated pipelines for provisioning and managing your infrastructure resources. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks.\n</p>\n\n<p>\n  In addition to these benefits, using Terraform with Meshery also provides a number of other advantages. For example, Meshery integrates with a wide range of tools and platforms, allowing you to easily incorporate your existing infrastructure resources into your management process. This can help to reduce the complexity of managing your infrastructure, and make it easier to keep everything running smoothly.\n</p>\n\n<p>\n  Overall, the use of Terraform with Meshery can help to streamline and improve your infrastructure management process. By integrating these two powerful tools, you can gain greater visibility and control over your infrastructure resources, and automate many of the tasks involved in managing them. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks. So, it is a good idea to use Terraform with Meshery to improve the efficiency and effectiveness of your infrastructure management process.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Terraform with Meshery","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/895ec8ea35cf68449389f73e4285cb39/terraform-color.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/895ec8ea35cf68449389f73e4285cb39/terraform-color.svg"}},"fields":{"slug":"/resources/cloud-native/terraform-with-meshery"}},{"id":"d28378ea-03c7-5dc2-99a3-95a1b827966a","body":"\nimport picture1 from \"./meshery-core-architecture.webp\"; \nimport picture2 from \"./settings.webp\"; \nimport picture3 from \"./context-switcher.webp\"; \nimport ClusterImg from \"./multi-cluster-kubernetes-management-with-meshery.webp\";\n\n<ResourcesWrapper>\n  \n  <h3> What is Kubernetes Management, and Why Should You Care? </h3>\n  \n  <p> \n  It is easy to understand why Kubernetes has become one of the most popular tools on the market today. Primarily, it allows you to easily manage Docker \n    containers across your entire infrastructure with very little overhead, making it easier than ever to manage massive amounts of information in a timely manner. \n    But what are you supposed to do with all this information? That’s where Kubernetes management comes into play—the process of using that information in an \n    effective manner can make or break your efforts, so it’s essential that you choose the right solutions from the get-go.\n </p>\n  \n  <h3> Defining Kubernetes management </h3>\n  \n  <p> \n  Kubernetes management is the process of managing your containers on a Kubernetes cluster. This can include things like adding or removing clusters, scaling \n    clusters up or down, balancing workloads across nodes in a cluster, and restarting failed containers or nodes in a cluster. These tasks are complicated and \n    involve many different types of actions. Figuring out how to do them all manually would be extremely time-consuming. Fortunately, there are tools like Meshery \n    that automate these tasks for you, making it easier to see what’s going on within your cluster so you can make informed decisions about what needs to happen \n    next. Staying on top of Kubernetes management will not only keep your cluster running smoothly but also help prevent problems before they occur. Automating this \n    process will save you time and money, leaving more time to focus on other aspects of the business. When things go wrong, automated Kubernetes management allows \n    you to have a plan and know exactly what steps need to be taken to recover from an incident. With these benefits in mind, it’s important that companies with \n    containerized infrastructure use some type of automation for their Kubernetes management.\n  </p>\n  \n  <h3> The benefits of Kubernetes management </h3>\n  \n  <p> \n  Kubernetes management can seem like a daunting task. In the past, IT teams had to worry about maintaining large clusters of machines that required constant \n    tweaking and monitoring. Kubernetes simplifies this process by automating tasks such as: \n    <ul>\n      <li> Monitoring cluster health </li>\n      <li> Deploying apps across nodes </li>\n      <li> Running rolling updates </li>\n      <li> Scaling up or down resources on demand </li>\n      <li> Auto-recover from failures </li>\n      <li> Application deployment consistency </li>\n      <li> Managing container upgrades </li>\n    </ul>\n  After reading through these benefits, you may be asking yourself, \"Why should I care? Here are two reasons why you should care about Kubernetes management: - \n  Kubernetes management has been shown to improve software development efficiency because it reduces time spent waiting for containers to restart and redeploy. \n  A recent study showed that developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration \n  solution.\n  </p>\n\n  <blockquote> Developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration solution. </blockquote>\n  \n  <p> Kubernetes management has also been shown to reduce operational costs because it eliminates the need for manual intervention in scaling applications, updating \n  running containers with new versions, etc. If your IT team was spending 10 hours per week on manual operations before adopting Kubernetes, they'll spend only 2 \n  hours after switching over! </p>\n  \n<CTA_FullWidth \n  image={ClusterImg}\n  alt=\"Multi-Cluster Kubernetes Management with Meshery\"\n  content=\"Multi-Cluster Kubernetes Management with Meshery\"\n  button_text=\"Read blog post\"\n  url=\"/blog/meshery/multi-cluster-kubernetes-management-with-meshery\"\n  external_link={false}\n  className=\"get-start-kubernetes-resource\"\n/>\n  \n  <h3> The challenges of Kubernetes management </h3>\n  \n  <p> Kubernetes management can seem like a difficult endeavour. Between determining how to automate deployment and scaling and comprehending the fundamentals of \n  how it operates, there are numerous factors to consider. Fortunately, there are numerous frameworks that simplify this procedure. But before going into new \n  frameworks or technologies, you must grasp what Kubernetes administration comprises so that you know what you're attempting to automate. Kubernetes management \n  comprises a variety of activities, such as building up clusters, keeping apps running on those clusters up-to-date, monitoring usage and providing alarms to keep \n  things running smoothly, and shutting down clusters when they are no longer required. </p>\n  \n  <p> There are numerous ways to manage these tasks: manually, with containers, with an orchestration system such as Ansible Tower, Cloud Control 12c, or ServiceNow \n  NMS, with containers-as-a-service providers such as Docker Datacenter or AWS EKS, with container service offerings from cloud providers such as Azure Container \n  Instances, by configuring Kubernetes with your own framework, and by installing Kubectl on your laptop for direct control. Each strategy has advantages and \n  disadvantages that may make one more suitable for your organisation than another. Regardless of the approach you adopt, you must plan accordingly. </p>\n  \n  <p> Importantly, the fact that Kubernetes is gaining popularity does not imply that it will replace your existing infrastructure layers. It augments their \n  capabilities with scalability and large-scale application management (which would have been difficult without automation). In addition, the definition of \n  management varies based on the size of the organisation: small businesses may prefer self-hosted platforms, whilst larger businesses would often primarily rely on \n  SaaS solutions. </p>\n  \n  <h3> How Meshery makes it easier to run Kubernetes </h3>\n  \n  <p> Meshery is the only cloud-native manager in the world that supports more adapters than any other project or product. </p>\n  \n  <img src = {picture1} className=\"image-center\" alt=\"Management of Kubernetes with Meshery\" />\n  \n  <p> Meshery has been designed for the world of many service meshes and many Kubernetes clusters. As such, great attention was made to guarantee that it is an \n  extensible management platform, able to handle a diverse range of infrastructure and new use cases quickly through its plugin mechanism. Meshery Server acts as an \n  operation delegator, determining which Meshery Adapter has registered its capacity for the given operation. The operation is then sent to the appropriate component \n  using a gRPC call. This could be one of Meshery's service mesh adapters, like the Istio adapter. </p> \n  \n  <p> Meshery's capability is constantly expanding, from multi-mesh to now multi-cluster, to give developers, operators, and security engineers more control over \n  their infrastructure. Each part of Meshery's architecture makes a big difference in how it manages multiple Kubernetes clusters. </p>\n  \n  <h3> Meshery management across many clusters </h3>\n  \n  <p> From the settings page, users can do things related to clusters, like add more clusters, remove data from existing clusters, or delete existing clusters. </p>\n  \n  <img src = {picture2} className=\"image-center\" alt=\"Management of Kubernetes with Meshery\" />\n  \n  <p> Meshery also deploys Meshery operators throughout the cluster it is about to manage. This operator is in charge of the Meshery broker and the MeshSync \n  lifecycle. MeshSync is responsible for monitoring various types of resources by establishing a watch stream over each of them. MeshSync then sends the data to the \n  NATS server, of which the Meshery server is a client. Meshery server then receives all necessary data relating to cluster activity. </p>\n  \n  <img src = {picture3} className=\"image-center\" alt=\"Management of Kubernetes with Meshery\" />\n  \n  <p> Meshery, by default, wants to be as aware of your infrastructure as possible in order to deliver value. As such, it deploys its operator across each identified \n  cluster. However, you can fine-tune this configuration by going over each one. </p>\n  \n  <h3> The future of Kubernetes management </h3>\n  \n  <p> Kubernetes management has been one of the buzzwords since 2018. But what does it actually mean? And why should you care about it? At its core, Kubernetes \n  management is a system that helps make sense of the nuances of how different containers work together to create an application. As we rely more on containers for \n  our everyday apps, there needs to be a way to keep track of them all. That's where Kubernetes comes in with its ability to manage these containers that are spread \n  out across different servers and understand which ones need more resources or want to be shut down because they're no longer needed. The easier it becomes for \n  developers and engineers to deploy applications without worrying about how they are going to be managed, the better off everyone will be. Fortunately, as \n  containerization grows in popularity among developers and IT teams alike, so does the number of tools for managing it. </p>\n  \n  <p> A lot of container platforms provide native management functionality: Docker Swarm allows you to use simple commands like swarm stop or swarm pull when your \n  swarm is up-to-date; Kargo automatically manages clusters using zero-touch configuration; Rancher provides tools to manage containers using any infrastructure \n  stack; and Mesos offers both orchestration capabilities through Marathon as well as advanced resource scheduling features. It's not always easy to know which \n  platform will work best for your organization, but it's important to find one that suits your company's needs—especially if IT is looking forward to a future \n  without manual management tasks! </p>\n \n</ResourcesWrapper>\n","frontmatter":{"title":"Management of Kubernetes","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/9287b4a708bb510f64057ea305498b77/kubernetes-logo.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/9287b4a708bb510f64057ea305498b77/kubernetes-logo.svg"}},"fields":{"slug":"/resources/kubernetes/management-of-kubernetes"}},{"id":"daa05956-2d58-5dc5-b0cf-e3a4428cde4b","body":"\nimport picture1 from \"./Picture1.webp\";\nimport ClusterImg from \"./multi-cluster-kubernetes-management-with-meshery.webp\";\nimport MeshmapDesigner from \"./MeshmapDesigner.webp\"\nimport MeshmapVisualizer from \"./MeshmapVisualizer.webp\"\n\n<ResourcesWrapper>\n  \n  <p> Kubernetes, an open-source container orchestration platform, is growing in popularity for deploying and managing cloud-native applications. Kubernetes was created by Google in 2014, and it is now used by many major companies, including IBM, Microsoft, Red Hat, and Amazon.In this article, we'll talk about Kubernetes, its benefits, and the best ways for your organization to use it. </p>\n  \n  <h3> What is Kubernetes? </h3>\n  \n  <p> Kubernetes offers fully managed and adapted architecture services that optimize your cloud-native application. Kubernetes is a platform that hides virtual machines, shows the infrastructure as an infrastructure-as-a-service (IAAS), network, and load balancer, and offers data storage and operations that are consistent across containers.</p>\n  \n  <p> For example, Kubernetes nodes work as Kubernetes containers, such as an application, an application server, and control processes in Docker containers. Kubernetes components such as Kubernetes nodes and Kubernetes containers can be defined or modified via configuration files or can be specified subsequently. Individual Kubernetes components can be scaled according to elasticity needs to optimize performance.</p>\n  \n  <p> Kubernetes optimizes a Kubernetes environment in the cloud, Docker containers on a system for development or testing, and the master or control plane of its cloud cluster management infrastructure.</p>\n  \n  <h3> What's the Difference between Kubernetes and Docker? </h3>\n  \n  <p> Over the past few years, containers have become increasingly popular within the software development community, and they have now evolved into two major platforms — Docker and Kubernetes. Both are incredibly powerful tools that allow developers to containerize their applications, but they are also slightly different in a number of ways, with more differences on the horizon as Docker announces its new focus on Kubernetes and containers orchestration. How do you decide which one to use? What does the future hold for each? Here’s what you need to know about the difference between Docker and Kubernetes.</p>\n  \n  <p> Docker is an open-source platform designed to help developers and IT professionals create, deploy, and run applications. This containerization technology is often used in conjunction with orchestration software such as Kubernetes. However, these two technologies are not interchangeable; they serve different purposes. </p>\n  \n  <h3> Why Should You Care About Kubernetes? </h3>\n  \n  <p> Kubernetes was first made available for Google's internal use for DNS hosting. Open-source software projects were not able to use it. </p>\n  \n  <p> Today, Kubernetes is in use by large-scale companies that use container orchestration. And in January 2019, The New Stack reported that a survey conducted in that month, which included the Kubernetes user group, discovered that Kubernetes reached more than 40,000 users and 200 companies were working on Kubernetes at that point. In addition, Gartner indicated that Kubernetes Inc. would make some $8.5 billion in 2019. </p> \n  \n  <h3> What does Kubernetes Do? </h3>\n  \n  <p> In contrast to an overall infrastructure, Kubernetes is a dynamic layer-oriented computing infrastructure. The essence of Kubernetes is how an entire infrastructure hops! Kubernetes is a container orchestration and management platform that has built-in features for self-replication, elasticity, and scalability. Through these and more features, Kubernetes \"promovi-is\" for container orchestrators for both production and lab environments. </p>\n  \n  <h3> Kubernetes Architecture </h3>\n  \n  <p> Even though Kubernetes is a software platform that lets organizations manage their application workloads in containers, a traditional Kubernetes cluster may not be the best solution for a number of business needs. </p>\n \n  <img src = {picture1} className=\"image-center\" alt=\"Kubernetes Architecture\" />\n  \n  <p> A cluster of virtual computing resources is only one option, and it has its drawbacks. What happens when you lose disk space (which can happen if you don't add new containers, users, or workloads to a cluster)? Do you have another cluster for redundancy, and how do you integrate the two together? </p>\n\n  <p> Hyperconverged infrastructures like Red Hat OpenShift are an alternative that combine several technologies into a single virtual machine or physical machine. </p> \n  \n  <h3> Best Practices for Kubernetes </h3>\n  \n  <p> Kubernetes is a container orchestration platform created by Google in 2014. It provides a way for companies to build fully self-sufficient, scalable, multi-container applications every time they need to deploy and manage their own containers. It's aimed at pretty much the same audience as Docker and other container orchestration platforms—that is, organizations that run containerized applications and want to deploy scalable, repeatable deployments.</p>\n  \n  <p> At the most basic and most simplistic level, a group of containers (usually 16) is cross-linked together in a cluster, based on Docker. Containers run inside a cluster of virtual machines (Kubernetes VM) as a single Linux file system. Kubernetes organizes the creation, deletion, and management of containers into container concepts that provide fault tolerance, availability, scaling, permission management, and secure containers that should be able to run together and share resources. Each host runs one or more containers, providing the abstraction of which containers can run on which hosts.</p>\n  \n  <p> Since Kubernetes services are usually very easy to use, the user experience is very similar to that of centralized solutions. </p>\n  \n  <p> With Kubernetes, businesses can make data repositories and containers, federate their resources in an efficient way, manage billing, certify capacity, quota, access rights, and more. </p>\n  \n  <p> It can scale to many nodes simultaneously, so when their machines scale up, then their containers could scale up too. </p>\n  \n  <h3> Kubernetes Concepts and Terminology </h3>\n  \n  <p> Kubernetes was developed in 2014 as a Google container orchestrator, a container scheduler and more. Kubernetes was created to manage distributed applications, including Docker containers. According to SUSE, Kubernetes is simple to learn, easy to manage, and supports an on-premise, private, public, or hybrid architecture. Kubernetes is flexible enough to be split up over many servers in your data center. </p>\n  \n  <p> This simplificator, one example of many, allows one to scale independent containers. </p>\n  \n  <p> Let's understand better what Kubernetes is: </p>\n  \n  <p> In an application ecosystem of operating system Docker containers, Kubernetes acts as a centralized management guided by distributed logic. Kubernetes can be used to deliver web traffic, graphics work, or IP traffic from IoT devices. The main benefit is that clusters can be easily expanded to a huge size with all functions. </p>\n \n  <p> What are pods? Pods are Docker instances that you can use to deploy your containers in environments like Kubernetes, which can be private, public, or a mix of the two.</p>\n  \n  <p> Environments may be private services or public clouds. </p>\n  \n  <p> Kubernetes can be used to manage containers because they are easy to use and make it easy to scale your containers. </p>\n  \n  <p> Installation tutorials are sometimes yoinked without ever reading the help. </p>\n  \n  <h3> RBAC and Firewall Security </h3>\n  \n  <p> Today, everything is hackable, and so is your Kubernetes cluster. Hackers often try to find vulnerabilities in the system in order to exploit them and gain access. So, keeping your Kubernetes cluster secure should be a high priority. The first thing to do is make sure you are using RBAC in Kubernetes. RBAC is role-based access control. Assign roles to each user in your cluster and to each service account running in your cluster. Roles in RBAC contain several permissions that a user or service account can perform. You can assign the same role to multiple people, and each role can have multiple permissions.</p>\n  \n  <p> RBAC settings can also be applied to namespaces, so if you assign roles to a user allowed in one namespace, they will not have access to other namespaces in the cluster. Kubernetes provides RBAC properties such as role and cluster role to define security policies. </p>\n  \n  <p> You can create a firewall for your API server to prevent attackers from sending connection requests to your API server from the Internet. To do this, you can either use regular firewalling rules or port firewalling rules. If you are using something like GKE, you can use a master authorized network feature in order to limit the IP addresses that can access the API server. </p>\n  \n  <h3> Managing Kubernetes Clusters </h3>\n  \n  <p> Kubernetes is a project that lets you create and manage individual containers or a container cluster on a mainframe. Clusters may consist of physical, virtual, or cloud-based computing resources.</p>\n<CTA_FullWidth \n  image={ClusterImg}\n  alt=\"Multi-Cluster Kubernetes Management with Meshery\"\n  content=\"Multi-Cluster Kubernetes Management with Meshery\"\n  button_text=\"Read blog post\"\n  url=\"/blog/meshery/multi-cluster-kubernetes-management-with-meshery\"\n  external_link={false}\n  className=\"get-start-kubernetes-resource\"\n/>\n<p> The Kubernetes projects auto-deploy container clusters anywhere there is a pluggable environment and an open-source base that includes system-config service, service account manager, and kubelet. So, developers and system administrators can easily put containers on a single machine or on nodes of machines in any scalable cluster to save money and time.</p>\n  \n<p> Kubernetes is an open-source system for automating the deployment, scaling, and management of containerized applications. Kubernetes was made by Google, and the Cloud Native Computing Foundation now takes care of it.</p>\n\n  <h3>Kubernetes Cluster Visualization and Designing using MeshMap</h3>\n<p> MeshMap has been developed for visualizing and managing kubernetes clusters. You can learn more about MeshMap <a href=\"https://layer5.io/cloud-native-management/meshmap\">here</a></p>\n<p>Users can drag-and-drop your cloud native infrastructure using a pallete of thousands of versioned Kubernetes components. Integrate advanced performance analysis into your pipeline.</p>\n  <img src = {MeshmapDesigner} className=\"image-center\" alt=\"Kubernetes Architecture\" />\n<p>Users can deploy their designs, apply patterns, manage and operate their deployments in real-time bringing all the Kubernetes clusters under a common point of management. Interactively connect to terminal sessions or initiate and search log streams from your containers.</p>\n  <img src = {MeshmapVisualizer} className=\"image-center\" alt=\"Kubernetes Architecture\" />\n  \n  <h3> Set Resource Requests & Limits</h3>\n  \n  <p> Occasionally, deploying an application to a production cluster can fail due to the limited resources available on that cluster. This is a common challenge when working with a Kubernetes cluster, and it’s caused when resource requests and limits are not set. Without resource requests and limits, pods in a cluster can start utilizing more resources than required. If the pod starts consuming more CPU or memory on the node, then the scheduler may not be able to place new pods, and even the node itself may crash. Resource requests specify the minimum amount of resources a container can use. </p>\n  \n  <p> For both requests and limits, it’s typical to define CPU in millicores and memory in megabytes or mebibytes. Containers in a pod do not run if the request for resources made is higher than the limit you set.</p>\n  \n  <p> In this example, we have set the limit of the CPU to 800 millicores and the memory to 256 mebibytes. The maximum request which the container can make at a time is 400 millicores of CPU and 128 mebibyte of memory.</p>\n  \n  <h3> Guide to Containers </h3>\n  \n  <p> Containers have been around for a while, but it wasn’t until Docker came along that they really took off. In its early days, developers were using it to build their applications in containers. Now companies like Walmart are using containers to deploy their entire infrastructure.</p>\n  \n  <p> Containers are lighter-weight than virtual machines because they don't need to emulate an entire operating system. This is why containers are typically faster to start up and use less resources. However, containers cannot be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case.</p>\n  \n  <p> Because they're so lightweight and take up less space than VMs do, containers are great for running lots of them at once! If your application needs more computing power or memory than your machine can provide on its own, using multiple containers in parallel will help balance out any resource shortages without having to invest in additional physical hardware like you would with traditional VM-based deployments.</p>\n  \n  <p> As they're isolated from each other, containers are great for running multiple apps at once without worrying about them stepping all over each other's toes! This makes them perfect for things like hosting websites or email services where you want lots of different people to be able to use it at the same time without slowing down or crashing because there's not enough resources available for everyone. </p>\n  \n  <p> What's more, since they're so easy to spin up and take down, they're also great for testing out new ideas quickly without having to worry about making permanent changes to your system (or losing any data along the way!). So if you want to try out a new CMS but don't want to go through the trouble of installing it on your machine first, just fire up a container with it inside and see how it goes! </p>\n  \n  <p> One downside to using containers is that they can't easily be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case. Fortunately, there are some great open source projects out there that help solve this problem!</p>\n  \n  <h3> Conclusion </h3>\n  \n  <p> Kubernetes is a popular containerization solution that continues to see increasing adoption rates. That being said, using it successfully requires thorough consideration of your workflows and departmental best practices. </p>\n  \n  \n</ResourcesWrapper>\n","frontmatter":{"title":"Getting Started with Kubernetes","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/b1a646c34f1a9ed49dcf37dd7b9b4662/kubernetes-logo.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/b1a646c34f1a9ed49dcf37dd7b9b4662/kubernetes-logo.svg"}},"fields":{"slug":"/resources/kubernetes/getting-started-with-kubernetes"}},{"id":"298319fe-14a3-5ee4-8ef1-453d93b5f4b1","body":"\nimport serviceMesh from \"./service-mesh.svg\";\nimport arch from \"./arch.svg\";\n\n<ResourcesWrapper>\n  \n<p> Microservice architectures offer some solutions while posing new ones. Application division into separate services makes scaling, updating, and development easier. It also provides you with a lot more moving pieces to connect and secure. It can get quite complicated to manage all of the network services, including load balancing, traffic management, authentication and authorisation, etc. </p>\n\n<p> Istio, an open-source service mesh created by Google, IBM, and Lyft, enables you to connect, monitor, and secure microservices that are hosted on-premises, in the cloud, or with orchestration systems like Kubernetes and Mesos. The beta version of Istio was announced in the year 2018 in KubeCon on Google Cloud. </p> \n\n<p> Before moving on to what Istio is and how it works, let us look into what service meshes are and why there was an urgent need for them as microservices started getting used more. </p>\n\n  <h3> Service Mesh </h3>\n  \n  <p> A service mesh is an infrastructural layer that is used to provide secure communication between different services for on-prem, cloud or multi-cloud infrastructure. It allows us to add features like observability, traffic management, and security without having to add that to our code. The term \"service mesh\" refers to both the kind of software you employ to carry out this pattern and the security or network domain that results from its application. </p>\n  \n  <p> Service meshes are divided into two parts: the control plane and the data plane. The control plane's responsibilities include securing the mesh, facilitating service discovery, doing regular health checks, enforcing policies, and handling other operational issues. A central registration of services and their corresponding IP addresses is referred to as service discovery. To share with other services how to communicate with it and to assist enforce rules on which services are allowed to communicate with which other services, the application must be registered on the control plane. </p>\n  \n  <p> The communication between services, on the other hand, is handled by the data plane. Because many service mesh solutions use a sidecar proxy to manage data plane connections, the amount of knowledge that the services must have about the network environment is constrained. </p>\n \n  <img src = {serviceMesh} className=\"image-center\" alt=\"Service Mesh\" />\n  \n  <h3> Inside the Istio service mesh </h3>\n  \n  <p> \n  A data plane and a control plane are logically separate parts of an Istio service mesh.\n  <ul>\n    <li> A group of intelligent proxies (Envoy) that are deployed as sidecars make up the data plane. All network connection among the microservices is mediated and managed by these proxies. Additionally, they gather and compile data on all mesh communications. </li>\n    <li> The proxies are controlled and set up by the control plane to route traffic. </li>\n  </ul>\n  </p>\n  \n   <img src = {arch} className=\"image-center\" alt=\"Istio Service Mesh Architecture\" />\n  \n  <h4> Envoy </h4>\n  \n  <p> The data plane of Istio consists of the Envoy sidecar proxy. Envoy is an edge and service proxy that is open source and free that aids in separating network concerns from core applications. Applications don't care about the network topology; they just transmit and receive messages to and from localhost. Envoy is fundamentally a network proxy that operates at the OSI model's L3 and L4 layers. It operates by processing connections through a series of pluggable network filters. Envoy additionally provides support for an extra L7 layer filter for HTTP-based traffic. Envoy also offers excellent support for the HTTP/2 and gRPC transports. </p>\n  \n  <p> Many of the features provided by Istio such as security, traffic control, network resiliency are possible due to Envoy. </p>\n  \n  <h4> Istiod </h4> \n  \n  <p> Service discovery, configuration, and certificate management are offered by Istiod. </p>\n  \n  <p> High level routing rules that govern traffic behavior are transformed into Envoy-specific configurations by Istiod and propagated to the sidecars during runtime. Any sidecar that complies with the Envoy API can use Pilot, which synthesizes platform-specific service discovery techniques into an abstract form. </p>\n  \n  <p> Istio can handle discovery in a variety of settings, including Kubernetes or virtual machines. </p>\n  \n  <p> To exert finer control over the traffic in your service mesh, you can ask Istiod to modify the Envoy configuration using the Traffic Management API. </p>\n  \n  <p> Strong service-to-service and end-user authentication are made possible by Istiod security's integrated identity and credential management. Istio can be used to enhance unencrypted service mesh traffic. </p>\n  \n  <p> Operators can enforce regulations with Istio based on service identity rather than on layer 3 or layer 4 network IDs, which are more prone to instability. Additionally, you can limit who has access to your services by using Istio's authorisation capability. </p>\n  \n  <p> In order to enable secure mTLS connection in the data plane, Istiod performs the role of a Certificate Authority (CA) and issues certificates. </p>\n  \n  <h3> Features </h3>\n  \n  <h4> Traffic Management </h4>\n  \n  <p> Performance is impacted by traffic routing, both within and across clusters, which improves deployment strategy. You can simply manage the flow of traffic and API requests between services using Istio's traffic routing rules. Istio makes it simple to configure critical activities like A/B testing, canary deployments, and staged rollouts with percentage-based traffic divides, as well as service-level attributes like circuit breakers, timeouts, and retries. </p>\n  \n  <h4> Observability </h4>\n  \n  <p> It becomes harder to comprehend behaviour and performance as services become more complicated. Istio produces comprehensive telemetry for each communication taking place within a service mesh. This telemetry makes service activity observable, enabling operators to maintain, optimise, and debug their applications. Even better, you can implement practically all of this instrumentation without making any changes to your applications. Operators are able to fully comprehend how the monitored services are communicating with Istio. </p>\n  \n  <p> Detailed metrics, distributed traces, and complete access logs are all included in Istio's telemetry. You get complete and thorough service mesh observability with Istio. </p>\n  \n  <h4> Security Capabilities </h4>\n  \n  <p> Particular security requirements for microservices include defense against man-in-the-middle attacks, adaptable access rules, auditing tools, and mutual TLS. Istio comes with a comprehensive security solution that enables administrators to handle each of these problems. To safeguard your services and data, it offers strong identity, strong policy, transparent TLS encryption, and authentication, authorization, and audit (AAA) tools. </p>\n  \n  <p> The security architecture used by Istio is built on security-by-default, and it aims to provide in-depth defense so you may deploy security-conscious apps even across networks with a low level of trust. </p>\n  \n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh: Istio","type":"Article","technology":null,"product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/c341f7820b8cb7e150bd32b3672ef4a5/istio-white.svg"}},"fields":{"slug":"/resources/service-mesh/service-mesh-istio"}},{"id":"88e08e13-0ab0-5e6b-94d9-12dec5e1eab4","body":"\n\n\nimport DevOps from \"./devops-adoption-choosing-the-right-metrics_compressed.pdf\";\nimport DevOpsAdoption from \"./devops-adoption.webp\";\n\n<ResourcesWrapper>\n<p>\nAccording to Puppet’s State of DevOps Report 2021, 83% of IT professionals report that their organizations have previously implemented DevOps practices or are doing so right now to unlock higher business value, achieve faster time to delivery, and boost security of systems.\n</p>\n\n<p>\nHowever, DevOps teams from many industries frequently struggle to identify the right metrics to monitor and measure success. In this <Link to={DevOps}>infographic</Link>, we highlight the metrics all DevOps professionals should measure to:\n</p>\n\n<ul>\n<li>Identify places in the pipeline to speed up deployments.</li>\n<li>Make data-driven decisions to improve the deployment process.</li>\n<li>Analyze the speed at which products are reaching the market in comparison to competitors.</li>\n</ul>\n\n<h3 style={{marginTop: \"1rem\"}}>Monitor these 5 metrics to understand how to speed up your DevOps toolchain:</h3>\n<ul>\n<li>Deployment Time</li>\n<li>Change Failure Rate</li>\n<li>Recovery Time</li>\n<li>Release Cadence</li>\n<li>Lead Time</li>\n</ul>\n\n<Link to={DevOps}><img src={DevOpsAdoption} alt=\"Right metrics for adopting DevOps\" /></Link>\n</ResourcesWrapper>\n","frontmatter":{"title":"DevOps Adoption: Identifying the Right Metrics","type":"Infographic","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACQAwCdASoUAAwAPtFUpEuoJKOhsAgBABoJbACdAB4ZXhaXIPKYAPaG9u2w8AHTtU+cyhybyQ2d8jlpRY3i9sqgENC0D+v3/skF/sV1UuobVW4bKjzUIc5tTnsJeCfeE0ZwvwkTwZWhhIj9/KO9fj9pqTxNIAAA"},"images":{"fallback":{"src":"/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp","srcSet":"/static/eba4e5898081df468c1c4288ce73623d/c89db/devops-adoption.webp 750w,\n/static/eba4e5898081df468c1c4288ce73623d/0dc9a/devops-adoption.webp 1080w,\n/static/eba4e5898081df468c1c4288ce73623d/24070/devops-adoption.webp 1366w,\n/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5994791666666667}},"extension":"webp","publicURL":"/static/eba4e5898081df468c1c4288ce73623d/devops-adoption.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACQAwCdASoUAAwAPtFUpEuoJKOhsAgBABoJbACdAB4ZXhaXIPKYAPaG9u2w8AHTtU+cyhybyQ2d8jlpRY3i9sqgENC0D+v3/skF/sV1UuobVW4bKjzUIc5tTnsJeCfeE0ZwvwkTwZWhhIj9/KO9fj9pqTxNIAAA"},"images":{"fallback":{"src":"/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp","srcSet":"/static/eba4e5898081df468c1c4288ce73623d/c89db/devops-adoption.webp 750w,\n/static/eba4e5898081df468c1c4288ce73623d/0dc9a/devops-adoption.webp 1080w,\n/static/eba4e5898081df468c1c4288ce73623d/24070/devops-adoption.webp 1366w,\n/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5994791666666667}},"extension":"webp","publicURL":"/static/eba4e5898081df468c1c4288ce73623d/devops-adoption.webp"}},"fields":{"slug":"/resources/devops/devops-adoption-identifying-the-right-metrics"}},{"id":"3e1c20c1-a961-5316-8916-cf7c8d1fad19","body":"\n\n\n<ResourcesWrapper>\n<p>\n    GitOps revolves around the central notion that infrastructure can be treated as code. It is an operational framework that incorporates DevOps best practices for infrastructure automation, including version control, collaboration, compliance, and CI/CD tooling, which are often used for application development. Like code, not only can you store your infrastructure configuration in a source code version system, but you can also take your infrastructure configuration and any changes to its configuration through the same change management process that you do when updating your applications and services. In part, GitOps is about change management, and consequently, it is about risk reduction and risk management. When you automate a process and classify the manner in which you systemize the process, risk is reduced through the consistency and series of processes and reviews changes go through.\n</p>\n<p> \n   GitOps is the acknowledgement that declarative systems that everything is (or should be) defined as code. With all code in a source code system, that system becomes the source of truth and in the system of record for how your infrastructure is running. Well, that is, assuming that your infrastructure configuration hasn't drifted from its desired state defined in your source code system. If Git is the source of truth, you cannot run operations manually by executing random commands. Doing so would mean that Git would stop being the only source of truth. Instead, the only goal of operations is to define the desired state as code and store it in git. Then, let the machines synchronize that with the actual state. Such synchronization must be continuous so that the two states are (almost) always in sync. In other words, GitOps is about defining everything as code, storing that code in Git, and letting the machines detect the drift between the desired and the actual state – and making sure that drifts are resolved as soon as possible, hence resulting in the two states being almost always in sync.\n</p>\n\n<h2> Principles of GitOps</h2>\n \n<h3> 1) Declarative</h3>\n\n <p> According to this principle, the entire system should have a declarative description. Let us first understand what a system description is. What is committed to your Git repository is called the System Description. One or more files that define each system component and its state will be included in the system description. According to GitOps, the way in which we store those definitions is crucial, and we must do so declaratively. That implies that the description of our system will be saved as data. </p>\n \n <p> In the declarative approach, we specify how we want the system to look not how we can achieve that state. If we want to make any changes, we change the description instead of the series of steps to get there. Declarative configuration is critical for GitOps because it provides a description of the system that an automated agent can understand and utilize to take action. </p>\n\n<h3> 2) Single Source of Truth</h3>\n\n <p> The second principle mandates that we keep that system description inside of Git. Therefore, we decide to maintain the official blueprints, which outline the ideal system state version in Git. A git commit is required if we wish to modify the blueprint. The blueprint can also be called the desired state. This helps developers, testers, operations, security, and automations to have a single reference and keep uniformity in everyone’s vision. </p>\n \n <p> GitOps also improves a system's ability to recover from failure because it's simple to roll back an unsuccessful change or restore the entire system from the repository.</p>\n\n<h3> 3) Automated Change Delivery</h3>\n\n <p> Only automation allows us to apply modifications made to the blueprint to systems already in operation. Delivery of changes is entirely automatic. GitOps doesn't allow manual editing. Because standard workflows only need GitHub, which is such a well-known platform, automation enables changes to be delivered through simpler for developers to use workflows. Additionally, automation standardizes your delivery processes, improving the predictability and consistency of system operations. </p>\n\n<h3> 4) Automated State Control</h3>\n\n <p> The fourth principle uses automation to keep our operating system in alignment with the desired state. Drift is the deviation of the runtime state of our system from the desired state. The system's blueprints and what is actually operating in the system don't match. Therefore, if the operating system drifts from what we have specified in Git, an operator will restore it by bringing it back to the intended condition. </p>\n\n<h2> Benefits of GitOps</h2>\n\n<h3> 1) Improves compliance and security:</h3>\n\n <p> Since teams use a single platform for infrastructure management, a streamlined toolchain reduces attack surfaces. Teams can use the version control system to roll back to a desired state in the event of an assault. GitOps lessens outages and downtime as a result, allowing teams to continue working on projects in a secure environment.</p>\n \n <h3> 2) Boosts productivity and cooperation:</h3>\n\n <p> GitOps includes CI/CD pipelines, Git workflows, and infrastructure as code best practices for software development. These prerequisite tools, knowledge, and skill sets are already present in operations teams, thus adopting GitOps won't need a steep learning curve. GitOps workflows streamline procedures in order to improve visibility, establish a single source of truth, and have a small number of tools on hand.</p>\n\n <h3> 3) Automation enhances developer efficiency and lowers costs:</h3>\n\n<p> Productivity rises with CI/CD tooling and continuous deployment since teams can concentrate on development rather than laboriously manual processes thanks to automation. Since team members can use any language and tools they like before pushing updates to GitHub, GitOps workflows enhance the developer experience. Infrastructure automation increases output and decreases downtime while enabling better cloud resource management, which can also save costs.</p>\n \n <h3> 4) Increases stability and reliability:</h3>\n\n <p> Human mistake is decreased through infrastructure that is codified and repeatable. Code reviews and collaboration are made easier by merge requests, which also assist teams in finding and fixing issues before they are released to the public. Additionally, there is less risk because all infrastructure changes are tracked through merge requests and may be undone if an iteration is unsuccessful. By allowing rollbacks to a more stable state and providing distributed backup copies in the event of a significant outage, Git processes speed up recovery time. GitOps gives teams the freedom to iterate more quickly and release new features without worrying about creating an unstable environment.</p>\n \n <h3> 5) Faster development and deployment:</h3>\n\n <p> GitOps provides quicker and more frequent deployments, making it easier for teams to make a minimum viable change. Teams can ship many times per day and roll back changes if there is a problem by utilizing GitOps best practices. Team members can offer business and customer value more quickly thanks to high velocity deployments. Teams are more flexible and able to react to customer needs more quickly with continuous integration.</p>\n \n <h2> Key Components of a GitOps workflow</h2>\n\n <p> To summarize, the following are the four components we require to a GitOps workflow:</p>\n   <ol>\n      <li> Git repository: The code and configuration of the application are verified there. </li>\n      <li> CD pipeline: It is responsible for building, testing, and deploying the application. </li>\n      <li> Application deployment tool: It is employed to manage the target environment's application resources. </li>\n      <li> Monitoring system: It keeps tabs on the performance of the application and gives the development team feedback. </li>\n   </ol>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"What is GitOps?","type":"Article","technology":"Kubernetes","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/a8d747801f0e266dbc9bb2b192cd3dc1/github-dark.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/06256dc26bfc3ff62237cb2590cb260b/github-light.svg"}},"fields":{"slug":"/resources/cloud-native/what-is-gitops"}},{"id":"a082cf72-65d4-5ad3-aab7-c04e9cdcbf93","body":"\nimport serviceMesh from \"./consul-service-mesh.webp\";\nimport agent from \"./consul-agent-architecture.webp\";\nimport datacenter from \"./datacenter-architecture.webp\";\nimport proxy from \"./service-proxy-architecture.webp\";\n\n<ResourcesWrapper>\n  \n  <h3> What is a Service Mesh? </h3>\n  \n  <p> A service mesh is a dedicated layer that provides secure service-to-service communication for on-prem, cloud, or multi-cloud infrastructure. Although service meshes are typically used with a microservice architectural pattern, they are useful in any situation involving complex networking. Their functionalities include traffic control, resiliency, observability and security. Traffic steering is used for content and it allows optimal usage of our resources. Service meshes provide control over chaotic situations (which usually arise in complex networks) along with proper identification and policies to enhance security. </p>\n  \n  <p> Service meshes can be divided into the control plane and the data plane. The role of the control plane is to secure the mesh, facilitate service discovery, conduct frequent health checks, enforce policies and other operational concerns. Service discovery refers to a central registry of the services and their respective IP addresses. The application needs to be registered on the control plane for it to be able to share with other services how to communicate with it and helps to enforce rules on which service gets to communicate with which other services. </p>\n  \n  <p> The data plane, on the other hand, handles the communication between services. The amount of knowledge that the services need to have about the network environment is limited by the fact that many service mesh solutions use a sidecar proxy to conduct data plane connections. </p>\n  \n  <img src = {serviceMesh} className=\"image-center\" alt=\"Service Mesh\" />\n  \n  <h3> What is Consul? </h3>\n  \n  <p> Consul Service Mesh (also known as Consul Connect) provides service-to-service connection authorization and encryption using mutual Transport Layer Security (TLS). Consul is the control plane of the service mesh. Consul can be used with Virtual Machines (VMs), containers, or with container orchestration platforms such as Nomad and Kubernetes. Applications can use sidecar proxies to establish TLS connections for inbound and outbound connections or natively integrate with Connect by using Connect aware SDKs for optimal performance and security. </p>\n  \n  <p> It is a multi-networking tool that provides a fully functional service mesh solution to address the networking and security issues associated with running cloud infrastructure and microservices. Consul offers a software technique for segmentation and routing. It also offers advantages such as handling failures, retries, and network observability. You can utilize any of these characteristics alone as required or combine them to create a full service mesh and achieve zero trust security. </p>\n  \n  <h3> Architecture </h3>\n  \n  <p> Consul is a distributed system built for a node cluster to operate on. A physical server, cloud instance, virtual machine, or container can all function as a Consul node. The collection of interconnected nodes that Consul runs on is known as a datacenter. Consul supports multiple datacenters and considers this as a common case. It is expected that there will be many clients and three to five servers in a datacenter. This creates a balance between performance and availability in the event of a breakdown because consensus slows down as more machines are added. The number of clients, however, is unlimited and can easily increase to thousands or tens of thousands. </p>\n  \n  <img src = {datacenter} className=\"image-center\" alt=\"Image of datacenter\" />\n  \n  <p> The Consul Agent is responsible for maintaining membership information, registering services, running checks, responding to queries, etc. It is required to run on every node that is a part of the Consul cluster. In some places, client agents may cache data from the servers to make it available locally for performance and reliability. They can either run in server mode or client mode. Client nodes make up for most of the cluster and are lightweight processes. They act as an interface between server nodes for most operations. They run on every node where services are running. </p>\n  \n  <p> Along with core agent operations, a server node participates in the consensus quorum. The Raft protocol, which offers excellent consistency and availability in the event of failure, serves as the foundation for the quorum. Because they consume more resources than client nodes, server nodes should run on dedicated instances. </p>\n  \n  <img src = {agent} className=\"image-center\" alt=\"Consul Agent\" />\n  \n  <p> A per-service proxy sidecar manages incoming and outgoing service connections by automatically wrapping and verifying TLS connections. Consul includes its own built-in L4 proxy and has first class support for Envoy. Other than this, we can choose to use any other proxy to plug in as well. The following diagram shows how proxies work: </p>\n  \n  <img src = {proxy} className=\"image-center\" alt=\"Side-car proxy\" />\n  \n  <p> \n  The lifecycle of a Consul cluster:\n    <ol>\n      <li> An agent is started. </li>\n      <li> An agent joins the cluster. </li>\n      <li> Information of the agent is communicated throughout the cluster</li>\n      <li> Existing servers will begin replicating to the new node. </li>\n    </ol>    \n  </p>\n  \n  <h3> Benefits and Compatibility of Consul Connect </h3>\n  \n  <p> New methods of networking are necessary due to the development of cloud infrastructure and microservices designs. There are numerous tools and companies, all of which make different attempts to address the issue. The Consul service mesh solution offers a pure software approach with an emphasis on simplicity and wide compatibility and makes no assumptions about the underlying network. </p>\n  \n  <p> Consul service mesh streamlines application deployment into a zero-trust network and makes service discovery easier in complex networking situations. </p>\n  \n  <p> \n  Features of Consul Service Mesh:\n  <br />\n    <ol>\n      <li> \n      Service Discovery \n        <p> Consul provides a service catalog, configurable service routing, health checks, automatic load balancing, and geo-failover across multiple instances of the same service. The capacity to control changes in the service landscape of your network becomes essential when new versions of a service are introduced and must coexist with existing instances of the same application, frequently running on different versions. The agent provides a simple service definition format to declare the availability of a service and to potentially associate it with a health check. </p>\n        </li>\n      <li> \n      Zero-trust Security Model\n        <p> Trust can be exploited and with the increasing number of services, there are higher chances of breach. The Consul service mesh control plane can be configured to enforce mutual TLS (mTLS), and will automatically generate and distribute the TLS certificates for every service in the mesh. The certificates are used for both service identity verification and communication encryption. </p> \n      </li>\n      <li> \n      Simplify Application Security with Intentions \n        <p> Communication between services is secure within the mesh once the service sidecar proxies have been set up. To designate which services are permitted to communicate with one another, you might want to build a more granular set of policies. Consul Intentions are used to limit which services can make requests or create connections and define access control for services through Connect. We can manage intentions via the UI, CLI, or API. The proxy or a natively integrated application enforces intentions on inbound connections or requests. </p> \n      </li>\n    </ol>\n  </p>\n  \n  <p> \n  Compatibility of Consul Connect:\n  <br />\n  <ol>\n    <li> \n    First-Class Kubernetes Support \n        <p> By offering an official Helm chart for installing, configuring, and upgrading Consul on Kubernetes, Consul enables first-class Kubernetes support. The chart automates Kubernetes's Consul service mesh installation and configuration. </p> \n     </li>\n    <li> \n    Platform Agnostic and Multi-Cluster Mesh\n        <p> Consul works with all cloud providers and architectures. You can expand the scope of your Kubernetes clusters to include services that aren't run using Kubernetes by using the service catalog sync and auto-join features. In order to facilitate safe service-to-service communication between Nomad tasks and jobs, Consul additionally interfaces with HashiCorp Nomad. </p> \n     </li>\n  </ol>\n  </p>\n  \n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh: Consul","type":"Article","technology":null,"product":null,"mesh":"Consul","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/ed21c2c53f2c64e86b016cfdfe7018ae/consul.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/ed21c2c53f2c64e86b016cfdfe7018ae/consul.svg"}},"fields":{"slug":"/resources/service-mesh/service-mesh-consul"}},{"id":"0bf099ea-9608-5c18-9882-81c42e07ea75","body":"\n\nimport mesheryui from \"./mesheryui.webp\"; \n\n<BlogWrapper>\n\n<div className=\"intro\">\n<p><a href=\"https://meshery.io/\">Meshery</a>'s goal is to make the operation of cloud native infrastructure and the service mesh layer of cloud simplified. Originally created by Layer5, Meshery is an open source project with hundreds of contributors world-wide and is actively maintained by engineers from Red Hat, VMware, Intel, Layer5 and others.</p>\n</div>\n<h2>Setup and run Meshery on AKS</h2>\n<p>The following instructions expects you to have an active Azure subscription, and Azure CLI installed on your system. </p>\n<h3> Spin up the AKS Cluster</h3>\n<p>Create the resource group (a logical group where all our resources will be deployed). The following command creates  a resource group named MesheryGroup in <code>southindia</code> location. </p>\n<pre><code className=\"language-bash\">\naz group create --name MesheryGroup --location southindia\n</code></pre>\n\n<p>Create AKS cluster using <code>az aks create</code>. The following command creates aks cluster with a single node. </p>\n\n<pre><code className=\"language-bash\">\naz aks create --resource-group MesheryGroup --name MesheryAKS --node-count 1 --generate-ssh-keys\n</code></pre>\n<p>After a few minutes, the command completes and returns a JSON formatted information about the cluster.</p>\n<p>You can connect with your cluster by using <code>az aks get-credentials</code> ,  which basically downloads credentials and configure the Kubernetes CLI. </p>\n<pre><code>\naz aks get-credentials --resource-group MesheryGroup --name MesheryAKS\n</code></pre>\n<p>Verify the connection to your cluster using the <code>kubectl get command</code>. </p>\n<pre><code>\n$kubectl get nodes\n</code></pre>\n<h3>Install Meshery into your AKS cluster</h3>\n\n```\nhelm repo add meshery https://meshery.io/charts/\n\nhelm install meshery meshery/meshery --namespace meshery --create-namespace\n\n```\n<p>Meshery server supports customizing authentication flow callback URL, which can be configured in the following way.</p>\n\n<pre><code>\nhelm install meshery meshery/meshery --namespace meshery --set env.MESHERY_SERVER_CALLBACK_URL=https://custom-host --create-namespace\n</code></pre>\n<p>Port forward to Meshery UI</p>\n\n```\nexport POD_NAME=$(kubectl get pods --namespace meshery -l \"app.kubernetes.io/name=meshery,app.kubernetes.io/instance=meshery\" -o jsonpath=\"{.items[0].metadata.name}\")\n\n$ kubectl --namespace meshery port-forward $POD_NAME 9081:8080\n\n```\n<p>Meshery should now be running in your AKS cluster and the Meshery UI should be accessible at the specified endpoint you’ve exposed to. Navigate to the meshery service endpoint to log into Meshery.</p>\n\n<div><img src={mesheryui} className=\"image-center\" alt=\"Meshery UI Dashboard\" /></div>\n\n<p>From here, your Meshery deployment on AKS is ready to use. In order to login to Meshery, authenticate with your chosen provider from the list.</p>\n<p>There are different ways to configure a Meshery on AKS. Join the <a href=\"https://layer5.io/community\">community</a> and share your deployment’s configuration on the <a href=\"https://discuss.layer5.io/\"> discussion forum </a>today! </p>\n\n\n</BlogWrapper>\n","frontmatter":{"title":"How to deploy Meshery on AKS","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmYAAABXRUJQVlA4IFoAAADQAwCdASoUAAoAPtFipk0oJiOiMAgBABoJaACw7GYVobqX7FMxDIAA/qX3az11ecS2G7Ywek1haVMFjWlflvPlov5ZOXa13PEkNYdR0wgoGPwU0M3fO53QAAA="},"images":{"fallback":{"src":"/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp","srcSet":"/static/3fe6493b7ebec3694bc03967df3a3a83/ee7ce/Meshery-on-AKS.webp 750w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/819dc/Meshery-on-AKS.webp 1080w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/3fe6493b7ebec3694bc03967df3a3a83/Meshery-on-AKS.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmYAAABXRUJQVlA4IFoAAADQAwCdASoUAAoAPtFipk0oJiOiMAgBABoJaACw7GYVobqX7FMxDIAA/qX3az11ecS2G7Ywek1haVMFjWlflvPlov5ZOXa13PEkNYdR0wgoGPwU0M3fO53QAAA="},"images":{"fallback":{"src":"/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp","srcSet":"/static/3fe6493b7ebec3694bc03967df3a3a83/ee7ce/Meshery-on-AKS.webp 750w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/819dc/Meshery-on-AKS.webp 1080w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/3fe6493b7ebec3694bc03967df3a3a83/Meshery-on-AKS.webp"}},"fields":{"slug":"/blog/meshery/how-to-deploy-meshery-on-aks"}},{"id":"c57a376e-18e9-5959-9332-330a4849e77a","body":"\n\n\n\n<ResourcesWrapper>\n<div className=\"intro\">\n  <p>Learn more about managing containers with our <a className=\"blog\" href=\"https://github.com/layer5io/containers-101-workshop\">Containers 101 Workshop</a>. Walk-through four hands-on exercises with Docker.</p>\n</div>\n\n<p>\n  Container management refers to a set of practices that govern and maintain\n  containerization software. Container management tools automate the creation,\n  deployment, destruction and scaling of application or systems containers.\n  Containerization is an approach to software development that isolates\n  processes that share an OS kernel -- unlike virtual machines (VMs), which\n  require their own -- and binds application libraries and dependencies into one\n  deployable unit. This makes containers lightweight to run, as they require\n  only the application configuration information and code from the host OS. This\n  design also increases interoperability compared to VM hosting. Each container\n  instance can scale independently with demand.\n</p>\n<p>\n  Modern Linux container technology was popularized by the Docker project, which\n  started in 2013. Interest soon expanded beyond containerization itself, to the\n  intricacies of how to effectively and efficiently deploy and manage\n  containers.\n</p>\n<p>\n  In 2015, Google introduced the container orchestration platform Kubernetes,\n  which was based on its internal data center management software called Borg.\n  At its most basic level, open source Kubernetes automates the process of\n  running, scheduling, scaling and managing a group of Linux containers. With\n  more stable releases throughout 2017 and 2018, Kubernetes rapidly attracted\n  industry adoption, and today it is the de facto container management\n  technology.\n</p>\n<p>\n  IT teams use containers for cloud-native, distributed -- often microservices-\n  based -- applications, and to package legacy applications for increased\n  portability and efficient deployment. Containers have surged in popularity as\n  IT organizations embrace DevOps, which emphasizes rapid application\n  deployment. Organizations can containerize application code from development\n  through test and deployment.\n</p>\n<h2>Benefits of container management</h2>\n<p>\n  The chief benefit of container management is simplified management for\n  clusters of container hosts. IT admins and developers can start, stop and\n  restart containers, as well as release updates or check health status, among\n  other actions. Container management includes orchestration and schedulers,\n  security tools, storage, and virtual network management systems and\n  monitoring.\n</p>\n\n<h3>Wrangling container sprawl</h3>\n<p>\n  Organizations can set policies that ensure containers share a host -- or\n  cannot share a host -- based on application design and resource requirements\n  For example, IT admins should colocate containers that communicate heavily to\n  avoid latency. Or, containers with large resource requirements might require\n  an anti-affinity rule to avoid physical storage overload. Container instances\n  can spin up to meet demand -- then shut down -- frequently. Containers also\n  must communicate for distributed applications to work, without opening an\n  attack surface to hackers.\n</p>\n<p>\n  A container management ecosystem automates orchestration, log management,\n  monitoring, networking, load balancing, testing and secrets management, along\n  with other processes. Automation enables IT organizations to manage large\n  containerized environments that are too vast for a human operator to keep up\n  with.\n</p>\n\n<h2>Challenges of container management</h2>\n<p>\n  One drawback to container management is its complexity, particularly as it\n  relates to open source container orchestration platforms such as Kubernetes\n  and Apache Mesos. The installation and setup for container orchestration tools\n  can be arduous and error prone. IT operations staff need container management\n  skills and training. It is crucial, for example, to understand the\n  relationships between clusters of host servers as well as how the container\n  network corresponds to applications and dependencies.\n</p>\n<p>\n  Issues of persistence and storage present significant container management\n  challenges. Containers are ephemeral -- designed to exist only when needed.\n  Stateful application activities are difficult because any data produced within\n  a container ceases to exist when the container spins down.\n</p>\n<p>\n  Container security is another concern. Container orchestrators have several\n  components, including an API server and monitoring and management tools. These\n  pieces make it a major attack vector for hackers. Container management system\n  vulnerabilities mirror standard types of OS vulnerabilities, such as those\n  related to access and authorization, images and intercontainer network\n  traffic. Organizations should minimize risk with security best practices --\n  for example, identify trusted image sources and close network connections\n  unless they're needed.\n</p>\n<h2>Container management strategy</h2>\n<p>\n  Forward-thinking enterprise IT organizations and startups alike use containers\n  and container management tools to quickly deploy and update applications. IT\n  organizations must first implement the correct infrastructure setup for\n  containers, with a solid grasp of the scope and scale of the containerization\n  project in terms of business projections for growth and developers'\n  requirements. IT admins must also know how the existing infrastructure's\n  pieces connect and communicate to preserve those relationships in a\n  containerized environment. Containers can run on bare-metal servers, VMs or in\n  the cloud -- or in a hybrid setup -- based on IT requirements.\n</p>\n<p>\n  In addition, the container management tool or platform should meet the\n  project's needs for multi-tenancy; user and application isolation;\n  authentication; resource requirements and constraints; logging, monitoring and\n  alerts; backup management; license management; and other management tasks. IT\n  organizations should understand their hosting commitment and future container\n  plans, such as if the company will adopt multiple cloud platforms or a\n  microservices architecture.\n</p>\n<h2>Kubernetes implementation considerations</h2>\n<p>\n  As described above, containers are arranged into pods in Kubernetes, which run\n  on clusters of nodes; pods, nodes and clusters are controlled by a master. One\n  pod can include one or multiple containers. IT admins should carefully\n  consider the relationships between pods, nodes and clusters when they set up\n  Kubernetes.\n</p>\n<p>\n  Organizations should plan their container deployment based on how many pieces\n  of the application can scale under load -- this depends on the application,\n  not the deployment method. Additionally, capacity planning is vital for\n  balanced pod-to-node mapping, and IT admins should ensure high availability\n  with redundancy with master node components.\n</p>\n<p>\n  IT organizations can address container security concerns by applying some\n  general IT security best practices to containerization. For example, create\n  multiple security layers throughout the environment, scan all container images\n  for vulnerabilities, enforce signed certificates and run the most up-to-date\n  version of any container or application image. Containers introduce the\n  benefits of an immutable infrastructure methodology as well; the regular\n  disposal and redeployment of containers, with their associated components and\n  dependencies, improves overall system availability and security. Additionally,\n  Kubernetes multi-tenancy promises greater resource isolation, but recently\n  revealed security vulnerabilities make multicluster management preferred for\n  now.\n</p>\n<p>\n  Networking is another significant factor. Kubernetes networking occurs within\n  pods, between pods and in user-to-containerized resource connections.\n  Kubernetes enables pods and nodes to communicate without address translation,\n  allocating subnets as necessary. Lastly, IT admins working with Kubernetes\n  should prepare to troubleshoot common container performance problems,\n  including those caused by unavailable nodes and noisy neighbors, in an\n  implementation.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Managing Containers","type":"Article","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/70f4c7f444e8b3494ddc0fb955f86d40/docker.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/70f4c7f444e8b3494ddc0fb955f86d40/docker.svg"}},"fields":{"slug":"/resources/kubernetes/managing-containers"}},{"id":"0d05b64b-7bb7-5e13-9834-1b40f12a2e9d","body":"\n\nimport ArchDiagram from \"./kubernetes-highlevel-architecture.webp\";\n\n\n<ResourcesWrapper>\n\nThe way Kubernetes is architected is what makes it powerful. Kubernetes has a basic client and server architecture, but it goes way beyond that. Kubernetes has the ability to do rolling updates, it also adapts to additional workloads by auto scaling nodes if it needs to and it can also self-heal in the case of a pod meltdown. These innate abilities provide developers and operations teams with a huge advantage in that your applications will have little to no down time. In this section we provide a brief overview of the master and its worker nodes with a high level overview of how Kubernetes manages workloads.\n\n<div className=\"right\" >\n<img src={ArchDiagram} alt=\"Simple Kubernetes Architecture Diagram\" />\n<i>Simple Kubernetes Architecture Diagram</i>\n</div>\n\n# Kubernetes Components\n\nLet's dive into each of the Kubernetes components, starting with the Master node.\n\n## Kubernetes Master\n\nThe Kubernetes master is the primary control unit for the cluster. The master is responsible for managing and scheduling the workloads in addition to the networking and communications across the entire cluster. The master node is responsible for the management of Kubernetes cluster. This is the entry point of all administrative tasks. The master node is the one taking care of orchestrating the worker nodes, where the actual services are running.\n\nThese are the components that run on the master:\n\n### Etcd Storage\nEtcd is an open-source key-value data store that can be accessed by all nodes in the cluster. It stores configuration data of the cluster’s state. etcd is a simple, distributed, consistent key-value store. It’s mainly used for shared configuration and service discovery.\n\nIt provides a REST API for CRUD operations as well as an interface to register watchers on specific nodes, which enables a reliable way to notify the rest of the cluster about configuration changes.\n\nAn example of data stored by Kubernetes in etcd is jobs being scheduled, created and deployed, pod/service details and state, namespaces and replication information, etc.\n\n### Kube-API-Server \nKube-API-Server manages requests from the worker nodes, and it receives REST requests for modifications, and serves as a front-end to control cluster. The API server is the entry points for all the REST commands used to control the cluster. It processes the REST requests, validates them, and executes the bound business logic. The result state has to be persisted somewhere, and that brings us to the next component of the master node.\n\n\n### Kube-scheduler \nKube-scheduler schedules the pods on nodes based on resource utilization and also decides where services are deployed. The deployment of configured pods and services onto the nodes happens thanks to the scheduler component. The scheduler has the information regarding resources available on the members of the cluster, as well as the ones required for the configured service to run and hence is able to decide where to deploy a specific service.\n\n### Kube-controller-manager\nKube-controller-manager runs a number of distinct controller processes in the background to regulate the shared state of the cluster and perform routine tasks. When there is a change to a service, the controller recognizes the change and initiates an update to bring the cluster up to the desired state. Optionally you can run different kinds of controllers inside the master node. controller-manager is a daemon embedding those.\n\nA controller uses apiserver to watch the shared state of the cluster and makes corrective changes to the current state to change it to the desired one.\nAn example of such a controller is the Replication controller, which takes care of the number of pods in the system. The replication factor is configured by the user, and it's the controller’s responsibility to recreate a failed pod or remove an extra-scheduled one. Other examples of controllers are endpoints controller, namespace controller, and serviceaccounts controller, but we will not dive into details here.\n\n## Worker Nodes\nThese nodes run the workloads according the schedule provided by the master. The interaction between the master and worker nodes are what’s known as the control plane. The pods are run here, so the worker node contains all the necessary services to manage the networking between the containers, communicate with the master node, and assign resources to the containers scheduled.\n\n### Kubelet\nKubelet ensures that all containers in the node are running and are in a healthy state.  If a node fails, a replication controller observes this change and launches pods on another healthy pod. Integrated into the kubelet binary is ‘cAdvisor` that auto-discovers all containers and collects CPU, memory, file system, and network usage statistics and also provides machine usage stats by analyzing the ‘root’ container. \n\nKubelet gets the configuration of a pod from the apiserver and ensures that the described containers are up and running. This is the worker service that’s responsible for communicating with the master node. It also communicates with etcd, to get information about services and write the details about newly created ones.\n\n### Kube Proxy\nKube Proxy acts as a network proxy and a load balancer for a service on a single worker node. . It takes care of the network routing for TCP and UDP packets. It forwards the request to the correct pods across isolated networks in a cluster. \n\n### Pods\nA pod is the basic building block on Kubernetes. It represents the workloads that get deployed. Pods are generally collections of related containers, but a pod may also only have one container. A pod shares network/storage and also a specification for how to run the containers.\n\n### Containers \nContainers are the lowest level of microservice. These are placed inside of the pods and need external IP addresses to view any outside processes. Docker is not the only supported container runtime, but is by far, the most popular. Docker runs on each of the worker nodes, and runs the configured pods. It takes care of downloading the images and starting the containers.\n\n### kubectl\nKubectl is a command line tool to communicate with the API service and send commands to the master node. kubectl must be configured to communicate with your cluster. If you have multiple clusters, you might try using kubectx, which makes switching between contexts easy.\n\n\n#### Managing objects with kubectl\nYou can divide a Kubernetes cluster into multiple environments by using namespaces (e.g., Dev1, Dev2, QA1, QA2, etc.), and each environment can be managed by a different user. One of the inconveniences of writing kubectl commands is that every time you write a command, you need the --namespace option at the end. People often forget this and end up creating objects (pods, services, deployments) in the wrong namespace. \n\nWith this trick, you can set the namespace preference before running kubectl commands. Run the following command before executing the kubectl commands, and it will save the namespace for all subsequent kubectl commands for your current context:\n\n```\nkubectl config set-context $(kubectl config current-context) --namespace=mynamespace\n```\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Kubernetes Architecture 101","type":"Article","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/9287b4a708bb510f64057ea305498b77/kubernetes.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/9287b4a708bb510f64057ea305498b77/kubernetes.svg"}},"fields":{"slug":"/resources/kubernetes/kubernetes-architecture-101"}},{"id":"dfec3ca5-0f24-5bdd-a318-0e9807c344ba","body":"\n\n\n\n\nLearn more about how to wrangle <Link to= \"/blog/meshery/multi-cluster-kubernetes-management-with-meshery\">Multiple Kubernetes clusters with Meshery.</Link>\n\n<ResourcesWrapper>\nDevelopers who work in fast-paced environments face the risk of infrastructure sprawl in their VMs or servers. Even with the rise in containerized deployments on Kubernetes and other platforms, admins still must determine how to efficiently manage hundreds and thousands of clusters for various projects.\n\nCommon concerns for an organization’s project deployments include how to run multiple workloads and whether a cluster is large enough to handle the work.\n\nA Kubernetes multi-cluster setup can solve these problems. Multi-cluster architecture is a strategy for spinning up several clusters to achieve better isolation, availability, and scalability. In this type of implementation, an application’s infrastructure is distributed and maintained across multiple clusters. Because this strategy can also make cluster management more difficult, it needs to be handled properly.\n\n## What Is a Kubernetes Multi-Cluster Setup?\n\nKubernetes works with clusters to efficiently run and manage workloads.\n\nIn Kubernetes multi-cluster orchestration, platforms such as managed services help you to run workloads across multiple clusters and environments. The multiple clusters can be configured within a single physical host, within multiple hosts in the same data center, or even in a single cloud provider across different regions. This allows you to provision your workloads in several clusters, rather than just one.\n\nThis type of deployment enables more scalability, availability, and isolation for your workloads and environments. It also enables you to better coordinate the planning, delivery, and management of these environments.\n\nA key feature of multi-cluster Kubernetes architecture is that each cluster is highly independent, managing its internal state for maximum resource provisioning and service configuration.\n\n## Why Use a Kubernetes Multi-Cluster Setup?\n\nThere are multiple use cases for a multi-cluster deployment. You can use it to deploy workloads spanning multiple regions for increased availability, eliminate cloud blast radius, prevent compliance issues, and enforce security around your clusters and tenants.\n\nAs your environment grows, so do the potential issues you need to solve in order to align your cluster maintenance with your business needs. Using a Kubernetes multi-cluster setup can help with the following concerns.\n\n## Cluster Discovery and Tenant Isolation\n\nIt is common for projects to exist in dev, staging, and production environments. To achieve this kind of isolation, you require multiple Kubernetes environments.\n\nConventionally, using namespaces would be enough for discovery and isolation in a single cluster, but Kubernetes isn’t a direct multitenant system. Namespaces are also not great for isolation since any compromise in the namespace means that your cluster is also compromised. Additionally, badly configured applications in a namespace can consume more resources than expected, which impacts other applications in the cluster.\n\nKubernetes multi-cluster environments enable you to isolate users and projects by cluster, simplifying the process.\n\n## Failover\n\nArchitecting multi-cluster workloads minimizes the downtime issues common within a single cluster, because you can freely transfer the workloads to other running clusters.\n\n# Multi-Cluster, Multitenancy, or a Mix?\n\nKubernetes is a complex, high-level platform that offers multiple options for your deployments: single server, multitenant, or multi-cluster.\n\nMultitenancy means a cluster is shared among several workloads, or tenants. Multiple users share the same cluster resources and control plane. Multitenant clusters require fair allocation of resources to the tenants as well as isolation of tenants from each other, in order to minimize the effects of a faulty tenant on other tenants and the overall cluster.\n\nA multi-cluster setup, on the other hand, involves several clusters deployed across one or many data centers. This type of deployment can be used to separate development and production. It improves availability and enhances security around workloads.\n\nThe best choice for your organization depends on factors that include the technical expertise of your team, your infrastructure availability, and your budget. Many organizations separate their critical production services from non-critical services by placing them in separate tenants across tiers, teams, locations, or infrastructure providers. Projects that are time- and resource-dependent (where resources are spun up and down on the go) are, however, suitable for multi-cluster architecture.\n\n# When to Use a Multi-Cluster Setup\n\nTo decide whether your projects would function best in a multi-cluster deployment, you first need to define your goals.\n\nYou should know the challenges you are trying to solve and how transitioning to a multi-cluster setup would help your organization. Projects that are performance-dependent with workloads that are sensitive to factors like latency can take advantage of the high availability and isolation available in multi-cluster setups. In other words, you can run workloads with intensive computations that don’t need to share resources.\n\nYou’ll need to collect workload data and other feedback from your various teams before making a decision. You should assess your teams’ expertise: are they well-versed in provisioning single clusters, even before transitioning to multi-clusters? You’ll also need to evaluate your business model and how such an infrastructure transition could affect your users or customers.\n\nThe following are some of the advantages of transitioning to a Kubernetes multi-cluster setup.\n\n<ul>\n<li>Tenant Isolation</li>\nYou might want to establish order while accommodating your development teams. The multi-cluster architecture allows workload isolation. For example, you could spin up separate clusters for staging and production.\n\nWith multiple clusters, any tenant configuration changes affect only that specific cluster. This way, cluster admins can easily identify issues, run new feature experiments, and carry out workload shifts without troubling other tenants and clusters.\n\n<li>No Single Point of Failure</li>\nRunning a single cluster can expose your project to a single point of failure, in\nwhich one malfunctioning component can bring down an entire system. Using a multi-cluster\nenvironment enables you to shift your workloads between clusters so that your projects\ncontinue to function if one cluster is down or even disappears entirely.\n\n<li>No Vendor Lock-In</li>\nThere are multiple third-party cloud vendors available with varying resource offerings. Because of evolving resource pricing and models, organizations change their usage models over time as well. A Kubernetes multi-cluster setup ensures your workloads are cloud-agnostic so that you can safely use multiple vendors or move workloads from one cloud to another.\n</ul>\nKubernetes provisions clusters that run and manage our workloads. Depending on the needs of an organization, Kubernetes deployments can be replicated to have the same workloads accessible across multiple nodes and environments. This concept is called Kubernetes multi-cluster orchestration. It’s simply provisioning your workloads in several Kubernetes clusters (going beyond a single cluster).\n\nA Kubernetes multi-cluster defines deployment strategies to introduce scalability, availability, and isolation for your workloads and environments. A Kubernetes multi-cluster is fully embraced when an organization coordinates the planning, delivery, and management of several Kubernetes environments using appropriate tools and processes.\n\n## Why Do You Need a Kubernetes Multi-Cluster?\n\nIn simple deployment cases, Kubernetes can spin workloads in a single cluster. However, some cases need advanced deployment models, and for such scenarios, a multi-cluster architecture is suitable and can improve the performance of your workloads.\n\nSimply put, a development team may need a Kubernetes multi-cluster to handle workloads spanning regions, eliminate a cloud blast radius, manage compliance requirements, solve multi-tenancy conflicts, and enforce security around clusters and tenants.\n\n### Cluster Upgrades and Security Management\n\nTeams that rely heavily on Kubernetes for deployments need to plan for regular upgrades and patches on their environments for comprehensive security fixes.\n\nRunning cluster upgrades without due care or proper tools can break more things, and more so when dependent resources are overloaded. Tools like kOPs and Cluster APIs can therefore be used to apply upgrades to your running clusters.\n\nThe tools that you install to run your clusters depend entirely on the workloads that your clusters support. How you upgrade a cluster and its tools also depends on how you initially deployed and ran the Kubernetes cluster, that is, whether you’re using a hosted Kubernetes provider or some other means for deployment. Most hosted providers support and handle automatic upgrades, which relieves developers from manual upgrades and patching.\n\nUpgrading a cluster and its toolset follows the approach of upgrading the control plane first, then the nodes in a cluster, followed by upgrading clients such as `kubectl`.\n\n### Managing Kubernetes Multi-Cluster Complexity\n\nThe complexity of management tasks across multiple Kubernetes clusters greatly increases your the number of clusters increase. You need higher-level view and control as you manage workloads across clusters; need to be able to simply switch between clusters; you need a management plane.\n\n<Link className=\"blog\" to=\"/meshery\">  Meshery</Link> is the open source, cloud native management plane that enables the adoption,\noperation, and management of Kubernetes, any service mesh, and their workloads.\n\nMeshSync, a custom controller managed by Meshery Operator, uniquely contains cluster-wide details of all objects across any number of managed clusters separated by Kubernetes Cluster ID.\n\n### Deprovisioning Clusters That Are No Longer Needed\n\nWhen you deprovision a cluster, its running resources are also deleted. The control plane resources, the node instances, pods, and stored data are all deleted.\n\nDifferent hosted Kubernetes providers have varying ways of deleting Kubernetes clusters. For instance, GKE supports deletion of clusters from the Google Cloud CLI and Cloud Console. Other tools for spinning Kubernetes clusters such as kOps and Amazon EKS also support the deletion from their CLIs and consoles.\n\nSuppose you have provisioned your clusters with the Google Kubernetes Engine; you can run the following command in the gcloud CLI to deprovision your clusters that are no longer needed:\n\n```\ngcloud container clusters delete CLUSTER_NAME\n```\n\nAt this point, you’ve seen the operations around managing a cluster lifecycle, that is, creation, deletion, and upgrading of clusters.\n\n## Conclusion\n\nTeams want working with clusters to be as easy as possible. This ease in operating clusters can be ensured by managing the cluster lifecycle. In this article, you learned what’s involved in managing a cluster lifecycle. You’ve seen how clusters are created at scale using various tools. You’ve also seen what cluster upgrades and security patch management involve while trying to maintain the health of your clusters.\n\nThe complexity of Kubernetes environments does present challenges, but setting clear goals and objectives for deploying your clusters can help you overcome any obstacles as your organization makes the transition.\n\nFinally, multi-cluster deployments are a good choice for organizations that are building highly distributed systems, with geographic and regulatory control in check to help scale workloads beyond the limits of single clusters. Multi-cluster deployment and management is useful for minimizing exposure of production services, preventing access to sensitive data in environments like development and testing. Organizations are now opting to deploy their more critical workloads on separate multiple clusters from their less critical ones.\n\n</ResourcesWrapper>\n","frontmatter":{"title":"What is Multi-Cluster Kubernetes?","type":"Article","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/9287b4a708bb510f64057ea305498b77/kubernetes.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/9287b4a708bb510f64057ea305498b77/kubernetes.svg"}},"fields":{"slug":"/resources/kubernetes/what-is-multi-cluster-kubernetes"}},{"id":"a3d9d6ca-504e-51f1-b0d0-d7a2b928f10c","body":"\n\n\n\n\n\n<ResourcesWrapper>\n<p>\nTechStrong TV hosts a variety of live conversations and panel discussions with world’s leading technology experts and leaders at global tech events and user conferences. In this episode of TechStrong TV, straight out of <Link to=\"/community/events/open-source-summit-north-america-2022\">Open Source Summit NA 2022</Link> , catch guest <Link to=\"https://layer5.io/community/members/lee-calcote\">Lee Calcote</Link> from Layer5 and host Alan Shimel discuss the power of <Link to=\"/projects\">Layer5 projects</Link> in managing service meshes, Kubernetes and the rest of your cloud native infrastucture. They also dive into some of the other network-centric CNCF projects like CoreDNS and gRPC. Tune in now! \n</p>\n <Button primary url=\"https://digitalanarchist.com/videos/open-source-summit-na-2022/lee-calcote-layer5\" className=\"btn-center\" >\n <h3>Check out the TechStrong TV Interview with Layer5!</h3>\n </Button>\n</ResourcesWrapper>\n","frontmatter":{"title":"TechStrong TV Interview","type":"Interview","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAADQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBUesX6ZASr6rLojbUAA/q2Y4OjbO04hKhCcWYa4hSfBkj5L39LSxqIGpOMe19Y5zEFgVSsDNDPZ8LN767ayRpz7k7XG9zzlYAjzCCt9H6JybGgtwZ/88yp1/dYqEE/HQKxd2wcpSbNcL2/Tg/UxwwAAAA=="},"images":{"fallback":{"src":"/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp","srcSet":"/static/25aeb82dc80044f21493d0295ca3b84b/0b2ce/techstrong.webp 750w,\n/static/25aeb82dc80044f21493d0295ca3b84b/ce61b/techstrong.webp 1080w,\n/static/25aeb82dc80044f21493d0295ca3b84b/9469d/techstrong.webp 1366w,\n/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5166666666666666}},"extension":"webp","publicURL":"/static/25aeb82dc80044f21493d0295ca3b84b/techstrong.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAADQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBUesX6ZASr6rLojbUAA/q2Y4OjbO04hKhCcWYa4hSfBkj5L39LSxqIGpOMe19Y5zEFgVSsDNDPZ8LN767ayRpz7k7XG9zzlYAjzCCt9H6JybGgtwZ/88yp1/dYqEE/HQKxd2wcpSbNcL2/Tg/UxwwAAAA=="},"images":{"fallback":{"src":"/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp","srcSet":"/static/25aeb82dc80044f21493d0295ca3b84b/0b2ce/techstrong.webp 750w,\n/static/25aeb82dc80044f21493d0295ca3b84b/ce61b/techstrong.webp 1080w,\n/static/25aeb82dc80044f21493d0295ca3b84b/9469d/techstrong.webp 1366w,\n/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5166666666666666}},"extension":"webp","publicURL":"/static/25aeb82dc80044f21493d0295ca3b84b/techstrong.webp"}},"fields":{"slug":"/resources/interview/techstrong-tv-interview"}},{"id":"2aa90303-18d9-549c-b397-e694e16459c9","body":"\n\n\n\n<ResourcesWrapper>\n\n<p>\n  Istio Virtual Service defines a set of traffic routing rules to apply when host is addressed. Each routing rule defines standards for the traffic of a specific protocol. If the traffic is matched, then it is sent to a named destination service defined in the registry.\n</p>\n\n<p>\n  The source of traffic can also be matched within a routing rule that allows routing to be customized for every specific client context.\n</p>  \n\n<div className=\"fact-left\">\n<p>\n  The below example on Kubernetes routes all HTTP traffic by default to pods of the reviews service with the label “version: v1”. Additionally, HTTP requests with path starting with /wpcatalog/ or /consumercatalog/ will be rewritten to /newcatalog and sent to the pods with label “version: v2”.\n</p>\n</div>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews-route\nspec:\n  hosts:\n  - reviews.prod.svc.cluster.local\n  http:\n  - name: \"reviews-v2-routes\"\n    match:\n    - uri:\n        prefix: \"/wpcatalog\"\n    - uri:\n        prefix: \"/consumercatalog\"\n    rewrite:\n      uri: \"/newcatalog\"\n    route:\n    - destination:\n        host: reviews.prod.svc.cluster.local\n        subset: v2\n  - name: \"reviews-v1-route\"\n    route:\n    - destination:\n        host: reviews.prod.svc.cluster.local\n        subset: v1\n\n```\n<h2>Virtual Service Configuration Affecting Traffic Routing </h2>\n\n<p>A single Virtual Service can be used to describe all the traffic properties of the hosts, including those for multiple HTTP and TCP ports.</p>\n\n<div>\n  <h3>Hosts</h3>\n  <ul>\n    <li>\n      The application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). \n      As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB). \n    </li>\n    <li>\n      The destination hosts to which traffic is being sent it could be a DNS name with wildcard prefix or an IP address depending on the platform.\n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>Gateways</h3>\n  <ul>\n    <li>\n      The names of gateways and sidecars that should apply all these routes. Gateways in other namespaces may be referred to by <code> gateway namespace>/gateway name </code>; specifying a gateway with no namespace qualifier is the same as specifying the VirtualService’s namespace.\n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>HTTP</h3>\n  <ul>\n    <li>\n      An ordered list of route rules for HTTP traffic. The HTTP routes will be applied to the platform service ports named <code>‘http-’/‘http2-’/‘grpc-*’, gateway ports with protocol HTTP/HTTP2/GRPC/ TLS-terminated-HTTPS </code> and service entry ports using HTTP/HTTP2/GRPC protocols.\n    </li>\n    <li>\n      The first rule is matching an incoming request which is used.\n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>TCP</h3>\n  <ul>\n    <li>  \t\n      An ordered list of all the routing rules for opaque TCP traffic. TCP routes will be applied to any of the port which is not a HTTP or TLS port. \n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>ExportTo</h3>\n  <ul>\n    <li>  \t\n      Exporting a virtual service allows it to be used by the sidecars and the gateways defined in other namespaces. \n    </li>\n    <li>  \t\n      If no namespaces are specified then the virtual service is exported to all namespaces by default.\n    </li>\n  </ul>\n</div>\n\n<h2>\n  Destination\n</h2>\n\n<p>\n  A destination indicates that the network addressable service to which the request/connection will be sent. A DestinationRule defines policies that apply to traffic intended for a service after routing has occurred.\n</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews-destination\nspec:\n  host: reviews.prod.svc.cluster.local\n  subsets:\n  - name: v1\n    labels:\n      version: v1\n  - name: v2\n    labels:\n      version: v2\n\n```\n<div className=\"fact-left\">\n<p>A version of the route destination is identified with a reference to a named service subset which should be declared in a corresponding DestinationRule.</p>\n</div>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Istio Virtual Service","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"}},"fields":{"slug":"/resources/service-mesh/istio-virtual-service"}},{"id":"de0c7552-7a04-5f35-8a06-4b6842d35504","body":"\n\n\n<BlogWrapper>\n\n<p>Hola folks, </p>\n<p>As a contributor, each of us is always striving hard in the ocean to open more and more pull-requests, but being a contributor just doesn&#39;t mean only raising PRs, it also means reviewing other PRs, pointing out mistakes, helping others in improving the code-quality/code-reusability/code-readability, helping in finding missing edge-cases that haven&#39;t been tackled yet, giving your opinions, writing LGTM, CITY helps nothing but just improving the confidence and engagement of the PR author.</p>\n<p>So put on your <strong>Quality Tester</strong> hats because here I&#39;ll talk about how to test the PRs with the label <code>component/mesheryctl</code> i.e. pull-requests related to <code>mesheryctl</code></p>\n<p>Okay before we start, I&#39;ll like to tell you about <a href=\"https://github.com/cli/cli\">GitHub CLI</a>, it helps you checkout PRs very easily in your local system.</p>\n<ol>\n<li><p>The very first step is to review the PR, suggest changes if you think of any, ask queries, help the author to improve the code quality/readability/reusability, ask questions because asking helps you learn asking more better questions next time.</p></li>\n<li><p>PR authors either attach a video showcasing expected behavior or add written instructions about their fix under <strong>User Acceptance Behavior</strong></p></li>\n<li>\n<p>Now it&#39;s the time to checkout PR in your local system, we can check out any PR like this</p>\n<pre><code className=\"language-bash\">gh pr checkout https://github.com/meshery/meshery/pull/4823</code></pre>\n</li>\n<li>\n<p>You can check if you&#39;re into the same branch as the PR author with </p>\n<pre><code className=\"language-bash\">git branch</code></pre>\n</li>\n<li>\n<p>Well, if we&#39;re testing a PR related to mesheryctl, we need to build the binary from the same branch. change your directory to <code>mesheryctl</code> folder and run</p>\n<pre><code className=\"language-bash\">make</code></pre>\n<p>This will create a mesheryctl binary according to your OS in the same directory</p>\n</li>\n<li><p>Now it&#39;s time to test out this newly built binary according to what&#39;s been tackled in the PR and related issues. For e.g. <code>system start</code> has some new functionality, make sure you followed the pull-request/linked-issue instruction for env setup, as sometimes fix/features are tackling an issue with a specific type of environment.</p></li>\n</ol>\n<pre><code className=\"language-bash\">./mesheryctl system start </code></pre>\n<p>the <code>./</code> helps us in using the newly built cli-binary present in the current directory which we built in 5th step</p>\n<ol start=\"7\">\n<li>make sure we have a similar experience as mentioned in the Video or the instructions added to the PR. but the wait is it okay to give green flags to the PR? not yet tbh. We as a tester should turn a little evil and think of the relevant situations/environments which might not have been tackled but should be(basically we&#39;re trying to break the new feature/fix)</li>\n<li>After spending a good amount of time testing the new behaviors, old standard behaviors, new test cases, few edge cases. We can provide new insights to the PR author about the behavior in your system, depending on our experience we can ask the PR author to address our new queries, or we can appreciate the work, or give green flags to the PR.</li>\n</ol>\n<p>Wow, that was a ton of work there. well being a Tester is tough but very important before we merge pull requests. Every PR should be marked green with end-to-end testing before merging, we as a project are using GH Workflows to perform standard golang-testing but manual end-to-end testing completely removes margins of error.</p>\n\n</BlogWrapper>\n","frontmatter":{"title":"Validating Meshery CLI Functionality","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uoJKMhsAgBABoJZwCdADBsAAD+8CVGzfndbE6d1gAA"},"images":{"fallback":{"src":"/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp","srcSet":"/static/9156c22b67aedb4c9c71f4951b06f17f/a4fab/thumbnail.webp 750w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16baf/thumbnail.webp 1080w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/5eb4b/thumbnail.webp 1366w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp 1895w","sizes":"100vw"},"sources":[]},"width":1,"height":0.36358839050131925}},"extension":"webp","publicURL":"/static/9156c22b67aedb4c9c71f4951b06f17f/thumbnail.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uoJKMhsAgBABoJZwCdADBsAAD+8CVGzfndbE6d1gAA"},"images":{"fallback":{"src":"/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp","srcSet":"/static/9156c22b67aedb4c9c71f4951b06f17f/a4fab/thumbnail.webp 750w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16baf/thumbnail.webp 1080w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/5eb4b/thumbnail.webp 1366w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp 1895w","sizes":"100vw"},"sources":[]},"width":1,"height":0.36358839050131925}},"extension":"webp","publicURL":"/static/9156c22b67aedb4c9c71f4951b06f17f/thumbnail.webp"}},"fields":{"slug":"/blog/meshery/validating-meshery-cli-functionality"}},{"id":"d3755e16-1694-5614-8d5f-5fe6f590fc95","body":"\n\n\n\nimport oldDesign from \"./initial-design.webp\";\nimport newDesign from \"./mesheryctl-docs.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro\">\n<p>Documentation plays a major role in any project. Even if the project is small or too big, the creator or the team behind the project needs to curate the documentation very well such that it'll be useful for new end users to refer and learn to use the project, troubleshoot the problems occurred and lot more. Thus, we, Layer5 have curated the documentation for Meshery to meet such purposes. Not to mention, <code>mesheryctl</code>, the CLI client of Meshery needs a curated documentation as well. This blog describes about the evolution of <code>mesheryctl</code> command reference page. </p>\n</div>\n\n<h3>Initial Command Reference Design</h3>\n<p>\nThe initial design of <code>mesheryctl</code> command reference page is all made using pure markdown and the functionality is handled using Jekyll, the main framework used for Meshery Docs. This handled great at initial stage but had many limitations, such as:\n    <ul>\n        <li>Updation of YAML for data is often required</li>\n        <li>Design was obselete at initial stage</li>\n        <li>No separate pages for each command and subcommand</li>\n    </ul>\n    Thus, the idea for redesigning the <code>mesheryctl</code> reference page was desperately needed.\n    </p>\n    <p><a href=\"https://docs.meshery.io\" alt=\"Meshery Documentation\" target=\"_parent\">\n    <img src = {oldDesign} className=\"image-center-shadow\" alt=\"Initial design of mesheryctl command reference\" /></a></p>\n\n<h3>Updated Command Reference Design</h3>\n<p>To tackle the shortcomings of the previous design, I was tasked to redesign the <code>mesheryctl</code> command reference page entirely. This was a big task at first glance to me, as I was a new contributor back then. Eventually after manipulating the reference section with help of great folks, I was able to pull off the task and the design was updated. </p> \n<p>\n    <a href=\"https://docs.meshery.io\" alt=\"Meshery Documentation\">\n<img src={newDesign} className=\"image-center-shadow\" alt=\"Meshery CLI command reference\" /></a>\n</p>\n<p>The redesign work was done with help of HTML in markdown and with optimization in YAML code. A sample is given below.</p>\n\n```\n    <!-- Copy this template to create individual doc pages for each mesheryctl commands -->\n\n    <!-- Name of the command -->\n    # mesheryctl mesh\n\n    <!-- Description of the command. Preferably a paragraph -->\n    ## Description\n\n    {% assign name = site.data.mesheryctlcommands.cmds[page.command] %}\n    {{ name.description }}\n\n    <!-- Basic usage of the command -->\n    <pre className=\"codeblock-pre\">\n    <div className=\"codeblock\">\n    mesheryctl mesh [flags] \n    </div>\n    </pre>\n    ...........\n```\n\n<h3>Adding auto generation feature in reference</h3>\n<p>As time passed, we realized that the command reference missed something for a while, though the design has been changed. Then, we thought the idea of automating the generation of docs such that developers don't need to change the code in docs section while working towards <code>mesheryctl</code>. That's where we got to know that Cobra library (the library for CLI apps made using golang) has a feature to make doc pages automatically. So we decided to incorporate that feature into <code>mesheryctl</code> docs page as well! After making several changes and a PR, I was finally able to introduce the feature in the docs site!</p>\n\n```\nvar startCmd = &cobra.Command {\n\tUse:   \"start\",\n\tShort: \"Start Meshery\",\n\tLong:  `Start Meshery and each of its service mesh components.`,\n\tArgs:  cobra.NoArgs,\n\tExample: `\n// Start meshery\nmesheryctl system start\n// To create a new context for in-cluster Kubernetes deployments and set the new context as your current-context\nmesheryctl system context create k8s -p kubernetes -s\n// (optional) skip checking for new updates available in Meshery.\nmesheryctl system start --skip-update\n// Reset Meshery's configuration file to default settings.\nmesheryctl system start --reset\n// Silently create Meshery's configuration file with default settings\nmesheryctl system start --yes\n.....\n}\n\t`,\n```\n\n<p>Using this information provided above in each golang file, the markdown page is generated using Cobra CLI library and thus reducing the workload on the developer by automating via <a href=\"https://github.com/meshery/meshery/blob/master/.github/workflows/mesheryctl-ci.yml#L73\">GitHub Actions</a>.</p>\n<br />\n<p>This is so far on how the <code>mesheryctl</code> command reference is evolved for now. And I hope that it'll continue to evolve in the field of documentation to serve the users to use Meshery in best way possible.</p>\n</BlogWrapper>\n","frontmatter":{"title":"Evolution of the Meshery CLI Command Reference","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABwBACdASoUAA0APtFWpEuoJKOhsAgBABoJbACdMoGvtgJwx880HleA8ofTgAD+2VgctvGN2cFdfAJj4YJ0Ha8AiiMSiWh82G/yk9ZshKIR54QST0HBPk98AjqzxGHfuVZiMjvT9XDm39S3tEJ+oAAA"},"images":{"fallback":{"src":"/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp","srcSet":"/static/8b8429808b6e7381fa812bf1f5d29572/f06bf/mesheryctl.webp 750w,\n/static/8b8429808b6e7381fa812bf1f5d29572/8c7d4/mesheryctl.webp 1080w,\n/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6316666666666667}},"extension":"webp","publicURL":"/static/8b8429808b6e7381fa812bf1f5d29572/mesheryctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABwBACdASoUAA0APtFWpEuoJKOhsAgBABoJbACdMoGvtgJwx880HleA8ofTgAD+2VgctvGN2cFdfAJj4YJ0Ha8AiiMSiWh82G/yk9ZshKIR54QST0HBPk98AjqzxGHfuVZiMjvT9XDm39S3tEJ+oAAA"},"images":{"fallback":{"src":"/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp","srcSet":"/static/8b8429808b6e7381fa812bf1f5d29572/f06bf/mesheryctl.webp 750w,\n/static/8b8429808b6e7381fa812bf1f5d29572/8c7d4/mesheryctl.webp 1080w,\n/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6316666666666667}},"extension":"webp","publicURL":"/static/8b8429808b6e7381fa812bf1f5d29572/mesheryctl.webp"}},"fields":{"slug":"/blog/meshery/evolution-of-the-meshery-cli-command-reference"}},{"id":"f2515b37-8209-5754-a3b5-ced2ef4f9551","body":"\n\nimport istiosecurityarch from \"./istio-securityarch.svg\"\n\n\n<ResourcesWrapper>\n<div className=\"intro\">\n<p>\nIstio is a massive project with a wide range of capabilities and deployment options. We will learn about the Istio’s authorization policy with an example .\n</p>\n</div>\n\n<p>\n    <h2>Let’s see Istio’s Security Architecture </h2> \n    </p>\n<p>\n    Before we directly jump into Istio's Authorization policies let's have a glance at Istio's Security architecture. The below diagram is directly referenced from Istio documentation. From the control plane, users can create things like authorization policies authentication policies, and policies will get translated into envoy config and streamed bent the varied proxies that form up the service mesh, on the information plane side there is east-west traffic from service b to c and also the actual communication takes place through sidecar proxies. If the traffic is entering it moves to the Ingress gateway and if it’s leaving it can attend the Egress gateway in between all this we will apply JWT enforcements.\n</p>\n<p>\n  <img src={istiosecurityarch} align=\"center\" alt=\"comparative spectrum\" />\n</p>\n<h2> Istio includes a high-level architecture that involves multiple factors such as:</h2>\n\n<p>\n<ul>\n    <li>  Certificate Authority for key and certificate management </li>\n    <li> Sidecar and perimeter proxies work as Policy Enforcement Points to secure communication between the clients and servers. </li>\n    <li> A set of Envoy proxy extensions is there to manage telemetry and auditing </li>\n\n</ul>\n</p>\n\n<h2> Istio’s Authorization policies</h2>\n<p>\n    <ul>\n    <li>  Workload-to-workload and end-user-to-workload authorization. </li>\n    <li> A Simple API includes one single Authorization Policy, which is easy to use and maintain.</li>\n    <li>Flexible semantics: operators can define custom conditions on Istio attributes, and use DENY and permit actions. </li>\n    <li>  High performance: Istio authorization gets enforced natively on the Envoy. </li>\n    <li> High compatibility: supports gRPC, HTTP, HTTPS, and HTTP2 natively, additionaly as well as any plain TCP protocols. </li>\n\n</ul>\n</p>\n\n<h2>\n    Example Authorization Policy\n</h2>\n<p>\nIn this example, we allow access to our service httpbin in namespace foo from any JWT (regardless of the principle) to use the GET method.\n</p>\n\n``` \napiVersion: \"security.istio.io/v1beta1\"\nkind: \"AuthorizationPolicy\"\nmetadata:\n  name: \"allow-reads\"\n  namespace: foo\nspec:\n  selector:\n    matchLabels:\n      app: httpbin\n  rules:\n  - from:\n    - source:\n        principals: [\"*\"]\n    to:\n    - operation:\n        methods: [\"GET\"]\n\n```\n<h2>Access Flow with Auth Policies</h2>\n\n<p>\n    There is some logic behind how authorization is set given defined AuthorizationPolicies. Below is that the flow as taken directly from the Istio documentation.\n    </p>\n<ul>\n    <li>If there are any CUSTOM policies that match the request, evaluate and deny the request if the evaluation result's is deny.</li>\n    <li>If there are any DENY policies that match with the request, deny the request.</li>\n    <li>If there are not any ALLOW policies for the workload, allow the request.</li>\n    <li>If any of the ALLOW policies gets match with the request, allow the request.</li>\n    <li>Deny the request.</li>\n</ul>\n\n\n</ResourcesWrapper>","frontmatter":{"title":"Istio Authorization Policy","type":"Article","technology":"Docker","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"}},"fields":{"slug":"/resources/service-mesh/istio-authorization-policy"}},{"id":"10d40198-40a0-5d1e-8617-a75e432b771e","body":"\n\n\n\n\nimport { PerfbytesPodcast } from \"./perfbytesPodcast\";\nimport ConsulDemo from \"./consul-docker-extension-demo.webp\"\n\n<BlogWrapper>\n<PerfbytesPodcast>\n\n<h2>Podcast Insights</h2>\n<p>Many questions were asked, answered, and a variety of topics were discussed. The story just gets better. This podcast goes deep into service meshes, load generators, circuit breaker, service mesh patterns in addition to a live demo of <Link to=\"/cloud-native-management/meshery\">Meshery</Link> and more. Hosted by Henrik from Perfbytes and joined by Mark, <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> from Layer5 and Mrittika Ganguli from Intel. Tune in to find out more. Get answers to all community questions as a bonus.</p>\n\n<h3>What is a service mesh?</h3>\n<div className=\"answer\">\n<p>Service mesh is one of the solutions that helps you to route traffic within your cluster so as to expose your services outside the cluster. It is a solution to control how different parts of an application share data with one another. Unlike other systems for managing this communication, a service mesh is a dedicated infrastructure layer built right into an app. You have different options like the service type load balancer or using ingress but service mesh makes sense because it will manage a lot of features around your service to service communication.</p>\n</div>\n\nIn general, service meshes arose from the concept of proxies such as the NGINX proxy. Then Envoy was introduced by Lyft. Lyft had the architecture, and Google came along and created it. That gave us Istio, which is now part of CNCF. \n<Blockquote\n  quote=\"We were slugging it out in our labs trying to figure out how to do performance benchmarking with a service mesh. Instead of ten tools, if we had just one, it would be nice. Then we see Meshery come into the field\"\n  person=\"Mrittika\"\n/>\n\nService meshes, according to Lee, \"hit a real sweet spot personally\", having been focused on networking for most part of his career.\nHe believes that there are a couple of different ways to speak about the genesis of service meshes, with Linkerd being the first to coin the term.\nWe had Linkerd v1 written in scala and use jvm and then came Linkerd v2 which is something totally different at this point. It's all different code, different languages and  a different service mesh architecture. There's a number of different architectures by which service meshes are deployed. There's a new one that's been softly announced in beta from called Cilium that is helping bring back some of the different architectures of how to run the proxies.\n\n<div className=\"intro\">\n<p>\nThe way I prefer to think about a surface mesh is that it's all about resiliency.\nIf you were to take a three-tiered web or three-tiered app and you think about how you're breaking out those tiers with some amount of\nkind of vertical scaling,  you'd probably, end up putting at least a virtual IP address out in front of the whole web tier and then you've got an app tier and a database tier because you've got multiple instances of those things. Maybe there's a load balancer in between.  This structure makes it simple to boost your resiliency.\n</p>\n</div>\n\nHenrik goes on to elaborate that in service mesh we can do a lot of things to make sure that the communication is reliable. \nWhen you design microservice architecture, there is a need of implementing retry logic. So if a service A needs to introduce another service B, then the service mesh will manage the retry logic such that if we reach at one time and the service B is not responding then the service mesh will try to reach out several times. Therefore a service mesh offers a variety of features like this to manage the certificates within the cluster and and circle them in a regular pace. You can also have traffic splitting if you do canary releases. In your service to service communication, there are a plethora of scenarios that the service mesh can handle.\nHenrik recalled that it's normally difficult to obtain a full view of what rules we've applied in the cluster, and when he first saw Meshery, his immediate thought was, \"Wow, this is exactly what is missing in the market at the moment.\"\n\n\nLets dig deeper into this tool we've been alluding to for a while now: <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.\n\n<h3>Meshery</h3>\nIf you were on a pager and were managing a large service mesh deployment with a number of rules and configurations around how security is enforced and identities are managed, and things like uniform observability and how metrics and logs are collected and enforced, and then the different traffic writing rules and stuff. You might soil myself if you had to go make a change in that sea of yaml. That's in part what we're working towards. There's a capability within Meshery for solving this challenge. As a cloud native management plane, Meshery presides over top of 10 different types of service meshes and it also presides over kubernetes. You can run it outside of kubernetes or inside of kubernetes.\n<p>\nMeshery has a number of components to its architecture. There is Meshery UI. It has a Mesheryctl, which is a CLI component. We have a number of service mesh adapters for each service mesh that Meshery supports.\n</p>\n\n<h5>What is the need for different adapters?</h5>\n<div className=\"answer\">\nMeshery, as the multi-mesh manager, supports couple of different adapters. Adapters are used by Meshery to manage the numerous service meshes. Different service mesh adapters are written to expose the unique value of each service mesh. Consequently, they are not equally capable just as each service mesh is not equally capable as the other. Some of them work in a similar way. Some of the service meshes have their own differentiated value, which is why there are individual adapters. Some of them work slightly differently depending on whether they're running as a managed service or not.\n</div>\n\n\nWe have a plug-in for Meshery it's called <Link to=\"/meshmap\">MeshMap</Link>, it is what you might consider a visual topology. It has a lot of use cases for observing in kind of a read-only mode. There's a second mode to this tool: The Designer Mode. It's a visual configurator of not only the specific settings within any of those service meshes that it supports like a circuit breaker and adjusting the sensor video\nbut also end up being a visual designer for your kubernetes deployments. When users drop in, they're able to go over and grab the specific capabilities of any of those service mesh adapters that are loaded for any of the versions of that mesh that they might want to design. The concept here is that they drag and drop these capabilities over and there's a bit of discoverability that's afforded through this ui rather than parsing through yaml, trying to understand what's going on.\n\n<img src={ConsulDemo} alt=\"Consul MeshMap Demo\" className=\"slides-right\" />\n\nI like to pretend that I know a lot about service meshes, but when it comes to having to keep track of all of them, I don't know what the gateway tls sds config is, and so this type of inline help is quite useful to design your deployments. The deployments may or may not use a mesh; in fact, you can use this to create your Kubernetes configuration and deployment as well.  You can even save and recall those designs.\n\nTaking this example of consul, produced by hashicorp, is a little more of an\nintriguing deployment and a simple two-tier deck.  We announced the <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> recently. So if you're using docker desktop, Meshery will be a first class app that's available inside of market and part of what it does as it integrates with docker desktop is it will import docker compose apps convert them to kubernetes manifests or kubernetes apps and they'll let you deploy those formerly docker compose apps onto a mesh which is why I'm talking about a two-tiered service.\n\n<h5>Does MeshMap allow you to load the current configuration that is has been applied in the current cluster?</h5>\n<div className=\"answer\">\nCurrently, there are two modes: the one we were looking at before was the designer mode, and the one we'll be looking at now is the visualizer mode, which is probably a little more of an it's not entirely read-only to the extent that you could grab a pod and start an interactive session with the containers in that pod or you could you start a logging session. You could also initiate a performance test against  that particular service or that particular endpoint. \nMeshery supports three different types of load generators, which is a nighthawk, fortio and wrk2. \n</div>\n\n<h5>What are the capabilities of these three load generators? When you speak about service mesh testing or performance testing, what is actually the process behind the scene? What should users think about when they're starting a gig and need to configure and optimize the service mesh?</h5>\n<div className=\"answer\">\n<p>Lee expounds on that for our benefit. \nIt takes weeks to months that you've got to dedicate for performance engineers to go over and like pull together various tools and scripts around them to then get into a spreadsheet or into some database that you then generate results. \nThe genesis of Meshery part was to help people comprehend what a service mesh is, when to use one and which one to use?  As you go to explain these common questions, the real answer is a totally disappointing, which is, it just depends on what you're asking to do.  </p>\n<p>\nPeople want to measure it in cold hard quantitative metrics but if you're asking to do 100 percent sampling then also consider the distributed tracing implementation you had somewhere else and the fact that you're getting it\nin a uniform way here. Maybe you're likely to consider the overhead that you would have over there. It's frustrating to be trying to explain stuff to folks and get them excited about the tech and and to give them a vague response. Instead we give them a tool that says \"Hey look here's a tool that will deploy any of the service meshes that you want to test out.\" \n</p>\n<p>\nThere's a reason why there's ten of them like and actually many more than that.\nThere's a lot of overlap between them but different tools for different purposes for different size orgs, so it would be inappropriate to say well you know here's the one. It's rather hey here's a tool that that lets you deploy any number of them quickly, answer your own question about performance, because we can pump out benchmarks of the various service meshes under various configurations, using different types of workloads but which may or may not match your environment and over time those reports are going to get stale and so rather he's a tool to make you empowered.\n</p>\n</div>\n\n<h5>Do you actually generate traffic that will go through the sidecar proxy of the service and then reach out the actual service?</h5>\n<div className=\"answer\">\nThat load is generated on demand or on schedule against one or more endpoints, one or more of your services or something that is not even on your service. You can generate load not only against something running within your infrastructure but something external as well to do statistical analysis based on the configuration that you gave it and so yeah the answer is yes the traffic flows through the sidecar.\n</div>\n\n<h5>If I say I have never scripted or built any scenarios for fortio or nighthawk. Let's say I'm a loadrunner, a neoload, or a k6 user, and I want to accomplish the same thing with them. So what is the journey on those load generator? is it the same thing you have to build a workflow of requests that you want to send in that scenario?</h5>\n<div className=\"answer\">\n<p>That leads us to probably talk about one of our other projects which is called <Link to=\"/projects/service-mesh-performance\">Service Mesh Performance</Link> which is a specification. It's another one of the projects that we've donated to the CNCF. Service Mesh Performance is the spec while Meshery is an implementation of the spec. At a high level, if those other load generators were to adhere to how we standardize and describe the test that you want to run and then hand off that configuration to generate the performance profiles that are created here  you're not gonna down download them but the descriptor is important.</p>\nThis implements a standard for the industry on what is the actual\nservice mesh test and then standardize the format so then anyone can use the same format to design their script or whatever they want and then use it to test. \nSo when I build a script, and I don't know loadrunner today and I want to use neologo tomorrow, then I don't have to rewrite everything. Great!\n</div>\n\nMissed the podcast? No worries, we got you covered. Check out the recording below :)\n\n<div className=\"iframe-container\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dGMGUocTvOk\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen></iframe>\n</div>\n\n\n</PerfbytesPodcast>\n</BlogWrapper>\n","frontmatter":{"title":"Perfbytes Podcast","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/4b1ebefd3c3c7dd448c0c60c75b58356/perfbytes-layer5.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/4b1ebefd3c3c7dd448c0c60c75b58356/perfbytes-layer5.svg"}},"fields":{"slug":"/blog/events/perfbytes-podcast"}},{"id":"b171f9fc-a31b-5e80-ba6b-cd0f83878e10","body":"\nimport bugEnvoy from \"./debug-envoy-proxy.svg\";\n\n\n<BlogWrapper>\n<p>\n    Trying to figure out what's happening with your request traffic? Not sure why your Envoy configuration isn't working? If you're using Istio as your gateway and need to troubleshoot your ingress traffic requests, here are a few tips for debugging Envoy proxy.\n</p>\n<h2>Enable Envoy Debug Logging</h2>\n<p>\n  By default Envoy system logs are sent to <code>/dev/stderr</code>. This location be overridden using <code>--log-path</code>. Logging to <code>/dev/stderr</code>  for system logs and to <code>/dev/stdout</code> for access logs can be useful when running Envoy inside a container. In this way, these two individual logstreams can be separated, and using this approach, logging requires no additional files or directories to be mounted.\n</p>\n<div className=\"intro\">\n<p>\n  We recommend setting the Envoy proxy’s log level to debug in a pre-production environment. Debug logs can help you identify issues before you graduate the associated configuration to your production environment.\n</p>\n</div>\n<h3>Using envoy CLI</h3>\n<p>\n  The envoy command has a <code>--log-level</code> flag that can be useful for debugging. By default, it’s set to info. To change it to debug, edit the envoy DaemonSet in the istio-system namespace and replace the <code>--log-level info</code> flag with <code>--log-level debug</code>. Setting the Envoy log level to debug can be particilarly useful for debugging TLS connection failures.\n</p>\n<h3>Using container image</h3>\n<p>\n  If you’re using the Envoy image, you can set the log level to debug through the <code>ENVOY_LOG_LEVEL</code> environment variable. The log level for Envoy system logs can be set using the <code>-l</code> or <code>--log-level</code> option.\n</p>\n\nThe available log levels are:\n\n<ul>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>trace</li>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>debug</li>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>info</li>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>warning/warn</li>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>error</li>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>critical</li>\n  <li className=\"highlight\" style={{width: \"fitContent\"}}>off</li>\n</ul>\n\nThe default is <span className=\"highlight\">info</span>.\n\n<h3>Setting Envoy logs in the Helm configuration</h3>\n\n<p>\n  The Consul helm chart uses <code>envoyExtraArgs:</code> to leverage Envoy command line options. One of the helpful options is <code>--component-log-level</code>. This provides granular control over setting log levels for Envoy components. In the example below, the components upstream, http, router and config are set to the debug log level. These four components are vital when debugging issues with requests between your services(sidecar proxies).\n</p>\n\n<div>\n  <pre>\n    <code>connectInject:\n  enabled: true\n  envoyExtraArgs: \"--component-log-level upstream:debug,http:debug,router:debug,config:debug\"</code>\n  </pre>\n</div>\n\n<p>\n  If you haven't set envoyExtraArgs: in consul-values.yaml just yet, you can set the log levels on the fly by using the following kubectl command:\n</p>\n\n<div>\n  <pre>\n    <code>$ kubectl exec pod/pod-name -c container-name -- curl -X POST http://localhost:19000/logging?config=debug</code>\n  </pre>\n</div>\n\n<p>Example:</p>\n\n<div>\n  <pre>\n    <code>$ kubectl exec pod/static-client-5bf4575d9c-zr2b -c static-client -- curl -X POST  http://localhost:19000/logging?config=debug</code>\n  </pre>\n</div>\n\n<p>\n  You will execute the kubectl command for each component. Make sure to append the correct component at the end of the curl command, i.e. <code>logging? component = debug</code>.\n</p>\n\n<p>\n  If curl is not able to be used in your pod, you can alternatively use <code>kubectl port-forward pod-name 19000</code> to make the Envoy admin accessible. From another terminal window, you can then curl to change the log levels. The output you receive in the terminal will show the modified component log levels.\n</p>\n\n<div>\n  <pre>\n    <code>$ curl -X POST http://localhost:19000/logging? component = debug</code>\n  </pre>\n</div>\n<h3>Access Envoy logs in Kubernetes</h3>\n\n<p>Accessing Envoy logs via pods can be done with the following command:</p>\n\n<div>\n  <pre>\n    <code>$ kubectl logs --follow pod/ pod-name -c envoy-sidecar</code>\n  </pre>\n</div>\n\n<p>The --follow flag provides a real time observation into Envoy logs. </p>\n\n<h3>Setting and Accessing Envoy logs when not using Helm.</h3>\n\n<p>The following command will start an envoy side car proxy, set the log level to debug with -l debug and capture Envoy logs in envoy_logs.txt. The .txt file will need to be created before executing this command.</p>\n\n<div>\n  <pre>\n    <code>$ consul connect envoy -sidecar-for counting-1 -- -l debug --log-path envoy_logs.txt</code>\n  </pre>\n</div>\n\n<p>To have granular control over the Envoy components that is needed to be debugged, use the following command:</p>\n\n<div>\n  <pre>\n    <code>$ consul connect envoy -sidecar-for counting-1 -- --log-path envoy_logs.txt --component-log-level upstream:debug,http:debug,router:debug,config:debug</code>\n  </pre>\n</div>\n\n<h2>Find your Istio Ingress Gateway</h2>\n<p>\n  With Istio as your gateway, you should first look at <code>VirtualService</code> objects. These can show if the hosts are registered to the gateway correctly.\n</p>\n\n<div>\n  <pre>\n    <code>$ kubectl get virtualservice -o=yaml</code>\n  </pre>\n</div>\n\n<p>\n  However, sometimes, the <a  className=\"highlight\" href=\"https://envoyproxy.io\">Envoy</a> inside the gateway container is not properly configured (likely due to a bug). You can dump Envoy configuration to debug this further.\n</p>\n\n<div>\n  <pre>\n    <code># find istio ingress gateway pod \\\n      $ kubectl get pods -n istio-system -l app=istio-ingressgateway</code>\n  </pre>\n</div>\n\n<p>\n  Let's use <code>istio-ingressgateway-a93019f9dfw-l39xd</code> as an example pod name.\n</p>\n\n<div>\n  <pre>\n    <code>\n      # enable debugging on envoy \\\n      $ kubectl exec --namespace=istio-system \\\n      istio-ingressgateway-a93019f9dfw-l39xd \\\n      -c istio-proxy -- curl -X POST \\\n      http://localhost:15000/logging?level=debug\n    </code>\n  </pre>\n</div>\n<p>\n  Then, use <code>istioctl</code> tool to dump route configuration (this will show the output from the <a href=\"https://www.envoyproxy.io/docs/envoy/latest/operations/admin#operations-admin-interface-config-dump\"><code>/config_dump</code> admin endpoint</a> on Envoy):\n</p>\n<div>\n  <pre>\n    <code>\n    $ istioctl proxy-config routes -n istio-system -o=json \\\n      istio-ingressgateway-a93019f9dfw-l39xd\n    </code>\n  </pre>\n</div>\n<p>\n  We hope these steps are useful to you. If you're still having trouble configuring Envoy proxy, open up a new thread on the <a href=\"https://discuss.layer5.io\" className=\"highlight\">community discussion forum</a> or subscribe to the <Link to=\"/subscribe\" className=\"highlight\">Layer5 newletter</Link> for tips and tricks.\n</p>\n\n</BlogWrapper>","frontmatter":{"title":"Debug Envoy Proxy","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/da5d909604f7704bb30151391b60cdbb/debug-envoy-proxy.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/da5d909604f7704bb30151391b60cdbb/debug-envoy-proxy.svg"}},"fields":{"slug":"/blog/envoy/debug-envoy-proxy"}},{"id":"0e3c402b-8ec4-5d70-ae25-47f401a3c656","body":"\n\n\n<NewsWrapper>\n\n<div className=\"test\">\n\nThe open source Service Mesh Performance project is getting a new metric called MeshMark to help organizations manage and measure cloud-native environments. In cloud-native environments, the use of service mesh technologies to connect different operations is a growing trend. What isn't always clear with a service mesh though is how well it's actually working.\n\nMeshMark, an open source effort jointly announced by Intel and service mesh startup Layer5 on May 18, looks to help organizations measure and quantify the performance and value of a service mesh deployment. MeshMark is part of the Service Mesh Performance project at the Cloud Native Computing Foundation (CNCF), which hosted its ServiceMeshCon EU event on May 18, co-located alongside KubeCon EU 2022.\n\n\"We're missing some performance characteristics,\" Lee Calcote, founder and CEO of Layer5 and co-chair of the CNCF Technical Advisory Group (TAG) Network, said during a ServiceMeshCon EU session. \"We have a need for a clear and concise way of conveying the characters and the performance of an environment.\"\n\n<h3>MeshMark Brings Metrics to Cloud-Native Service Mesh</h3>\n\nThe Service Mesh Performance project at its core is an effort to define specifications for capturing the details of a cloud-native environment in a uniform and consistent way, according to Calcote. In cloud-native environments, the use of service mesh technologies to connect different operations is a growing trend. What isn't always clear with a service mesh though is how well it's actually working.\n\nMeshMark, an open source effort jointly announced by Intel and service mesh startup Layer5 on May 18, looks to help organizations measure and quantify the performance and value of a service mesh deployment. MeshMark is part of the Service Mesh Performance project at the Cloud Native Computing Foundation (CNCF), which hosted its ServiceMeshCon EU event on May 18, co-located alongside KubeCon EU 2022.\n\n\"We're missing some performance characteristics,\" Lee Calcote, founder and CEO of Layer5 and co-chair of the CNCF Technical Advisory Group (TAG) Network, said during a ServiceMeshCon EU session. \"We have a need for a clear and concise way of conveying the characters and the performance of an environment.\"\n\nThe Service Mesh Performance project looks at capturing infrastructure and service mesh configuration details and then providing a means to characterize the details of running workloads. The project also aims to provide the details in a consistent approach that can enable organizations to develop a baseline for an environment, as well as benchmark in a consistent way. Simply being aware of what's running in a service mesh isn't quite enough though, and there is a need for a performance metric, which is where the new MeshMark effort comes into play. Mrittika Ganguli, principal engineer and network architect at Intel, explained that MeshMark is a cloud-native value measurement.\n\n\"With MeshMark, you're essentially trying to measure if the performance of your infrastructure matches what kind of business value you want to get from your deployment,\" Ganguli said.\n\nA business value could be defined with key performance indicators on, for example, how well video gets loaded on a particular webpage, she said.\n\n\"If you click on something, you may often see the text get rendered first and then the video,\" Ganguli said. \"The load latency of the video traffic is what impacts what you see visually.\"\n\nMeshMark aims to provide metrics that an organization can use to determine how resources are being used. Ganguli said that in a cloud-native environment an organization is utilizing different kinds of resources. The utilization classes include, for example, compute or network or any other type of resource.\n\nMeshMark provides an efficiency metric called Mesh Utilization Efficiency (MUE) that can help determine a score for a given resource utilization and the level of optimization. The MeshMark score will be able to help identify what the load latency is for a given workload, given the available resources. Overall, the goal with MeshMark is to take a number of different signals coming from a service mesh and combine them into an approach that can help organizations understand how well a deployment is, or isn't, working.\n\nThe need to better understand the performance of service meshes was further underscored by a report released on May 17 by the CNCF. The report found that 60% of surveyed organizations are using a service mesh in production today — and that key challenges for deployment of service meshes are a lack of guidance, blueprints, and best practices.\n\n</div>\n\n</NewsWrapper>\n","frontmatter":{"title":"Intel, Layer5 Announce MeshMark to Quantify Cloud-Native Performance","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAADwAgCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwAAUU0usAD+9hPekOv5EN4vIa+8oARkiR/1LCYUhAC/k+W3o2CuRwAAAA=="},"images":{"fallback":{"src":"/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp","srcSet":"/static/49cbc7ef20d9383088e20f773af6a13e/9860d/it-pro.webp 750w,\n/static/49cbc7ef20d9383088e20f773af6a13e/9ec3b/it-pro.webp 1080w,\n/static/49cbc7ef20d9383088e20f773af6a13e/20dcd/it-pro.webp 1366w,\n/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp 1540w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5194805194805194}},"extension":"webp","publicURL":"/static/49cbc7ef20d9383088e20f773af6a13e/it-pro.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAADwAgCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwAAUU0usAD+9hPekOv5EN4vIa+8oARkiR/1LCYUhAC/k+W3o2CuRwAAAA=="},"images":{"fallback":{"src":"/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp","srcSet":"/static/49cbc7ef20d9383088e20f773af6a13e/9860d/it-pro.webp 750w,\n/static/49cbc7ef20d9383088e20f773af6a13e/9ec3b/it-pro.webp 1080w,\n/static/49cbc7ef20d9383088e20f773af6a13e/20dcd/it-pro.webp 1366w,\n/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp 1540w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5194805194805194}},"extension":"webp","publicURL":"/static/49cbc7ef20d9383088e20f773af6a13e/it-pro.webp"}},"fields":{"slug":"/company/news/intel-layer5-announce-meshmark-to-quantify-cloud-native-performance"}},{"id":"44b1509f-0ba1-5ea3-9341-82abe59558cd","body":"\n\n\nimport slidesTAG from \"../../../events/kubecon-china-2021/cncf-tag-network-and-service-mesh-working-group-kubecon-china-2021-lee-calcote-ken-owens.pdf\";\n\nimport meshmark from \"./meshmark-dark-text-side.svg\";\nimport performanceQuestion from \"./performance-question.webp\";\nimport smp from \"./smp.webp\";\nimport meshmarkSlide from \"./meshmark.webp\";\nimport example from \"./example.webp\";\nimport formula from \"./formula.webp\";\nimport MUE from \"./mue.webp\";\nimport MeshMapDemo from \"./meshmark-score.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro \">\n<p>\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and <Link to=\"\">Mrittika Ganguli</Link> presented <i>MeshMark: Service Mesh value measurement</i> at ServiceMeshCon Europe 2022.\n</p>\n</div>\n\n<p>\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative product and technology leader, passionate about empowering engineers and enabling organizations. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement.  \n    <Link to=\"\"> Mrittika Ganguli</Link> is the Director Cloud Native Data Plane, Principle Engineer and Network Architect at Intel. \n</p>\n\n<img src={meshmark} alt=\"Developers need to access service mesh\" style={{display: \"block\", margin: \"0 auto 0.5rem\", width: \"40%\"}} />\n\n<p>\n<h2>What is Meshmark?</h2>\n</p>\n\n<p>\n MeshMark is a performance index that measures the value and overhead of your cloud native environment. By converting performance measurements into insights about the value of individual, cloud native application networking functions, MeshMark distills a variety of overhead signals and key performance indicators into a simple index. \n</p>\n\n<img src={performanceQuestion}  alt=\"Developers need to access service mesh\" style={{width: \"50%\", float: \"right\"}} />\n<p>\n<h3>Talk started with a question to audience: Missing performance characteristics?</h3>\n</p>\n\n<p>\n    <Blockquote className=\"pull-left\"\n    quote=\"We are missing some performance characteristics, as people has many metrics used to track environments it might take a while to articulate the characteristics performance of your environment.\"\n    person=\"Lee Calcote\"\n    />\n</p>    \n\n<h3>Lee Calcote explains about \"Business Performance\"</h3>\n\n<p>\nWe're quite frequently overlooking business performance, which is in large respect to why we're running the infrastructure in the first place. We usually talk about performance and cold, hard, quantitative speeds and feeds, but instead, I would submit to you that performance should absolutely be measured in terms of speeds and feeds, but it's a lot more meaningful to layer in the value and to quantify\nthe value that your infrastructure is providing. So we're really kind of missing the business performance aspects of what we're tracking, how we're characterizing.\n</p>    \n\n\n<img src={smp}  alt=\"Developers need to access service mesh\" style={{width: \"50%\", float: \"right\"}} />\n<h3>Introduction to Service Mesh Performance</h3>\n\n<p>\n    The Service Mesh Performance project falls under the umbrella of CNCF project. This project is, at its core, probably a specification for capturing the details of your environment in a uniform way, in a consistent way,\n    capturing your infrastructure configuration, your service mesh configuration, and characterizing the details of your workloads and doing so consistently such that you can baseline your environments.\n    You can benchmark them in a consistent way, share with others, maybe compare with the performance that others are having. To the extent that it's codified, you can have system to system exchange of this information.\n</p>\n\n\n<h2>Mrittika Ganguli introduces MeshMark with an example</h2>\n\n<p>\n    MeshMark is a Cloud Native value measurement, from value you are essentially trying to measure if the performance of your infrastructure matches what you want to get from your deployment,\n    what kind of value you want to get, business value you want to get from your deployment. So, for example, if you have some key performance indicators, do you want to measure whether the MeshMark value is directly responsible for how your video gets loaded or your image gets loaded on a particular webpage.\n    <p>\n    <Blockquote className=\"pull-right\"\n    quote=\"Are my resources utilized as best as possible? Why am I not getting the SLO met with 4 resources when I only needed 1 resource without the service mesh? How can I improve my 99.9% latencies or can I map my service policy to utilization? Is the network a performance hog, or storage, or cache? Meshmark intends to help model and provide an index for many of these areas\"\n    person=\"Mrittika Ganguli\"\n    />\n    So often you see when you have a YouTube video uploaded, it will have only the text and not the video. \n</p>   \n    And so what happens is you do not want that kind of an experience. You want the video to be and the images to be loaded first. As you can see in video if you click on something, you may often see the text get rendered first and then the video.\n    The load latency of the video traffic is what impacts you see visually. And so the deployment of your cloud native environment. If it can be indexed through a MeshMark ratio, your load latency will be directly proportional to that and then the number of resources you're using to deploy this environment to get a particular lower latency or a higher latency is a usage metric and that's directly proportional to your MeshMark.\n    The TCO of your application hence becomes directly related to MeshMark.\n</p>\n\n<p>\n<img src={meshmarkSlide} className=\"slides\" align=\"center\" style={{marginLeft: \"30px\"}} alt=\"meshmark\" />\n<img src={example} className=\"slides\" align=\"center\" style={{marginLeft: \"30px\"}} alt=\"meshmark example\" />\n</p>\n\n<img src={formula} alt=\"MeshMark formula\" style={{width: \"50%\", float: \"right\"}} />\n<h2>MeshMark The Formula</h2>\n<p>\n    MeshMark functions as a value performance index (a scale) to provide organizations  the ability to weigh the value of their service mesh versus the overhead of their service mesh and assess whether they are getting out of the mesh what they are “paying” for in it. MeshMark’s scoring system ranges from 0 to 100 and incorporates collections of resource utilization efficiency calculations, categorized into similar consumption classes.\n</p>\n\n<h3>Mrittika explains MUE</h3>\n<p>\n    It's a calculation, combined ratio of measured platform resources to assign resources. If you're able to measure what your assigned resources are in whatever form and able to also monitor what's the used resources, you can have this ratio. So, for example, a very simple one is CPU performance. \n    <img src={MUE} alt=\"MeshMark MUE\" style={{width: \"50%\", float: \"left\", paddingRight: \"1rem\"}} /> And you would want to see if the CPU performance as a ratio to the available resources is a loss or a gain. So CPU performance, raw loss over total CPU is our MUE one.\n    And that's just one minus CPU utilization over 100. That's a very simple ratio and if you see on the slide, the graph shows you that as the latency increases, your Mue lowers. And so that's a very good indicator that your efficiency of your infrastructure is not very good because your latencies are increasing as your QPS increases.\n    So like this you can measure and create other MUEs. We will look at how you can visualize this within an environment and so let's look at the demonstration. So let's jump into a sibling CNCF project called Meshery.\n    Meshery is a cloud native management plane. Users of Meshery can configure their Kubernetes deployments any and every service mesh as well as on board and off board their workloads onto any given mesh.\n</p>    \n\n<img src={MeshMapDemo} alt=\"MeshMap demo\" style={{width: \"40%\", float: \"right\"}}  />\n<h3>Lee demonstrates MeshMap with an example Consul application</h3>\n\n<p>\nLet's take an example workload a  Consul application, load it into the visual designer, take a look at the service splitting functionality of console and note in this case we're assigning a weight of three when we can change that to four to derive its MeshMark which is a mesh utilization efficiency calculation of the efficiency by which that network function is being performed.\nWe could also take a look at service intentions of console and examine the efficiency of that network function. Now that you've seen the demo you want to go ahead and publish the results and call everyone to get together.\n</p>    \n\n<div style={{textAlign: \"center\"}}>\n<iframe width=\"70%\" height=\"450px\"  style={{marginRight: \"1.5rem\", marginLeft: \"1.5rem\"}} src=\"https://www.youtube.com/embed/yvqn6ckO7BI\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen></iframe>\n<p style={{fontStyle: \"italic\", fontSize: \"1rem\", marginLeft: \"1rem\"}}>MeshMark in Meshery (an excerpt from ServiceMeshCon EU 2022 demo)</p>\n</div>\n\n<p><strong>Lee Calcote and Mrittika Ganguli covered all the concepts of SMP and MeshMark in this great talk. Learn more about MeshMark on the <Link to=\"https://meshery.io/service-mesh-interface\">Service Mesh Performance </Link>website.</strong></p>\n\n</BlogWrapper>\n","frontmatter":{"title":"MeshMark: Cloud Native Value Measurement","type":"Blog","technology":null,"product":"MeshMap","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdMoADAVZpocZffp7rwAD+8eCe2HI33vty8iA8g87WkluUHUOOVrCnLZT6QrpQ3MgZ8CTBlCyKjycJ5kqTGGOPP80t64fDwjjCC4PKH6lVg+SCeFAA"},"images":{"fallback":{"src":"/static/262c08771cc081196228e58152adc495/c8936/banner.webp","srcSet":"/static/262c08771cc081196228e58152adc495/8d8ff/banner.webp 750w,\n/static/262c08771cc081196228e58152adc495/fc98a/banner.webp 1080w,\n/static/262c08771cc081196228e58152adc495/62268/banner.webp 1366w,\n/static/262c08771cc081196228e58152adc495/c8936/banner.webp 1898w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5600632244467861}},"extension":"webp","publicURL":"/static/262c08771cc081196228e58152adc495/banner.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdMoADAVZpocZffp7rwAD+8eCe2HI33vty8iA8g87WkluUHUOOVrCnLZT6QrpQ3MgZ8CTBlCyKjycJ5kqTGGOPP80t64fDwjjCC4PKH6lVg+SCeFAA"},"images":{"fallback":{"src":"/static/262c08771cc081196228e58152adc495/c8936/banner.webp","srcSet":"/static/262c08771cc081196228e58152adc495/8d8ff/banner.webp 750w,\n/static/262c08771cc081196228e58152adc495/fc98a/banner.webp 1080w,\n/static/262c08771cc081196228e58152adc495/62268/banner.webp 1366w,\n/static/262c08771cc081196228e58152adc495/c8936/banner.webp 1898w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5600632244467861}},"extension":"webp","publicURL":"/static/262c08771cc081196228e58152adc495/banner.webp"}},"fields":{"slug":"/blog/service-mesh-performance/meshmark-cloud-native-value-measurement"}},{"id":"f2512afd-5871-5b42-9a4d-d8e7e3ed3a8e","body":"\n\n\nimport slidesTAG from \"../../../events/kubecon-china-2021/cncf-tag-network-and-service-mesh-working-group-kubecon-china-2021-lee-calcote-ken-owens.pdf\";\n\nimport DDE from \"./docker-extension-meshery.webp\";\nimport developer from \"./developers-need.webp\";\nimport dashboard from \"./dashboard.webp\";\nimport designer from \"./designer-1.webp\";\nimport visualizer from \"./viz-1.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro \">\n<p>\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and <Link to=\"/community/members/nic-jackson\">Nic Jackson</Link> gave a presentation entitled <i>Extending the Docker Compose Experience to Service Mesh</i> at DockerCon 2022.\n</p>\n</div>\n\n<p>\n    The <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> extends Docker Desktop's position as the cloud native developer's go-to Kubernetes environment with easy access to the next\n    layer of cloud native infrastructure: service meshes. \n</p>\n\n<p>\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative product and technology leader, passionate about empowering engineers and enabling organizations. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement. \n    <Link to=\"/community/members/nic-jackson\"> Nic Jackson </Link> is a developer advocate at HashiCorp, and the author of “Building Microservices in Go”, a book which examines the best patterns and practices for building microservices with the Go. Nic is also a coauthor of the Service Mesh Patterns book.\n</p>\n\n<p>\n    Nic Jackson has been using Docker Desktop from long time and tells how Docker Desktop provides feasibility to run Kubernetes for his local environment,\n    while Lee Calcote recalls how Docker Desktop has become a staple of his daily routine while building an extension for Meshery.\n    </p>\n\n<p>\n<h3>Discussing Developers need to access Service Mesh</h3>\n<img src={developer} alt=\"Developers need to access service mesh\" style={{width: \"50%\", float: \"right\"}} />\n</p>\n\n<p>\nMoving forward with the introduction to Docker Extension for Meshery, Nic says, \"When it comes to Service Mesh, should developers care about Service Mesh? And the answer is Yes because developers need service mesh because of the changing reliability patterns implementation rapidly, it provides a tight feedback loop for developing and deploying workloads onto your service mesh and makes the over developer experience smooth. With the help of service, mesh developers should be able to create environments without needing to be operational experts.\"\n</p>\n\n<p>\n    <h3>Meshery Extension offers an easy single click button to go from Docker Compose to Kubernetes wih all cloud native infrastructure supported.</h3>\n<img src={DDE} alt=\"Docker Desktop Extension Meshery\" style={{width: \"50%\", float: \"right\"}} />\n</p>\n<p>\n    The Docker Extension for Meshery provides:\n</p>\n<ul>\n<li>Kubernetes support for your Docker Compose apps - Import your Docker Compose apps. Configure and deploy them to Kubernetes and integrate into your GitOps pipeline.</li>\n<li>Collaborative designer for Docker Compose apps - Early access to the Docker Extension for Meshery that offers a visual topology for designing Docker Compose applications, operating Kubernetes, Kubernetes Operators, and their workloads.</li>\n<li>Single-click deployment of any service mesh - Support of 10 different service meshes to the fingertips of developers in connection with Docker Desktop’s ability to deliver Kubernetes locally.</li>\n</ul>\n<p>\n    \n    <img src={dashboard} alt=\"Docker Desktop Extension Meshery Dashboard\" style={{width: \"50%\", float: \"left\", paddingRight: \"30px\"}} />\n    </p>\n<p>\n    <ul>\n    <li>\n    While giving the demo Meshery Lee explained how with Docker Desktop running and Meshery extension installed we can see that Meshery has discovered\n    the installed service mesh automatically and it performs action with the adapter present. \n    </li>\n    <li>\n    Meshery is a Kubernetes multi-cluster manager capable of performing lifecycle management of all CNCF projects, like Flux, Argo, Prometheus, Envoy, Jaeger, and so on.\n     </li>  \n    <li>\n    We can configure different service mesh based on their configurations and performs actions such as deploy, design, and explore all of the capabilities of service mesh via a rich schema with a live preview.\n    </li> \n    </ul>\n</p>\n\n<p>\n    <p>\n    <h3>Lee Calcote introduces MeshMap</h3>\n    </p>\n        <img src={designer} alt=\"MeshMap Designer\" style={{width: \"50%\", float: \"right\"}} />\nMeshMap is the world's only visual designer for Kubernetes and all cloud native infrastructure. Collaborate with other engineers in real-time as you use MeshMap to design, deploy, and manage your Kubernetes-based deployments. Save time and use a design template. Take advantage of the best practices embedded in the patterns found in Meshery Catalog. MeshMap not only allows you to create and verify your cloud native application and infrastructure configurations, but to deploy and operate that infrastructure as well.\n\n    Lee demonstrated MeshMap <strong>Designer</strong>  design capabilities using Consul Service Mesh as an eample and configures various Consul-specific features. He designs a service mesh deployment with application and Envoy filter from scratch. \n</p>\n       <p>\n       <img src={visualizer} alt=\"MeshMap Designer\" style={{width: \"50%\", float: \"left\", paddingRight: \"30px\"}} />\n     MeshMap <strong>Visualizer Mode</strong> allows you to examines a visual topology of Kubernetes cluster and its services. View and search log streams from your pod's containers. Connect an interactive terminal to instances of your containers.\n       </p>\n\n<p>\n    To Lee's demo, Nic also added in the context of developer experience that MeshMap also makes it easy to do the job and with Meshery extension it makes it super easy to write and configure code without being worried for the developer environment.\n    </p>\n    <p>\n       These Docker Extensions are so powerful that it allows you to do multiple tasks without leaving Docker Desktop. \n        </p>\n\n<div className=\"iframe-container\">\n<iframe src=\"https://www.youtube.com/embed/3DPZafR8VWM\" loading=\"lazy\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen ></iframe>\n</div>\n\n<p><strong>Lee Calcote and Nic Jackson packed a great deal of information in this talk. Find the recording below. The Meshery Extension is now out! Try now, and Share your Experience </strong><Link to=\"/meshmap\">Apply for MeshMap Beta Program</Link></p>\n\n</BlogWrapper>\n","frontmatter":{"title":"Extending the Docker Compose Experience to Service Mesh","type":"Blog","technology":"Docker","product":"Docker Extension","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwAB6/pABoj2NUy/koAADL/k2zUZNSDZNP4McvnXa+KZwCUuZErfVazXD/7BG3PNmBDAo+RXP2IQbdHXgMBjCf0RJ75yHgAAA="},"images":{"fallback":{"src":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp","srcSet":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/a66aa/DC22-talk-HashiCorp.webp 750w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/65dd5/DC22-talk-HashiCorp.webp 1080w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/f9724/DC22-talk-HashiCorp.webp 1366w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp 1499w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630420280186791}},"extension":"webp","publicURL":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/DC22-talk-HashiCorp.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwAB6/pABoj2NUy/koAADL/k2zUZNSDZNP4McvnXa+KZwCUuZErfVazXD/7BG3PNmBDAo+RXP2IQbdHXgMBjCf0RJ75yHgAAA="},"images":{"fallback":{"src":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp","srcSet":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/a66aa/DC22-talk-HashiCorp.webp 750w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/65dd5/DC22-talk-HashiCorp.webp 1080w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/f9724/DC22-talk-HashiCorp.webp 1366w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp 1499w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630420280186791}},"extension":"webp","publicURL":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/DC22-talk-HashiCorp.webp"}},"fields":{"slug":"/blog/docker/extending-the-docker-compose-experience-to-service-mesh"}},{"id":"6f70ddf7-740d-5640-b104-fa03b4622855","body":"\n\n\n\nimport CloudNative from \"./cloud-native-management.webp\";\nimport CloudNativeIdentity from \"./cloud-native-identity.webp\";\nimport dde from \"./dde.webp\";\nimport designer  from \"./Designer.webp\";\nimport visualizer from \"./Visualizer.webp\";\nimport meshmapInDocker from \"./meshmap-docker-extension-for-meshery.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro\">\n<p>\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and <Link to=\"/community/members/maximiliano-churichi\">Maximiliano Churichi</Link> gave a presentation entitled <i>Extending Docker with Meshery, SPIRE, and Istio</i> at DockerCon 2022.\n</p>\n</div>\n\n<p style={{marginLeft: \"10px\", fontStyle: \"italics\"}}>\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative product and technology leader, passionate about empowering engineers and enabling organizations. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement.\n</p>\n\n<p style={{marginLeft: \"10px\", fontStyle: \"italics\"}}>\n    <Link to=\"/community/members/maximiliano-churichi\">Maximiliano Churichi</Link> is a Software Engineer at Hewlett Packard Enterprise, working in the Security Engineering team, and fully engaged in open source technologies, passionate about service mesh and cloud-native security.\n</p>\n\n<div>\n    <h3>\n        Cloud Native Management\n        <img src={CloudNative} alt=\"Meshery Docker Extension\" style={{width: \"50%\", float: \"right\"}} />\n    </h3>\n    <p>\n        Lee Calcote introduces Meshery as a Cloud Native Management Plane, stating, \"Meshery does Lifecycle and Performance Management of 10 different service meshes more than that it helps with configuration management with Kubernetes and with the Meshery Docker Extension it does same for the Docker Compose application.\"\n    </p>\n</div>                                                                        \n                                                                           \n<p>\n    \"As a <Link to=\"https://www.docker.com/blog/docker-captain-take-5-lee-calcote/\">Docker Captain</Link>, Lee have always been a proponent of Docker, and in particular its enablement of developer workflows\", \"Now, Docker Extensions bring an integrated experience with ecosystem tooling, like Meshery - a critical tool for developers, who are configuring and managing cloud native applications.\"\n</p>\n\n<div>\n    <h3>\n        Cloud Native Identity\n    </h3>\n    <p>\n        Maximiliano Churichi briefly explains about Cloud Native Identity and HPE's open source Project Mithril, \"<Link to=\"https://spiffe.io\">SPIFFE</Link> (Secure Production Identity Framework For Everyone) is a <Link to=\"https://www.cncf.io/projects/\">CNCF-incubated</Link> project that defines a set of standards for identifying and securing communications between application services. The <Link to=\"https://spiffe.io/docs/latest/spire-about\">SPIRE</Link> project (another CNCF project), the SPIFFE Runtime Environment, is a production-ready reference implementation of the SPIFFE principles, and additionally it also implements a set of APIs for controlling attestation policies, and coordinate certificate issuance and rotation.\"\n    </p>\n    <img src={CloudNativeIdentity} alt=\"Meshery Docker Extension\" style={{width: \"50%\", float: \"right\"}} />\n    <p>\n        Maximiliano also tells how HPE's Project Mithril integrates SPIRE and Istio to strengthen service identity in the data plane. <strong>Project Mithril leverages the service management capabilities of Istio and the strong identity by attestation principles of SPIFFE and SPIRE to deliver robust and flexible attestation beyond Kubernetes namespaces and service accounts</strong>, and provide end-to-end secure attestation of workloads based on zero trust principles regardless of the location of such workloads. The improvements introduced by Project Mithril were already upstreamed into Istio, and are expected to be released in the upcoming Istio 1.14. Starting from this release, Istio users will be able to leverage SPIRE for SPIFFE identities management, and stronger identity attestation mechanisms.\n    </p>\n</div>\n\n<p>\n    <h3>How \"Docker Extension for Meshery\" helps to deploy with the click of a button?</h3>\n    <p>\n    <img src={dde} alt=\"Meshery Extension Meshery\" style={{width: \"50%\", float: \"left\", paddingRight: \"2rem\"}} />\n    The new Meshery Docker Extension brings <Link to=\"/meshmap\">Layer5 MeshMap</Link>, the world's only visual designer for Kubernetes and service mesh deployments, to the desktop of millions of developers. Developers and operators alike can visually configure and operate their cloud native infrastructure and applications using MeshMap's low code visual designer.\n    </p>\n</p>    \n<p>\n    Maximiliano Churichi, Software Engineer at HPE says how conveniently Meshery integrates different services into Docker.\n</p>\n<ul>\n<li><strong>Kubernetes and service mesh support for your Docker Compose apps</strong> - Import your Docker Compose apps. Configure and deploy them to Kubernetes and any service mesh.</li>\n\n<li><strong>Visual design of Kubernetes applications</strong> - Using <Link to=\"/meshmap\">MeshMap</Link> as a visual topology for designing Docker Compose applications, operating Kubernetes, service meshes, and their workloads.</li>\n\n<li><strong>Single-click deployment of any service mesh</strong> - Support of 10 different service meshes to the fingertips of developers in connection with Docker Desktop’s ability to deliver Kubernetes locally.</li>\n\n<li><strong>Detection of Kubernetes environments -</strong> Scan your kubeconfigs and select your current Kubernetes environment. Switch from one environment to another or manage all clusters concurrently.</li> \n</ul>\n\n<p>\n  <h3>Maximiliano demonstrates MeshMap</h3>\n</p>\n\n<img src={meshmapInDocker} alt=\"Layer5 MeshMap in Meshery Docker Extension\" />\n\n<div style={{display: \"grid\", gridTemplateColumns: \"auto auto\", padding: \"10px\"}}>\n  <div style={{padding: \"20px\", textAlign: \"center\"}}>\n  <p style={{paddingBottom: \"1.6rem\"}}>\n    <h5>Designer Mode</h5>\n    Design a service mesh deployment with application and Envoy filter from scratch. Customize a service mesh deployment with application and Envoy filter from pattern.\n</p>\n    <img src={designer} alt=\"Meshery Docker Extension\" align=\"center\" alt=\"MeshMap Designer\" />\n\n  </div>\n  <div style={{padding: \"20px\", textAlign: \"center\"}}>\n  <p>\n    <h5>Visualizer Mode</h5>\n    Examine a visual topology of Kubernetes cluster and its services. View and search log streams from your pod's containers. Connect an interactive terminal to instances of your containers. \n</p>\n    <img src={visualizer} alt=\"Meshery Docker Extension\" align=\"center\" alt=\"MeshMap Visualizer\" />\n  </div>\n</div>\n\n\n<div className=\"iframe-container\">\n<iframe src=\"https://www.youtube.com/embed/SazEJizK4xQ\" loading=\"lazy\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen ></iframe>\n</div>  \n\n<p><strong>Lee Calcote and Maximiliano Churichi packed a great deal of information in this talk. Find the recording below. The Meshery Extension is now out! Try now, and Share your Experience </strong><Link to=\"/meshmap\">Apply for MeshMap Beta Program</Link></p>\n\n\n</BlogWrapper>","frontmatter":{"title":"Extending Docker with Meshery, SPIRE, and Istio","type":"Blog","technology":"Docker","product":"Docker Extension","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsAAAABXRUJQVlA4ILQAAADwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwIsAKKsXQ3bDU0Sh7xNByx8AA3QTx+NCIdbtlgNUIj8p8TTldQEJK/Onajgz/QWQc/tznhrECMWd6h2YF5Vur29u/3qZIIEF6x1ljtCpku538y8znYOZfzbugSVf57n6bu5fySdDxuSAlPHMO8HeUR+DU0Js9dn/ooTZ5vtV1ZIsjnj3E/a5Rec1TEKlY1hCyDOdAAAA="},"images":{"fallback":{"src":"/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp","srcSet":"/static/6d9aae3d5df3089bd154e53c9d945331/8d8ff/dc22-hpe-talk.webp 750w,\n/static/6d9aae3d5df3089bd154e53c9d945331/eedfa/dc22-hpe-talk.webp 1080w,\n/static/6d9aae3d5df3089bd154e53c9d945331/e048d/dc22-hpe-talk.webp 1366w,\n/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp 1907w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5595175668589407}},"extension":"webp","publicURL":"/static/6d9aae3d5df3089bd154e53c9d945331/dc22-hpe-talk.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsAAAABXRUJQVlA4ILQAAADwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwIsAKKsXQ3bDU0Sh7xNByx8AA3QTx+NCIdbtlgNUIj8p8TTldQEJK/Onajgz/QWQc/tznhrECMWd6h2YF5Vur29u/3qZIIEF6x1ljtCpku538y8znYOZfzbugSVf57n6bu5fySdDxuSAlPHMO8HeUR+DU0Js9dn/ooTZ5vtV1ZIsjnj3E/a5Rec1TEKlY1hCyDOdAAAA="},"images":{"fallback":{"src":"/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp","srcSet":"/static/6d9aae3d5df3089bd154e53c9d945331/8d8ff/dc22-hpe-talk.webp 750w,\n/static/6d9aae3d5df3089bd154e53c9d945331/eedfa/dc22-hpe-talk.webp 1080w,\n/static/6d9aae3d5df3089bd154e53c9d945331/e048d/dc22-hpe-talk.webp 1366w,\n/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp 1907w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5595175668589407}},"extension":"webp","publicURL":"/static/6d9aae3d5df3089bd154e53c9d945331/dc22-hpe-talk.webp"}},"fields":{"slug":"/blog/docker/extending-docker-with-meshery-spire-and-istio"}},{"id":"787f689e-ebc6-55b4-ac65-2821194b82f3","body":"\n\n\nimport Working from \"./Istio Ingress Gateway.webp\";\nimport Rep from \"./Istio Ingress Gateway No Title.webp\";\n\n\n<ResourcesWrapper>\n\n<p>\n    Predominantly, Kubernetes has used an Ingress controller to handle the traffic that enters the cluster from the outside. \n    Istio has replaced all the familiar Ingress resource with new Gateway and VirtualServices resources.\n    They work in sync to route all the traffic into the mesh.\n    Inside the mesh there is no requirement for Gateways since the services can access each other by a cluster local service name.\n</p>\n<h3>Let’s understand the working with a representation</h3>\n<p>\n    <img src={Rep} align=\"center\" alt=\"Istio Ingress Gateway in Kubernetes No Title\" />\n</p>\n<p>\n<ul>\n<li>Firstly A request is made by a client on a specific port</li>\n<li>Then a load balancer on this port listens and forwards the request to one of the workers in theh cluster on same or a new port</li>\n<li>Inside the cluster the request is routed to the Istio Ingress Gateway which is listened on the port of the load balancer</li>\n<li>The Service forwards the requestto an Istio Ingress Gateway Pod which is managed by a deployment</li>\n<li>The Ingress Gateway Pod is configured by a Gateway and a VirtualService.</li>\n<li>The Gateway configures all the ports, protocol, and certificates.</li>\n<li>The Virtual Service configures all the routing information to find the correct Servicein it.</li>\n<li>The Istio Ingress Gateway Pod routes the request to the application Service.</li>\n<li>And lastly, the application Service routes the request to an application Pod which is managed by a deployment.</li>\n</ul>\n</p>\n<ul>\n</ul>\n\n<h2>\n   Ingress Gateway Service\n</h2>\n\n<p>\n    The Ingress Gateway Service must listen to all the ports to be able to forward the traffic to the Ingress Gateway pods. \n    Here we will be using routing to bring all the port numbers back to their initial state.\n</p>\n\n<p>\n    Note that a Kubernetes Service is not a real service, but, since we are using type: \n    \"NodePort\", all the request will be handled by the kube-proxy provided by Kubernetes and forwarded to a node with a current running pod. \n    Once on the node, an IP-tables is configured a request will be forwarded to the appropriate pod.\n</p>\n\n```yaml\n\n# From the istio-ingressgateway service\n  ports:\n  - name: http2\n    nodePort: 30000\n    port: 80\n    protocol: TCP\n  - name: https\n    nodePort: 30443\n    port: 443\n    protocol: TCP\n  - name: mysql\n    nodePort: 30306\n    port: 3306\n    protocol: TCP\n```\n<p>\n    If we inspect the service, we will see that it defines more ports than we have describe above.\n    So these ports will be used for all the internal Istio communication.\n</p>\n\n<h2>\n    Ingress Gateway Deployment\n</h2>\n\n<p> \nIt's a wrapper around the Envoy proxy and it is configured as the sidecars used inside the service mesh. \nWhen a Gateway or VirtualService gets changed,\nthey are detected by the Istio Pilot controller and converts this information to an Envoy configuration and sends it to all the proxies, including the Envoy inside the IngressGateway.\n</p>\n\n<p>\n    Since container ports are not supposed to be declared in Kubernetes pods, we don't have to declare the ports in the Ingress Gateway Deployment.\n    If we look inside the deployment we can see that there are a number of ports that are already declared anyway.\n    We have to take care about the Ingress Gateway Deployment in SSL certificates. \n    To access the certificates inside the Gateway resources, make sure that we have mounted all the required certificates properly.\n</p>\n\n```yaml\n\n# Example represents volume mounts\nvolumeMounts:\n- mountPath: /etc/istio/ingressgateway-certs\n  name: ingressgateway-certs\n  readOnly: true\n- mountPath: /etc/istio/ingressgateway-ca-certs\n  name: ingressgateway-ca-certs\n  readOnly: true\n\n# Example represents volumes\nvolumes:\n- name: ingressgateway-certs\n  secret:\n    defaultMode: 420\n    optional: true\n    secretName: istio-ingressgateway-certs\n- name: ingressgateway-ca-certs\n  secret:\n    defaultMode: 420\n    optional: true\n    secretName: istio-ingressgateway-ca-certs\n```\n\n<h2>The Gateway</h2>\n\n<p>\n    The Gateway resources are used to configure the ports for Envoy and also support for the Kubernetes Ingress. \n    Since all the three ports are exposed with the servies, we need these ports to be handled by the Envoy. \n    It can be handled by declaring one or more Gateways.\n</p>\n\n```yaml\n\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: default-gateway\n  namespace: istio-system\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n\n  - hosts:\n    - '*'\n    port:\n      name: http\n      number: 80\n      protocol: HTTP\n\n  - hosts:\n    - '*'\n    port:\n      name: https\n      number: 443\n      protocol: HTTPS\n    tls:\n      mode: SIMPLE\n      privateKey: /etc/istio/ingressgateway-certs/tls.key\n      serverCertificate: /etc/istio/ingressgateway-certs/tls.crt\n\n  - hosts: # For all the TCP routing this fields will be ignored, but it will be matched\n    - '*'  # with the VirtualService, We use * since it will match anything.\n    port:\n      name: mysql\n      number: 3306\n      protocol: TCP\n```\n\n<h2>VirtualService</h2>\n<p>\n    The last interesting resource we have is the VirtualService, it used in concert with the Gateway to configure Envoy. \n</p>\n<p>\n    A general configuration for an HTTP(s) service\n</p>\n\n```yaml\n\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: counter\nspec:\n  gateways:\n  - default-gateway.istio-system.svc.cluster.local\n  hosts:\n  - counter.lab.example.com\n  http:\n  - match:\n    - uri:\n      prefix: /\n    route:\n    - destination:\n        host: counter\n        port:\n          number: 80\n\n```\n<h2>Application Service and Deployment</h2>\n<p>\n    The request have now reached the application service and deployment. These are normal Kubernetes resources.\n</p>\n\n<h2>Extras:</h2>\n\n<h3>Debugging Istio Gateway</h3>\n<p>\n     First we will use istioctl to check the configuration status of Istio Ingress Gateway:\n</p>\n\n```yaml\n\n# istioctl proxy-status istio-ingressgateway-5586f47659-r64lb.istio-system\nClusters Match\nListeners Match\nRoutes Match\n\n```\n<p>\n    If anything does not get synced with it, try restarting the ingress gateway pod once - it may be possible that it somehow an update got missed.\n    If RDS looked good, we can check access logs of it. \n</p>\n\n```yaml\n\n#kubectl get configmap istio -n istio-system -o yaml | grep \"accessLogFile: \"\ndisable access log.\\naccessLogFile: \\\"/dev/stdout\\\"\\n\\n# If accessLogEncoding\n\n```\n<p>\n    Once all the access logs are enabled, we can try torequest a few more times and check the logs on the Ingress Gateway:\n</p>\n\n```yaml\n\n# kubectl logs -n istio-system istio-ingressgateway-5586f47659-r64lb | grep -v deprecated\n\n```\n\n</ResourcesWrapper>","frontmatter":{"title":"Istio Ingress Gateway in Kubernetes","type":"Article","technology":"Kubernetes","product":"Meshery","mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4WAoAAAAQAAAAEwAACwAAQUxQSBEAAAABD9D/iAgIBJL2J98gov+ZHQBWUDggWgAAANADAJ0BKhQADAA+0VSjS6gkoyGwCAEAGglpAABSui9EcCMXxIZwAAD+9hPeHc9BJcicWg4Stt4P6RO2muLV0Jjky6cPrFHMbfr8+JsYVp9/uo+acFskxC8IAA=="},"images":{"fallback":{"src":"/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp","srcSet":"/static/eec5644b77e71f1ff68a36b674aea59c/33c00/Istio%20Ingress%20Gateway.webp 750w,\n/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp 950w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5757894736842105}},"extension":"webp","publicURL":"/static/eec5644b77e71f1ff68a36b674aea59c/Istio Ingress Gateway.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4WAoAAAAQAAAAEwAACwAAQUxQSBEAAAABD9D/iAgIBJL2J98gov+ZHQBWUDggWgAAANADAJ0BKhQADAA+0VSjS6gkoyGwCAEAGglpAABSui9EcCMXxIZwAAD+9hPeHc9BJcicWg4Stt4P6RO2muLV0Jjky6cPrFHMbfr8+JsYVp9/uo+acFskxC8IAA=="},"images":{"fallback":{"src":"/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp","srcSet":"/static/eec5644b77e71f1ff68a36b674aea59c/33c00/Istio%20Ingress%20Gateway.webp 750w,\n/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp 950w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5757894736842105}},"extension":"webp","publicURL":"/static/eec5644b77e71f1ff68a36b674aea59c/Istio Ingress Gateway.webp"}},"fields":{"slug":"/resources/service-mesh/istio-ingress-gateway-in-kubernetes"}},{"id":"5d6e85c1-a958-51c5-a20e-1308e5fd0237","body":"\n\n\n\nimport UnitTest from \"./unit-test.webp\";\nimport IntegrationTest from \"./integration-test.webp\";\nimport TreeGraph from \"./tree-graph.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro \">\n<p>Delivering a high quality user experience is our pinnacle goal in the design of Meshery's CLI: <code>mesheryctl</code>. Delivering a high quality user experience means testing both qualitatively and quantatively. As a concept, quality - whether you're talking about software or anything else - can be directly measured by consistency. A quality user experience is consistent and consistency of <code>mesheryctl</code> is reinforced by its many unit tests.</p>\n</div>\n\n<p><code>mesheryctl</code> is written in Golang. In the Meshery project, we use CodeCov to calculate the code coverage across <code>mesheryctl</code>'s line of code. And there are plenty of lines of code. Achieving high percentages of code coverage in Meshery's CLI with grows in criticality as we bring more features into <code>mesheryctl</code> as a robust and sophisticated command line client of Meshery. Unit and integration tests bolster and roll up into broader end-to-end, functional testing performed across Meshery and the rest of its components. </p>\n\n<p>High levels of code coverage makes it easier for each project contributor to be confident that their code changes aren’t breaking any preexisting <code>mesheryctl</code> commands, side-swiping their functionality unknowingly, and consequently, unwittingly lowering the quality of Meshery's overall user experience.</p>\n\n<h3> mesheryctl lines of code</h3>\n\n\n```yaml\n\n    270 text files.\n    106 unique files.\n    166 files ignored.\n\n    cloc v 1.92  T=0.15 s (692.3 files/s, 110063.3 lines/s)\n    ------------------------------------------------------------------\n    Language       files          blank        comment           code\n    ------------------------------------------------------------------\n    Go                88           2128           1330          13045\n    YAML              12              0              0            215\n    JSON               4              0              0             42\n    make               1             10              2             31\n    Markdown           1             23              0             27\n    ------------------------------------------------------------------\n    SUM:             106           2161           1332          13360\n    ------------------------------------------------------------------\n```\n\n<p>Unit Tests can be written in two ways:</p>\n\n<ol>\n    <li>\n        Test <code>mesheryctl</code> subcommand\n        <ol>\n            <li>Mock Meshery(backend) response if needed</li>\n            <li>Grab console output</li>\n            <li>Store standard/verified mesheryctl output in a golden file(a text file)</li>\n            <li>Match the stored/expected output with what we grab from the console</li>\n            <li>Cover as many scenarios as possible, test the situations where errors must be thrown</li>\n            <li>This is a standard format, changes can be made accordingly</li>\n        </ol>\n    </li>\n    <li>\n        Test <code>mesheryctl</code> functions\n        <ol>\n            <li>This is the standard testing you may have come across in every project</li>\n            <li>You write one test dedicated to one function covering all possible test-cases, matching expected outputs</li>\n        </ol>\n    </li>\n</ol>\n\n<h3>Example tree graph</h3>\n<p>This example of a tree graph (from <a href=\"https://github.com/meshery/meshery/pull/4823\">meshery/meshery/pull/4823</a>) shows the impact given changes make on the level of code coverage.</p>\n\n<img src={TreeGraph} />\n\n<h3>Integration Tests</h3>\n\n<p>Integrations tests come into view when you cannot mock something easily and when a given behavior is cross-functional / cross-component. Integration tests put more, but not all of the focus validating system behavior and that the system completes all the necessary actions. Take <code>mesheryctl system start</code> for example. This command deploys Meshery, its adapters, and Kubernetes Operator; it starts Meshery. So, you run the command to start Meshery in a GitHub workflow and after running the <code>mesheryctl</code> subcommand through the tests and make sure that Meshery actually started. And if the workflow successfully runs the test, then boom!, you aced your integration writing test... errr... test writing.</p>\n\n<p>The integration test writing exam can initially be challenging, but... that’s the fun in it. :) Running tests and making sure a command that is otherwise hard to verify, hard to test, and making it automatic through GH workflows.</p>\n\n<h3>How you can make an impact</h3>\n\n<p>Writing tests and making them work is in itself a tough task to do, so writing one test for a single function counts and makes a big difference over the long term. Don't hesitate. Start writing tests now. A single, new test is worthy of raising a pull request and will get you well on your way to learning much more about Golang, Docker, Kubernetes, and service meshes.</p>\n\n<ul>\n    <li><a href=\"https://codecov.io/gh/meshery/meshery/\">Codecov</a> is used to check code coverage in <code>mesheryctl</code> (login with GitHub to get an in-depth idea of lines-of-code being covered in code coverage).</li>\n    <li>You can check the files on CodeCov’s website to figure out which mesheryctl commands haven’t been covered by existing tests.</li>\n    <li>Guide: <a href=\"https://docs.google.com/document/d/1xRlFpElRmybJ3WacgPKXgCSiQ2poJl3iCCV1dAalf0k/edit#heading=h.rzpmb66db1sq\">Writing tests for mesheryctl</a>. This guide will briefly introduce how tests are supposed to be written for mesheryctl.</li>\n    <li>Contributing to Tests doesn’t always mean writing new tests, It also means improving the effectiveness of already written-ones.</li>\n    <li> Search for Issues marked with area/tests in <a href=\"https://github.com/meshery/meshery\">GitHub - meshery/meshery</a>: Meshery, the cloud native management plane.</li>\n</ul>\n\n<p>The impact that you make with by writing even a single test is quite high. Your tests will be executed and used time-and-time again. I can’t explain in words (I don’t have that good of a vocabulary). Your Tests are going to run in each pull request raised against the Meshery project, in each commit someone pushes to a pull request, in every nightly regression test suite, in every release. Just think: if another contributor incidently introduces a defect or doesn't consider for an edge case, and fails to uphold the intended behavior of the code, your tests are going to catch them redhanded. How cool is that?</p>\n\n<p>So, what are you waiting for? Jump in and write a few tests today! When you raise your pull request, label it with <code>area/tests</code> and <code>component/mesheryctl</code> and I'll be there to review! Let’s get <code>mesheryctl</code> 100% code coverage badge.</p>\n\n</BlogWrapper>","frontmatter":{"title":"How to write unit and integration tests for mesheryctl","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uwJKMhsAgCABoJaQDImC0kAAD+8jqXyPcoCEgyAAAA"},"images":{"fallback":{"src":"/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp","srcSet":"/static/228cadb307e48d8dd59978517c9862a3/0622a/integration-test.webp 750w,\n/static/228cadb307e48d8dd59978517c9862a3/56413/integration-test.webp 1080w,\n/static/228cadb307e48d8dd59978517c9862a3/28a59/integration-test.webp 1366w,\n/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp 1882w","sizes":"100vw"},"sources":[]},"width":1,"height":0.35281615302869285}},"extension":"webp","publicURL":"/static/228cadb307e48d8dd59978517c9862a3/integration-test.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uwJKMhsAgCABoJaQDImC0kAAD+8jqXyPcoCEgyAAAA"},"images":{"fallback":{"src":"/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp","srcSet":"/static/228cadb307e48d8dd59978517c9862a3/0622a/integration-test.webp 750w,\n/static/228cadb307e48d8dd59978517c9862a3/56413/integration-test.webp 1080w,\n/static/228cadb307e48d8dd59978517c9862a3/28a59/integration-test.webp 1366w,\n/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp 1882w","sizes":"100vw"},"sources":[]},"width":1,"height":0.35281615302869285}},"extension":"webp","publicURL":"/static/228cadb307e48d8dd59978517c9862a3/integration-test.webp"}},"fields":{"slug":"/blog/meshery/how-to-write-unit-and-integration-tests-for-mesheryctl"}},{"id":"9b0a1004-cf4e-5a13-8bd0-a8bda49ae654","body":"\n\n\n<NewsWrapper>\n\nAs a forthcoming, ubiquitous layer of cloud native infrastructure, service meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices. Managing the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly summarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure of choice is a challenge unto its own.\n\nWe explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties of resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance analysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of workloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations.\n\n</NewsWrapper>","frontmatter":{"title":"Analyzing Service Mesh Performance","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgCdAB6V1vFmRI1iw0AA/umSK0KdRjjz9YXdu7S/97FNJD1J4/X373Sa+zEas27Peze33ZGm9Qqc4gPEikHmOZ4vTAD704vlc6FBdmm/nPn0bdXFsSJFMUJQXAAA"},"images":{"fallback":{"src":"/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp","srcSet":"/static/1b674dee7c478103de63e91d9f37fff0/5f850/cover.webp 750w,\n/static/1b674dee7c478103de63e91d9f37fff0/2c010/cover.webp 1080w,\n/static/1b674dee7c478103de63e91d9f37fff0/5126b/cover.webp 1366w,\n/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp 1783w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5457094784071789}},"extension":"webp","publicURL":"/static/1b674dee7c478103de63e91d9f37fff0/cover.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgCdAB6V1vFmRI1iw0AA/umSK0KdRjjz9YXdu7S/97FNJD1J4/X373Sa+zEas27Peze33ZGm9Qqc4gPEikHmOZ4vTAD704vlc6FBdmm/nPn0bdXFsSJFMUJQXAAA"},"images":{"fallback":{"src":"/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp","srcSet":"/static/1b674dee7c478103de63e91d9f37fff0/5f850/cover.webp 750w,\n/static/1b674dee7c478103de63e91d9f37fff0/2c010/cover.webp 1080w,\n/static/1b674dee7c478103de63e91d9f37fff0/5126b/cover.webp 1366w,\n/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp 1783w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5457094784071789}},"extension":"webp","publicURL":"/static/1b674dee7c478103de63e91d9f37fff0/cover.webp"}},"fields":{"slug":"/company/news/analyzing-service-mesh-performance"}},{"id":"a8f09cde-c9bd-5f47-b328-0d7aea181ac9","body":"\n\n\n\nimport token from \"./download-token.webp\";\nimport perfdashboard from \"./service-mesh-performance-profile-test-results.webp\"\nimport smidashboard from \"./smi-conformance-result.webp\";\nimport smpLogo from \"../../../../assets/images/service-mesh-performance/horizontal/smp-dark-text-side.svg\";\nimport smiLogo from \"../../../../assets/images/service-mesh-icons/service-mesh-interface/horizontal-stackedtext/color/servicemeshinterface-horizontal-stackedtext-color.svg\";\nimport githubBlack from \"../../../../assets/images/socialIcons/github_black.svg\";\n\n<BlogWrapper>\n  \n<p>With growing adoption of service meshes in cloud native environments, service mesh abstractions - service mesh-neutral specifications - have emerged. <Link to=\"/projects/service-mesh-performance\">Service Mesh Performance</Link>  and <Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface</Link> are two open specifications that address the need for universal interfaces for interacting with and managing any type of service mesh. Let’s examine what each specification provides.</p>\n\n<img src={smpLogo} className=\"image-left-no-shadow\" alt=\"service mesh performance logo\" /><p><a href=\"https://smp-spec.io\">Service Mesh Performance</a> standardizes service mesh value measurement, characterizing any deployment's performance by capturing the details of infrastructure capacity, service mesh configuration and workload metadata.</p>\n\n<img src={smiLogo} className=\"image-right-no-shadow\" alt=\"service mesh interface logo\" /><p><a href=\"https://smi-spec.io\">Service Mesh Interface</a> provides a standard interface for service meshes on Kubernetes. These (currently) four specfications offer a common denominator set of interfaces to support most common service mesh use cases and the flexibility to evolve to support new service mesh capabilities over time.</p>\n\n<p>As a service mesh agnostic tool that provides lifecycle and performance management of a large number of (10+) service meshes, Kubernetes applications, service mesh patterns and WebAssembly filters, Meshery is the ideal tool for the job when it comes to implementing these specifications.</p>\n\n<p>Meshery also comes with two new GitHub Actions that do exactly this. The <a href=\"https://github.com/layer5io/meshery-smi-conformance-action\">Meshery SMI Conformance Action</a> which <a href=\"https://meshery.io/blog/validating-smi-conformance-with-meshery\">validates SMI conformance</a> in your pipeline and the <a href=\"https://github.com/layer5io/meshery-smp-action\">Meshery SMP Action</a> which runs <a href=\"https://docs.meshery.io/functionality/performance-management\">SMP compatible performance benchmarks</a>.</p>\n<p>But how do we use these actions? What do they offer? Let’s find out!</p>\n\n<h2>Service Mesh Interface Conformance GitHub Action</h2>\n\n<p>Conformance of SMI specifications is defined as a series of test assertions. These test assertions are categorised by SMI specification (of which, there are currently four specifications) and comprise the complete suite of SMI conformance tests. Conformance requirements will change appropriately as each new version of the SMI spec is released. Refer to Meshery's documentation for details of how <a href=\"https://docs.meshery.io/functionality/service-mesh-interface\">Meshery performs SMI conformance</a>.</p>\n\n<img src={githubBlack} className=\"image-left-no-shadow\" style={{maxWidth: \"9vw\"}} />\n\n<h3>Using Meshery's SMI Conformance GitHub Action</h3>\n\n<p>The <a href=\"https://github.com/marketplace/actions/service-mesh-interface-conformance-with-meshery\">Service Mesh Interface Conformance GitHub Action</a> is available in the GitHub Marketplace. You can configure this action to trigger with each of your releases, on every pull request. or any GitHub workflow trigger event.</p>\n<p>An example of the action configuration which runs on every release is shown below. The action handles setting up a Kubernetes environment, deploying the service mesh (see supported service meshes), running the conformance tests and reporting back the results to the SMI Conformance dashboard in Meshery.</p>\n\n```yaml\nname: SMI Conformance with Meshery\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  smi-conformance:\n    name: SMI Conformance\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: SMI conformance tests\n        uses: layer5io/mesheryctl-smi-conformance-action@master\n        with:\n          provider_token: ${{ secrets.MESHERY_PROVIDER_TOKEN }}\n          service_mesh: open_service_mesh\n          mesh_deployed: false\n```\n\n<p>You can also bring in their own cluster with specific capabilities and with a service mesh already installed.</p>\n\n```yaml\nname: SMI Conformance with Meshery\non:\n  push:\n    branches:\n      - 'master'\n\njobs:\n  smi-conformance:\n    name: SMI Conformance tests on master\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: Deploy k8s-minikube\n        uses: manusa/actions-setup-minikube@v2.4.1\n        with:\n          minikube version: 'v1.21.0'\n          kubernetes version: 'v1.20.7'\n          driver: docker\n\n      - name: Install OSM\n        run: |\n           curl -LO https://github.com/openservicemesh/osm/releases/download/v0.9.1/osm-v0.9.1-linux-amd64.tar.gz\n           tar -xzf osm-v0.9.1-linux-amd64.tar.gz\n           mkdir -p ~/osm/bin\n           mv ./linux-amd64/osm ~/osm/bin/osm-bin\n           PATH=\"$PATH:$HOME/osm/bin/\"\n           osm-bin install --osm-namespace default\n\n      - name: SMI conformance tests\n        uses: layer5io/mesheryctl-smi-conformance-action@master\n        with:\n          provider_token: ${{ secrets.MESHERY_PROVIDER_TOKEN }}\n          service_mesh: open_service_mesh\n          mesh_deployed: true\n```\n\n<p>You can download a token from Meshery and add it as a GitHub secret (in the example above, the secret is <code>MESHERY_PROVIDER_TOKEN</code>). After the test is run, you can view the results from the Service Mesh Interface dashboard in Meshery UI.</p>\n\n<p style={{align: \"center\"}}>\n<img src={smidashboard} className=\"image-center-shadow\" style={{width: \"70%\"}} alt=\"smi conformance dashboard\" /> <br />\n<i>Meshery's Service Mesh Interface Conformance Results</i>\n</p>\n\n<p>Participating service mesh projects can also <a href=\"https://docs.meshery.io/functionality/service-mesh-interface#reporting-conformance\">automatically report their conformance test results</a> to the <a href=\"https://meshery.io/service-mesh-interface\">SMI Conformance dashboard</a></p>\n\n<h2>Service Mesh Performance GitHub Action</h2>\n\n<p>Measuring and managing the performance of a service mesh is key to efficient operation of any service mesh. Meshery is the canonical implementation of the Service Mesh Performance specification. You can choose from multiple load generators and use a highly configurable set of load profiles with variable tunable facets to run a performance test. Meshery packages all these features into an easy-to-use GitHub Action.</p>\n\n<img src={githubBlack} className=\"image-left-no-shadow\" style={{maxWidth: \"9vw\"}} />\n\n<h3>Using Meshery's Service Mesh Performance GitHub Action</h3>\n\n<p>The <a href=\"https://github.com/marketplace/actions/performance-testing-with-meshery\">Service Mesh Performance GitHub Action</a> is available in the GitHub Marketplace.You can create your own performance profiles to run repeatable tests with Meshery. You can configure this action to trigger with each of your releases, on every pull request. or any GitHub workflow trigger event. A sample configuration of the action is shown below.</p>\n\n```yaml\nname: Meshery SMP Action\non:\n  push:\n    branches:\n      'master'\n\njobs:\n  performance-test:\n    name: Performance Test\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v2\n        with:\n          ref: 'perf'\n\n      - name: Deploy k8s-minikube\n        uses: manusa/actions-setup-minikube@v2.4.1\n        with:\n          minikube version: 'v1.21.0'\n          kubernetes version: 'v1.20.7'\n          driver: docker\n\n      - name: Run Performance Test\n        uses: layer5io/meshery-smp-action@master\n        with:\n          provider_token: ${{ secrets.PROVIDER_TOKEN }}\n          platform: docker\n          profile_name: soak-test\n```\n\n<p>You can also define your test configuration in an SMP compatible configuration file as shown below.</p>\n\n```yaml\nsmp_version: v0.0.1\nid:\nname: Istio Performance Test\nlabels: {}\nclients:\n- internal: false\n  load_generator: fortio\n  protocol: 1\n  connections: 2\n  rps: 10\n  headers: {}\n  cookies: {}\n  body: \"\"\n  content_type: \"\"\n  endpoint_urls:\n  - http://localhost:2323/productpage\nduration: \"30m\"\n```\n\n<p>See this sample GitHub workflow (<a href=\"https://github.com/layer5io/meshery-smp-action/blob/master/action.yml\">action.yml</a>) for more configuration details.</p>\n\n<img src={perfdashboard} className=\"image-center\" alt=\"performance management dashboard\" />\n\n<p>The results from the tests are updated on the Performance Management dashboard in Meshery. To learn more about interpreting the test results, check out <a href=\"https://docs.meshery.io/guides/interpreting-performance-test-results\">this guide</a>. You can always checkout the <a href=\"https://docs.meshery.io/guides\">Meshery User Guides</a> to dive deep into these features.</p>\n\nStay meshy!\n</BlogWrapper>\n","frontmatter":{"title":"Pipelining Service Mesh Specifications","type":"Blog","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAwBACdASoUAAsAPtFWo0uoJKMhsAgBABoJQAqP23yHCf3s8zj7Q4Ot54AA/vYSdhBu5a5XcB/63qjz5sojm43GF+2H9fEBMTKbmVPEU59GLBaiyKva9gYciPhcLWvnHZREEmuIToMwwyupq3UEwAAA"},"images":{"fallback":{"src":"/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp","srcSet":"/static/81aa70f0509f2123d8f460d3633f063c/a66aa/service-mesh-specifications.webp 750w,\n/static/81aa70f0509f2123d8f460d3633f063c/65dd5/service-mesh-specifications.webp 1080w,\n/static/81aa70f0509f2123d8f460d3633f063c/4fad6/service-mesh-specifications.webp 1366w,\n/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp 1600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/81aa70f0509f2123d8f460d3633f063c/service-mesh-specifications.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAwBACdASoUAAsAPtFWo0uoJKMhsAgBABoJQAqP23yHCf3s8zj7Q4Ot54AA/vYSdhBu5a5XcB/63qjz5sojm43GF+2H9fEBMTKbmVPEU59GLBaiyKva9gYciPhcLWvnHZREEmuIToMwwyupq3UEwAAA"},"images":{"fallback":{"src":"/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp","srcSet":"/static/81aa70f0509f2123d8f460d3633f063c/a66aa/service-mesh-specifications.webp 750w,\n/static/81aa70f0509f2123d8f460d3633f063c/65dd5/service-mesh-specifications.webp 1080w,\n/static/81aa70f0509f2123d8f460d3633f063c/4fad6/service-mesh-specifications.webp 1366w,\n/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp 1600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/81aa70f0509f2123d8f460d3633f063c/service-mesh-specifications.webp"}},"fields":{"slug":"/blog/service-mesh-specifications/pipelining-service-mesh-specifications"}},{"id":"01336bab-b9d8-5b9a-b18f-6b7a3378e1da","body":"\n\n\n\n<ResourcesWrapper>\n<p>\n<Link to=\"/cloud-native-management/meshery\">Meshery</Link> is an open source, vendor-neutral, extensible management plane that enables service mesh users to overcome the challenges of complex virtual networking, empowers them to design and apply patterns containing tried and true best practices, benchmarks the performance of your service mesh deployments and enables developers, operators, and product managers to understand and manage their cloud native services with confidence. \n</p>\n\n<h3>\nLet’s learn how to manage service meshes with confidence with the extensible service mesh manager, <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.\n</h3>\n\n<div className=\"iframe-container\">\n<iframe width=\"460\" height=\"215\" src=\"https://www.youtube.com/embed/mU8qHUGYsk8\" loading=\"lazy\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen></iframe></div>\n\n</ResourcesWrapper>","frontmatter":{"title":"An Introduction to Meshery (Webinar-on-Demand)","type":"Recorded Webinar","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/2f4a78ada287ae5dcc2e75fad653f671/meshery-logo-light-text.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/2f4a78ada287ae5dcc2e75fad653f671/meshery-logo-light-text.svg"}},"fields":{"slug":"/resources/meshery/an-introduction-to-meshery-webinar-on-demand"}},{"id":"eb6adc56-cf51-5a5d-819a-e8ba1a0db5fd","body":"\n\n\n\n<ResourcesWrapper>\n  <div>\n    <FAQ category={[\"Service Mesh\"]} />\n  </div>\n</ResourcesWrapper>\n;\n","frontmatter":{"title":"Service Mesh FAQs","type":"FAQ","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"}},"fields":{"slug":"/resources/faq/service-mesh-faqs"}},{"id":"026b5e97-a286-53d0-b507-8f9ed86d2cae","body":"\n\n\n\n<ResourcesWrapper>\n  <div>\n    <FAQ category={[\"Meshery\"]} />\n  </div>\n</ResourcesWrapper>\n;\n","frontmatter":{"title":"Meshery FAQs","type":"FAQ","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRooAAABXRUJQVlA4IH4AAADwAwCdASoUAA8APtFUo0uoJKMhsAgBABoJbACdMoACZNTMZvLPw/oAAP7ZUrvgQ7hVtNtvV7hXXCZrxWyqJsc8NVTd2E2fcSmqDspjWKr+UXIi716HI+AFGNfb4VwB7WrWScZXrre8zZ9NfQKIvIAt9xgUCAoRlz8B9ZAAAAA="},"images":{"fallback":{"src":"/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp","srcSet":"/static/2db8d89cdff9c95760d3235b380b39ea/ba09c/meshery-logo-dark-text.webp 750w,\n/static/2db8d89cdff9c95760d3235b380b39ea/bc96e/meshery-logo-dark-text.webp 1080w,\n/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp 1113w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7619047619047619}},"extension":"webp","publicURL":"/static/2db8d89cdff9c95760d3235b380b39ea/meshery-logo-dark-text.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRooAAABXRUJQVlA4IH4AAADwAwCdASoUAA8APtFUo0uoJKMhsAgBABoJbACdMoACZNTMZvLPw/oAAP7ZUrvgQ7hVtNtvV7hXXCZrxWyqJsc8NVTd2E2fcSmqDspjWKr+UXIi716HI+AFGNfb4VwB7WrWScZXrre8zZ9NfQKIvIAt9xgUCAoRlz8B9ZAAAAA="},"images":{"fallback":{"src":"/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp","srcSet":"/static/2db8d89cdff9c95760d3235b380b39ea/ba09c/meshery-logo-dark-text.webp 750w,\n/static/2db8d89cdff9c95760d3235b380b39ea/bc96e/meshery-logo-dark-text.webp 1080w,\n/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp 1113w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7619047619047619}},"extension":"webp","publicURL":"/static/2db8d89cdff9c95760d3235b380b39ea/meshery-logo-dark-text.webp"}},"fields":{"slug":"/resources/faq/meshery-faqs"}},{"id":"14a9d010-447a-5ad3-bd1f-7016887e2f5d","body":"\n\n\n\n\n\n<ResourcesWrapper>\n <div>\n   <FAQ category={[\"Layer5\"]} /> \n </div>\n</ResourcesWrapper>\n","frontmatter":{"title":"Layer5 FAQs","type":"FAQ","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoACtcg53I4/HmZQ4AD+0C/LiaNYp/gAptl+AxIcPxvl67IhZN4oeuHuj0hO+8RPUMPR/JulDon1IZvwiZPOAxPH6F7m/pw+6es+w3zgAAA="},"images":{"fallback":{"src":"/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp","srcSet":"/static/4817b5f110f099c46c7d31dfcab76aeb/a66aa/layer5-gradient.webp 750w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/65dd5/layer5-gradient.webp 1080w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/4fad6/layer5-gradient.webp 1366w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/4817b5f110f099c46c7d31dfcab76aeb/layer5-gradient.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoACtcg53I4/HmZQ4AD+0C/LiaNYp/gAptl+AxIcPxvl67IhZN4oeuHuj0hO+8RPUMPR/JulDon1IZvwiZPOAxPH6F7m/pw+6es+w3zgAAA="},"images":{"fallback":{"src":"/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp","srcSet":"/static/4817b5f110f099c46c7d31dfcab76aeb/a66aa/layer5-gradient.webp 750w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/65dd5/layer5-gradient.webp 1080w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/4fad6/layer5-gradient.webp 1366w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/4817b5f110f099c46c7d31dfcab76aeb/layer5-gradient.webp"}},"fields":{"slug":"/resources/faq/layer5-faqs"}},{"id":"c65e2e9b-9b5c-5994-a495-fc14ded2327f","body":"\n\n\n\n<ResourcesWrapper>\n  <div>\n    <FAQ category={[\"internships\"]} />\n  </div>\n</ResourcesWrapper>\n;\n","frontmatter":{"title":"Internship FAQs","type":"FAQ","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpoBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSKwAAAABgLJt2/lX9v23m9LsLdq26hqbVa3EaHurTtYHsK1kpv2evx0REwB7zqv0MMMyeZuWf0A+pu0R4wdEmnC92fPUnX/natzcE+kOGspSucwypPclVo+0qv52hYzsBJJbn+nvM2T/xsCqBKgn3e/v+NJXIma8sAmIvdJDtCiQd20GoaAFw2TkWTqA7OsTf0X/v6GnAgBpB+MOQMCunt8WGYxl5TwSM+0EU6XVoTAaVlA4IMgAAABwBgCdASoUABQAPtFWpk0oJCOiMBgIAQAaCWcABEFPGJ84aiB+qodM63A9zAWf18SPYalFhDgO3HTEJkAA/vd5mgQA2cByfbsxLlZ3azENuxPSupy6lFcmZ5xWXix5UmHhue4m7lhIK9sMlzFCY97FzXrfW+r9vifnpsw50ef9rqzQcHtjNDRqVOvKsgsNfqL0jz3js3QMU0TPOTe+viuahzYjLvKCJLj79c4msbu+XexWJUbckQA2UKJNzpuiUI4QGIlhUjgAAA=="},"images":{"fallback":{"src":"/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp","srcSet":"/static/527d1d45923fb0b266d35b755e1f1879/4f03f/workshops.webp 750w,\n/static/527d1d45923fb0b266d35b755e1f1879/4f506/workshops.webp 1080w,\n/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/527d1d45923fb0b266d35b755e1f1879/workshops.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpoBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSKwAAAABgLJt2/lX9v23m9LsLdq26hqbVa3EaHurTtYHsK1kpv2evx0REwB7zqv0MMMyeZuWf0A+pu0R4wdEmnC92fPUnX/natzcE+kOGspSucwypPclVo+0qv52hYzsBJJbn+nvM2T/xsCqBKgn3e/v+NJXIma8sAmIvdJDtCiQd20GoaAFw2TkWTqA7OsTf0X/v6GnAgBpB+MOQMCunt8WGYxl5TwSM+0EU6XVoTAaVlA4IMgAAABwBgCdASoUABQAPtFWpk0oJCOiMBgIAQAaCWcABEFPGJ84aiB+qodM63A9zAWf18SPYalFhDgO3HTEJkAA/vd5mgQA2cByfbsxLlZ3azENuxPSupy6lFcmZ5xWXix5UmHhue4m7lhIK9sMlzFCY97FzXrfW+r9vifnpsw50ef9rqzQcHtjNDRqVOvKsgsNfqL0jz3js3QMU0TPOTe+viuahzYjLvKCJLj79c4msbu+XexWJUbckQA2UKJNzpuiUI4QGIlhUjgAAA=="},"images":{"fallback":{"src":"/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp","srcSet":"/static/527d1d45923fb0b266d35b755e1f1879/4f03f/workshops.webp 750w,\n/static/527d1d45923fb0b266d35b755e1f1879/4f506/workshops.webp 1080w,\n/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/527d1d45923fb0b266d35b755e1f1879/workshops.webp"}},"fields":{"slug":"/resources/faq/internship-faqs"}},{"id":"874bb1f5-6259-560f-a9cc-4d0264946625","body":"\n\nimport Infrastructure from \"./figure1.webp\";\n\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about WebAssembly's use within service mesh data planes in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.</p>\n  </div>\n\n<p>\nWASM stands for WebAssembly, which is an open standard for defining a binary format for executable programs. It also defines Interfaces for interacting with host environments through the WebAssembly System Interface (WASI). Browsers and large web applications were the primary focus of these host environments, with the goal of securely running programmes to enhance performance. The W3C maintains WASM as an open standard, and all modern browsers have adopted it. WebAssembly is the fourth language that can run natively in web browsers, following HTML, CSS, and Javascript.\n</p>\n\n<p>\nGoogle's open-source high-performance JavaScript and WebAssembly engine, V8, is being embedded into Envoy, bringing WASM support to the platform. Envoy exposes an Application Binary Interface (ABI) to WASM modules via the WebAssembly System Interface, allowing them to function as Envoy filters. WASI operates effortlessly. Your application is written in one of your favorite languages, such as Rust, C++, or C. Then, for the host environment, build and compile them into a WebAssembly binary. For the resulting binary to execute, the WebAssembly runtime must offer the necessary interfaces to system calls. Conceptually, this is similar to JVM. If you have a JVM installed, then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary.\n</p>\n\n<p>\nAdditional filters can be added to Envoy in one of two ways:\n<ul>\n<li>By incorporating your custom filter into Envoy's C++ source code and building a new version of Envoy natively. The disadvantage is that you'll have to maintain your own version of Envoy, but the advantage is that your custom filter will run at native speed.</li>\n<li>Via WASM, by developing your custom filter in C++, Rust, AssemblyScript, or Go and integrating it as a WebAssembly binary. The disadvantage is that WASM-based filters have considerable overhead, but the advantage is that WASM-based filters may be dynamically loaded and reloaded in Envoy at runtime.</li>\n</ul>\n</p>\n\n<p>\nOn startup, Envoy's configuration is initialised using bootstrap. The xDS APIs in Envoy enable dynamic configuration loading and reloading during runtime. There are several sections in the Envoy configuration (e.g. LDS which is for configuring Listeners and CDS which is for configuring clusters). WASM plugins can be configured in each section (programs).\n</p>\n\n<h3>Dynamically (Re)loadable Intelligence</h3>\n<p> Data planes are powerful because they can dynamically load WASM programs to inspect, rewrite, and reroute packets carrying application requests. WASM applications can integrate business logic considerations when filtering application requests when using a management plane. The service mesh can implement business logic, as well as common application infrastructure logic: </p>\n<ul>\n<li>Subscription plan enforcement: rate limiting requests based on user’s subscription plan</li>\n<li>Class of Service: directing requests to high performance clusters based on user demographics or activity</li>\n<li>Multivariate testing: facilitating comparison a of high number of variables between deployments (service versions) and users</li>\n</ul>\n<div className=\"fact\">\n<p>\nTo get a feel of these capabilities, try experimenting with the <Link to=\"/projects/image-hub\">Image Hub</Link>,a prototype application developed in Rust that runs on Consul and allows you to explore WebAssembly modules used as Envoy filters.\n</p>\n</div>\n\n  <div className=\"center\" >\n  <img src={Infrastructure} align=\"center\" alt=\"application infrastructure logic\" />\n  <p>Figure 1:. How the intelligence of the cloud native management plane and the power of the service mesh data plane combine to deliver application infrastructure logic.  </p>\n  </div>\n\n<p>\nWebAssembly is intriguing in part because of its performance characteristics, which vary depending on the program/filter used. For network filtering use cases, some have a 10% to 20% overhead as compared to natively executed code.  Given its high degree of portability, WebAssembly resembles Docker in certain ways. WASM's virtual stack machine, like the Java Virtual Machine (JVM), is evolving into a write once, run anywhere system (WORA). WASM executables are precompiled with a wide range of languages that support it as a compilation target (currently around 40 languages).\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Envoy and WebAssembly","type":"Article","technology":"WebAssembly","product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/06775492c84a32dae01532165deed01e/wasm-envoy.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/06775492c84a32dae01532165deed01e/wasm-envoy.svg"}},"fields":{"slug":"/resources/webassembly-filters/envoy-and-webassembly"}},{"id":"26141097-8979-5e2e-989a-90bae6f54b40","body":"\n\n\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about WebAssembly's use within service mesh data planes in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.</p>\n  </div>\n\n<h3>The Power of the Data Plane</h3>\n<p>\nOperators benefit from control planes because they provide much-needed element management. Data planes require control planes to apply service mesh-specific use cases to their fleet of service proxies. A control plane performs activities like configuration management, telemetry collecting, infrastructure-centric authorization, identity, etc. However, the service proxy is a massive source of power for them. Users frequently require customizing the chain of traffic filters (modules) that service proxies employ to perform much of their heavy lifting. Different technologies are used to provide data plane extensibility, and consequently, additional custom data plane intelligence, including:\n</p>\n\n<ul>\n  <li>Lua - a scripting language for execution inside a Just-In-Time compiler, LuaJIT.</li>\n  <li>WebAssembly (WASM) - a virtual stack machine as a compilation target for different languages to use as an execution environment.</li>\n</ul>\n\n<h3>Lua and WebAssembly</h3>\n<p>\nPeople are discussing the merits of using a WebAssembly runtime since the introduction of WASM into service meshes. A  Lua runtime can be as little as 4 kb, with LuaJIT being surprisingly fast, having a runtime of only ~200 kb.\n</p>\n<p>\nThe WebAssembly loader, not the runtime, is the source of complexity for the host software. When comparing the two, how do you weigh GCC or LLVM in terms of making optimized C or C++ faster or slower than LuaJIT?\n</p>\n\n<p>\nThe complexity of a WebAssembly runtime stems from the fact that it contains arch-specific optimizers as well as an Intermediate Representation to machine code translation stage that would usually be executed inside GCC or LLVM. Machine code can be created once and then cached on non-volatile storage until the input WASM file's hash changes (like the extracted contents of a Zip file). Since WASM has a similar approach to sandboxing (making the language/bytecode unable to describe accessing resources outside of what is granted), the result is lighter than Lua once the machine code is generated. However, WASM's compiled machine code does not require a garbage collector or JIT engine.\n</p>\n\n<p>\nWebAssembly follows the same flat, garbage-collected memory model as malloc and free. Suppose you want a garbage collector in a WebAssembly application. In that case, you can either compile it to WebAssembly and run it inside the sandbox or wait for extensions currently developing, such as \"opaque reference types,\" which allows WebAssembly applications to interact with objects managed by a Garbage Collector outside the sandbox.\n</p>\n\n<h3>NGINX and Lua</h3>\n<p>\nNGINX allows you to write dynamic modules that can be loaded at runtime based on configuration files. By modifying the configuration files and reloading NGINX, these modules can be unloaded. NGINX enables you to use Lua to embed custom logic into dynamic modules.\n</p>\n<p>\nLua is a lightweight, embeddable scripting language that supports procedural, functional, and object-oriented programming. Lua is dynamically typed, and runs by interpreting bytecode with a register-based virtual machine.\n</p>\n<p>\nNGINX provides the ability to integrate dynamic Lua scripts using the ngx_lua module. Using NGINX with ngx_lua helps you offload logic from your services and hand their concerns off to an intelligent data plane. Leveraging NGINX's subrequests, the ngx_lua module allows the integration of Lua threads (or coroutines into the NGINX event model. Instead of passing logic to an upstream server, the Lua script can inspect and process service traffic. ngx_lua modules can be chained to be invoked at different phases of NGINX request processing.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Lua vs WebAssembly","type":"Article","technology":"WebAssembly","product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/e618b16625c039ca1840620451fc92dd/lua-wasm.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/e618b16625c039ca1840620451fc92dd/lua-wasm.svg"}},"fields":{"slug":"/resources/webassembly-filters/lua-vs-webassembly"}},{"id":"b6ff733a-1416-533b-90e2-d3a30f77f689","body":"\n\n\nimport Communication from \"./figure4.webp\";\nimport Timeouts from \"./figure3.webp\";\nimport Metrics from \"./figure2.webp\";\nimport Mixer from \"./figure1.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<p>\n    Service meshes provide visibility, resiliency, traffic, and security control of distributed application services.\n</p>\n\n<h3>Observability</h3>\n\n<p>\nMany organisations are attracted to the uniform observability that service meshes provide. There is no such thing as a fully healthy complex system. Service-level  t elemetry sheds light on difficult-to-answer questions like why your requests are slow to respond. It's quite simple to figure out when a service is down, but figuring out where it's slow and why is a different story.\n</p>\n\n<p>\nService meshes allow both black-box (observing a system from the outside) and white-box (monitoring a system from the inside) monitoring of service-to-service communication. To provide white-box monitoring, some service meshes combine with a distributed tracing library. In contrast, other service meshes use protocol-specific filters as a capability of their proxies to provide a deeper level of visibility. The components of the data plane are well-positioned (transparently, in-band) to create metrics, logs, and traces, ensuring uniform and thorough observability across the mesh.\n</p>\n  <div className=\"center\" >\n  <img src={Mixer} align=\"right\" alt=\"Istio Mixer\" />\n  <p>Figure 1: Istio’s Mixer is capable of collecting multiple telemetric signals and sending those signals to backend monitoring, authentication, and quota systems via adapters</p>\n  </div>\n<p>Service meshes centralize and assist in solving these observability challenges by providing the following:</p>\n\n  <div className=\"right\" >\n  <img src={Metrics} align=\"right\" alt=\"Request Metrics\" />\n  <p>Figure 2: Request metrics generated by Istio and visible in Meshery</p>\n  </div>\n<ul>\n    <li>\n        <strong>Logging</strong>\n        <p>\n            Logs are used to baseline visibility for access requests to your entire fleet of services. Figure 1 illustrates how telemetry transmitted through service mesh logs include source and destination, request protocol, endpoint (URL), response time, size, and associated response code.\n        </p>\n    </li>\n    <li>\n        <strong>Metrics</strong>\n        <p>\nMetrics are used to eliminate the need for the development process to instrument code in order to emit metrics. When metrics are ubiquitous across your cluster, additional insights become available. Consistent metrics allow for things like autoscaling to be automated. Telemetry emitted by service mesh metrics include global request volume, global success rate, individual service responses by version, source and time.\n</p>\n    </li>\n    <li>\n        <strong>Tracing</strong>\n        <p>\nSlow services (as opposed to services that simply fail) are the most difficult to debug without tracing. Imagine manually enumerating and tracking all of your service dependencies in a spreadsheet. Dependencies, request volumes, and failure rates are visualised using traces. Service meshes enable incorporating tracing functionality extremely simple with the help of automatically generated span identifiers. The mesh's individual services still must forward context headers.  Many application performance management (APM) solutions, on the other hand, need manual instrumentation to extract traces from your services.\n</p>\n    </li>\n</ul>\n<h3>Traffic control</h3>\n\n<p>\nService meshes provide for granular, declarative control over network traffic, such as determining where a request should be routed to perform canary release. Circuit breaking, latency-aware load balancing, eventually consistent service discovery, timeouts, deadlines, and retries are all common resiliency features.\n</p>\n\n<p>\n   When a request does not return to the client within a certain amount of predefined time, a  <strong>timeout</strong> is used to terminate it. They provide a time restriction on how much time can be spent on an individual request and are enforced at a point after which a response is considered invalid. <strong>Deadlines</strong> are an advanced service mesh feature that helps minimise retry storms by facilitating feature-level timeouts rather than independent service timeouts. As a request travels through the mesh, deadlines deduct time remaining to handle it at each stage, propagating elapsed time with each downstream service call. \n  Timeouts and deadlines might be considered enforcers of your Service-Level Objectives (SLOs).\n</p>\n\n<p>\nYou can choose to retry a request if a service times out or is unsuccessfully returned. Retrying the same call to a service that is already under water (retry three times = 300 percent additional service load) can make things worse. Retry budgets (aka maximum retries) offer the benefit of multiple tries but come with a limit to avoid overloading an already a load-challenged service. Some service meshes go even further to reduce client contention by using jitter and an exponential back-off algorithm to calculate the timing of the next retry attempt.\n</p>\n\n  <div className=\"left\" >\n  <img src={Timeouts} align=\"right\" alt=\"Deadlines\" />\n  <p>Figure 3:Deadlines, not ubiquitously supported by different service meshes, set feature-level timeouts</p>\n  </div>\n\n<p>\nYou can choose to fail fast and disconnect the service, prohibiting calls to it, rather than retrying and putting more load to the service. <strong>Circuit breaking</strong> allows users to set configurable timeouts (or failure thresholds) to assure safe maximums and graceful failure, which is common for slow-responding services. When applications (services) are oversubscribed, using a service mesh as a distinct layer to implement circuit breaking minimises undue overhead.\n</p>\n<p>\n    <strong>Rate limiting</strong>(throttling) is implemented to ensure service stability. When requests by one client surge, the service continues to function smoothly for others. The rate limits are calculated over a period of time. You can also utilise various algorithms, such as a fixed or sliding window, a sliding log, etc. The purpose of rate limits is to ensure that your services are not oversubscribed.\n</p>\n\n<p>When a limit is reached, well-implemented services commonly adhere to IETF RFC 6585, sending 429 Too Many Requests as the response code, including headers, such as the following, describing the request limit, number of requests remaining, and amount of time remaining until the request counter is reset:</p>\n\n<div className=\"fact-left\">\n<p>X-RateLimit-Limit: 60</p>\n<p>X-RateLimit-Remaining: 0</p>\n<p>X-RateLimit-Reset: 1372016266</p>\n</div>\n\n\n<p><strong>Quota management</strong> (or conditional rate-limiting) accounts for requests based on business requirements instead of limiting rates based on operational concerns. It can be difficult to tell the difference between rate limiting and quota management because both features are handled by the same service mesh capability but are exposed to users in different ways.</p>\n\n<p>\nConfiguring a policy setting a threshold for the number of client requests allowed to a service over time is the canonical example of quota management. User Lee, for example, is on the Free service plan and is allowed upto 10 requests per day. Quota policy imposes consumption limitations on services by keeping track of incoming requests in a distributed counter,often using an in-memory datastore like Redis  Conditional rate limits are a powerful service mesh capability when applied based on a user-defined set of arbitrary attributes.\n</p>\n\n  <h3>Security</h3>\n\n  <div className=\"right\" >\n  <img src={Communication} align=\"right\" alt=\"Communication Paths\" />\n  <p>Figure 4: An example of service mesh architecture. Secure communication paths in Istio</p>\n  </div>\n\n  <p>\nFor securing service-to-service communication, most service meshes include a certificate authority that manages keys and certificates. Certificates are generated for each service and serve as the service's unique identifier. When sidecar proxies are employed, they assume the identity of the service and perform lifecycle management of certificates (creation, distribution, refresh, and revocation) on its behalf.   Local TCP connections are often established between the service and the sidecar proxy, whereas mutual Transport Layer Security (mTLS) connections are typically established between proxies in sidecar proxy deployments.\n  </p>\n\n  <p>\nInternal traffic within your application should be encrypted as a matter of security. The service calls in your application are no longer contained within a single monolith via localhost; they are now exposed over the network. Allowing service calls without TLS on the transport is a recipe for disaster in terms of security. When two mesh-enabled services communicate, they have strong cryptographic proof of their peers.   After identities have been established, they are used to create access control policies that determine whether or not a request should be serviced. Policy controls configuration of the key management system (e.g., certificate refresh interval) and operational access control are used to determine whether a request is accepted, based on service mesh employed. Approved and unapproved connection requests, as well as more granular access control parameters like time of day, are identified using white and blacklists.\n  </p>\n\n  <h3>Delay and fault injection</h3>\n\n  <p>\nIt's important to accept that your networks and/or systems will fail. Why not introduce failure and verify behaviour ahead of time? As proxies sit in line to service traffic, they frequently support protocol-specific fault injection, which allows you to configure the percentage of requests that should be subjected to faults or network delays. For example, generating HTTP 500 errors might be used to test the robustness of your distributed application's response behaviour.\n  </p>\n\n  <p>\nInjecting latency into requests without a service mesh is a time-consuming procedure, but it is probably a more prevalent problem encountered during  operation of an application. Users are far more irritated by slow replies that result in an HTTP 503 after a minute of waiting than by a 503 after a few seconds. The finest element of these resilience testing capabilities is that no application code needs to be changed to make these tests possible. The results of the tests, on the other hand, may prompt you to make changes to the application code.\n  </p>\n\n  <p>\nUsing a service mesh, developers spend far less time creating code to cope with infrastructure issues—code that could be commoditized by service meshes in the future. The separation of service and session-layer concerns from application code is manifested as a phenomenon I refer to as decoupling at Layer 5.\n  </p>\n<p>\nA service mesh can be regarded of as surfacing the OSI model's session layer as a separately addressable, first-class citizen in your modern architecture. They are a secret weapon of cloud native systems, waiting to be exploited as a highly configurable work horse.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Value of a Service Mesh","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"}},"fields":{"slug":"/resources/service-mesh/value-of-a-service-mesh"}},{"id":"e5466ac3-43d5-5cb7-b523-c2fdf055b9cf","body":"\n\nimport Swappingproxy from \"./figure1.webp\";\n\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about WebAssembly's use within service mesh data planes in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.</p>\n  </div>\n\n<p>\n    One of the most significant considerations to make when establishing a service mesh is the proxy's functionality. From the standpoint of a developer, a proxy's cloud native integrations (e.g., with OpenTelemetry / OpenTracing, Prometheus, and so on) are extremely important. Surprisingly, a developer may be uninterested in the APIs of a proxy. The control plane for the service mesh is the point of control for managing proxy settings. A developer, however, will be interested in the APIs of a management plane. Protocol support is at the top of the developers' wish list for proxies. Protocol considerations can be divided into two categories:\n</p>\n<ul>\n    <li>TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing.</li>\n    <li>gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.</li>\n</ul> \n\n<p>The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:</p>\n<ul>\n    <li>High performance and low latency</li>\n<li>High scalability and small memory footprint</li>\n<li>Deep observability at all layers of the network stack</li>\n<li>Programmatic configuration and ecosystem integration</li>\n<li>Thorough documentation to facilitate an understanding of expected proxy behavior</li>\n</ul>  \n\n<p>\n    Envoy is used as a service proxy by a variety of service meshes. Within Istio, Envoy is the default service proxy. Using Envoy’s APIs, various projects have demonstrated the ability to displace Envoy as the default service proxy with the choice of an alternative.\n</p>\n\n  <div className=\"intro\">\n      <h3 style={{textAlign: \"center\"}}>Standardizing Data Plane APIs</h3>\n    <p>\n        The xDS APIs are a collection of Envoy's APIs. The Universal Data Plane API (UDPA) working group attempts to create a set of APIs that will serve as the de facto standard for L4/L7 data plane configuration (similar to OpenFlow's role in SDN at L2/L3/L4). The Envoy xDS APIs are being evolved to address service discovery, load balancing assignments, routing discovery, listener configuration, secret discovery, load reporting, health check delegation, and more, in combination with a well-defined, stable API versioning policy.\n    </p>    \n  </div>\n\n<p>\n    In early versions of Istio, Linkerd exhibited an integration in which Istio was the control plane, supplying configuration to Linkerd proxies.  NGINX also hosted a project called nginMesh, in which Istio served as the control plane and NGINX proxies operated as the data plane.\n</p>\n<p>\n    With many service proxies in the ecosystem, outside of Envoy, only two have currently demonstrated integration with Istio . Linkerd is not yet intended to be a general-purpose proxy; instead, it is focused on being lightweight, placing extensibility as a secondary concern by offering extensions via gRPC plug-in.  Consul makes use of Envoy as a proxy. Why would you want to use another service proxy?\n</p>\n\n<strong>NGINX</strong>\n<p>\nWhile you won't be able to use NGINX as a proxy to replace Envoy, you could wish to employ NGINX based on your operational expertise, the necessity for a battle-tested proxy, or the integration of an F5 load balancer. You might also be looking for caching, a web application firewall (WAF), or other features in NGINX Plus. The service proxy used in the NGINX Service Mesh data plane is an enhanced version of NGINX Plus that interfaces natively with Kubernetes.\n</p>\n<strong>CPX</strong>\n<p>\nIf you already have Citrix Application Delivery Controllers and want to use them across your diverse infrastructure, you might choose to use the Citrix Service Mesh (which is an Istio control plane with a CPX data plane).With infrastructure diversity, holistic control, and monitoring for operational consistency across all your workloads (new microservices and existing monoliths).\n</p>\n<strong>MOSN</strong>\n<p>\n    MOSN can deploy as an Istio data plane. You might choose to deploy MOSN if you need to highly customize your service proxy and are a Golang shop. MOSN supports a multi-protocol framework, and you access private protocols with a unified routing framework. It has a multi-process plug-in mechanism, which can easily extend the plug-ins of independent MOSN processes through the plug-in framework, and do some other management, bypass and other functional module extensions.\n</p>\n\n<div className=\"fact\">\n    You might find this article on <a href=\"https://www.oreilly.com/content/how-to-customize-an-istio-service-mesh/\">How to customize an Istio service mesh and its adjoining webcast</a> helpful in further understanding Istio’s extensibility with respect to swappable service proxies.\n</div>\n\n<p>\n    Without configuration, proxies are without instructions to perform their tasks. Pilot is the head of the ship in an Istio mesh, keeping synchronized with the underlying platform by tracking and representing its services to istio-proxy. istio-proxy contains the proxy of choice (e.g. Envoy). Typically, the same istio-proxy Docker image is used by Istio sidecar and Istio ingress gateway, which contains not only the service proxy but also the Istio Pilot agent.  At regular intervals, the Istio Pilot agent pulls configuration from Pilot to the service proxy, so that each proxy knows where to route traffic.\n</p>\n\n  <div className=\"center\" >\n  <img src={Swappingproxy} align=\"center\" alt=\"Swapping Proxy\" />\n  <p>\n  Figure 1: Example of swapping proxies—Istio + nginMesh.\n  </p>\n  </div>\n\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Swappable Sidecars","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAADQBACdASoUABIAPtFapE0oJSMiKA1RABoJYwDJEywA2g3eJStczueWulM7gfhUgAD+8EhFDF8XrmRfXTXVSni42vS8Gdj0JTekggeGiW5kPw43A0QluVRALO2BHRhEXEyP6/L1M1JfV2mQSVkGx7DxcGs+b+DrJiGjMMfCpwGSAAAA"},"images":{"fallback":{"src":"/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp","srcSet":"/static/78e798081ea95d1107c53e978a86330d/1de7a/figure1.webp 750w,\n/static/78e798081ea95d1107c53e978a86330d/ebf50/figure1.webp 1080w,\n/static/78e798081ea95d1107c53e978a86330d/479e6/figure1.webp 1366w,\n/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp 1397w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9019327129563349}},"extension":"webp","publicURL":"/static/78e798081ea95d1107c53e978a86330d/figure1.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAADQBACdASoUABIAPtFapE0oJSMiKA1RABoJYwDJEywA2g3eJStczueWulM7gfhUgAD+8EhFDF8XrmRfXTXVSni42vS8Gdj0JTekggeGiW5kPw43A0QluVRALO2BHRhEXEyP6/L1M1JfV2mQSVkGx7DxcGs+b+DrJiGjMMfCpwGSAAAA"},"images":{"fallback":{"src":"/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp","srcSet":"/static/78e798081ea95d1107c53e978a86330d/1de7a/figure1.webp 750w,\n/static/78e798081ea95d1107c53e978a86330d/ebf50/figure1.webp 1080w,\n/static/78e798081ea95d1107c53e978a86330d/479e6/figure1.webp 1366w,\n/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp 1397w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9019327129563349}},"extension":"webp","publicURL":"/static/78e798081ea95d1107c53e978a86330d/figure1.webp"}},"fields":{"slug":"/resources/service-mesh/swappable-sidecars"}},{"id":"05109a77-89f8-5206-807c-40d28f604c9d","body":"\n\n\n<NewsWrapper>\n\nMicroservices have grown tremendously in use—they enable decoupled, reusable components and support a rapid development approach. However, it’s challenging to manage a sea of disparate microservices. It’s specifically difficult to consistently apply standard features such as traffic management, security and observability mechanisms across all microservices. This issue grows as the number of microservices climbs into the hundreds and thousands.\n\nThis is where service mesh comes in. Service mesh helps to apply common observability and security features across applications. It’s typically split into a control plane, used to configure features, and a data plane, consisting of a sidecar proxy alongside each application. Nowadays, several service mesh options exist in the market, each with varying levels of complexity.\n\nThe Cloud Native Computing Foundation (CNCF) is home to much of today’s innovative cloud-native technology. The foundation now hosts a few service meshes and related projects. Below, we’ll outline the CNCF service mesh toolset to better understand how engineers can adopt these tools and their benefits.\n\n</NewsWrapper>","frontmatter":{"title":"6 CNCF Service Mesh Tools","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlQAAABXRUJQVlA4IEgAAACQAwCdASoUAAkAPtFapEwoJSOiMAgBABoJYgC7ABuk0bOyyqZgAP7p6OmnnCJO5bEuRFOOaGK/LzEkAUhqxyi9UCgm/v4AAAA="},"images":{"fallback":{"src":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp","srcSet":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/e30f5/mesh-tools.webp 750w,\n/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp 770w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42857142857142855}},"extension":"webp","publicURL":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/mesh-tools.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlQAAABXRUJQVlA4IEgAAACQAwCdASoUAAkAPtFapEwoJSOiMAgBABoJYgC7ABuk0bOyyqZgAP7p6OmnnCJO5bEuRFOOaGK/LzEkAUhqxyi9UCgm/v4AAAA="},"images":{"fallback":{"src":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp","srcSet":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/e30f5/mesh-tools.webp 750w,\n/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp 770w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42857142857142855}},"extension":"webp","publicURL":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/mesh-tools.webp"}},"fields":{"slug":"/company/news/6-cncf-service-mesh-tools"}},{"id":"1ffdfb7b-b0bf-52fe-a1e9-68e00a4f0f56","body":"\n\n\n<NewsWrapper>\n\nThe Cloud Native Computing Foundation (CNCF) announced this week during the ServiceMeshCon/KubeCon + CloudNativeCon conference that Meshery, a service mesh management plane created by Layer5, has become a sandbox-level project.\n\nIn addition, Layer5 has also donated Service Mesh Performance (SMP), a set of tools for measuring the efficiency of a service mesh, to the CNCF. SMP provides an open source framework to define standardized benchmarking practices, performance test configurations and measurements as part of an effort to create a MeshMark index for rating a service mesh. A set of service mesh performance methodologies will also be published by the IEEE later this month, developed in collaboration with engineers from Layer5, Intel, Red Hat and HashiCorp.\n\nLayer5 CEO Lee Calcote said the goal is to make it simpler for IT teams to determine which service mesh to employ based on their specific use case requirements.\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Adopts Meshery to Advance Service Mesh Management","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJYgC7ABuSM6zFAAD+GA/HJuewcu/c1Xfaf/pnrcrTaDXToWAnjwbkbfRz//EhC/d/Q5/gVwXVku1qn9x5wAAA"},"images":{"fallback":{"src":"/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp","srcSet":"/static/0e6f6057cddda267d28c32d2fef01c1e/9122e/devops.webp 750w,\n/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp 802w","sizes":"100vw"},"sources":[]},"width":1,"height":0.483790523690773}},"extension":"webp","publicURL":"/static/0e6f6057cddda267d28c32d2fef01c1e/devops.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJYgC7ABuSM6zFAAD+GA/HJuewcu/c1Xfaf/pnrcrTaDXToWAnjwbkbfRz//EhC/d/Q5/gVwXVku1qn9x5wAAA"},"images":{"fallback":{"src":"/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp","srcSet":"/static/0e6f6057cddda267d28c32d2fef01c1e/9122e/devops.webp 750w,\n/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp 802w","sizes":"100vw"},"sources":[]},"width":1,"height":0.483790523690773}},"extension":"webp","publicURL":"/static/0e6f6057cddda267d28c32d2fef01c1e/devops.webp"}},"fields":{"slug":"/company/news/cncf-adopts-meshery-to-advance-service-mesh-management"}},{"id":"ac5614bd-e99a-506d-a2bb-b9fab335ee3e","body":"\n\nimport smpMeshery from \"./smp-meshery.webp\";\n\n<NewsWrapper>\n\nLOS ANGELES, Oct. 13, 2021 - ServiceMeshCon/KubeCon + CloudNativeCon: Layer5 today announced Service Mesh Performance, an open source standard for service mesh efficiency, a growing consideration for cloud native operators and developers utilizing a service mesh in their infrastructure. With the myriad service meshes available and their sophisticated configurations, distributed systems efficacy and performance management is a continuous concern.\n\n“We donated the Service Mesh Performance specification and body of research surrounding it offers a much-needed vendor-neutral home for providing (often contentious) insights to the popular performance and efficiency questions facing service mesh vendors and more broadly cloud native infrastructure”, said Layer5 Founder and CEO Lee Calcote. “Service Mesh Performance provides a unified framework to define standardized benchmarking practices, performance test configurations, homogenous measurements, and ultimately, MeshMark, a new performance measurement index to measure the efficiency of  service meshes and their workloads both in and outside of Kubernetes.”\n\n<h3>Standardizing Service Mesh Value Measurement</h3>\n\n<a href=\"https://smp-spec.io\">Service Mesh Performance</a> is a vendor neutral, cloud native performance measurement standard for capturing and characterizing application and infrastructure efficiency, including details of infrastructure capacity, service mesh configuration, and workload metadata.\n<ol>\n    <li>the ability to reason over the efficiency by which cloud native infrastructure is run, specifically in context of a service mesh and its network functions, including custom filters and/or protocol translators using WebAssembly or other.</li>\n    <li>standard benchmarks of service mesh performance</li>\n    <li>common vernacular and measurement for exchange of performance information from system-to-system and mesh-to-mesh</li>\n    <li>apples-to-apples performance comparisons of service mesh deployments and tooling to trend workload performance.</li>\n    <li>a universal performance index to gauge a service mesh’s efficiency against deployments in other organizations’ environments.</li>\n</ol>\n\n<p>\"A common language and understanding when dealing with system performance measurements is incredibly important when comparing benchmarks from different systems or historical data from a single system; a slight variation in the measurement approach completely invalidates the comparison.”, said Nic Jackson, SMP Maintainer and Principal Developer Advocate at HashiCorp. “SMP attempts to solve these problems, bringing together a community of incredibly knowledgeable practitioners passionate about improving system performance measurements.\"</p>\n\n<img src={smpMeshery} alt=\"SMP in Meshery\"/>\n\n<h3>CNCF Adopts the Service Mesh Performance project</h3>\n\nWith multiple academic institutions and many vendors involved in the project, the CNCF provides a neutral place for publication of this research and encourages participation from each service mesh vendor under the promise of unbiased analysis, which will help all involved to collectively improve their service mesh implementations and end users to improve operations of their deployments.\n\n“As communication networks evolve toward cloud native 5G and Edge computing, service mesh forms the basis of underlying infrastructure and application networking”, said Sunku Raganath, SMP Maintainer and Solutions Architect at Intel. “Studying service mesh performance across the multitude of deployment scenarios enables us to understand its impact on latency and throughput, in turn, enabling application developers and infrastructure providers to customize and control service mesh behavior within these latency constrained environments”. Service Mesh Performance is squarely focused on critical scenarios of performance management across 5G and Edge computing environments. “An efficient service mesh performance for the given combination of resources for a particular KPI will determine whether the current hardware and software scheduling environment is optimal or needs a change“, said Mrittika Ganguli, Director and PE, cloud native solutions, NEXG, Intel.\n\n\n<h3>Partnership with University of Texas at Austin, Intel, HashiCorp, and Red Hat engineers</h3>\n\n“More than performance, in collaboration with our maintainers from Layer5, Intel, Red Hat, and HashiCorp, we are actively standardizing service mesh value measurement in the form of a new index to be announced early next year”, said Calcote. “As a foundation for this research, 5,000 service mesh performance tests donated by users of Meshery have been donated and are under analysis.” \n\nPerformance tests are run by Meshery, the open source, multi-mesh manager. Meshery is the canonical implementation of Service Mesh Performance (SMP) and the conformance tool of Service Mesh Interface (SMI). Meshery implements and helps users adopt and vendors uphold these specifications. A jointly authored paper on service mesh performance methodologies will be published by the IEEE later this month, which explores how to model your service mesh topology and optimize for your ideal configuration in context of how much operators value properties of resiliency, performance, throughput, and latency.\n\n<h3>Service Mesh Performance Resources</h3>\n<ul>\n    <li><a href=\"https://smp-spec.io/subscribe\">Community Newsletter</a></li>\n    <li><a href=\"https://discuss.layer5.io\">Service Mesh Discussion Forum</a></li>\n    <li><a href=\"https://twitter.com/smp_spec\">Service Mesh Performance Twitter</a></li>\n    <li><a href=\"https://www.linkedin.com/showcase/service-mesh-performance\">Service Mesh Performance LinkedIn</a></li>\n    <li><a href=\"https://www.youtube.com/watch?v=_yrncjtPpg4&list=PL3A-A6hPO2INwi8A3NNClvdCxDoHa9NOU\">Service Mesh Performance YouTube</a></li>\n    <li><a href=\"https://smp-spec.io\">Service Mesh Performance Website</a></li>\n</ul>\n\n<h3>About Layer5</h3>\nLayer5 offers cloud native application management by harnessing the unique position service meshes have in changing how developers write applications, how operators run modern infrastructure and how product owners manage their service offerings. Layer5’s MeshMap delivers the world’s only universal service mesh designer. Layer5’s leadership stewards the Network and Service Mesh groups in the CNCF.\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Adopts Service Mesh Performance Standard Established by Layer5 ","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRtYAAABXRUJQVlA4WAoAAAAQAAAAEwAABwAAQUxQSFQAAAABcFtt2/E8v139HSsFZRZgzS4dS2MDYwOr9gLJbsYCETEB+LSXrQ8v6zj5Che0AJsJ367iM0IFQOcAQcvMO71Jc77HPd1WACA03ZVKxbL9QEjgTwFWUDggXAAAADADAJ0BKhQACAA+0VSjS6gkoyGwCAEAGgllDbAAASQoegAA/u2kobYzYhdr5h/tYzGKbJ9RwZn3dQu5n9OXPnrv18eOnup445ufanApwPnJCQRbzsM3E6HsUOAA"},"images":{"fallback":{"src":"/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp","srcSet":"/static/8e7ee27ed78326adb6f595dc42afafa5/9a010/smp-dark-text-side.webp 750w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/a0387/smp-dark-text-side.webp 1080w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/25bb2/smp-dark-text-side.webp 1366w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.409375}},"extension":"webp","publicURL":"/static/8e7ee27ed78326adb6f595dc42afafa5/smp-dark-text-side.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRtYAAABXRUJQVlA4WAoAAAAQAAAAEwAABwAAQUxQSFQAAAABcFtt2/E8v139HSsFZRZgzS4dS2MDYwOr9gLJbsYCETEB+LSXrQ8v6zj5Che0AJsJ367iM0IFQOcAQcvMO71Jc77HPd1WACA03ZVKxbL9QEjgTwFWUDggXAAAADADAJ0BKhQACAA+0VSjS6gkoyGwCAEAGgllDbAAASQoegAA/u2kobYzYhdr5h/tYzGKbJ9RwZn3dQu5n9OXPnrv18eOnup445ufanApwPnJCQRbzsM3E6HsUOAA"},"images":{"fallback":{"src":"/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp","srcSet":"/static/8e7ee27ed78326adb6f595dc42afafa5/9a010/smp-dark-text-side.webp 750w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/a0387/smp-dark-text-side.webp 1080w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/25bb2/smp-dark-text-side.webp 1366w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.409375}},"extension":"webp","publicURL":"/static/8e7ee27ed78326adb6f595dc42afafa5/smp-dark-text-side.webp"}},"fields":{"slug":"/company/news/cncf-adopts-service-mesh-performance-standard-established-by-layer5"}},{"id":"baff9d59-5310-58fe-a823-6147f4f03957","body":"\n\nimport MeshMap from \"./MeshMap.webp\";\nimport Management from \"./configuration-management.webp\";\nimport Meshery from \"../../../../assets/images/meshery/full-logo/meshery-logo-light-text-side.svg\";\n\n\n<NewsWrapper>\n\nLOS ANGELES, CA, Oct. 13, 2021 - ServiceMeshCon/KubeCon + CloudNativeCon:  Layer5 today announced Meshery, the cloud native management plane, has been adopted by the CNCF. Offering lifecycle, configuration, and performance management, <Link to=\"/cloud-native-management/meshery\">Meshery</Link> enables the confident operation of any service mesh and their workloads. Built for the world of many service meshes, Meshery interoperates with ten different service meshes embracing their differentiated features. \n\n<h3>The Service Mesh Management Plane</h3>\n\n“We’re on a mission to see that organizations are successful in their operation of the world’s next layer of cloud native infrastructure: service meshes”, said Layer5 founder and CEO, Lee Calcote. “Through Meshery’s management of powerful, service mesh data planes, users can expect more from their infrastructure.” \n\n<img src={MeshMap} alt=\"Layer5 MeshMap\"/>\n\n\n\"Meshery is the perfect tool for ensuring that your service mesh applications are optimally configured and performing well; it also gives you a fantastic visual insight into what can be a large amount of textual configuration.\", said Nic Jackson, Principal Developer Advocate at HashiCorp.\n\nMeshery provides: \n\n<ol>\n    <li><i>Performance Management</i> - for workloads on and off of service meshes and inside and outside of Kubernetes clusters. .</li>\n    <li><i>Configuration Management</i> - with deployment of established usage patterns and analysis against configuration best practices; integration of Open Application Model.</li>\n    <li><i>Lifecycle Management</i> - for service mesh provisioning and workload onboarding.</li>\n    <li><i>Intelligence Management</i> - for dynamic configuration and deployment of WebAssembly filters for Envoy</li>\n    <li><i>Interoperation and federation</i> - by managing multiple service meshes concurrently.</li>\n</ol>\n\n60+ best practice deployment templates are actively being captured in the <Link to=\"/learn/service-mesh-books/service-mesh-patterns\">Service Mesh Patterns book</Link>, all of which will be deployable using Meshery. With 20+ service meshes available today, the <Link to=\"/service-mesh-landscape\">service mesh landscape</Link> offers some perspective as to why Meshery supports 10 different service meshes: \n<ul>\n    <li>AWS App Mesh </li>\n    <li>Citrix Service Mesh</li>\n    <li>HashiCorp Consul </li>\n    <li>Istio </li>\n    <li>Kuma</li>\n    <li>Linkerd</li>\n    <li>Network Service Mesh</li>\n    <li>NGINX Service Mesh </li>\n    <li>Open Service Mesh </li>\n    <li>Traefik Mesh</li>\n</ul>\n\n<h3>Meshery and Service Mesh Standards </h3>\n\nMeshery is the canonical implementation of <Link to=\"/projects/service-mesh-performance\">Service Mesh Performance (SMP)</Link> and the conformance tool of <Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface (SMI)</Link> - two service mesh specifications both hosted by the CNCF. Meshery implements and validates these specifications so that users can confidently operate their service mesh infrastructure, knowing their service mesh upholds industry standards. \n\n“Layer5 has been instrumental in helping us understand the patterns, best practices, and strategies in our approach to the service mesh ecosystem. Meshery has simplified the process of configuring and operating meshes. Meshery's service mesh neutrality, open source governance, and defining of industry standards like SMP, SMI, and now service mesh patterns  will ensure that Meshery helps any organization adopt meshes with utmost clarity curated to their needs\", said Yogi Porla, Customer Success Manager at HPE.\n\n<img src={Management} alt=\"Meshery-Configuration-Management\"/>\n\n<h3>The Extensible Cloud Native Manager </h3>\n\nNot just a service mesh manager, Meshery comprises a set of microservices each one fitted with extension points. Users and integrators may extend Meshery by taking advantage of designated extension points. “With one of the world’s largest enterprise information technology companies, leveraging Meshery as an extensible platform,” said said Layer5 founder and CEO Lee Calcote, “maintainers have spent a lot of time ensuring that extension points allow a variety of plugins and are available through Meshery’s architecture.”\n\n<h3>CNCF Hosts Meshery </h3>\n\n“Donation of Meshery to the CNCF has been the goal from the genesis of the project,” said Lee Calcote, chair of the CNCF’s Technical Advisory Group for Networking. “The community around Meshery is what has made it the success that it is.” The CNCF’s hosting of Meshery further enables existing participation of 300+ contributors from Layer5, Red Hat, VMware, HashiCorp, Cisco, Rackspace, Citrix, Instabase, Microsoft, OpenGov, Computas AS, Rill Data, Quantex, Lumina Networks, Asteria Aerospace and others. \n\n\n<h3>Meshery Resources</h3>\n<ul>\n    <li><a href=\"https://meshery.io/\">Meshery Website </a></li>\n    <li><a href=\"https://twitter.com/mesheryio\">Meshery Twitter </a></li>\n    <li><a href=\"https://www.linkedin.com/showcase/meshery/\">Meshery LinkedIn </a></li>\n    <li><a href=\"https://meshery.io/subscribe\">Community Newsletter</a></li>\n    <li><a href=\"https://discuss.layer5.io\">Service Mesh Discussion Forum</a></li>\n</ul>\n\n<h3>About Layer5</h3>\n<p>Layer5 offers cloud native application management by harnessing the unique position service meshes have in changing how developers write applications, how operators run modern infrastructure and how product owners manage their service offerings. Layer5’s MeshMap delivers the world’s only universal service mesh designer. Layer5’s leadership stewards the Network and Service Mesh groups in the CNCF.</p>\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Adopts Meshery, the Service Mesh Management Plane","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/229ce8bf95d65aa50bd877579da6123f/meshery-logo-light-text-side.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/229ce8bf95d65aa50bd877579da6123f/meshery-logo-light-text-side.svg"}},"fields":{"slug":"/company/news/cncf-adopts-meshery-the-service-mesh-management-plane"}},{"id":"683cd5d7-bc78-524d-a803-1b30c9c5ff57","body":"\n\nimport smp from \"./smp-in-meshery.webp\"\n\n<NewsWrapper>\n\n<p>Layer5 announced Service Mesh Performance, an open source standard for service mesh efficiency, a growing consideration for cloud native operators and developers utilizing a service mesh in their infrastructure. With the myriad service meshes available and their sophisticated configurations, distributed systems efficacy and performance management is a continuous concern.</p>\n\n<p>\"We donated the Service Mesh Performance specification and body of research surrounding it offers a much-needed vendor-neutral home for providing (often contentious) insights to the popular performance and efficiency questions facing service mesh vendors and more broadly cloud native infrastructure\", said Layer5 Founder and CEO Lee Calcote. \"Service Mesh Performance provides a unified framework to define standardized benchmarking practices, performance test configurations, homogenous measurements, and ultimately, MeshMark, a new performance measurement index to measure the efficiency of service meshes and their workloads both in and outside of Kubernetes.\"</p>\n\n<h4>Standardizing Service Mesh Value Measurement</h4>\n<p><a href=\"https://smp-spec.io/\">Service Mesh Performance</a> is a vendor neutral, cloud native performance measurement standard for capturing and characterizing application and infrastructure efficiency, including details of infrastructure capacity, service mesh configuration, and workload metadata.</p>\n\n<ol>\n  <li>the ability to reason over the efficiency by which cloud native infrastructure is run, specifically in context of a service mesh and its network functions, including custom filters and/or protocol translators using WebAssembly or other.</li>\n  <li>standard benchmarks of service mesh performance</li>\n  <li>common vernacular and measurement for exchange of performance information from system-to-system and mesh-to-mesh</li>\n  <li>apples-to-apples performance comparisons of service mesh deployments and tooling to trend workload performance.</li>\n  <li>a universal performance index to gauge a service mesh's efficiency against deployments in other organizations' environments.</li>\n</ol>\n\n<p>\"A common language and understanding when dealing with system performance measurements is incredibly important when comparing benchmarks from different systems or historical data from a single system; a slight variation in the measurement approach completely invalidates the comparison.\", said Nic Jackson, SMP Maintainer and Principal Developer Advocate at HashiCorp. \"SMP attempts to solve these problems, bringing together a community of incredibly knowledgeable practitioners passionate about improving system performance measurements.\"</p>\n\n<img src={smp} alt=\"SMP in Meshery\" />\n\n<h4>CNCF Adopts the Service Mesh Performance project</h4>\n\n<p>With multiple academic institutions and many vendors involved in the project, the CNCF provides a neutral place for publication of this research and encourages participation from each service mesh vendor under the promise of unbiased analysis, which will help all involved to collectively improve their service mesh implementations and end users to improve operations of their deployments.</p>\n\n<p>\"As communication networks evolve toward cloud native 5G and Edge computing, service mesh forms the basis of underlying infrastructure and application networking\", said Sunku Raganath, SMP Maintainer and Solutions Architect at Intel. \"Studying service mesh performance across the multitude of deployment scenarios enables us to understand its impact on latency and throughput, in turn, enabling application developers and infrastructure providers to customize and control service mesh behavior within these latency constrained environments\". Service Mesh Performance is squarely focused on critical scenarios of performance management across 5G and Edge computing environments. \"An efficient service mesh performance for the given combination of resources for a particular KPI will determine whether the current hardware and software scheduling environment is optimal or needs a change\", said Mrittika Ganguli, Director and PE, cloud native solutions, NEXG, Intel.</p>\n\n</NewsWrapper>","frontmatter":{"title":"CNCF Adopts Service Mesh Performance Standard Established by Layer5","type":"News","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRswAAABXRUJQVlA4WAoAAAAQAAAAEwAADwAAQUxQSDgAAAABR6CQkSQ2mFP4Xg2e7iMitAiLwwNNJKmZQQQ1HjCBBFpUYACSGL8yfUT/J6AadR7GUv5mKMxRAFZQOCBuAAAA0AMAnQEqFAAQAD7RVKNLqCSjIbAIAQAaCWcAwoAeiOKola2qw4oAAP7xeXDpdGKQe2d8Z7gKUU7TLzjNUf/zjotfTU4sHqRsAxLXrvQw8XwzFQ0U9z5nB6wu2ISxCh1or4lWM4j7W7LThSToAAA="},"images":{"fallback":{"src":"/static/6fb2de4f1814afd4d4f98583830e989c/b89d9/smp-in-meshery.webp","srcSet":"/static/6fb2de4f1814afd4d4f98583830e989c/379db/smp-in-meshery.webp 750w,\n/static/6fb2de4f1814afd4d4f98583830e989c/2a0e5/smp-in-meshery.webp 1080w,\n/static/6fb2de4f1814afd4d4f98583830e989c/c5b39/smp-in-meshery.webp 1366w,\n/static/6fb2de4f1814afd4d4f98583830e989c/b89d9/smp-in-meshery.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8052083333333334}},"extension":"webp","publicURL":"/static/6fb2de4f1814afd4d4f98583830e989c/smp-in-meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRswAAABXRUJQVlA4WAoAAAAQAAAAEwAADwAAQUxQSDgAAAABR6CQkSQ2mFP4Xg2e7iMitAiLwwNNJKmZQQQ1HjCBBFpUYACSGL8yfUT/J6AadR7GUv5mKMxRAFZQOCBuAAAA0AMAnQEqFAAQAD7RVKNLqCSjIbAIAQAaCWcAwoAeiOKola2qw4oAAP7xeXDpdGKQe2d8Z7gKUU7TLzjNUf/zjotfTU4sHqRsAxLXrvQw8XwzFQ0U9z5nB6wu2ISxCh1or4lWM4j7W7LThSToAAA="},"images":{"fallback":{"src":"/static/6fb2de4f1814afd4d4f98583830e989c/b89d9/smp-in-meshery.webp","srcSet":"/static/6fb2de4f1814afd4d4f98583830e989c/379db/smp-in-meshery.webp 750w,\n/static/6fb2de4f1814afd4d4f98583830e989c/2a0e5/smp-in-meshery.webp 1080w,\n/static/6fb2de4f1814afd4d4f98583830e989c/c5b39/smp-in-meshery.webp 1366w,\n/static/6fb2de4f1814afd4d4f98583830e989c/b89d9/smp-in-meshery.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8052083333333334}},"extension":"webp","publicURL":"/static/6fb2de4f1814afd4d4f98583830e989c/smp-in-meshery.webp"}},"fields":{"slug":"/company/news/cncf-adopts-service-mesh-performance-standard-established-by-layer5"}},{"id":"9e6d6d38-989d-5fb6-8743-b7b4ccc5b9b0","body":"\n\n\n\nimport MeshManager from \"./mesh-manager.webp\";\nimport MesheryClients from \"./meshery-clients.webp\";\nimport Mesheryfeatures from \"./meshery-features.webp\";\nimport MesheryDeployments from \"./meshery-deployment.webp\";\nimport Nighthawk from \"./nighthawk.webp\";\nimport Patterns from \"./patterns.webp\";\nimport ServiceMeshPatterns from \"./service-mesh-patterns.webp\";\nimport Planes from \"./planes.webp\";\nimport Mesheryoperatoricon from \"../../../../assets/images/meshery-operator/meshery-operator.svg\";\nimport MesheryLogo from \"../../../../assets/images/meshery/icon-only/meshery-logo-light.svg\";\nimport NighthawkIcon from \"../../../../assets/images/nighthawk/icon-only/SVG/nighthawk-logo.svg\";\nimport PatternsLogo from \"./patterns-logo.webp\";\n\n\n<BlogWrapper>\n\n<div className=\"intro \">\n  <p>\n    Meshery is the open-source, multi-service mesh management plane that can\n    provision ten different service meshes, onboard your applications, manage\n    WebAssembly filters, apply service mesh patterns, validate against best\n    practices, and benchmarks the performance of your service mesh deployments.\n    Let’s learn how to manage service meshes with confidence with the multi-mesh\n    manager, Meshery.{\" \"}\n  </p>\n</div>\n\n<h3>Network Planes</h3>\n<img src={Planes} className=\"slides-right\" align=\"right\" alt=\"network-planes\" />\n<p>\n  As we unfold what a management plane is, it would serve us well to talk about\n  network planes in this regard. Architecturally, a service mesh consists of two\n  planes. One of those is the data plane, while the other one is the control\n  plane. A service mesh data plane is the collection of intelligent proxies that\n  operate in unison under the coordination of the control plane. The control\n  plane performs configuration management of these intelligent proxies.\n</p>\n<p>\n  A management plane can do many things. Essentially, a management plane helps\n  you integrate service meshes into your backend systems. A robust management\n  plane allows you to take full advantage of the power of the network while\n  integrating your service delivery processes seamlessly. Your management plane\n  might federate different types of service meshes, help you instigate chaos\n  through controlled experiments, or offer automated traffic splitting in order\n  to execute different styles of canarying of your applications. Your management\n  plane might offer deep insights into the performance of your applications and\n  to the performance of your infrastructure or might deliver a change in\n  management framework.\n</p>\n\n<h3>\n  <img\n    src={MesheryLogo}\n    align=\"center\"\n    alt=\"meshery-logo\"\n    height=\"35rem\"\n    width=\"35rem\"\n    style={{paddingBottom: \"5px\", paddingTop: \"auto\"}}\n  />{\" \"}\n  Meshery\n</h3>\n\n<img\n  src={MeshManager}\n  className=\"slides-left\"\n  align=\"right\"\n  alt=\"mesh-manager\"\n/>\n<p>\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> manages the\n  lifecycle of service meshes. Meshery does workload management, helps you\n  onboard or offboard your applications onto the mesh. It also lets you do\n  performance management.{\" \"}\n  <a href=\"https://docs.meshery.io/concepts/architecture/meshsync\">MeshSync</a>,\n  a custom controller within{\" \"}\n  <Link to=\"/cloud-native-management/meshery/meshery-operator\">\n    Meshery operator\n  </Link>\n  , performs discovery of existing service meshes and deep fingerprinting of the\n  specific functions that version of your service mesh is capable of performing.\n  Through MeshSync, Meshery supports brownfield deployments of your service meshes\n  (Meshery discovers your existing service mesh deployment that is already running\n  inside your cluster(s) whether those service meshes were deployed by Meshery or\n  not){\" \"}\n</p>\n<p>\n  In order to facilitate such a deep level of understanding of each type of\n  service mesh, <Link to=\"/cloud-native-management/meshery\">Meshery</Link> has\n  adapters that are specific to each service mesh (given that each service mesh\n  has its own set of features). Consequently, in order to leverage the maximum\n  functionality of each service mesh, Meshery has separate, dedicated adapter\n  for each of the{\" \"}\n  <a href=\"https://docs.meshery.io/getting-started/overview#meshery-is-for-any-service-mesh\">\n    supported service meshes\n  </a>\n  :{\" \"}\n</p>\n\n<table className=\"table-1\" align=\"center\">\n  <thead>\n    <tr>\n      <th align=\"left\">Service Mesh</th>\n      <th className=\"status\">Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/consul\">\n          Meshery Adapter for Consul\n        </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/istio\">\n          Meshery Adapter for Istio\n        </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/kuma\">\n          Meshery Adapter for Kuma\n        </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/linkerd\">\n          Meshery Adapter for Linkerd\n        </a>\n{\" \"}\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/nsm\">\n          Meshery Adapter for Network Service Mesh\n        </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/osm\">\n          Meshery Adapter for Open Service Mesh\n        </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/traefik-mesh\">\n          Meshery Adapter for Traefik Mesh\n        </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/cpx\">\n          Meshery Adapter for Citrix Service Mesh\n        </a>\n      </td>\n      <td className=\"status\">beta</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/nginx-sm\">\n          Meshery Adapter for NGINX Service Mesh\n        </a>\n      </td>\n      <td className=\"status\">beta</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/app-mesh\">\n          Meshery Adapter for App Mesh\n        </a>\n      </td>\n      <td className=\"status\">alpha</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://docs.meshery.io/service-meshes/adapters/tanzu-sm\">\n          Meshery Adapter for Tanzu Service Mesh\n        </a>\n      </td>\n      <td className=\"status\">alpha</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> also lets you\n  integrate your Prometheus and Grafana add-ons so you can import your existing\n  Grafana dashboards to Meshery. When you first start Meshery, we also have a\n  configuration wizard, which basically walks you through the entire setup to\n  get Meshery up and running. By the end of this, it will make sure that you\n  have Meshery running on your cluster.\n</p>\n<img\n  src={MesheryDeployments}\n  className=\"slides-right\"\n  align=\"right\"\n  alt=\"meshery-deployment\"\n/>\n<p>\n  If you want a more finer configuration, you can configure your environment\n  through settings and you can configure service meshes, and you can configure\n  the metrics, you can define your performance tests to be reused.\n</p>\n<p>\n  For configuration management,{\" \"}\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> will analyze your\n  runtime environment for certain service meshes and tell you if you're doing\n  things right or not. What you can do is you can upload your applications\n  directly into Meshery, edit them in the Meshery UI itself and actually apply\n  these applications or onboard these applications on your service mesh.\n</p>\n\n<h3>\n  <img\n    src={Mesheryoperatoricon}\n    align=\"center\"\n    alt=\"meshery-operator-logo\"\n    height=\"32rem\"\n    width=\"32rem\"\n    style={{paddingBottom: \"5px\", paddingTop: \"auto\"}}\n  />{\" \"}\n  Meshery Operator\n</h3>\n<img\n  src={Mesheryfeatures}\n  className=\"slides-left\"\n  align=\"right\"\n  alt=\"Meshery-features\"\n/>\n<p>\n  <Link to=\"/cloud-native-management/meshery/meshery-operator\">\n    Meshery operator\n  </Link>\n  {\" \"}\n  is a custom controller called MeshSync. MeshSync helps keep Meshery apprised\n  of the various changes that are going on to the service meshes and various\n  changes that are happening within Kubernetes itself. In this way Meshery\n  supports not only greenfield deployments like deploying service meshes itself,\n  it also supports connecting to existing service mesh deployments, that is,\n  brownfield deployment. So it will discover your existing deployments as well.\n</p>\n<p>\n  There's an extensible concept in Meshery called a{\" \"}\n  <a href=\"https://docs.meshery.io/extensibility/providers\">provider</a>.\n  Providers can typically offer a layer of persistence so to the extent that\n  users are running performance tests intensely or to the extent that users want\n  to have a particular type of directory integrated to bring their own identity\n  to Meshery and have a multi-user experience. The other area of extensibility\n  is the notion that Meshery has a couple of APIs both – rest API and graphql\n  API. It comes with a command-line interface as well as a user interface.{\" \"}\n</p>\n\n<h3>Layer5 MeshMap</h3>\n<p>\n  Another capability of Meshery that is going to be released in the upcoming\n  version is visually configuring your service mesh using MeshMap. You can add\n  filters, applications as well as make other configurations visually here and\n  you can export it as patterns to make it reusable quite easily. It\n  automatically figures out the sample application we have deployed, then\n  generates a visual representation. It provides users the ability to design\n  service meshes, service mesh configuration, and the applications that run on\n  it.\n</p>\n\n<img src={Patterns} className=\"slides-left\" align=\"right\" alt=\"Patterns\" />\n<h3>\n  <img\n    src={PatternsLogo}\n    align=\"center\"\n    alt=\"patterns-logo\"\n    height=\"35rem\"\n    width=\"32rem\"\n    style={{paddingBottom: \"5px\", paddingTop: \"auto\"}}\n  />{\" \"}\n  Patterns\n</h3>\n<p>\n  {\" \"}\n  A pattern is capable of describing the deployment of any of the meshes that Meshery\n  supports as well as the configuration of the mesh. It also notes ongoing behavior\n  so if you wanted to run a canary you can describe that in a pattern. So, patterns\n  are like a template, they're customizable and ingestible into Meshery itself.\n</p>\n<img\n  src={ServiceMeshPatterns}\n  className=\"slides-right\"\n  align=\"right\"\n  alt=\"Service-Mesh-Patterns\"\n/>\n<p>\n  Meshery will take action based on what you've described in the pattern, things\n  like generating or running a performance test, generating load, and then doing\n  statistical analysis on that set of results. In the future, if you want to\n  deploy a web assembly filter, you can describe that in a pattern as well and\n  have Meshery apply it. The patterns are service mesh agnostic, they're\n  reusable and the initial set of them is being stored in a public-facing\n  repository. There are almost 60 patterns that have been identified.\n  Ultimately, it will allow you to ingest these and measure then orchestrate and\n  apply them to your infrastructure. You can also use Meshery to visually\n  represent them and to visually design.\n</p>\n\n<h3>\n  <img\n    src={NighthawkIcon}\n    align=\"center\"\n    alt=\"nighthawk-logo\"\n    height=\"35rem\"\n    width=\"35rem\"\n    style={{paddingBottom: \"5px\", paddingTop: \"auto\"}}\n  />{\" \"}\n  Nighthawk\n</h3>\n<p>\n  There’s a project called <Link to=\"/projects/nighthawk\">Nighthawk</Link> that\n  helps advance the existing integration of nighthawk and Meshery. Nighthawk is\n  a load generator that is an envoy project. It's written in c plus plus and has\n  a couple of intriguing capabilities that are the ongoing study within\n  Nighthawk. There is an ongoing effort to take advantage of nighthawk’s\n  adaptive load controllers, add a couple of those in and expose them through\n  Meshery to let people recursively evaluate what is ultimately an optimal\n  configuration in your environment and the service mesh.\n</p>\n<img src={Nighthawk} className=\"slides-right\" align=\"right\" alt=\"Nighthawk\" />\n\n<p>\n  If you consider that you've got a certain SLO or a certain minimum latency\n  requirement that you need to stick to that but you also want to at the same\n  time maximize resiliency characteristics of your deployment, that can be a\n  difficult thing to figure out particularly if any of your infrastructure\n  changes:\n</p>\n<ul>\n  <li>if you add another node to your environment, your clusters,</li>\n  <li>if you upgrade your service mesh,</li>\n  <li>if you change the configuration of your service mesh,</li>\n  <li>\n    if you add another service to your set of workloads that you're running.\n  </li>\n</ul>\n<p>\n  If these factors change, so does the ability to run optimization routines. To\n  help you identify the optimal configuration of your mesh but in accordance\n  with your own constraints is again the study of{\" \"}\n  <Link to=\"/projects/nighthawk\">Nighthawk</Link>.{\" \"}\n</p>\n\n<h3>\n  Check out the CNCF On-Demand Webinar:{\" \"}\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> - The Cloud Native\n  Manager to learn more!\n</h3>\n<div className=\"iframe-container\">\n  <iframe\n    width=\"460\"\n    height=\"215\"\n    src=\"https://www.youtube.com/embed/mU8qHUGYsk8\"\n    loading=\"lazy\"\n    title=\"YouTube video player\"\n    frameBorder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n    allowFullScreen\n  ></iframe>\n</div>\n\n</BlogWrapper>\n","frontmatter":{"title":"An Introduction to Meshery (Webinar-on-Demand) ","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABQAwCdASoUAAsAPtFipk0oJiOiMAgBABoJZgCw7GlXTbijAAD+0jMMBfop23C2fGXyMOcvtj4R0cAWOYI9rXbL4gq6+9RFfodXXX946n/c7bfC7T9i6EDDw4DwHhsAAAA="},"images":{"fallback":{"src":"/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp","srcSet":"/static/28ae2a6f951a849aa29443d8f5f79f4e/06597/meshery-webinar.webp 750w,\n/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp 810w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5641975308641975}},"extension":"webp","publicURL":"/static/28ae2a6f951a849aa29443d8f5f79f4e/meshery-webinar.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABQAwCdASoUAAsAPtFipk0oJiOiMAgBABoJZgCw7GlXTbijAAD+0jMMBfop23C2fGXyMOcvtj4R0cAWOYI9rXbL4gq6+9RFfodXXX946n/c7bfC7T9i6EDDw4DwHhsAAAA="},"images":{"fallback":{"src":"/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp","srcSet":"/static/28ae2a6f951a849aa29443d8f5f79f4e/06597/meshery-webinar.webp 750w,\n/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp 810w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5641975308641975}},"extension":"webp","publicURL":"/static/28ae2a6f951a849aa29443d8f5f79f4e/meshery-webinar.webp"}},"fields":{"slug":"/blog/meshery/an-introduction-to-meshery-webinar-on-demand"}},{"id":"66aed892-af50-5d83-ad6d-4dfe1659fb22","body":"\n\n\nimport Differences from \"./figure1.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<p>\nMany emerging technologies are based on or reincarnated from prior thinking and approaches to computing and networking paradigms. Why is this phenomenon required? We'll look to the microservices and containers movement for service meshes, a cloud-native approach to design scalable, independently supplied services. What was previously internal application communications have become a mesh of service-to-service remote procedure calls (RPCs) transported via networks thanks to microservices. Microservices democratize language and technology choice across independent service teams that generate new features quickly as they iteratively and continuously provide software(typically as a service). The most crucial driver of microservices as an architectural model is the decoupling of engineering teams and their enhanced speed.\n</p>\n\n<h3>Operating Many Services</h3>\n\n<p>\nThe initial couple of microservices are relatively simple to deliver and operate—at least in comparison to organizations' challenges when they first use many microservices. Whether that \"many\" is three or one hundred, a major technological issue will inevitably arise. To relieve microservices headaches, several remedies are prescribed; one notable example is the use of client libraries. In microservices environments, language and framework-specific client libraries, whether pre-existing or generated, are utilized to address distributed systems challenges. Many teams first explore their path to a service mesh in these situations. The sheer volume of services that must be managed on an individual, distributed basis (rather than centrally as with monoliths) and the challenges of ensuring their reliability, observability, and security cannot be met with outmoded paradigms, necessitating the need to reincarnate prior thinking and approaches. It is necessary to adapt new tools and techniques.\n</p>\n\n<p>\nSince microservices are distributed (often ephemeral) by nature, and the network is critical to their functioning, we should consider the fallacy that networks are reliable, have no latency, have infinite bandwidth, and that communication is guaranteed. When you consider how important it is to be able to control and secure service communication in distributed systems that rely on network calls with every transaction, every time an application is invoked, you can see why you are under tooled and why running more than a few microservices on a network topology that is in constant flux is so difficult. In the age of microservices, a new layer of tooling for the caretaking of services is needed—a service mesh is needed.\n</p>\n\n<h3>What Is a Service Mesh?</h3>\n\n<p>Service meshes provide intent-based networking for microservices describing desired behavior of the network in the face of constantly changing conditions and network topology. At their core, service meshes provide:</p>\n<ul>\n  <li>A services-first network;</li>\n  <li>A developer-driven network;</li>\n  <li>A network that is primarily concerned with alleviating application developers from building infrastructure concerns into their application code; </li>\n  <li>A network that empowers operators with the ability to declaratively define network behavior, node identity, and traffic flow through policy; </li>\n  <li>A network that enables service owners to control application logic without engaging developers to change its code.</li>\n</ul>\n\n<p>\nValue derived from the layer of tooling that service meshes provide is most evident in the land of microservices. The more services, the more value derived from the mesh. In subsequent chapters, I show how service meshes provide value outside of the use of microservices and containers and help modernize existing services (running on virtual or bare metal servers) as well.\n</p>\n\n\n<p>\nMany of you will find yourself working in organizations that have more than one sort of service mesh. Diversity is driven by a broad set of workload requirements varying from process-based to event-driven in their design, from those running on bare metal to executing in functions and those representing every style of deployment artifact in-between. The scope of service mesh capability required by different organizations varies. As a result, different service meshes are created with slightly different use cases in mind, resulting in differences in service mesh architecture and deployment models. Service meshes, which are driven by Cloud, Hybrid, On-Prem, and Edge, can enable each of these. With the requirements of different edge devices and their functions, along with ephemeral cloud-based workloads, microservice patterns and technologies give a plethora of opportunities for service mesh differentiation and specialization. Cloud vendors produce and collaborate as they provide service mesh as a managed service on their platforms.\n</p>\n\n  <div className=\"center\" >\n  <img src={Differences} align=\"center\" alt=\"comparative spectrum\" />\n  <p>Figure 1: A comparative spectrum of the difference between some of the service meshes based on their individual strengths.</p>\n  </div>\n\n<p>\nThe demand for service meshes, including meshes native to specific cloud platforms, is growing in tandem with the number of microservices. As a result, many enterprises now use various service mesh products, either separately or together.\n</p>\n\n<h3>Service Mesh Abstractions</h3>\n<p>Because there are any number of service meshes available, independent specifications have cropped up to provide abstraction and standardization across them. Three service mesh abstractions exist today:</p>\n<ul>\n    <li><Link to=\"/projects/service-mesh-performance\">Service Mesh Performance</Link> (SMP) is a format for describing and capturing service mesh performance. Created by Layer5; Meshery is the canonical implementation of this specification.</li>\n    <li>Multi-Vendor Service Mesh Interoperation (Hamlet) is a set of API standards for enabling service mesh federation. Created by VMware.</li>\n    <li><Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface</Link> (SMI) is a standard interface for service meshes on Kubernetes. Created by Microsoft; Meshery is the official SMI conformance tool used to ensure that a cluster is properly configured and that its behavior conforms to official SMI specifications.</li>\n</ul>\n\n<h3>Service Mesh Landscape</h3>\n<p>\nLet's start characterizing different service meshes now that we better understand why we live in a multi-mesh world. Some service meshes support non-containerized workloads (services operating on a VM or on bare metal), while others specialize in layering on top of container orchestrators, such as Kubernetes. All service meshes support integration with service discovery systems. The subsections that follow provide a very brief survey of service mesh offerings within the current technology landscape.\n</p>\n\n<div className=\"fact-left\">\n<p>\nSee the Layer5 <Link to=\"/service-mesh-landscape\">service mesh landscape</Link> for a comprehensive overview and characterizing of all of the service meshes, service proxies, and related tools available today. This landscape is community-maintained and places service meshes in contrast with one another so that the reader might make the most informed decision about which service mesh best suits their needs.\n</p>\n</div>\n\n<h3>Why Do I Need One?</h3>\n\n<p>\n\"I have a container orchestrator; why do I need another infrastructure layer?\" you might wonder. Container orchestrators provide most of what the cluster (nodes and containers) requires.  Container orchestrators' primary focus is on scheduling, discovery, and health, mainly at the infrastructure level (networking being a Layer 4 and below focus). As a result, microservices have unmet service-level needs. A service mesh is a specialized infrastructure layer that makes service-to-service communication safe, fast, and reliable. Its operation is typically based on a container orchestrator or integration with another service discovery system. Although service meshes are frequently deployed as a separate layer on top of container orchestrators, they do not require one because control and data plane components could be deployed independently of containerized infrastructure.\n</p>\n\n<p>\nAs stated previously, the network is directly and critically involved in every transaction, every execution of business logic, and every request made to the application in microservices deployments. For modern, cloud-native applications, network stability and latency are top priorities. A cloud native application may be made up of hundreds of microservices, each of which could have several instances, and each of those ephemeral instances could be rescheduled by a container orchestrator as needed.\n</p>\n\n<p>\nWhat would you want from a network that connects your microservices, given the network's criticality? You want your network to be as intelligent and resilient as possible. To improve the aggregate reliability of your cluster, you want your network to route traffic around from failures. You want to avoid overhead like high-latency routes or servers with cold caches in your network. You want your network to protect the traffic that flows between services against trivial attacks. You want your network to provide insight into service communication failures by exposing unforeseen dependencies and root causes. You want your network to let you impose policies at the granularity of service behaviors, not just at the connection level. You also don’t want to write all this logic into your application.\n</p>\n\n<p>You want Layer 5 management. You want a services-first network. You want a service mesh!</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh Fundamentals","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"}},"fields":{"slug":"/resources/service-mesh/service-mesh-fundamentals"}},{"id":"69ed0e3c-9a02-52ec-a145-d0e586e51424","body":"\n\n\nimport Planes from \"./figure1.webp\";\nimport Topology from \"./figure2.webp\";\nimport Architecture from \"./figure3.webp\";\nimport Meshery from \"./figure4.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<p>\nService mesh architectures typically consist of three planes: a management plane, a control plane, and a data plane. The analogy between how physical networks (and their equipment) are designed and managed along with the concept of these three planes immediately resonates with network engineers. \nThe OSI model is another type of training that network engineers receive. For those who haven't seen the OSI model in a while, Figure 1 serves as a refresher.\n</p>\n\n <div className=\"right\" >\n  <img src={Planes} align=\"right\" alt=\"Network Planes\" />\n  <p>Figure 1: Physical networking versus software-defined networking planes</p>\n </div>\n\n<p>Let’s contrast physical networking planes and network topologies with those of service meshes:</p>\n\n<h3>Physical network planes</h3>\n\n<p>\nThe application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB). A forwarding information base (FIB) is a basic, dynamic table that maps a media access control address (MAC address) to a physical network port, allowing traffic to be transmitted at wire speed (using ASICs) to the next device.\n</p>\n\n<p>\nThe physical networking control plane is the logical entity that is linked to router processes and functions and is responsible for generating and maintaining necessary intelligence about the state of the network (topology) and the router's interfaces. The control plane includes network protocols, such as routing, signaling, and link-state protocols that are used to build and maintain the operational state of the network and provide IP connectivity between IP hosts.   As physical network control planes run in-band with network traffic, they are vulnerable to Denial of service (DoS) attacks, which can result in:\n</p>\n\n<ul>\n  <li>Exhaustion of memory and/or buffer resources.</li>\n  <li>Loss of routing protocol updates and keepalives.</li>\n  <li>Slow or blocked access to interactive management sessions.</li>\n  <li>High CPU utilization.</li>\n  <li>Routing instability, interrupted network reachability, or inconsistent packet delivery.</li>\n</ul>\n\n<p>\nThe physical networking management plane is a logical entity that specifies the traffic used to access, manage, and monitor all network elements via protocols such as SNMP, SSH, HTTPS, and Telnet. All network provisioning, maintenance, and monitoring operations are supported by the management plane. Although control plane network traffic is handled in-band with all other data plane traffic, management plane traffic can be carried over an out-of-band (OOB) management network to enable separate reachability if the primary in-band IP path is unavailable (and create a security boundary). Restricting management plane access to devices on trusted networks is critical.\n</p>\n\n<p>\nPhysical networking control and data planes are tightly coupled and generally vendor-provided as a proprietary integration of hardware and firmware. Software-defined networking (SDN) has done much to standardize and decouple. OpenvSwitch and OpenDaylight are two examples of SDN projects. We’ll see that control and data planes of service meshes are not necessarily tightly coupled.\n</p>\n\n  <div className=\"left\" >\n  <img src={Topology} align=\"right\" alt=\"Mesh Topology\" />\n  <p>Figure 2: Mesh topology—fully connected network nodes</p>\n  </div>\n\n<h3>Physical network topologies</h3>\n\n<p>\nStar, spoke-and-hub, tree (also called hierarchical), and mesh are some of the most used physical networking topologies. Nodes in mesh networks connect directly and non-hierarchically, such that each node is connected to an indefinite number (typically as many as possible or as needed dynamically) of neighbour nodes, allowing at least one path from a given node to any other node to route data efficiently .\n</p>\n\n<p>\nWireless is the canonical use case for physical mesh networks in which the networking medium is sensitive to line-of-sight, weather-induced, or other disruptions, and so reliability is a top priority. Mesh networks typically self-configure, allowing dynamic task distribution. This ability is especially important to mitigate the risk of failure (improving resiliency) and reacting to continuously changing topologies. It's easy to see why this network topology is the preferred design for service mesh architectures.\n</p>\n\n<h3>Service mesh network planes</h3>\n\n<p>Service mesh architectures typically employ the same three networking planes: data, control, and management. </p>\n\n<div className=\"right\" >\n<img src={Architecture} align=\"right\" alt=\"Service mesh architecture\" />\n<p>Figure 3: An example of service mesh architecture. In Conduit’s architecture, control and data planes divide in-band and out-of-band responsibility for service traffic</p>\n</div>\n\n<p>\nA service mesh data plane (also known as the proxying layer) intercepts all packets in a request and performs health checks, routing, load balancing, authentication, authorization, and generation of observable signals. Service proxies are transparently inserted, and applications are oblivious of the data plane's existence when they conduct service-to-service calls. Intra-service communication, as well as inbound (ingress) and outbound (egress) service mesh traffic, are handled by data planes. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling prior to sending (or not sending) along to the application.  Traffic is transparently intercepted and redirected to the service proxy in order to reroute traffic from the service proxy to the service application. The service proxy intercepts and redirects traffic between the service proxy and service application places the service application’s container onto a network it would otherwise not be on. All traffic to and from the service application is seen by the service proxy.  Service proxies are the building blocks of service mesh data planes.\n</p>\n\n<div className=\"fact\">\nTraffic Interception and Redirection:\n<p>The technology utilised to intercept and redirect traffic varies between service meshes. Some meshes allow you the option of using iptables, IPVS, or eBPF to transparently proxy requests between clients and service applications. Other service mesh proxies operate in a less transparent manner, requiring application traffic to be configured to direct their traffic to the proxy. The operating system type and kernel version used for the service mesh deployment are constrained by the choice of each of these technologies, which influences the speed with which packets are processed.</p>\n</div>\n\n<p>\nEnvoy is one of the most widely used proxy in service mesh data planes. It's also common to see it deployed as a load balancer or ingress gateway. The proxies used in service mesh data planes are highly intelligent.  In order to manipulate network packets (including application level data), they may include any number of protocol-specific filters . Extending data plane capabilities with technology advancements like WebAssembly allows service meshes to inject additional logic into requests while simultaneously handling large traffic loads.\n</p>\n\n<p>\nWhen the number of proxies becomes unmanageable or when a single point of visibility and control is required, a service mesh control plane is essential. Control planes offer policy and configuration for the services in the mesh, transforming a set of isolated, stateless proxies into a service mesh. Control planes run out-of-band and do not directly touch any network packets in the mesh. Control planes usually include a command-line interface (CLI) and a user interface to interact with, both of which provide access to a centralised API for regulating proxy behaviour holistically. You can use the control plane's APIs to automate changes to its configuration (for example, using a continuous integration/continuous deployment pipeline), where configuration is generally version controlled and updated.\n</p>\n\n<div className=\"fact\">\n  Proxies are generally considered stateless, but this is a thought-provoking concept. In the way in which proxies are generally informed by the control plane of the presence of services, mesh topology updates, traffic and authorization policy, and so on, proxies cache the state of the mesh but aren’t regarded as the source of truth for the state of the mesh.\n</div>\n\n<p>\n  We can see how the data and control planes are packaged and deployed in Linkerd (pronounced \"linker-dee\") and Istio (pronounced \"Ist-tee-oh\"), two prominent open source service meshes. In terms of packaging, Linkerdv1 contains both its proxying components (linkerd) and its control plane (namerd) packaged together simply as “Linkerd,” and Istio brings a collection of control plane components (Galley, Pilot, and Citadel) to pair by default with Envoy (a data plane) packaged together as “Istio.” Envoy is often labeled a service mesh, inappropriately so, because it takes packaging with a control plane to form a service mesh. \n</p>\n\n<p>\n  A service mesh management plane is a higher order level of control as shown in Figure 4. A management plane may provide a variety of functions. As such, implementations vary in their functionality: some focusing on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, providing insight across a collection of diverse meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.\n</p>\n\n  <div className=\"left\" >\n  <img src={Meshery} align=\"right\" alt=\"Meshery\" />\n  <p>Figure 4: Meshery, the cloud native management plane’s architecture.</p>\n  </div>\n  \n<p>\nA service mesh management plane is a higher order level of control. A management plane can provide various functions. As a result, implementations differ in functionality, with some focused on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, which provides insight across a set of meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.\n</p>\n\n<p>\nIn terms of deployments, data planes, such as Linkerdv2, contain proxies that are created as part of the project and are not designed to be configured by hand, but rather to have their behaviour completely controlled by the control plane. Other service meshes, such as Istio, prefer not to develop their own proxy and instead ingest and utilise independent proxies (separate projects), simplifying proxy selection and deployment outside of the mesh(standalone). Control planes are often deployed in a separate \"system\" namespace, using Kubernetes as the example infrastructure. Depending on how closely they integrate with non-containerized workloads and a business's backend systems, management planes are deployed both on and off cluster.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh Architecture and Components","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAACwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJZwDA3BrR9Xt/P25pgAD+9hOmVk+abt1tHkl3ma3Uj4FzlaUBYXhUB46QVek8w/FQwowWf4bDOrGt2cgz076DS6IIMQQusskVT7huWtpcwAAA"},"images":{"fallback":{"src":"/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp","srcSet":"/static/31130b77471902ca1778529343876be1/eb15a/figure2.webp 750w,\n/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp 981w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6442405708460754}},"extension":"webp","publicURL":"/static/31130b77471902ca1778529343876be1/figure2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAACwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJZwDA3BrR9Xt/P25pgAD+9hOmVk+abt1tHkl3ma3Uj4FzlaUBYXhUB46QVek8w/FQwowWf4bDOrGt2cgz076DS6IIMQQusskVT7huWtpcwAAA"},"images":{"fallback":{"src":"/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp","srcSet":"/static/31130b77471902ca1778529343876be1/eb15a/figure2.webp 750w,\n/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp 981w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6442405708460754}},"extension":"webp","publicURL":"/static/31130b77471902ca1778529343876be1/figure2.webp"}},"fields":{"slug":"/resources/service-mesh/service-mesh-architecture-and-components"}},{"id":"6c707281-4d7e-5605-aea8-0c70e1869079","body":"\n\n\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<h2>Data Plane</h2>\n<p>\nService proxies (gateways) are elements of the data plane. The number of proxies present depends on the number of services you’re running and the design of the service mesh’s deployment model. Some service mesh initiatives create their own proxies, while others rely on existing ones. Envoy is a popular choice as the data plane element.\n</p>\n<strong>BFE</strong>\n   <p><a href=\"https://github.com/bfenetworks/bfe\">BFE</a> is a Golang-based modern proxy. HTTP, HTTPS, SPDY, HTTP2, WebSocket, TLS, and FastCGI are among the load balancing algorithms and multiple protocols it supports. Users can configure rule and content-based routing using BFE's own domain-specific language.</p>\n<strong>Envoy</strong>\n<p>\nEnvoy is a modern proxy developed in C++. Envoy's initial success stemmed from its ability to hot-reload both its configuration and itself (update itself in place while handling connections). API gateways, ingress controllers, service meshes, and managed offerings by Cloud providers are just a few of the projects that have been built on top of Envoy. Istio, App Mesh, Kuma, Open Service Mesh, and other service meshes (discussed in the Control Plane section) have been built on top of Envoy.\n</p>\n<strong>Linkerdv2 </strong>\n<p>\nThe linkerd2-proxy is explicitly built for the service mesh sidecar use case, Linkerd, can be significantly smaller and faster than Envoy-based service meshes. Rust was chosen as the implementation language because it is memory-safe and highly performant. This service proxy purports a sub-1ms p99 traffic latency. Open-source.  From Buoyant.\n</p>\n<strong>NGINX</strong>\n   <p><a href=\"https://github.com/nginxinc/nginmesh\">nginMesh</a> project deploys NGINX as a sidecar proxy in Istio. Open source. Written primarily in C and Rust. From NGINX. </p>\n\n<br />\n<p>The following are a couple of early, and now antiquated, service mesh–like projects, forming control planes around existing load-balancers:</p>\n\n<strong>SmartStack</strong>\n<p>Comprising two components: Nerve for health-checking and Synapse for service discovery. Open source. From AirBnB. Written in Ruby.</p>\n<strong>Nelson</strong>\n<p>Takes advantage of integrations with Envoy, Prometheus, Vault, and Nomad to provide Git-centric, developer-driven deployments with automated build-and-release workflow. Open source. From Verizon Labs. Written in Scala.</p>\n\n<h2>Control Plane</h2>\n<strong>Consul </strong>\n<p>Announced service mesh capable intention in v1.5. Became a full service mesh in v1.8. Consul uses Envoy as its dataplane, offering multi-cluster federation.\nOpen and closed source. From HashiCorp. Primarily written in Go.</p>\n<strong>Linkerd</strong>\n<p>Linkerd is hosted by the Cloud Native Computing Foundation (CNCF) and has undergone two major releases with significant architectural changes and an entirely different code base used between the two versions.</p>\n<strong>Linkerdv1</strong>\n<p>The first version of Linkerd was built on top of Twitter Finagle. Pronounced “linker-dee”, it includes both a proxying data plane and control plane, Namerd (“namer-dee”), all in one package.\nOpen source. Written primarily in Scala.</p>\n<li>Data plane can be deployed in a node proxy model (commonly)  or in a proxy sidecar (not common). Proven scale, having served more than one trillion service requests.</li>\n<li>Supports services running within container orchestrators and as standalone virtual or physical machines.</li>\n<li>Service discovery abstractions to unite multiple systems.</li>\n<strong>Linkerdv2</strong>\n<p>The second major version of Linkerd is based on a project formerly known as Conduit, a Kubernetes-native and Kubernetes-only service mesh announced as a project in December 2017. In contrast to Istio and in learning from Linkerdv1, Linkerdv2’s design principles revolve around a minimalist architecture and zero configuration philosophy, optimizing for streamlined setup.</p>\n<li>Open Source. From Buoyant. Control-plane written in Go. Hosted by the CNCF.</li>\n<li>Support for gRPC, HTTP/2, and HTTP/1.x requests plus all TCP traffic. Currently only supports Kubernetes.</li>\n\n<strong>Istio</strong>\n<p>Announced as a project in May 2017, Istio is considered to be a “second explosion after Kubernetes” given its architecture and surface area of functional aspiration.</p>\n<li>Supports services running within container orchestrators and as standalone virtual or physical machines.</li>\n<li>Was the first service mesh to promote the model of supporting automatic injection of service proxies as sidecars using Kubernetes Admission controller.</li>\n<li>\nMany projects have been built around Istio. Commercial, closed source offerings built around Istio include: AspenMesh, VMware Tanzu Service Mesh, Octarine (acquired by VMware in 2020).\nCommercial, closed source offerings built inside of Istio include Citrix Service Mesh To be built “within Istio” means to offer the Istio control plane with an alternative service proxy. Citrix Service Mesh displaces Envoy with CPX. \nOpen source, data plane proxy, MOSN released support for running under Istio as the control plane, while displacing Envoy as the service proxy.\n</li>\n<li>Many projects have been built within Istio.</li>\n<li>Mesher. Layer 7 (L7) proxy that runs as a sidecar deployable on Huawei Cloud Service Engine. Open source. Written primarily in Go. From Huawei.</li>\n\n<strong>NGINX Service Mesh </strong>\n<p>NGINX Service Mesh is a more recent arrival into the service mesh arena, having released in September 2020. Using an Nginx Plus augmented to interface with Kubernetes natively as its dataplane, supports ingress and egress gateways through NGINX Plus Kubernetes Ingress Controllers. NGINX Service Mesh offers its control plane as a CLI, meshctl, using the Service Mesh Interface (SMI) specification as its API. \nBoth Open and closed source. From NGINX. Primarily written in C.</p>\n<strong>Others including Open Service Mesh, Maesh, Kuma, App Mesh...</strong>\n<p>\nThis list is meant to give you an idea of the wide range of service meshes that are currently available. A complete list of service meshes and their details may be found in the Layer5 <Link to=\"/landscape\">service mesh landscape</Link>, maintained by the community.\n</p>\n\n<h2>Management Plane</h2>\n<p>\nThe management plane sits a level above the control plane. It can perform various tasks such as operational patterns, business system integration, and application logic enhancement while functioning across different service meshes. A management plane can perform workload and mesh configuration validation, whether in preparation for onboarding a workload into the mesh or as you upgrade to new versions of components running your control and data planes or new versions of your applications. Management planes help organizations running a service mesh get the most out of their investment. Performance management is one part of maintaining service meshes, a function at which Meshery excels. \n </p>\n<strong>Meshery</strong>\n<p>\nthe cloud native management plane for adopting, operating and developing on different service meshes. Meshery integrates business processes and application logic into service meshes by deploying custom WebAssembly (WASM) modules as filters in Envoy-based data planes. It provides governance, policy and performance and configuration management of service meshes with a visual topology for designing service mesh deployments and managing the fine-grained traffic control of a service mesh. \n- Open source. Created by Layer5. Primarily written in Go.\n</p>\n\n<div className=\"fact\">\nService Mesh Linguistics\n<p>As the lingua franca of the cloud-native ecosystem, Go is certainly prevalent and you might expect most service mesh projects to be written in Go. By the nature of their task, data planes must be highly efficient in the interception, introspection, and rewriting of network traffic. As a data plane component, Envoy is written in C++11 because it provides excellent performance (surprisingly, some say it provides a great developer experience). Rust has found its way into service meshes as a growing language (and something of a C++ competitor). Because of its properties around efficiency (outperforming Go) and memory safety (when written to be so) without garbage collection, Rust has been used for Linkerdv2’s data plane component, for the former nginMesh’s Mixer module (see “How to customize an Istio service mesh”), and is now being used in WebAssembly programs as data plane filters (see “Write WASM filters for Envoy in Rust and deploy with Consul”).</p>\n</div>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Network Planes","type":"Article","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRn4AAABXRUJQVlA4IHIAAAAQBACdASoUAA4APtFUo0uoJKMhsAgBABoJYwCdACG/20zLpOrRzp1pAAD+64UofulJnwob3V1z7pVQLm83y8IJL2P9n6OeIYHPEGjQ7RW28lChlIv756RQsITjxgIPKXo+hXEB9JrFPstG98qGK+sQAAA="},"images":{"fallback":{"src":"/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp","srcSet":"/static/e4a8a3456e3bf7e3eab6615f593cc287/f03b4/network-planes.webp 750w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/2e49b/network-planes.webp 1080w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp 1272w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6761006289308176}},"extension":"webp","publicURL":"/static/e4a8a3456e3bf7e3eab6615f593cc287/network-planes.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRn4AAABXRUJQVlA4IHIAAAAQBACdASoUAA4APtFUo0uoJKMhsAgBABoJYwCdACG/20zLpOrRzp1pAAD+64UofulJnwob3V1z7pVQLm83y8IJL2P9n6OeIYHPEGjQ7RW28lChlIv756RQsITjxgIPKXo+hXEB9JrFPstG98qGK+sQAAA="},"images":{"fallback":{"src":"/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp","srcSet":"/static/e4a8a3456e3bf7e3eab6615f593cc287/f03b4/network-planes.webp 750w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/2e49b/network-planes.webp 1080w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp 1272w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6761006289308176}},"extension":"webp","publicURL":"/static/e4a8a3456e3bf7e3eab6615f593cc287/network-planes.webp"}},"fields":{"slug":"/resources/network-planes/network-planes"}},{"id":"c0ba14fc-089b-5939-abc8-083252a26606","body":"\n\n\n\nimport Hamlet from \"./Hamlet.webp\";\nimport Graph from \"./Graph1.webp\";\nimport Bucket from \"./Graph2.webp\";\nimport SMI from \"./SMI-demo.webp\";\nimport SMP from \"./SMP.webp\";\nimport Abstractions from \"./abstractions.webp\";\nimport Journey from \"./cloud-native-journey.webp\";\nimport Flowchart from \"./flowchart.webp\";\n\n\n\n<BlogWrapper>\n\n<div className=\"intro \">\n  <p>\n   <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovator, product and technology leader, active in the community as a Docker Captain, Cloud Native Ambassador and GSoC, GSoD, and Community Bridge Mentor. In this talk, he walked through service mesh specifications and why they matter in your deployment.\n   How many service mesh specifications do you know? He went through all of them. So, no worries if you're unfamiliar.\n  </p>\n</div>   \n\n### Service Mesh Specifications:\n<img src={Abstractions} className=\"slides-left\" align=\"left\" alt=\"abstractions\" />\n\nAs the ubiquity of service meshes unfolds and they become a commonplace for any cloud native or edge environment, so does the need for vendor and technology-agnostic interfaces to interact with them. The Service Mesh Interface (SMI), the Service Mesh Performance (SMP), and Multi-Vendor Service Mesh Interoperation (Hamlet) are three open specifications solving the challenge of interoperability, workload and performance management between service meshes. \n\nLearn what makes each of them unique and why they are much needed. See each of these three specifications in action as we use Meshery, the open-source service mesh management plane to demonstrate the value and functionality of each service mesh abstraction, and the adherence of these specifications by Istio, Linkerd, Consul and other popular service meshes.\n\n### Cloud native Journey to service meshes:\n\n<img src={Journey} className=\"slides-right\" align=\"right\" alt=\"journey-image\" />\n\nThe advent of cloud native was the popularization of containers. Thank you Docker! From there, containers took off like wildfire. Turns out you need an orchestrator to wrangle that sprawl. We saw a number of orchestrators come and we still have a number of orchestrators around.\n\nService meshes have become a hot topic in the last few years. They still continue to be, rightfully so, a very powerful piece of technology. “A lot of the power is yet to come from my perspective. For my part, I believe that there is a tomorrow in which data plane intelligence really matters. And matters about how people write cloud native applications.”, Lee emphasized. Not everyone quite understands the capabilities of meshes as they are promoted and spoken about today. So come along into the journey of service mesh.\n\nThere are a number of service meshes out there. One of the community projects is to track the landscape of all of the meshes there are. There’s a lot to say about each of them, their architecture, and their working. Why are they made? Who are they focused on? What do they do? When did they come about? Why are some of them not here anymore? Why are we still seeing new ones? A lot of things to go through. You might be interested in any number of the details that the landscape tracks.\n <div className=\"note\">Be Aware, It's Meshy Out There!</div>\n\n### Service Mesh Interface\n<img src={SMI} className=\"slides-left\" align=\"left\" alt=\"smi-image\" />\n<ul>\n    <li>Its goal and genesis were born inside of Kubernetes.</li>\n    <li> Being a specification that is native to Kubernetes, its focus is on lowest common denominator functionality.</li>\n    <li> The focus on bringing forth APIs that highlight and reinforce the most common use cases that service meshes are being used for currently</li>\n    <li>Leaves space and provides extensibility room for additional APIs to address other service mesh functionality as more people adopt and make use cases well known.</li>\n    <li>There are seven service meshes that claim compatibility with SMI. There's been a community effort, open-source effort to create service mesh conformance tests to assert whether or not a given service mesh is compatible with SMI</li>\n    <li> In order to facilitate those types of tests, you need to have a tool to provision a sample application on those services which will generate load and test whether traffic splitting behaves as expected or works with that service mesh implementation properly.</li>\n    <li>Then you need to be able to collect the results, guarantee the provenance of those results and publish them.</li>\n    <li> As a community, we turned to Meshery as the tool to implement <Link to=\"/projects/service-mesh-interface-conformance\">SMI conformance</Link> and we have been working with the individual service meshes to validate their conformance. </li>\n</ul>    \n<b>Meshery</b>\n<ul>\n  <li> We work on an open-source project called <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.</li>\n  <li> Meshery, the cloud native management plane, is the canonical implementation of the service mesh performance.</li>\n  <li>The management planes can do a number of things to help bridge the divide between other back-end systems and service meshes. They also help performance management, configuration management, making sure you are following best practices in your implementations by taking common patterns and applying them to your environment </li>\n</ul>\nLet's take a moment to demo what it looks like to validate conformance in SMI using Meshery.\n\n<img src={Graph} className=\"slides-left\" align=\"left\" alt=\"graph\" />\n<ul>\n   <li> We need to spin up Meshery locally</li>\n   <li> We use mesheryctl as the command line interface to work with Meshery.</li>\n   <li> We can interact with a number of different service mesh. The service mesh we’re going to work with today is an Open service mesh (one of those 7 that is compatible with SMI). Let’s put it to the test.</li>\n   <li> We'll initiate <Link to=\"/projects/service-mesh-interface-conformance\">SMI conformance</Link></li>\n   <li>These tests go and do assertions across these different specifications. We’re looking at traffic access, traffic splitting, traffic specification. Meshery then collects these results and will eventually be publishing them in combination with the SMI project.</li>\n</ul>\n\n### Service Mesh Performance\n<img src={SMP} className=\"slides-right\" align=\"right\" alt=\"smp-image\" />\n<ul>\n    <li>Focused on describing and capturing the performance of a service mesh.</li>\n    <li>The overhead of the value is another way of looking at it and characterizing it.</li>\n    <li>Trying to characterize the performance of the infrastructure of a service mesh can be really difficult.</li>\n    <li>Considering the number of variables that you would have to track, how difficult it can be to have repeatable tests, and benchmark your environment, to track your history based on your environment, compare performance between other meshes people need.</li>\n    <li>SMP creates a standard way of capturing the performance of the mesh to help with these issues.</li>\n    <li>It's also the way in which you're configuring your control plan of your service mesh.</li>\n</ul>    \n\nYou might be using a client library to do some service mesh functionality. Maybe you're using those in combination with the service mesh. What costs more? What's more efficient? What's more powerful? Maybe you're using web assembly and filters there.\nThese are all open questions that <Link to=\"/projects/service-mesh-performance\">SMP</Link> assists in answering in your environment. You’d be surprised by some of the results of some tests that we have done and that the community has done in combination with a couple of universities and graduate students.\n\n<b>Performance Test</b>\n\nDemonstration of the implementation of service mesh Performance:\n\n<img src={Flowchart} className=\"slides-left\" align=\"left\" alt=\"flowchart\" />\n<ul>\n  <li> On the terminal, we have a local deployment of Meshery running. You can also deploy on Kubernetes as well as the vendor Kubernetes platforms like AKS, EKS and GCP or you can use a dockerized container to run Meshery. You can also have your Kubernetes on Docker desktop.</li>\n  <li>We have the Open service mesh deployed.</li>\n  <li> The Meshery UI is exposed at 9081 port. This is the UI which is used to instantiate a Load test.</li>\n  <li> Over here you can see we have 3 load generators fortio, wrk2, nighthawk.</li>\n  <li> All of these load generators have their own set of attributes which they record correctly and each of its attributes have their own significance. We begin with fortio.</li>\n  <img src={Bucket} className=\"slides-right\" align=\"right\" alt=\"graph\" />\n\n  <li> You can actually download the test results or you can just browse into the Results Tab and see all of the tests which you have run until now.</li>\n  <li>Next, we used nighthawk to generate the load and benchmark the service for the same. Nighthawk is a load generator which is maintained by the Envoy community and is relatively new. It still hasn't got its 1.0 release but right now Nighthawk has sufficient features to compete with different generators which are still in the play. It can generate a gRPC service on its own and it has some more attributes which you can expose using their CLI tools.</li>\n  <li> You can also see that Meshery has the capability to search your environment, see what specifications are being used and what's the load on your Kubernetes.</li>\n  <li>Jump into the results Tab and see how we compare with these results.</li>\n  <li>You can click on the download. You will see that a yaml gets downloaded in which you can browse and see that the start time, load time, the performance latencies, the metrics are being captured.</li>\n</ul>  \n\n### Hamlet or Multi-vendor Service Mesh Interoperation\n<img src={Hamlet} className=\"slides-left\" align=\"left\" alt=\"hamlet-image\" />\n<ul>\n  <li>Focus on service mesh federation</li>\n  <li>Specifies a set of API standards for enabling service mesh federation</li>\n  <li>Hamlet takes on a client-server architecture in which resources and services of one service mesh are discovered, registered and using a common format, information about them is exchanged between different service mesh.</li>\n  <li>Rules around authentication and authorization rules around which Services get exposed and to whom and who can communicate with them and whether or not they can do it securely. These are things that Hamlet addresses.</li>\n  <li>\n  The specification currently consists of two APIs:\n    <ul>\n      <li><strong>The Federated Resource Discovery API</strong>: API to authenticate and securely distribute resources between federated service meshes.</li>\n      <li>The <strong>Federated Service Discovery API</strong>: API to discover, reach, authenticate and securely communicate with federated services.</li>\n    </ul>\n  </li>\n  <li>Part of the real power is the ability to overcome what are likely to be separate administrative domains. The intention here is to marry up connect two disparate service mesh deployments, those deployments might be of the same type, they might be of two different types.</li>\n</ul>\n\nIn addition to SMI, SMP and Hamlet there has been an emergence of service mesh patterns, by which people are running and operating service meshes. There is a service mesh working group under CNCFs network that is helping identify those patterns of which there's a list right now unbeknownst to you. Reach out, join it, help us work through the 60 patterns that are defined right now. 30 of those are going into an <Link to=\"/learn/service-mesh-books\">O’Reilly</Link> book called <Link to=\"/learn/service-mesh-books/service-mesh-patterns\">Service Mesh Patterns</Link>.\n\nSomething that isn’t always obvious to folks is this piece of value that people get from a service mesh and actually from the specifications that we were just mentioning. It is the fact that teams are decoupled when you’re running a mesh. Developers get to iterate a bit independently of operators, and so do operators get to make changes to implement infrastructure to the way that applications behave independent of developers in the presence of a mesh.  Both of these teams are significantly empowered. Everybody gets a piece of power when they deploy a mesh.\n\n\n_**P.S.: If these topics excite  come and say \"Hi\" on our [Slack Channel](http://slack.layer5.io) and one of us will reach out to you!**_\n\n</BlogWrapper>\n","frontmatter":{"title":"Service Mesh Specifications and Why They Matter","type":"Blog","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoR3N4AAWScxK3A0AAD+y+7TltDm8faWnWkrgNwKEaB+a5F7h6kfv+PNmIbiHtDLJbrKy70mpaSz/NUvAS+UKSii+WgoY4/+Ld6wAAAA"},"images":{"fallback":{"src":"/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp","srcSet":"/static/f9e70b0d102359852501532eaf88c857/a66aa/Cover-image.webp 750w,\n/static/f9e70b0d102359852501532eaf88c857/65dd5/Cover-image.webp 1080w,\n/static/f9e70b0d102359852501532eaf88c857/f9724/Cover-image.webp 1366w,\n/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630208333333334}},"extension":"webp","publicURL":"/static/f9e70b0d102359852501532eaf88c857/Cover-image.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoR3N4AAWScxK3A0AAD+y+7TltDm8faWnWkrgNwKEaB+a5F7h6kfv+PNmIbiHtDLJbrKy70mpaSz/NUvAS+UKSii+WgoY4/+Ld6wAAAA"},"images":{"fallback":{"src":"/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp","srcSet":"/static/f9e70b0d102359852501532eaf88c857/a66aa/Cover-image.webp 750w,\n/static/f9e70b0d102359852501532eaf88c857/65dd5/Cover-image.webp 1080w,\n/static/f9e70b0d102359852501532eaf88c857/f9724/Cover-image.webp 1366w,\n/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630208333333334}},"extension":"webp","publicURL":"/static/f9e70b0d102359852501532eaf88c857/Cover-image.webp"}},"fields":{"slug":"/blog/service-mesh-specifications/service-mesh-specifications-and-why-they-matter"}},{"id":"44f6283d-2e84-5856-9fca-f4c479fcb658","body":"\n\n\nimport Stakeholders from \"./figure1.webp\";\nimport Graph from \"./citrix-architectures-for-kubernetes-environments.svg\";\nimport TwoTier from \"./citrix-two-tier-ingress.svg\";\nimport Unified from \"./citrix-unified-ingress.svg\";\nimport Servicemesh from \"./citrix-service-mesh.svg\";\nimport Servicemeshlite from \"./citrix-service-mesh-lite.svg\";\nimport Comparison from \"./citrix-oss-integration-categories.svg\";\n\n\n<ResourcesWrapper>\n\n<h2>The Role of Application Delivery in Your Cloud Native Journey</h2>\n<p>\n    As digital transformation is changing how your organization conducts business, so is it changing how your products and services are delivered. The infrastructure and practices by which your software is continuously deployed and operated — your application delivery — is the fulcrum of your organization’s digital transformation. Likely you are progressing on your cloud native journey — that is, transitioning from monolithic to container-based microservices architectures with the goal of achieving agility, portability, and on-demand scalability. Kubernetes is the platform of choice for many, providing the automation and control necessary to manage microservices-based applications at scale and with high velocity. \n</p>\n<p>\n    With the network part and parcel to each and every service request in your microservices-based application, it may come as no surprise that at the core of application delivery is your application delivery controller, an intelligent proxy that accelerates and manages application delivery. With no standard definition of what an application delivery controller does, the capabilities of intelligent proxies vary broadly. And so in this white paper, we’ll explore application delivery controllers as they relate to your architecture choices, your use of Kubernetes platforms, and open source tools. \n</p>\n\n<h2>7 Key Considerations for Microservices-Based Application Delivery</h2>\n<p>\n    Before embarking on your cloud native journey, it is essential to critically assess your organization’s readiness with regard to skill set so that you can choose the solutions that best fit the business objective you are seeking to meet in context of your ability to do so. There are seven key considerations to address when planning your microservices-based application delivery design:\n</p>\n<ol>\n<li>Architecting your foundation the right way </li>\n<li>Openly integrating with the cloud native ecosystem</li>\n<li>Choosing the perfect proxy</li>\n<li>Securing your applications and APIs</li>\n<li>Enabling CI/CD and canary deployment with advanced traffic steering </li>\n<li>Achieving holistic observability</li>\n<li>Managing monoliths and microservices</li>\n</ol>\n<p>\nA thorough evaluation of these seven considerations is best done with specific tasks and goals in mind. Depending on the size and diversity of your organization, you may need to account for a variety of stakeholders’ needs — that is, tasks and goals that differ based on role and responsibility. In context of application delivery, let’s survey the most common roles with a generalized view of their responsibilities and needs as stakeholders. To help facilitate a general understanding, we’ve grouped some roles when responsibilities overlap across multiple teams:\n</p>\n\n<ul>\n    <li>\n        <h3>Platform</h3>\n        <p>\n            Platform teams are responsible for deploying and managing their Kubernetes infrastructure. They are responsible for platform governance, operational efficiency, and developer agility. The platform team is the connective tissue among various teams like DevOps, SREs, developers, and network operations teams and therefore must address and balance the unique needs of a diverse group of stakeholders, or influencers, when choosing cloud native solutions. \n        </p>    \n    </li>\n    <li>\n        <h3>DevOps</h3>\n        <p>\n             DevOps teams are responsible for continuously deploying applications. They care about faster development and release cycles, CI/CD and automation, and canary and progressive rollout.\n        </p>    \n    </li>\n    <li>\n        <h3>SREs</h3>\n        <p>\n             Site reliability engineers must ensure application availability. They care about observability, incident response, and postmortems. SREs often act as architects for DevOps team and as such are often extensions of or directly belong to DevOps teams.\n        </p>    \n    </li>\n    <li>\n        <h3>Developers</h3>\n        <p>\n             Development teams are responsible for application performance and are focused on ensuring a seamless end-user experience, including troubleshooting and microservices discovery and routing. Application performance and troubleshooting is shared responsibility among multiple teams.\n        </p>    \n    </li>\n    <li>\n        <h3>NetOps </h3>\n        <p>\n             Network operations teams are responsible for ensuring stable, high-performing network connectivity, resiliency, security (e.g. web application firewalls and TLS), and are commonly focused on north-south traffic. They care about establishing networking policies and enforcing compliance; achieving management, control, and monitoring of the network; and gaining visibility for the purpose of resources and capacity planning.\n        </p>    \n    </li>\n    <li>\n        <h3>DevSecOps</h3>\n        <p>\n             DevSecOps teams care about ensuring a strong security posture and rely on automated tools to orchestrate security for infrastructure, applications, containers, and API gateways. DevSecOps works very closley with NetOps team for holistic secure posture. \n        </p>    \n    </li>\n</ul>\n  <div className=\"center\" >\n  <img src={Stakeholders} align=\"center\" alt=\"Diverse Stakeholders have different needs\" />\n  </div>\n\n<p>\nEach role has nuanced responsibilities. Whether you have a single person or teams of people assigned to these roles, each role’s function needs to be accounted for. \n</p>\n<p>\nIt’s important to note that these stakeholders are undergoing a transformation in their responsibilities — or at least a transformation in the way in which they perform their responsibilities. Depending upon your organization’s size and structure, your stakeholders may have clearly defined lines of accountability or not among roles. As you adopt a cloud native approach to application deployment and delivery, you may find that the once-defined lines have blurred or that they are being redrawn. Be aware that the individuals who fill these roles typically go through a period of adjustment that can be unsettling until they adapt to their own and their teams’ new identities.\n</p>\n<p>\nYour cloud native infrastructure should be as accommodating as possible to you, your team, and your collective responsibilities and process, so we encourage you to seek solutions that address the needs of all your stakeholders. Significantly, this includes evaluating different architectural models for as best fit for purpose. While every organization doesn’t travel the same road to cloud native, every journey starts with initial architectural decisions – decisions which have substantial bearing on your path to cloud native. \n</p>\n\n<h2>Architecting Your Foundation the Right Way</h2>\n<p>\nCloud native novices and experts alike find that designing their application delivery architectures is the most challenging part of building microservices. Your architectural choices will have a significant impact on your cloud native journey. Some architectures will provide greater or fewer benefits while others will prove less or more difficult to implement. \n</p>\n<p>\nWhether you are a cloud native pro or a novice, your selection of the right application delivery architecture will be one that balances the tradeoff between the greatest benefits and the simplicity needed to match your team’s skill set. Figure 1 highlights four common application delivery architecture deployment models:\n</p>\n\n  <div className=\"center\" >\n  <img src={Graph} align=\"center\" alt=\"Graph\" />\n  </div>\n\n<div className=\"intro\">\n    <h3 style={{textAlign: \"center\"}}>Tip: Traffic Directions</h3>\n    <p>\n        North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.\n    </p>\n</div>\n\n<p>\n    Each of the deployment models in Figure 1 come with their list of pros and cons and are typically the point of focus of different teams. So how do you choose the right architecture for your deployment? Given the needs of your stakeholders and the many specifics involved in managing both north-south (N-S) and east-west (E-W) traffic, it is critical to assess the four different architectures with respect to the following areas:\n</p>\n<ul>\n<li>Application security </li>\n<li>Observability </li>\n<li>Continuous deployment </li>\n<li>Scalability and performance </li>\n<li>Open source tools integration </li>\n<li>Service mesh & Istio  integration </li>\n<li>IT skill set required </li>\n</ul>\n\nLet’s examine each of the four deployment models.\n\n<h3>Two-Tier Ingress</h3>\n\n  <div className=\"right\" >\n  <img src={TwoTier} align=\"centre\" alt=\"Two Tier Ingress\" />\n  </div>\n<p>\n    Two-tier ingress is the simplest architectural model to deploy to get teams up and running quickly. In this deployment model, Tthere are two layers of ADCs for N-S traffic ingress. The external ADC (at Tier 1), shown in green in Figure 2, provides L4 traffic management. Frequently, additional services are assigned to this ADC and can include web application firewall (WAF) and, secure sockets layer/transport layer security offload (SSL/TLS) functionality and authentication. A two-tier ingress deployment model is often managed by the existing network team (which is familiar with internet-facing traffic), and it can also be used as an ADC for other existing applications simultaneously.\n</p>\n<p>\n    The second ADC (Tier 2), shown in yellow in Figure 2, handles L7 load balancing for N-S traffic. It is managed by the platform team and is used within the Kubernetes cluster to direct traffic to the correct node. Layer 7 attributes, like information in the URL and HTTP headers, can be used for traffic load-balancing decisions. The yellow ADC continuously receives updates about the availability and respective IP addresses of the microservices pods within the Kubernetes cluster and can make decisions about which pod is best able to handle the request. Deployed as a container inside the Kubernetes cluster, the yellow ADC can be deployed as a container with Citrix CPX or with another similar product.\n</p>\n<p>\n    The E-W traffic between microservices pods is managed by kube-proxy, an open source, basic L4 load balancer with simple IP address-based round robin or least connection algorithm. kube-proxy lacks advanced features like Layer 7 load balancing, security, and observability, making it a blind spot for E-W traffic.\n</p>\n\n\n<b>Pros of Two-Tier Ingress</b>\n<p>\n    With the right proxy, SSL termination can be done at the edge, and traffic can be inspected easily. This enables N-S traffic to be comprehensively secured across L3-7. ADC collects and reports telemetry on the N-S application traffic it sees, which means that this architecture provides robust observability for N-S traffic. ADC can also also integrate with CI/CD tools like Spinnaker to provide traffic management to N-S traffic for excellent continuous deployment capabilities.\n</p>\n<p>\n    Two-tier ingress scales very well for N-S traffic, as an example Citrix ADC reach hundreds of Gbps or even Tbps throughput through active-active clustering of ADCs if required. Integration with third-party tools like Prometheus, Grafana and Zipkin are supported out of the box with ADC, so you can continue to use the tools with which you are familiar to collect data and manage your systems for N-S traffic. \n</p>\n<p>\n    The bifurcated design of two-tier ingress makes it relatively simple to implement demarcation points for control. The network team can own and manage the green ADC, and the platform team can work inside the Kubernetes environment. Neither the network team nor the platform team needs extensive retraining, which makes this architecture quick to implement.\n</p>\n<b>Cons of Two-Tier Ingress</b>\n<p>\n    The limitations of kube-proxy have made the use of third-party tools like Project Calico necessary to provide network policies, segmentation, and security support for inter-microservices communication. Similarly, kube-proxy's lack of detailed telemetry capabilities provides very little observability for E-W traffic. kube-proxy does not have the extensive APIs to integrate with continuous deployment tools, and its basic round-robin load balancing does not provide the granular load balancing needed to incorporate a CI/CD strategy inside the cluster. In general so you lack advanced load balancing tool set required to manage your inter-pod traffic. And kube-proxy does not currently integrate with service meshes, so there is no open source control plane integration for your E-W traffic management.\n</p>\n<p>\n    Overall, two-tier ingress provides excellent services for N-S traffic but lacks control for E-W traffic. It is a popular architecture because it is simple to implement and is frequently a starting point for enterprises on their cloud native journey to microservices adoption.\n</p>\n\n<div className=\"note\">\nBy default, kube-proxy uses iptables (x_tables kernel modules), so it does not perform as well as other proxies. You can configure kube-proxy to run in different modes by setting the --proxy-mode flag. Setting this flag to ipvs enables IPVS mode (netfilter kernel modules), which provides a much improved performance and also enables choice of load balancing algorithm through the --ipvs-scheduler parameter beyond the default round robin algorithm.\n</div>\n\n<h3>Unified Ingress</h3>\n  <div className=\"right\" >\n  <img src={Unified} align=\"centre\" height=\"50%\" alt=\"Unified Ingress\" />\n  </div>\n<p>\n    Unified ingress is very similar to the two-tier ingress architecture, except that it unifies two tiers of application delivery controllers (ADCs) for N-S traffic into one. Reducing an ADC tier effectively removes one hop of latency for N-S traffic. \n</p>\n<p>\n    Unified ingress has the same benefits and drawbacks as the two-tier ingress proxy architecture for security, observability, continuous deployment, scale and performance, open source tools support, and service mesh integration. Where it differs is in the skill sets required for implementation. With unified ingress, both the ADCs for N-S traffic and kube-proxy for the E-W traffic are managed by the platform team, who must be very network savvy to implement and manage this architecture. \n</p>\n<p>\n    A unified ingress proxy architecture is capable of participating in the Kubernetes cluster’s overlay network. This allows it to communicate directly with the microservices pods. Therefore, the platform team has to be knowledgeable about layers 3-7 of the network stack to take full advantage of this architecture. \n</p>\n<p>\n    In summary, unified ingress proxy architecture is moderately simple to deploy compared to service mesh (which we will cover next), and it offers robust capabilities for N-S traffic, but has very limited functionality for E-W traffic due to the limitations of kube-proxy. A network-savvy platform team is key for implementing this architecture.\n</p>\n\n<h3>Service Mesh</h3> \n\n<p>\n    A service mesh is a dedicated infrastructure layer to control how different parts of an application communicate with one another with one another. The service mesh landscape has exploded because service meshes offer the best observability, security, and fine-grained management for traffic among microservices — that is, for E-W traffic. As an additional layer of infrastructure, service meshes do bear additional complexity as a tradeoff to the value they provide. \n</p>\n  <div className=\"left\" >\n  <img src={Servicemesh} align=\"centre\" alt=\"Service Mesh\" />\n  </div>\n<p>\n    A typical service mesh architecture is similar to the two-tier ingress proxy architecture for N-S traffic and offers the same rich benefits for N-S traffic. The key difference between service mesh and two-tier ingress, and where most of the value lies, is that service mesh employs a lightweight proxy as a sidecar to each microservice pod for E-W traffic. Microservices do not communicate directly: Communication among microservices happens via the sidecar, which enables inter-pod traffic to be inspected and managed as it enters and leaves the pods. \n</p>\n<p>\n    By using proxy sidecars, service mesh offers the highest levels of observability, security, and fine-grained traffic management and control among microservices. Additionally, select repetitive microservice functions like retries and encryption can be offloaded to the sidecars. Despite each sidecar’s being assigned its own memory and CPU resources, sidecars are typically lightweight.  \n</p>\n<p>\n    You have the option to use Citrix CPX as a sidecar. Sidecars, which are managed by the platform team and attached to each pod, create a highly scalable, distributed architecture, but they also add complexity because they result in more moving parts.\n</p> \n<strong>Pros of Service Mesh</strong>\n<p>\n    The advantages of service mesh for N-S traffic are similar to those for two-tier ingress. Service mesh, however, brings added advantages for E-W traffic.The presence of sidecars enables you to set security policies and control communication among your microservices. You can mandate things like authentication, encryption, and rate limiting for APIs among microservices if required. \n</p>\n<p>\n    Because E-W traffic is seen by the sidecars, there is much more telemetry to provide holistic observability for better insights and improved troubleshooting. Furthermore, Citrix CPX as a sidecar has well-defined APIs that integrate with myriad open source tools, so that you can use the observability tools you're used to. Sidecar APIs allow integration with CI/CD tools like Spinnaker. \n</p>\n<p>\n    Similarly, sidecars will integrate with a service mesh control plane like Istio for E-W traffic. Additionally, repetitive functions like retries and encryption can be offloaded to the sidecars. The distributed nature of the sidecar means that the solution is scalable for such features as observability and security. \n</p>\n<strong>Cons of Service Mesh</strong>\n<p>\n    The biggest drawback of a service mesh architecture is the complexity of implementation (managing hundreds or thousands of sidecars is not trivial). The learning curve can be steep for the platform team because there are so many moving parts. A sidecar for every pod adds to CPU and memory needs. Similarly, sidecars add latency. Latency, which may affect application performance, varies with proxy implementation and can be easily measured by the open source tool, Meshery. Citrix CPX as a sidecar offers latency as low as 1ms, whereas other solutions can add much more. \n</p>\n<p>\n    Overall, a service mesh architecture provides excellent security, observability, and fine-grained traffic management for all traffic flows. The major downside is that it is complex to implement and manage.\n</p>\n\n<h3>Service Mesh Lite</h3>\n  <div className=\"right\" >\n  <img src={Servicemeshlite} align=\"centre\" alt=\"Service Mesh Lite\" />\n  </div>\n<p>\n    What if you want service mesh-like benefits with much less complexity?  The answer is service mesh lite, which is a variant of service mesh.\n</p>\n<p>\n    With a service mesh lite architecture, the ADC shown in green in Figure 5 is responsible for Layer 4-7 load balancing for N-S traffic to handle inbound requests and load balance to the right Kubernetes cluster. The green ADC may carry out SSL termination, web application firewalling, authentication, or other network services. It is managed by the networking team. \n </p>\n<p>\n    Depending on isolation and scale requirements, service mesh lite proxy architecture uses a single or several ADCs (shown in yellow in Figure 5) that proxy communications among microservices pods to manage inter-pod (E-W) traffic rather than using individual sidecars attached to each pod. Proxies can be deployed per node or per namespace and are managed by platform teams. \n</p>\n<strong>Pros of Service Mesh Lite</strong>\n<p>\n    Service mesh lite provides many of the same benefits as service mesh but reduces the overall complexity by only having a small set of proxy instances per cluster to manage the inter-pod traffic. Passing all E-W traffic through a small set of proxies provides the same advanced policy control, security, and fine-grained traffic management of a service mesh proxy architecture without all the complexity. \n</p>\n<p>\n    Another advantage of service mesh lite is reduced latency as compared to service mesh because end user request goes through fewer  proxies. The main advantage is reduced complexity and the lower skill set required to implement compared to service mesh. Similar to two-tier ingress, the networking team can manage the green ADC, and the platform team can manage the yellow ADC. With service mesh lite, both teams can work in familiar environments and develop at their own speed.\n</p>\n<strong>Cons of Service Mesh Lite</strong>\n<p>\n    Service mesh lite removes the implementation and management associated with service mesh, but the absence of a proxy per pod means that you sacrifice some functionality offload. For example, encryption for E-W must be implemented in each microservice, itself, if required.\n </p>\n<p>\n    Overall, service mesh lite provides most of the service mesh features but with reduced complexity and a lower IT skill set requirement. Many organizations who started with the two-tier ingress architecture find it an easy transition to service mesh lite for the added benefits it brings to their E-W traffic including better observability, enhanced security, better integration with open source tools, and support for continuous deployment.\n</p>\n<p>\n    So after reviewing the four architecture choices, you’re probably wondering: What ‘s the right architecture choice for my organization? There are no right or wrong answers. Like other architectural choices, proxy deployment models should be selected based on, in part, your application needs and your team structure and your team’s skill set. \n</p>\n<p>\n    Your model of proxy deployment is an important consideration, but just one of many when planning for your application delivery infrastructure. Ensuring that the application delivery components in your deployment are well-integrated into the cloud native ecosystem is your next consideration. \n</p>\n\n<h2>Openly Integrating with the Cloud Native Ecosystem </h2>\n<p>\nIt’s imperative that your various application delivery tools and processes, including your proxy, be well-integrated into commonplace cloud native infrastructure. It’s no secret that much of today’s innovation happens in open source software. And clouds, both public and private, are built upon open source software. So in most cases, your infrastructure will be comprised of popular open source infrastructure and tools that you have picked up on your journey to cloud native. To the extent this is the case, you’ll find common integrations by categories in Figure below:\n</p>\n  <div className=\"center\" >\n  <img src={Comparison} align=\"center\" alt=\"\" />\n  <p>Figure - Key categories of consideration for proxy integration with Kubernetes platforms and open source tools</p>\n  </div>\n\n<p>\n    Cloud native environments make liberal use of open source software projects. Irrespective of which projects you use, suffice it to say that cloud native application delivery can’t be done with just containers. The combination of containers, container orchestration, and a service mesh will get you very far. And alongside a CI/CD system, these components are the most significant and ubiquitously used components of cloud native infrastructure. Integration with each of these categories of cloud native infrastructure is critical so that developers and operators can design and run systems that communicate and inter-operate as a whole. The fact that these bedrocks of cloud native infrastructure are open source unlocks their ability to be integrated.\n</p>\n<p>\n    At the heart of the cloud native ecosystem is the extensible and scalable orchestration infrastructure that is Kubernetes. The cloud native ecosystem (both open source and closed source) extends Kubernetes by writing custom resource definitions (CRDs) and associated controllers. The controllers and CRDs give operators a Kubernetes-native way to manage all parts of their platforms — both open source and closed source. This integration affords tool unification and powerful composable intent-based primitives that truly enable a software-defined platform.\n</p>\n<p>\n    Critical to the speed of delivery is an early investment in continuous integration/continuous delivery (CI/CD). It’s likely you have already wrangled continuous integration. Continuous deployment pipelines are your next step in seeing that changes to your source code automatically result in a new container being built and a new version of your microservice being tested and deployed to staging and eventually to production. \n</p>\n<p>\n    For many, the notion that CI/CD is an area of early investment is counterintuitive, and they find it hard to swallow the upfront engineering effort required to get a solid pipeline in place. The sooner CI/CD basics are implemented, however, the sooner the dividends start paying out. We will cover advanced continuous delivery considerations later in this white paper.\n</p>\n<p>\n    With cloud native infrastructure’s being inherently dynamic (in contrast to infrastructure not driven by APIs,) the ability to observe cloud native infrastructure and its workloads is also necessary. Software is written with functionality and debugging in mind. Most often, developers use logging as the primary method for debugging their applications. Integration with Elasticsearch and Kibana is key here. \n</p>\n<p>\n    Performance counters are another way to track application behavior and performance. Akin to SNMP for physical and virtual network monitoring, the equivalent cloud native “standard” is the use of Prometheus and Grafana, so it’s important that your application delivery solution integrate with these tools. Currently there is no recognized standard for cloud native application performance monitoring metrics.\n</p>\n\n<div className=\"intro\">\n    <h3 style={{textAlign: \"center\"}}>OpenMetrics</h3>\n    <p>\n        The cloud native ecosystem needs a common format for the exchange of metrics. Observability pains grow with the release of each newly instrumented service that presents its own metric format. OpenMetrics is an effort to create an open standard for transmitting metrics at scale, with support for both text representation and protocolbBuffers. OpenMetrics builds on Prometheus’s exposition format, popular telemetry formats, and protocols used in infrastructure and application monitoring. \n    </p>\n</div>\n\n<p>\n    Irrespective of the metrics format, there are a few metrics that have been identified as key indicators of the health of a cloud native application (that is, the health of a service): latency, traffic, errors, and saturation. Your application delivery solution should assist in producing these signals as well as provide support for the tracing of your distributed, cloud native workloads. \n</p>\n<p>\n    The aforementioned integrations with open source tools enable loosely coupled systems that are resilient, manageable, and observable. Citrix ADC also embodies these characteristics. All of the infrastructure integrations detailed here depend upon APIs for interchange and interoperability. Cloud native applications, too, are centered around declarative APIs to interface with the infrastructure and serve user-facing workloads. \n</p>\n<p>\n    The endpoints that your APIs expose are now being managed by open source service meshes. Service meshes deliver the next generation of networking designed for cloud native applications. At the core of a service mesh is its data plane (its collection of proxies). Proxy selection criteria and deployment model tradeoffs are our next area of consideration.\n</p>\n\n_** Check out the topic <Link to=\"/resources/service-mesh/choosing-the-perfect-proxy\">Choosing the Perfect Proxy</Link> to learn more! **_\n\n\n</ResourcesWrapper>\n","frontmatter":{"title":"7 Key Considerations for Microservices-Based Application Delivery","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/d933a542c39e21f591328eb08d0ce2b2/citrix-path-to-cloud-native.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/d933a542c39e21f591328eb08d0ce2b2/citrix-path-to-cloud-native.svg"}},"fields":{"slug":"/resources/service-mesh/7-key-considerations-for-microservices-based-application-delivery"}},{"id":"d82c6a92-eef7-56fd-9b27-61c345b946a1","body":"\n\n\n<ResourcesWrapper>\n<h3>What Is a Service Proxy?</h3>\n<p>\nA service proxy is a client-side mediator that handles requests for a service. The service proxy allows applications to send and receive messages as method calls via a channel. Service proxy connections can be created as needed or persist open connections to facilitate pooling. Applications are oblivious to the data plane's existence. As applications conduct service-to-service calls, service proxies are transparently inserted. Inbound (ingress) and outbound (egress) cluster network traffic are handled by data planes. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling. In Istio, traffic is transparently intercepted using iptables rules and redirected to the service proxy.\n</p>\n<p>\nRemember that Pilot configures traffic policy and service proxies implement it. The data plane is a collection of service proxies. Service proxies are responsible for health checks, routing, load balancing, authentication, authorization, and the production of observable signals by intercepting every packet in the request. As the service may change from location to location, proxies provide indirection so that clients may point to the same location (e.g., proxy.example.com), representing a permanent reference. They add resilience to distributed systems.\n</p>\n\n<h3>Envoy Proxy Overview</h3>\n<p>The versatile and performant Envoy has evolved as an open source, application-level service proxy, living up to its tagline as the universal data plane API. Lyft developed Envoy in order to solve major distributed systems problems. Envoy has had broad reuse and has been integrated into the cloud native ecosystem.</p>\n<h4>Why Envoy?</h4>\n<p>\nEnvoy was originally intended to be used as an edge proxy rather than a sidecar. Envoy transitioned to the sidecar pattern over time.\nThe concept of hot reloads vs. hot restarts was at the center of the decision for the Istio project to leverage Envoy. Envoy's runtime configuration has always been API-driven, allowing it to drain and hot reload its own process with an old configuration with a new process and new configuration (displacing itself). Envoy achieves hot reloading of its processes by shared memory and communication through a Unix Domain Socket (UDS), in a manner that resembles GitHub's tool for zero-downtime HAProxy reloads.\nAdditionally, and uniquely, Envoy offers an Aggregated Discovery Service (ADS) for delivering the data for each xDS API.\n</p>\n\n<h4>HTTP/2 and gRPC</h4>\n<p>\nEnvoy stood apart from other proxies at the time because of its early support for HTTP/2 and gRPC. HTTP/2 significantly improves on HTTP/1.1 in that HTTP/2 enables request multiplexing over a single TCP connection. Proxies that support HTTP/2 benefit from the reduced overhead of combining several connections into a single one. HTTP/2 allows clients to send numerous parallel requests and load resources preemptively using server-push.\n</p>\n<p>\nEnvoy is HTTP/1.1 and HTTP/2 compatible, including proxying compatibility for both downstream and upstream protocols. This means Envoy can accept incoming HTTP/2 connections and proxy them to upstream HTTP/2 clusters, but it can also take HTTP/1.1 connections and proxy them to HTTP/2 clusters (and vice-versa).\n</p>\n<p>\ngRPC is an RPC protocol that uses protocol buffers on top of HTTP/2. Envoy supports gRPC natively (over HTTP/2) and can also bridge an HTTP/1.1 client to gRPC. Envoy has the ability to operate as a gRPC-JSON transcoder. The gRPC-JSON transcoder functionality allows a client to send HTTP/1.1 requests with a JSON payload to Envoy, which translates the request into the corresponding gRPC call and subsequently translates the response message back into JSON. These are powerful capabilities (and challenging to execute correctly), which set Envoy apart from other service proxies.\n</p>\n\n<h3>Envoy in Istio</h3>\n<p>\nAs an out of process proxy, Envoy transparently forms the base unit of the mesh. Akin to proxies in other service meshes, it is the workhorse of Istio. Istio deploys Envoy sidecarred to application services.\nIdentified as <code>istio-proxy</code> in deployment files, Envoy does not require root privileges to run, but runs as user 1337 (non root). \n</p>\n\n<h3>Sidecar Injection (or Sidecarring)</h3>\n<p>\nThere are two steps to adding a service proxy: sidecar injection and network capture. Sidecar injection is the method of adding a proxy to a given application. Network capture is the method of directing inbound traffic to the proxy (instead of the application) and outbound traffic to the proxy (instead of directly back to the client or directly to subsequent upstream application services).\n</p>\n\n<h4>Manual Sidecar Injection</h4>\n<p>\n<code>Istioctl</code> can be used to manually inject the Envoy sidecar definition into Kubernetes manifests manually. Use <code>istioctl</code>’s <code>kube-inject</code> capability to manually inject the sidecar into deployment manifests by manipulating yaml.\n</p>\n\n```\n$ istioctl kube-inject -f samples/sleep/sleep.yaml | kubectl apply -f -\n```\n<p>\nYou can update Kubernetes specifications on-the-fly at the time of applying them to Kubernetes for scheduling. Alternatively, you might use the <code>istioctl kube-inject</code> utility like so:\n</p>\n\n```\n$ kubectl apply -f <(istioctl kube-inject -f <resource.yaml>)\n```\n<p>\nIf you don’t have the source manifests available, you can update an existing Kubernetes deployment to bring its services onto the mesh:\n</p>\n\n```\n$ kubectl get deployment -o yaml | istioctl kube-inject -f - | kubectl apply -f -\n```\n<p>\nLet's look at an example of an existing application being onboarded onto the mesh. Let's use a freshly installed copy of BookInfo as an example of a Kubernetes application that isn't deployed on the service mesh yet. We'll start with exploring BookInfo's pods.\n</p>\n\n```\n$ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\ndetails-v1-69658dcf78-nghss       1/1     Running   0          43m\nproductpage-v1-6b6798cb84-nzfhd   1/1     Running   0          43m\nratings-v1-6f97d68b6-v6wj6        1/1     Running   0          43m\nreviews-v1-7c98dcd6dc-b974c       1/1     Running   0          43m\nreviews-v2-6677766d47-2qz2g       1/1     Running   0          43m\nreviews-v3-79f9bcc54c-sjndp       1/1     Running   0          43m\n```\n<p>\nThe atomic unit of deployment in Kubernetes is a Pod.  Since a Pod is a collection of containers, it can be one or more containers deployed atomically together. In our example, we can see that each of BookInfo's pods is only executing one container. When <code>istioctl kube-inject</code> is run against  on BookInfo's manifests, it adds another container to the Pod specification but does not deploy anything yet.\n</p>\n<p>\n<code>istioctl kube-inject</code> supports modification of Pod-based Kubernetes objects (Job, DaemonSet, ReplicaSet, Pod and Deployment) that may be embedded into long yaml files containing other Kubernetes objects. <code>Istioctl kube-inject</code> will parse the other Kubernetes objects without modification. Unsupported resources are left unmodified so it is safe to run kube-inject over a single file that contains multiple Service, ConfigMap, Deployment, etc. definitions for a complex application. It is best to do this when the resource is initially created.\n</p>\n<p>\nIn order to onboard this existing application, we can execute <code>istioctl kube-inject</code> against each Deployment and have a rolling update of that Deployment initiated by Kubernetes as shown below. Let’s start with the <code>productpage</code> service.\n</p>\n\n```\n$ kubectl get deployment productpage-v1 -o yaml | istioctl kube-inject -f - | kubectl apply -f -\ndeployment.extensions/productpage-v1 configured\n```\n<p>\nWe now notice that the productpage pod has grown to two containers when we look at the BookInfo pods again. Istio’s sidecar has been successfully injected. The rest of BookInfo’s application services need to be onboarded in order for BookInfo as an application to work.\n</p>\n\n```\n$ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\ndetails-v1-69658dcf78-nghss       1/1     Running   0          45m\nproductpage-v1-64647d4c5f-z95dl   2/2     Running   0          64s\nratings-v1-6f97d68b6-v6wj6        1/1     Running   0          45m\nreviews-v1-7c98dcd6dc-b974c       1/1     Running   0          45m\nreviews-v2-6677766d47-2qz2g       1/1     Running   0          45m\nreviews-v3-79f9bcc54c-sjndp       1/1     Running   0          45m\n```\n<p>\nYou may choose to do this manual injection operation once and persist the new manifest file with istio-proxy (Envoy) inserted instead of ad-hoc onboarding of a running application. You can create a persistent version of the sidecar injected deployment outputting the results of <code>istioctl kube-inject</code> to a file. As Istio evolves the default sidecar configuration is subject to change.\n</p>\n\n```\n$ istioctl kube-inject -f deployment.yaml -o deployment-injected.yaml\n```\nOr like so:\n\n```\n$ istioctl kube-inject -f deployment.yaml > deployment-injected.yaml\n```\n<h4>Ad-hoc Sidecarring</h4>\n<p>\nSidecar injection is responsible for configuring network capture. Injection and network capture can be selectively applied to enable incremental adoption of Istio. Using the BookInfo sample application as an example, let’s take the <code>productpage</code> service as the external-facing service and selectively remove this service (and just this service out of the set of four) from the service mesh. Let's start by checking for the presence of its sidecarred service proxy.\n</p>\n\n```\n$ kubectl get pods productpage-8459b4f9cf-tfblj -o jsonpath=\"{.spec.containers[*].image}\"\nlayer5/istio-bookinfo-productpage:v1 docker.io/istio/proxyv2:1.0.5\n```\n<p>\nAs you can see, productpage container is our application container, while the istio/proxy is the service proxy (Envoy) that Istio injected into the pod. To manually onboard and offboard a deployment onto and off of the service mesh, you can manipulate annotation within its Kubernetes Deployment specification.\n</p>\n\n```\n$ kubectl patch deployment nginx --type=json --patch='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations\", \"value\": {\"sidecar.istio.io/inject\": \"false\"}}]'\ndeployment.extensions/productpage-v1 patched\n```\n<p>\nOn opening your browser to the <code>productpage</code> application, and you’ll find that it is still being served through Istio’s Ingress Gateway, but that its pods no longer have sidecars. Hence, the productpage app has been removed from the mesh.\n</p>\n\n```\nUNAVAILABLE:upstream connect error or disconnect/reset before headers\n```\n<h4>Automatic Sidecar Injection</h4>\n<p>\nNo code change to receive much more visibility into how your services are behaving and how they are being interacted gives Istio a magical feeling once your services are on the mesh. Automatic sidecar injection is the magical feeling you get as you go to onramp your services.Not only does automatic sidecar injection eliminate the need to alter your code, but it also eliminates the need to change your Kubernetes manifests. Automatic sidecar injection in Kubernetes relies on mutating admission webhooks. The <code>istio-sidecar-injector</code> is added as a mutating webhook configuration resource when Istio is installed on Kubernetes.\n</p>\n\n```\n$ kubectl get mutatingwebhookconfigurations\nNAME                                    CREATED AT\nistio-sidecar-injector                  2019-04-18T16:35:03Z\nlinkerd-proxy-injector-webhook-config   2019-04-18T16:48:49Z\n```\n\n```\n$ kubectl get mutatingwebhookconfigurations istio-sidecar-injector -o yaml\n\napiVersion: admissionregistration.k8s.io/v1beta1\nkind: MutatingWebhookConfiguration\nmetadata:\n  creationTimestamp: \"2019-04-18T16:35:03Z\"\n  generation: 2\n  labels:\n    app: sidecarInjectorWebhook\n    chart: sidecarInjectorWebhook\n    heritage: Tiller\n    release: istio\n  name: istio-sidecar-injector\n  resourceVersion: \"192908\"\n  selfLink: /apis/admissionregistration.k8s.io/v1beta1/mutatingwebhookconfigurations/istio-sidecar-injector\n  uid: eaa85688-61f7-11e9-a968-00505698ee31\nwebhooks:\n- admissionReviewVersions:\n  - v1beta1\n  clientConfig:\n    caBundle: <redacted>\n    service:\n      name: istio-sidecar-injector\n      namespace: istio-system\n      path: /inject\n  failurePolicy: Fail\n  name: sidecar-injector.istio.io\n  namespaceSelector:\n    matchLabels:\n      istio-injection: enabled\n  rules:\n  - apiGroups:\n    - \"\"\n    apiVersions:\n    - v1\n    operations:\n    - CREATE\n    resources:\n    - pods\n    scope: '*'\n  sideEffects: Unknown\n  timeoutSeconds: 30\n```\n\n<p>\nIf the namespace contains the <code>istio-injection=enabled</code> label, Kubernetes will transmit all Pod creation events to the <code>istio-sidecar-injector</code> service (in the istio-system namespace) if this mutating webhook is registered. The injector service will then modify the PodSpec to include two more containers, one for the init-container to configure traffic rules and the other for istio-proxy (Envoy) to perform proxying.  The sidecar injector service uses a template to add these two additional containers; the template may be found in the <code>istio-sidecar-injector configmap</code>.\n</p>\n<p>\nKubernetes lifecycle allows customization of resources before they are committed to the etcd store, the ‘source of truth’ for Kubernetes configuration. When an individual Pod is created (either via kubectl or a Deployment resource), it goes through this same lifecycle, hitting mutating admission webhooks which modify the pod before it actually gets applied.\n</p>\n\n<h4>Kubernetes Labels</h4>\n<p>\nAutomatic sidecar injection relies on labels to identify which pods to inject Istio’s service proxy and initialize as pod on the data plane. Kubernetes objects, like pods and namespaces, can have user-defined labels attached to them. Labels are essentially <code>key:value</code> pairs like you finding in other systems that support the concept of tags. Webhook Admission controller relies on labels to select the namespaces they apply to. Istio-injection is the specific label that Istio uses. Familiarize by labeling the default namespace with <code>istio-injection=enabled</code>:\n</p>\n\n```\n$ kubectl label namespace default istio-injection=enabled\n````\n\n<p>Confirm which namespaces have the istio-injection label associated:</p>\n\n```\n$ kubectl get namespace -L istio-injection\nNAME           STATUS    AGE       ISTIO-INJECTION\ndefault        Active    1h        enabled\nDocker         Active    1h        enabled\nistio-system   Active    1h        disabled\nkube-public    Active    1h        \nkube-system    Active    1h\n```\n<p>\nNotice that only the <code>istio-system</code> namespace has the <code>istio-injection</code> label assigned. By virtue of having the <code>istio-injection</code> label and its value set to disabled, the <code>istio-system</code> namespace will not have service proxies automatically injected into their pods upon deployment. This does not mean that pods in this namespace cannot have service proxies. It just means that service proxies won’t be automatically injected. \n</p>\n<p>\nOne caveat to watch out for, when using the <code>namespaceSelector</code>, make sure that the namespace(s) you are selecting really has the label you are using. Keep in mind that the built-in namespaces like default and <code>kube-system</code> don’t have labels out of the box.\n</p>\n\n<p>Conversely, the namespace in the metadata section is the actual name of the namespace, not a label:</p>\n\n```\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: test-network-policy\n  namespace: default\nspec:\n...\n```\n\n<h4>Kubernetes Init Containers</h4>\n<p>\nVery similar to cloud-init for those familiar with VM provisioning, init containers in Kubernetes allows you to run temporary containers to perform a task before engaging your primary container(s). Init containers are Init containers in Kubernetes allow you to run temporary containers to execute a task before activating your principal container, comparable to cloud-init for people acquainted with VM provisioning (s). Init containers are frequently used for provisioning operations such as asset bundling, database migration, and cloning a git repository onto a volume. In the instance of Istio, init containers are used to set up network filters - iptables - that control traffic flow. used to perform provisioning tasks like bundling assets, performing database migration, or clone a git repository into a volume. In Istio’s case, init containers are used to setup network filters - iptables to control the flow of traffic.\n</p>\n\n</ResourcesWrapper>","frontmatter":{"title":"Service Proxy","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/ef8ca37dab5018498438c17e69966940/envoy-icon-color.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/ef8ca37dab5018498438c17e69966940/envoy-icon-color.svg"}},"fields":{"slug":"/resources/service-mesh/service-proxy"}},{"id":"d93b1f22-fe0f-5ae7-9dff-dba0f5ab8ceb","body":"\n\n\n\n<ResourcesWrapper>\n<p>\nThis article covers Istio's Pilot, its basic model, the sources of configuration it consumes to produce a model of the mesh, how it uses that model of the mesh to push configuration to Envoys, how to debug it, and how to understand the transformation Pilot performs from Istio configuration to Envoy's. With this knowledge, you should be able to debug and resolve the vast majority of issues that new and intermediate Istio users encounter.\n</p>\n<p>\nIn an Istio deployment, Pilot is in charge of programming the data plane, ingress and egress gateways, and service proxies. Pilot models a deployment environment by combining Istio configuration from Galley  with service information from a service registry, such as the Kubernetes API server or Consul. Pilot utilises this model to produce data plane configuration and pushes it out to the fleet of service proxies that are connected to it.\n</p>\n<h3>Configuring Pilot</h3>\n<p>\nLet's look at the surface area of Pilot's configuration to understand better all aspects of the mesh that concerns it. As we process this, keep in mind that Pilot's dependency on Galley for the underlying platform and environment information will grow as the Istio project progresses. Pilot has three primary sources of configuration:\n</p>\n<h4>Mesh Configuration</h4>\n<p>\nMesh configuration is a set of global configuration that is static for the installation of the mesh. Mesh configuration is split over three API objects:\n</p>\n<ol>\n<li>MeshConfig (<code>mesh.istio.io/v1alpha1.MeshConfig</code>) - MeshConfig allows you to configure how Istio components communicate with one another, where configuration sources are located, etc.</li>\n<li>ProxyConfig (<code>mesh.istio.io/v1alpha1.ProxyConfig</code>) - ProxyConfig tracks where Envoy's bootstrap configuration is located, which ports to bind to, and other options concerned with initialising Envoy.</li>\n<li>MeshNetworks (<code>mesh.istio.io/v1alpha1.MeshNetworks</code>) - MeshNetworks is a collection of networks across which the mesh is deployed, together with the addresses of each network's ingress gateways.</li>\n</ol>\n<p>\nMeshConfig is generally used to define whether policy and/or telemetry are enabled, where to load configuration and locality-based load balancing settings. The exhaustive set of concerns that MeshConfig contains is listed below:\n</p>\n<ul>\n<li>\nHow to user Mixer?\n<ul>\n<li>The addresses of the policy and telemetry servers</li>\n<li>Whether policy checks are enabled at runtime</li>\n<li>Whether to fail open or closed when Mixer Policy is inaccessible or returns an error</li>\n<li>Whether to perform policy checks on the client side.</li>\n<li>Whether to use session affinity to target the same Mixer Telemetry instance. Session affinity is always enabled for Mixer Policy (performance of the system relies on it!)</li>\n</ul>\n</li>\n<li>\nHow to configure service proxies for listening?\n<ul>\n<li>The ports to bind to to accept traffic (i.e. the port IPTables redirects to) and to accept HTTP PROXY requests</li>\n<li>TCP connection timeout and keepalive settings</li>\n<li>Access log format, output file, and encoding (JSON or text)</li>\n<li>Whether to allow all outbound traffic, or restrict outbound traffic to only services Pilot knows about</li>\n<li>Where to listen for secrets from Citadel (the SDS API), and how to bootstrap trust (in environments with local machine tokens)</li>\n</ul>\n</li>\n<li>Whether to support Kubernetes Ingress resources</li>\n<li>The set of configuration sources for all Istio components (e.g. the local file system, or Galley), and how to communicate with them (the address, whether to use TLS or not, which secrets, etc)</li>\n<li>Locality-based load balancing settings—configuration about failover and traffic splits between zones and regions.</li>\n</ul>\n\n<p>ProxyConfig is mostly used for customising bootstrap settings for Envoy. The exhaustive set of concerns that ProxyConfig contains is the following:</p>\n<ul>\n<li>The location of the file with Envoy’s bootstrap configuration, as well as the location of the Envoy binary itself</li>\n<li>The location of the trace collector (i.e. where to send trace data)</li>\n<li>Shutdown settings (both connection draining and hot restart)</li>\n<li>The location of Envoy’s xDS server (Pilot) and how to communicate with it</li>\n<li>Envoy’s service cluster, meaning the name of the service this Envoy is sidecar for</li>\n<li>Which ports to host the proxy’s admin server and statsd listener</li>\n<li>Envoy’s concurrency (number of worker threads)</li>\n<li>Connection timeout settings</li>\n<li>How Envoy binds the socket to intercept traffic (either via IPTables REDIRECT or TPROXY)</li>\n</ul>\n<p>\nMeshNetworks defines a collection of named networks, the method for sending traffic into those networks (ingress), and their locality. A CIDR range or a set of endpoints returned by a service registry define each network (e.g. the Kubernetes API server). The API object ServiceEntry, which is used to define services in Istio, has a set of endpoints. A ServiceEntry can represent a service that is deployed across multiple networks(or clusters) by labelling each endpoint with a network.\n</p>\n<p>\nMost values in MeshConfig cannot be updated dynamically, therefore the control plane must be restarted for them to take effect. Similarly, updates to values in ProxyConfig only occur when Envoy is redeployed (e.g., in Kubernetes, when the pod is rescheduled). MeshNetworks can be dynamically upgraded at runtime without requiring any control plane components to be restarted.\n</p>\n<p>\nOn Kubernetes, the majority of MeshConfig and ProxyConfig configuration is concealed behind options in the Helm installation, although not all of it is exposed via Helm. To have complete control over the installation, you'll need to post-process the file output by Helm.\n</p>\n\n<h4>Networking Configuration</h4>\n<p>\nNetworking configuration is Istio’s bread and butter—the configuration to manage how traffic flows through the mesh.\n</p>\n<p>\nIstio's networking APIs revolve around ServiceEntry. ServiceEntry defines a service by its names—the set of hostnames clients use to call the service. DestinationRules define how clients communicate with a service: what load balancing, outlier detection, circuit breaking, and connection pooling strategies to use, which TLS settings to use, etc. VirtualServices configure how traffic flows to a service: L7 and L4 routing, traffic shaping, retries, timeouts, etc. Gateways configure how services are exposed outside of the mesh: what hostnames are routed to which services, how to serve certs for those hostnames, etc. Service proxies configure how services are exposed inside of the mesh, which services are available to which clients.\n</p>\n<h4>Service Discovery</h4>\n<p>\nPilot integrates with different service discovery systems, such as the Kubernetes API server, Consul, and Eureka, to discover service and endpoint information about the local environment. Adapters in Pilot consume service discovery data from their source and synthesize ServiceEntry objects. For example, the integration with Kubernetes uses the Kubernetes SDK to watch the API server for service creation and service endpoint update events. The registry adapter in Pilot creates a ServiceEntry object based on this data. That ServiceEntry is used to update Pilot’s internal model and generate an updated configuration for the data plane.\n</p>\n<p>\nPilot registry adapters were previously implemented in Golang.  These adapters can now be detached from Pilot with the introduction of Galley. A service discovery adapter reads an existing service registry and produces a set of ServiceEntry objects as a separate job (or an offline process done by a continuous integration system). Those ServiceEntries can then be supplied to Galley as files and uploaded to the Kubernetes API server. Alternatively, you can create your own Mesh Config Protocol server and feed Galley the ServiceEntries. Static ServiceEntries can be useful to enable Istio in largely static environments (e.g., legacy VM-based deployments with rarely-changing IP addresses).\n</p>\n<p>\nServiceEntries bind a set of hostnames to endpoints to construct a Service. IP addresses or DNS names can be those endpoints. A network, locality, and weight can be assigned to each endpoint individually. ServiceEntries can define complex network topologies as a result of this. A service deployed across separate clusters (with different networks) that are geographically disparate (have different localities) can be created and have traffic split amongst its members by percentage (weights)—or in fact, by nearly any feature of the request.  Since Istio knows where distant networks' ingress points are, when a service endpoint in a remote network is selected, the service proxy will route traffic to the remote network's ingress. We can even write policies to prefer local endpoints over endpoints in other localities but automatically failover to other localities if local endpoints are unhealthy. \n</p>\n\n<h3>Config Serving</h3>\n<p>\nPilot constructs a model of the environment and state of a deployment using these three config sources—mesh config, networking config, and service discovery. As service proxy instances are deployed into the cluster, they connect to Pilot asynchronously. Pilot groups the service proxies based on their labels and the service to which they are sidecarred. Pilot creates Discovery Service (xDS) responses for each group of connected service proxies using this paradigm. Pilot transmits the current state of the environment and the configuration that reflects the environment when a service proxy connects. The model is updated regularly due to the generally dynamic nature of the underlying platform(s). Updates to the model mean updating the current set of xDS configurations. When the Discovery Service config is changed, Pilot computes the groups of affected service proxies and pushes the updated configuration to them.\n</p>\n<p>Service proxy (Envoy) configuration can be divided into two main groups: </p>\n<ul>\n<li>Listeners and Routes</li>\n<li>Clusters and Endpoints</li>\n</ul>\n<p>\nListeners define a set of filters (for example, an HTTP filter delivers Envoy's HTTP functionality) and how Envoy connects those filters to a port. These are of two types: physical and virtual. A physical listener is one where Envoy binds to the specified port. A virtual listener accepts traffic from a physical listener without binding to a port (instead, some physical listener must direct traffic to it). Listeners and Routes work together to configure how a Listener routes traffic to a specified Cluster (e.g., by matching on HTTP path or SNI name). A cluster is a collection of endpoints that includes information on how to contact them (TLS settings, load balancing strategy, connection pool settings, etc.).  A Cluster is analogous to a \"service.\" Finally, Endpoints are individual network hosts (IP addresses or DNS names) that Envoy will forward traffic to. \n</p>\n\n<h3>Troubleshooting Pilot</h3>\n<p>\nTo examine the state of service proxies connected to Pilot, see these endpoints:\n</p>\n<ul>\n<li><code>/debug/edsz</code> - prints all of Pilot’s set of pre-computed EDS responses; i.e. the endpoints it sends to each connected service proxy</li>\n<li><code>/debug/adsz</code> - prints the set of listeners, routes, and clusters pushed to each service proxy connected to Pilot</li>\n<li><code>/debug/cdsz</code> - prints the set of clusters pushed to each service proxy connected to Pilot</li>\n<li><code>/debug/synz</code> - print the status of ADS, CDS, and EDS connections of all service proxies connected to pilot. In particular this shows the last nonce Pilot is working with vs the last nonce Envoy has ACK’d, showing which Envoys are not accepting configuration updates</li>\n</ul>\n\n<p>\nTo examine Pilot’s understanding of the state of the world (its service registries), see these endpoints:\n</p>\n<ul>\n<li><code>/debug/registryz</code> - print the set of services Pilot knows about across all registries</li>\n<li><code>/debug/endpointz[?brief=1]</code> - print the endpoints for every service Pilot knows about, including their ports, protocols, service accounts, labels, etc. If you provide the brief flag, the output will be a human-readable table (as opposed to a JSON blob for the normal version). This is a legacy endpoint and <code>/debug/endpointShardz</code> provides strictly more information.</li>\n<li><code>/debug/endpointShardz</code> - print the endpoints for every service Pilot knows about, grouped by the registry that provided the endpoint. For example, if the same service exists in both Consul and Kubernetes, endpoints for the service will be grouped into two shards, one each for Consul and Kubernetes. This endpoint provides everything from <code>/debug/endpoint</code> and more, including data like the endpoint’s network, locality, load balancer weight, representation in Envoy xDS config, etc.</li>\n<li><code>/debug/workloadz</code> - print the set of endpoints (“workloads”) connected to Pilot, and their metadata (like labels)</li>\n<li><code>/debug/configz</code> - print the entire set of Istio configuration Pilot knows about. Only validated config that Pilot is using to construct its model will be returned; useful for understanding situations where Pilot is not processing new config itself.</li>\n</ul>\n\n<p>\nYou can also find miscellaneous endpoints with higher level debug information, be wading through these endpoints:\n</p>\n<ul>\n<li><code>/debug/authenticationz[?proxyID=pod_name.namespace]</code> - prints the Istio authentication policy status of the target proxy for each host and port it’s serving, including: the name of the authentication policy affecting it, the name of the DestinationRule affecting it, whether the port expects mTLS, standard TLS, or plain text, and if settings across configuration cause a conflict for this port.</li>\n<li><code>/debug/config_dump[?proxyID=pod_name.namespace]</code> - prints the listeners, routes, and clusters for the given node; this can be diff’d directly against the output of <code>istioctl proxy-config</code></li>\n<li><code>/debug/push_status</code> - prints the status of each connected endpoint as of Pilot’s last push period; includes the status of each connected proxy, when the push period began (and ended), and the identities assigned to each port of each host.</li>\n</ul>\n\n<h3>Tracing Configuration</h3>\n<p>\nIn this section, we’ll use some tools to understand the before-and-after of Istio configuration and the resultant xDS configuration pushed to service proxies. \n</p>\n<h4>Listeners</h4>\n<p>Gateways and VirtualServices results in Listeners for Envoy. Gateways result in physical listeners (listeners that bind to a port on the network), while VirtualServices result in virtual listeners (listeners that do not bind to a port, but instead receive traffic from physical listeners). Demonstration of how Istio configuration manifests into xDS configuration by creating a Gateway:</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: foo-com-gateway\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n  - hosts:\n    - “*.foo.com”\n    port:\n      number: 80\n      name: http\n      protocol: HTTP\n```\n<p>Creation of this Istio Gateway results in a single HTTP listener on port 80 on our Ingress Gateway.</p>\n\n```\n$ istioctl proxy-config listener istio-ingressgateway_PODNAME -o json -n istio-system\n[\n    {\n        \"name\": \"0.0.0.0_80\",\n        \"address\": {\n            \"socketAddress\": {\n                \"address\": \"0.0.0.0\",\n                \"portValue\": 80\n            }\n        },\n        \"filterChains\": [\n            {\n                \"filters\": [\n                    {\n                        \"name\": \"envoy.http_connection_manager\",\n...\n                            \"rds\": {\n                                \"config_source\": {\n                                    \"ads\": {}\n                                },\n                                \"route_config_name\": \"http.80\"\n                            },\n...\n```\n<p>It's worth noting that the newly created filter is listening on address 0.0.0.0. This is the listener for all HTTP traffic on port 80, regardless of the host to which it is addressed. If we enable TLS termination for this Gateway, we'll see a new listener created just for the hosts we’re terminating TLS for, while the rest would fall into this catch-all listener.</p>\n<p>Let’s bind a VirtualService to this Gateway</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n name: foo-default\nspec:\n hosts:\n - bar.foo.com\n gateways:\n - foo-com-gateway\n http:\n - route:\n   - destination:\n       host: bar.foo.svc.cluster.local\n```\n\n<p>See how it manifests as virtual listener.</p>\n\n```\n$ istioctl proxy-config listener istio-ingressgateway_PODNAME -o json\n\n\n[\n    {\n        \"name\": \"0.0.0.0_80\",\n        \"address\": {\n            \"socketAddress\": {\n                \"address\": \"0.0.0.0\",\n                \"portValue\": 80\n            }\n        },\n        \"filterChains\": [\n            {\n                \"filters\": [\n                    {\n                        \"name\": \"envoy.http_connection_manager\",\n...\n                            \"rds\": {\n                                \"config_source\": {\n                                    \"ads\": {}\n                                },\n                                \"route_config_name\": \"http.80\"\n                            },\n...\n```\n<p>\nWe encourage that you try different protocols for the ports (or list a single Gateway with many ports with various protocols) to see how this results in different filters. Configuring different TLS settings within the Gateway also changes the generated Listener configuration. For each protocol you use, you'll notice a protocol-specific filter configured in the Listener (for HTTP, this is the http connection manager and its router, for MongoDB another, for TCP another, and so on). To explore how different combinations of hosts in the Gateway and VirtualService interact, we also recommend exploring different combinations of hosts in the Gateway and VirtualService.\n</p>\n\n<h4>Routes</h4>\n<p>We've seen how VirtualServices cause Listeners to be created. In Envoy, the majority of the configuration you specify in VirtualServices manifests as Routes. Routes exist in a variety of flavors, with a set of routes for each protocol supported by Envoy.</p>\n\n```\n$ istioctl proxy-config route istio-ingressgateway_PODNAME -o json\n\n$ istioctl proxy-config route istio-ingressgateway_PODNAME -o json\n[\n    {\n        \"name\": \"0.0.0.0_80\",\n        \"virtualHosts\": [\n            {\n                \"name\": \"bar.foo.com:80\",\n                \"domains\": [\n                    \"bar.foo.com\",\n                    \"bar.foo.com:80\"\n                ],\n                \"routes\": [\n                    {\n                        \"match\": {\n                            \"prefix\": \"/\"\n                        },\n                        \"route\": {\n                            \"cluster\": \"outbound|8000||bar.foo.svc.cluster.local\",\n                            \"timeout\": \"0s\",\n                            \"retryPolicy\": {\n                                \"retryOn\": \"connect-failure,refused-stream,unavailable,cancelled,resource-exhausted,retriable-status-codes\",\n                                \"numRetries\": 2,\n                                \"retryHostPredicate\": [\n                                    {\n                                        \"name\": \"envoy.retry_host_predicates.previous_hosts\"\n                                    }\n                                ],\n                                \"hostSelectionRetryMaxAttempts\": \"3\",\n                                \"retriableStatusCodes\": [\n                                    503\n                                ]\n                            },\n...\n\n\nExample 7.5 -  Envoy Route (RDS) configuration for the VirtualService in Example 7.3. Notice the default Retry Policy and the embedded Mixer configuration (which is used for reporting telemetry back to Mixer).\n\nWe can update our Route to include some match conditions to see how this results in different Routes for Envoy (Example 7-6):\n\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n name: foo-default\nspec:\n  hosts:\n  - bar.foo.com\n  gateways:\n  - foo-com-gateway\n  http:\n  - match:\n    - uri:\n        prefix: /whiz\n    route:\n    - destination:\n        host: whiz.foo.svc.cluster.local\n  - route:\n    - destination:\n        host: bar.foo.svc.cluster.local\n\n```\n<p>We can update our Route to include some match conditions to see how this results in different Routes for Envoy</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n name: foo-default\nspec:\n  hosts:\n  - bar.foo.com\n  gateways:\n  - foo-com-gateway\n  http:\n  - match:\n    - uri:\n        prefix: /whiz\n    route:\n    - destination:\n        host: whiz.foo.svc.cluster.local\n  - route:\n    - destination:\n        host: bar.foo.svc.cluster.local\n\n```\n\n<p>Similarly we can add retries, split traffic amongst several destinations, inject faults, and more. All of these options in VirtualServices manifest as Routes in Envoy.</p>\n\n```\n$ istioctl proxy-config route istio-ingressgateway_PODNAME -o json\n\n\n[\n    {\n        \"name\": \"http.80\",\n        \"virtualHosts\": [\n            {\n                \"name\": \"bar.foo.com:80\",\n                \"domains\": [\n                    \"bar.foo.com\",\n                    \"bar.foo.com:80\"\n                ],\n                \"routes\": [\n                    {\n                        \"match\": {\n                            \"prefix\": \"/whiz\"\n                        },\n                        \"route\": {\n                            \"cluster\": \"outbound|80||whiz.foo.svc.cluster.local\",\n...\n                    {\n                        \"match\": {\n                            \"prefix\": \"/\"\n                        },\n                        \"route\": {\n                            \"cluster\": \"outbound|80||bar.foo.svc.cluster.local\",\n...\n```\n\n<h4>Clusters</h4>\n<p>We can see that Istio creates a cluster for each service and port in the mesh if we use <code>istioctl</code> to look at clusters. To see a new Cluster emerge in Envoy, we can construct a new ServiceEntry:</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: ServiceEntry\nmetadata:\n  name: http-server\nspec:\n  hosts:\n  - some.domain.com\n  ports:\n  - number: 80\n    name: http\n    protocol: http\n  resolution: STATIC\n  endpoints:\n  - address: 2.2.2.2\n```\n\n```\n$ istioctl proxy-config cluster istio-ingressgateway_PODNAME -o json\n\n\n[\n...\n    {\n        \"name\": \"outbound|80||some.domain.com\",\n        \"type\": \"EDS\",\n        \"edsClusterConfig\": {\n            \"edsConfig\": {\n                \"ads\": {}\n            },\n            \"serviceName\": \"outbound|80||some.domain.com\"\n        },\n        \"connectTimeout\": \"10s\",\n        \"circuitBreakers\": {\n            \"thresholds\": [\n                {\n                    \"maxRetries\": 1024\n                }\n            ]\n        }\n    },\n...\n\n```\n<p>We can experiment with adding new ports (with different protocols) to the ServiceEntry to see how this affects the generation of new Clusters. A DestinationRule is another tool that may be used to generate and update Clusters in Istio. We establish new Clusters by creating Subsets, and we impact the configuration inside the Cluster by modifying load balancing and TLS settings.</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: some-domain-com\nspec:\n  host: some.domain.com\n  subsets:\n  - name: v1\n    labels:\n      version: v1\n  - name: v2\n    labels:\n      version: v2\n```\n\n```\n$ istioctl proxy-config cluster istio-ingressgateway_PODNAME -o json\n\n\n[\n...\n    {\n        \"name\": \"outbound|80||some.domain.com\",\n...\n    },\n    {\n        \"name\": \"outbound|80|v1|some.domain.com\",\n...\n        \"metadata\": {\n            \"filterMetadata\": {\n                \"istio\": {\n                    \"config\": \"/apis/networking/v1alpha3/namespaces/default/destination-rule/some-domain-com\"\n                }\n            }\n        }\n    },\n    {\n        \"name\": \"outbound|80|v2|some.domain.com\",\n...\n    },\n...\n\n```\n\n<p>Notice that we still have our original cluster, outbound|80||some.domain.com, but that we got a new cluster for each Subset we defined as well. Istio annotates the Envoy configuration with the rule that resulted in it being created to help debug.</p>\n\n\n</ResourcesWrapper>","frontmatter":{"title":"Istio Pilot","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"}},"fields":{"slug":"/resources/service-mesh/istio-pilot"}},{"id":"4ce0d80d-d5ec-5b79-bd12-85e0eddf15a4","body":"\nimport BookinfoWith from \"./bookinfo-with-proxies.svg\";\nimport BookinfoWithout from \"./bookinfo-without-proxies.svg\";\nimport IstioArchitecture from \"./istio-architecture.svg\";\n\n<ResourcesWrapper>\n<h2>Planes</h2>\n\n<p>\nThe <strong>data plane</strong> in Istio intercepts each packet in the request and performs health checks, routing, load balancing, authorization, authentication,  and generation of observable signals. Service proxies are transparently placed in-band, and applications are oblivious of the data plane's presence when they conduct service-to-service calls. Intra-cluster communication and inbound (ingress), and outgoing (egress) cluster network traffic are handled by data planes. Application service traffic is directed first to the service proxy for processing, whether it is entering or leaving the mesh (ingressing or egressing). Istio's traffic is transparently intercepted and redirected to the service proxy using iptables rules.\n</p>\n<p>\nIstio's <strong>control plane</strong> provides a single point of administration for service proxies, which require programmatic configuration due to the need to manage a large number of them efficiently and have their configuration updated in real-time as services are rescheduled around your environment (i.e., container cluster). Control planes offer policy and configuration for the mesh's services, transforming a collection of isolated, stateless proxies into a service mesh. The control planes do not directly touch any network packets in the mesh. They operate out-of-band. Control planes usually feature a command line interface and a user interface, both of which provide access to a centralized API for regulating proxy behavior holistically. Changes to control plane configuration can be automated using its APIs (for example, using a CI/CD pipeline), however configuration is usually version-controlled and updated in practise. To summarize, Istio's control plane:\n</p>\n<ul>\n<li>\nProvides policy and configuration for services in the mesh.\n<ul>\n<li>APIs for operators to specify desired routing/resilience behavior.</li>\n</ul>\n</li>\n<li>\nTakes a set of isolated stateless sidecar proxies and turns them into a service mesh.\n<ul>\n<li>APIs for the data plane to consume localized configuration.</li>\n<li>Service discovery abstraction for the data plane.</li>\n</ul>\n</li>\n<li>\nAPIs for specifying usage policies\n<ul>\n<li>Quota and Usage restrictions</li>\n</ul>\n</li>\n<li>\nSecurity\n<ul>\n<li>Certificate issuance and rotation</li>\n<li>Assigning workload identity</li>\n</ul>\n</li>\n<li>\nRouting configuration\n<ul>\n<li>Does not touch any packets/requests in the system.</li>\n<li>Specifying network boundaries and how to access them</li>\n</ul>\n</li>\n<li>Unified telemetry collection</li>\n</ul>\n\n<h3>Istio Control Plane Components</h3>\nWe'll go over the high-level functionality of each control plane component in this section.\n\n<h4>Pilot</h4>\n<p>\nPilot is the head of the ship in an Istio mesh. Pilot keeps in sync with the underlying platform (e.g., Kubernetes) by tracking and representing the state and location of running services to the data plane. Pilot communicates with the service discovery system in your environment and generates configuration for data plane service proxy.\n</p>\n<p>\nAs Istio evolves, Pilot's focus will shift from interfacing with underlying platforms towards scalable serving of proxy configuration. It provides Envoy-compatible configuration by integrating configuration and endpoint information from multiple sources and translating it into xDS objects. Galley, another component, will eventually take responsibility for interfacing directly with underlying platforms.\n</p>\n\n<h4>Galley</h4>\n<p>\nGalley is Istio's configuration aggregation and dissemination component. As its role progresses, it will insulate the rest of Istio's components from the underlying platform and user-supplied configuration by ingesting and validating configuration. Galley uses the Mesh Configuration Protocol (MCP) as a mechanism for serving and distributing configuration.\n</p>\n\n<h4>Mixer</h4>\n<p>\nMixer is a stand-alone control plane component that abstracts infrastructure backends from the rest of Istio. Infrastructure backends include things like Stackdriver and New Relic. Precondition checking, quota management, and telemetry reporting are all responsibilities of the Mixer.\n</p>\n<ol>\n<li>Enables platform & environment mobility</li>\n<li>Responsible for providing granular control over operational policies and telemetry for policy evaluation and telemetry reporting</li>\n<li>Has a rich configuration model</li>\n<li>Most infrastructure concerns are abstracted using intent-based configuration</li>\n</ol>\n<p>\nMixer is used by service proxies and gateways to execute precondition checks to assess whether a request should be allowed to proceed (check) or has exceeded quota depending on communication between the caller and the service, and to report telemetry once a request has completed (report). Mixer uses a set of native and third-party adapters to interface to infrastructure backends. Which telemetry is sent to which backend at what time is determined by adapter configuration. Mixer's adapters, which act as an attribute processing and routing engine, can be used by service mesh operators as a point of integration and intermediation with their infrastructure backends.\n</p>\n\n<h4>Citadel</h4>\n<p>\nCitadel gives Istio the ability to deliver strong service-to-service and end-user authentication via mutual TLS, as well as built-in identity and credential management. Citadel's certificate authority (CA) component handles key and certificate generation, deployment, rotation, revocation, and approving and signing certificate signing requests (CSRs) sent by Citadel agents. Citadel has the (optional) ability to interact with an Identity Directory during the certificate approval process.\n</p>\n<p>\nCitadel offers a pluggable architecture that allows alternative certificate authorities (CAs) to sign workload certificates instead of Citadel's self-generated, self-signed signing key and certificate. Istio's CA pluggability enables and facilitates:\n</p>\n<ul>\n<li>Integration with your organization’s existing Public Key Infrastructure (PKI) system.</li>\n<li>Secure communication between Istio services and non-Istio legacy services (by sharing the same root of trust)</li>\n<li>Protection of the CA signing key by storing it in a well-protected environment (e.g. Vault + HSM)</li>\n</ul>\n\n<h3>Istio Data Plane Components</h3>\n<p>\nTo mediate both inbound and outbound traffic for all services in the service mesh, Istio uses an extended version of Envoy, a high-performance proxy written in C++. Istio utilizes  Envoy's capabilities like dynamic service discovery, load balancing, TLS termination, HTTP/2 and gRPC proxying, circuit breakers, health checks, staged rollouts with %-based traffic split, fault injection, and rich metrics.\n</p>\n<p>\nEnvoy is deployed as a sidecar to the relevant service in the same Kubernetes pod. This allows Istio to extract a multitude of signals about traffic behavior as attributes, which it can use in Mixer to enforce policy decisions and be sent to monitoring systems to provide information about the behavior of the entire mesh.\n</p>\n\n<h4>Injection</h4>\n<img src={BookinfoWithout} className=\"image-right\" alt=\"BookInfo without proxies\" />\n<p>\nYou can easily add Istio capabilities to an existing deployment without having to re-architect or rewrite code using the sidecar proxy model. This is one of the most compelling reasons to use Istio. The promises of immediate view to top-level service metrics, detailed traffic control, and automated authentication and encryption across all services without having to do either:\n</p>\n<ol>\n<li>change your application code</li>\n<li>change your deployment manifests</li>\n</ol>\n\n<p>Using the canonical sample application BookInfo you can see how service proxies come into play and form a mesh.</p>\n<img src={BookinfoWith} className=\"image-left\" alt=\"BookInfo with proxies\" />\n\n<p>\nIn Kubernetes, automatic proxy injection is implemented as a webhook using a Kubernetes API Server with the Mutating Webhook Admission Controller. It is stateless, relying solely on the injection template and mesh configuration configmaps and the to-be-injected pod object. It can be easily horizontally scaled, either manually via the deployment object or automatically via a Horizontal Pod Autoscaler.\n</p>\n<p>\nIstio addresses one of the most well-known distributed systems issues: the lack of homogeneous, reliable, and unchanging networks. It accomplishes this by using lightweight proxies  deployed between your application containers and the network.\n</p>\n\n<h3>Gateways</h3>\n<p>\nIngress and egress gateways were first introduced in Istio 0.8. Ingress and egress gateways are symmetrically similar and serve as reverse and forward proxies for traffic entering and leaving the mesh, respectively. Istio Gateways' behavior, like that of other Istio components, is defined and controlled through configuration, allowing you to specify which traffic to let in and out of the service mesh, at what rate, and so on.\n</p>\n<h4>Ingress</h4>\n<p>\nConfiguration of ingress gateways allow you to define traffic entryways into the service mesh for incoming traffic to flow through. Consider that ingressing traffic into the mesh is a reverse proxy situation - akin to traditional web server load balancing. The configuration for egressing traffic out of the mesh is a forward proxy situation (similar to traditional) in which you determine which traffic to allow out of the mesh and where it should be routed.\n</p>\n<p>\nFor example, the following Gateway configuration sets up a proxy to act as a load balancer exposing port 80 and 9080 (http), 443 (https), and port 2379 (TCP) for ingress. The gateway will be applied to the proxy running on a pod with labels app: my-gateway-controller. While Istio will configure the proxy to listen on these ports, it is the responsibility of the user to ensure that external traffic to these ports are allowed into the mesh.\n</p>\n\n\n```yaml\n\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: my-gateway\nspec:\n  selector:\n    app: my-gateway-controller\n  servers:\n  - port:\n      number: 80\n      name: http\n      protocol: HTTP\n    hosts:\n    - uk.bookinfo.com\n    - eu.bookinfo.com\n    tls:\n      httpsRedirect: true # sends 301 redirect for http requests\n  - port:\n      number: 443\n      name: https\n      protocol: HTTPS\n    hosts:\n    - uk.bookinfo.com\n    - eu.bookinfo.com\n    tls:\n      mode: SIMPLE #enables HTTPS on this port\n      serverCertificate: /etc/certs/servercert.pem\n      privateKey: /etc/certs/privatekey.pem\n  - port:\n      number: 9080\n      name: http-wildcard\n      protocol: HTTP\n    hosts:\n    - \"*\"\n  - port:\n      number: 2379 # to expose internal service via external port 2379\n      name: mongo\n      protocol: MONGO\n    hosts:\n    - \"*\"\n```\n<h4>Egress</h4>\n<p>Traffic can exit an Istio service mesh in two ways - directly from the sidecar or funnelled through an egress gateway, where traffic policy may be applied.</p>\n\n<div className=\"fact\">\nBy default, Istio-enabled applications are unable to access URLs external the cluster.\n</div>\n\n<h4>Direct from Service Proxy</h4>\n<p>\nYou can configure the ConfigMap of the istio-sidecar-injector to allow traffic headed for an external source, bypassing the egress gateway. Set the following configuration in the sidecar injector, which will identify cluster-local networks and keep traffic destined locally within the mesh, while forwarding traffic for all other destinations externally.\n</p>\n\n```yaml\n--set global.proxy.includeIPRanges=\"10.0.0.1/24\"\n```\n<p>\nExternal requests bypass the sidecar and route directly to the intended destination once this configuration is deployed and istio proxies are updated. Only internal requests within the cluster will be intercepted and managed by the Istio sidecar.\n</p>\n\n<h4>Route through an Egress Gateway</h4>\n<p>\nIstio monitoring and route rules can be applied to traffic leaving the mesh through an egress gateway. It also enables communication between applications running in a cluster where the nodes lack public IP addresses, preventing the mesh's applications from accessing the Internet. The nodes (and the applications running on them) can access external services in a regulated manner by defining an egress gateway, directing all egress traffic through it, and allocating public IPs to the egress gateway nodes. \n</p>\n<img src={IstioArchitecture} className=\"image-center\" alt=\"Istio Architecture\" />\n\n<div className=\"intro\" style={{textAlign: \"center\"}}>\n<p><b>Why use Istio Gateways and not Kubernetes Ingresses?</b></p>\n<p>In general, the Istio v1alpha3 APIs leverage Gateways for richer functionality as Kubernetes Ingress has proven insufficient for Istio applications. In comparison to Kubernetes Ingress, Istio Gateways can function as a pure L4 TCP proxy and support all protocols supported by Envoy.</p>\n<p>\nAnother factor to examine is the division of trust domains between organizational teams. Kubernetes Ingress API combines specification for L4 to L7, which makes it challenging for different teams in organizations with separate trust domains (such as SecOps, NetOps, ClusterOps and Developers) to own Ingress traffic management.\n</p>\n</div>\n\n</ResourcesWrapper>\n\n","frontmatter":{"title":"Istio v1.5 at a Glance","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"}},"fields":{"slug":"/resources/service-mesh/istio-v15-at-a-glance"}},{"id":"be9a13a3-5dd1-581f-9e7b-e28c67e58168","body":"\n\n\n\n<ResourcesWrapper>\n<div className=\"intro\">\n<p>\nIstio is a massive project with a wide range of capabilities and deployment options. We will perform a basic installation on your local machine and deploy a few services onto the mesh. Let’s start by understanding its supported platforms and configuring our environment for deployment.\n</p>\n</div>\n\n<h3>Preparing Your Environment for Istio</h3>\n<p>\nIn addition to Istio, we'll be deploying BookInfo, its sample application. Our Istio and BookInfo deployments will lay down several containers. We will use Kubernetes as the platform to manage these containers. Kubernetes is a robust container orchestration system capable of forming clusters (a collection of nodes) and scheduling containers across nodes within the fleet of host machines (nodes) that form the cluster. Nodes are Linux or Windows servers that can run containers with a Kubernetes agent, kubelet, installed. Kubernetes is the first and best supported underlying platform among a variety of to-be-supported underlying systems. As a result, we'll be using Kubernetes throughout our examples. To be clear, Istio is not dependent on Kubernetes. Istio is designed to be platform agnostic and supports multiple deployment platforms including those without a container orchestrator.\n</p>\n\n<h4>Docker Desktop as the Installation Environment</h4>\n<p>\nWe can deploy Kubernetes in a variety of ways. We'll utilize Docker Desktop as a convenient tool for this. Docker Desktop is an easy-to-install application for your Mac or Windows environment that allows you to run Kubernetes and Istio on your local machine.\n</p>\n<p>\nInstall Docker Desktop and verify that you have a functional Docker environment by running <code>`$ docker run hello-world`</code> on the command line. If you get a <code>“Hello from Docker!”</code> message, you’ve confirmed that Docker isable to pull images, create new instances, and run as expected.\n</p>\n<p>\nWe'll run Kubernetes on Docker Desktop and leverage Kubernetes as the platform to deploy Istio. The Docker Desktop managed Kubernetes server is a single-node Kubernetes cluster that runs locally within your Docker instance. It is not configurable.\n</p>\n<p>\nThe Docker Desktop for Mac Kubernetes integration provides the Kubernetes CLI executable at <code>/usr/local/bin/kubectl</code>. The Docker Desktop for Windows Kubernetes integration provides the Kubernetes CLI executable at <code>C:\\>Program Files\\Docker\\Docker\\Resources\\bin\\kubectl.exe</code>. This location may not be in your shell’s <code>PATH</code> variable, so you may need to type the full path of the command or add it to the <code>PATH</code>. For more information about <code>kubectl</code>, see the official <code>kubectl</code> documentation. \n</p>\n\n<h4>Configuring Docker Desktop</h4>\n<p>\nTo make sure your Docker Desktop virtual machine has enough memory to run Kubernetes, Istio, and Istio's sample application, BookInfo, you'll need to set it up with at least 4GiB of RAM. All Istio and BookInfo services require this amount of memory to operate effectively.  Pilot, in particular, may have problems running as it requests 2048Mi of memory in an Istio deployment with default settings (see <Link to=\"/resources/service-mesh/istio-v15-at-a-glance\"> Istio v1.5 at a Glance</Link> for a quick overview of Pilot's purpose). Considering 2048Mi is also the default limit for Docker Desktop, Pilot may refuse to start due to insufficient resources if this limit is not increased in your Docker installation.\n</p>\n<p>\nInstead of increasing the amount of memory allocated to your Docker Desktop installation, you may limit the amount of memory that Pilot requests of your Kubernetes cluster.  Depending on whether you're utilizing a package manager like Helm or directly using Kubernetes spec files, there are a couple of options.\n</p>\n\n<p>\nUsing <code>install/kubernetes/istio-demo.yaml</code> as an example manifest, lets highlights which section of the Pilo spec to edit in order to reduce the 2048Mi of memory requested by Pilot to something smaller like 512Mi.\n</p>\n\n``` \napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: istio-pilot\n  namespace: istio-system\n...\n          resources:\n            requests:\n              cpu: 500m\n              memory: 2048Mi\n...\n\n```\n<p>\nWhen deploying Istio with Helm, you can also offer custom settings. \nTo customize Istio install using Helm, use the <code>--set key=value</code> option in Helm command to override one or more values. \nAn example of reducing Pilot’s requested memory resources is shown below.\n</p>\n\n``` \n$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system --set pilot.resources.requests.memory=\"512Mi\" | kubectl apply -f -\n```\n\n<h4>Deploying Kubernetes</h4>\n<p>\nIf Kubernetes is not installed on your desktop please refer to Troubleshooting for helpful tips on installing Kubernetes. Verify <code>kubectl</code> installation by running:\n</p>\n\n``` \n$ kubectl version --short\nClient Version: v1.13.0\nServer Version: v1.13.0\n\n```\n<p>\nIf you see both client and server version numbers, your <code>kubectl</code> client is installed in your <code>PATH</code> and a Kubernetes cluster is accessible. Verify Kubernetes installation and your current context by running <code>`$ kubectl get nodes`</code> which will confirm that your kubeconfig (typically located at <code>~/.kube/config</code>) is correctly configured to the `docker-desktop` context and your single-node cluster is up:\n</p>\n\n``` \n$ kubectl get nodes\nNAME             STATUS   ROLES    AGE   VERSION\ndocker-desktop   Ready    master   32m   v1.13.0\n\n```\n<h4>Install Kubernetes Dashboard</h4>\n<p>The Kubernetes dashboard is a web-based user interface that allows you to manage your cluster and its resources. Containerized applications can be deployed and troubleshooted. The Kubernetes dashboard shows the current state of Kubernetes resources in your cluster as well as any faults that may have occurred. The Kubernetes dashboard can be used to reinforce your understanding of how Istio runs. The easiest and most common way to access the cluster is through <code>kubectl proxy</code>, which creates a local web server that securely proxies data to the Kubernetes dashboard through the Kubernetes API server. Execute the following command to deploy the Kubernetes dashboard:</p>\n\n``` \n$ kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml\n\n```\n\n<p>Once deployed, you can access the Kubernetes dashboard using the kubectl command-line tool by running the following command:</p>\n\n``` \n$ kubectl proxy\n```\n<p>This command creates a local web server that uses the Kubernetes API server to securely proxy data to the Kubernetes dashboard. It's important to note that the Kubernetes dashboard can only be accessed from the machine where the command is executed.</p>\n<p>\n See <code>kubectl proxy --help</code> for more options and the Kubernetes dashboard documentation for more information. <code>kubectl</code> will make the Kubernetes dashboard available at <code>http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</code>.\n</p>\n<p>\nDashboard deploys with a minimal RBAC configuration by default to secure your cluster data. Only a Bearer Token is currently supported for logging into the Kubernetes dashboard. Create a sample user and use its token, or use an existing token provided by your Docker Desktop deployment, and then run:\n</p>\n\n``` \n$ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | awk '/default-token/ {print $1}')\n```\nThis will print something similar to:\n\n``` \nName:         default-token-tktcn\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  kubernetes.io/service-account.name: default\n              kubernetes.io/service-account.uid: 3a0a68b1-4abd-11e9-8561-025000000001\n\nType:  kubernetes.io/service-account-token\n\nData\n====\nca.crt:     1025 bytes\nnamespace:  11 bytes\ntoken:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLXRrdGNuIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzYTBhNjhiMS00YWJkLTExZTktODU2MS0wMjUwMDAwMDAwMDEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.WBOH85PHBVjky9JZLidfzS8EWNunIlFZR8MIJjMgBxQbVnqaVl0RmzcvZqYZRY9W7bwQddkXXHAuw5QQMfy8S-I2KdgxpQEP18tfU9wicv6TWt9bRfw9N7QsvB-twlMCEpRKtHwrORZqgRb7_13UH14RB18DiUAIiMok6rs1Pl5w9y0RXVUk9_RXMA2hJnkZ09cTOqJmQ80Vg4QvgAhuxwgmb6kl2rMjb0LegXihAN6j6Yv_JHZ2Vgjk73Priig0Pbjic6t87XfO51Kgjgw7g0vCF0OlOylvp-5oroPMa3nnnlqh6PGnFzOq0zLqjqYXMXZFI5cWkNmf71Q_qKSOsA\n\n```\n<p>Copy the token and use it to authenticate in the Kubernetes dashboard.</p>\n\n<h3>Installing Istio</h3>\n<p>With Kubernetes deployed and dashboard up, it’s time to install our service mesh. You can download the latest Istio release by executing the following command:</p>\n\n```\n$ curl -L https://git.io/getLatestIstio | sh -\n```\n<p>The script fetches the latest Istio release candidate and untars it.</p>\n<p>If you would like to fetch a particular version of Istio, specify the desired version number as so:</p>\n\n```\n$ curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.1.0 sh -\n```\n<p>\nIstio can also be downloaded from the <a href=\"https://github.com/istio/istio/releases\">Istio release page</a>. There are versions for Windows, MacOS, and Linux to pick from. After downloading the distribution for your operating system, extract the compressed file to a directory and acquaint yourself with the contents of the distribution, regardless of the operating system you're using.\n</p>\n<p>Each release includes <code>istioctl</code>, configuration samples, a sample application and platform-specific installation resources. <code>istioctl</code> is a command line utility for service operators to debug and diagnose their Istio service mesh. Alternatively, <code>istioctl</code> can be installed via your preferred  package manager.</p>\n<p>Explore release contents on MacOS or Linux by changing directory to “istio-x.x.x”. For example: </p>\n\n```\n$ cd istio-1.1.0\n```\n<p>\nThis directory contains the files necessary for installing Istio, sample files and also <code>istioctl</code>, an important command-line tool used to manage your Istio deployment.\n</p>\n\n```\n$ ls -l\ntotal 48\n-rw-r--r--   1  user  staff  11343 Mar 18 16:08 LICENSE\n-rw-r--r--   1  user  staff   5921 Mar 18 16:08 README.md\ndrwxr-xr-x   3  user  staff     96 Mar 18 16:08 bin\ndrwxr-xr-x   7  user  staff    224 Mar 18 16:08 install\n-rw-r--r--   1  user  staff    602 Mar 18 16:08 istio.VERSION\ndrwxr-xr-x  16  user  staff    512 Mar 18 16:08 samples\ndrwxr-xr-x  21  user  staff    672 Mar 18 16:08 tools\n```\n<p>\nThe installation directory contains Istio installation <code>YAML</code> files for Kubernetes in <code>install/</code>, sample applications in <code>samples/</code>, the <code>istioctl</code> client binary in the <code>bin/</code> directory. \nThe <code>istio.VERSION</code> configuration file contains a list of Istio components and their version numbers for the release’s distribution.\n</p>\n<p>\n<code>istioctl</code> is the Istio configuration command line utility. <code>istioctl</code> is used for setting routing rules, policies, and injecting Envoy as a service proxy manually, among other things. It is also used to create, list, modify, and delete configuration resources in the Istio system. Let’s add it to your <code>PATH</code> environment variable:\n</p>\n\n```\n$ export PATH=$PWD/bin:$PATH\n```\n<p>Verify your istioctl installation by running:</p>\n\n```\n$ istioctl version\n```\n<p>This should validate path and istioctl command options (see Example 4.7). If not, see Troubleshooting. </p>\n\n```\nversion.BuildInfo{\nVersion:\"1.1.0\", GitRevision:\"82797c0c0649a3f73029b33957ae105260458c6e\", \nUser:\"root\", \nHost:\"996cd064-49c1-11e9-813c-0a580a2c0506\", GolangVersion:\"go1.10.4\", \nDockerHub:\"docker.io/istio\", \nBuildStatus:\"Clean\", \nGitTag:\"1.1.0-rc.6\"\n}\n```\n<p>Now that we have downloaded an Istio distribution and verified it’s CLI tool, istioctl, is functional on our local machine, let’s perform a basic installation.</p>\n<h4>Istio Installation Options</h4>\n<p>There are numerous installation and deployment architectures to choose from. Typically, installations fit into one of the following categories:</p>\n<h5>Choice of Security Configuration</h5>\n<ul>\n<li>\nInstall with strict mutual TLS authentication.\n<ul>\n<li>Recommended for fresh kubernetes cluster. This method enforces authentication between sidecars by default.</li>\n</ul>\n</li>\n<li>\nInstall with permissive mutual TLS authentication between sidecars.\n<ul>\n<li>Recommended if you have existing clusters and services.</li>\n<li>Recommended if you have applications where services with an Istio sidecar need to be able to communicate with other non-Istio Kubernetes services</li>\n</ul></li>\n<li>\nCustom deployments that include or exclude certain default Istio components.\n<ul>\n<li>Recommended if a function of one of Istio’s components isn’t necessary or desired in your environment (e.g. removal of Citadel if mTLS is not to be used).</li>\n</ul></li>\n</ul>\n\n<h5>Choice of Deployment Utility</h5>\n<ul>\n<li>\n\nRender Kubernetes manifests with a package / configuration management system like Helm or Ansible.\n<ul> \n<li>Recommended for production deployments with templated configuration.</li>\n</ul>\n</li>\n</ul>\n\n<h4>Registering Istio’s Custom Resources</h4>\n<p>Use the following command to apply Istio’s CustomResourceDefinition objects to your cluster:</p>\n\n```\n$ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl apply -f $i; done\n```\n<p>This installation does not leverage Helm (a package manager for Kubernetes). The generally preferred method for any installation of Istio that may find its way into production is to use Helm or Ansible; both included in the distribution you just downloaded. With Helm or Ansible you get more flexibility in which components you install and can fine-tune your setup.</p>\n\n```\n$ kubectl  api-resources | grep istio\nmeshpolicies                                   authentication.istio.io        false        MeshPolicy\npolicies                                       authentication.istio.io        true         Policy\nadapters                                       config.istio.io                true         adapter\napikeys                                        config.istio.io                true         apikey\nattributemanifests                             config.istio.io                true         attributemanifest\nauthorizations                                 config.istio.io                true         authorization\nbypasses                                       config.istio.io                true         bypass\nchecknothings                                  config.istio.io                true         checknothing\ncirconuses                                     config.istio.io                true         circonus\ncloudwatches                                   config.istio.io                true         cloudwatch\n...\n```\n<p>\nIstio actually registers new types of resources, Custom Resource Definitions (CRDs) which represent things like Gateways or Services. We can manipulate (create/update/delete) them just like any other Kubernetes object:\n</p>\n\n```\n$ kubectl get crd | grep istio\nadapters.config.istio.io               2019-03-24T03:17:08Z\napikeys.config.istio.io                2019-03-24T03:17:07Z\nattributemanifests.config.istio.io     2019-03-24T03:17:07Z\nauthorizations.config.istio.io         2019-03-24T03:17:07Z\nbypasses.config.istio.io               2019-03-24T03:17:07Z\nchecknothings.config.istio.io          2019-03-24T03:17:07Z\ncirconuses.config.istio.io             2019-03-24T03:17:07Z\ncloudwatches.config.istio.io           2019-03-24T03:17:08Z\nclusterrbacconfigs.rbac.istio.io       2019-03-24T03:17:07Z\ndeniers.config.istio.io                2019-03-24T03:17:07Z\ndestinationrules.networking.istio.io   2019-03-24T03:17:07Z\ndogstatsds.config.istio.io             2019-03-24T03:17:08Z\nedges.config.istio.io                  2019-03-24T03:17:08Z\nenvoyfilters.networking.istio.io       2019-03-24T03:17:07Z\n...\n```\n<p>Once Istio’s custom resources are registered with Kubernetes, Istio control plane components may be installed.</p>\n\n<h4>Installing Istio Control Plane Components</h4>\n<p>\nThe istio-demo.yaml specification file contains Istio configuration that allows services to run in mutual TLS permissive mode. If you have existing services or applications in your Kubernetes cluster, it is recommended to use mTLS permissive mode. If you're setting up a fresh cluster, security best practises recommend using <code>istio-demo-auth.yaml</code> to encrypt service traffic between sidecars.\n</p>\n\n```\n$ kubectl apply -f install/kubernetes/istio-demo.yaml\n```\n<p>Please wait for a few minutes to let the installation run, for the Docker images to properly download and for the deployments to succeed. The application of this extensive yaml file has Kubernetes realize many new Custom Resource Definitions.</p>\n<p>\nYou might also use <code>istio-demo-auth.yaml</code>, which enforces mutual TLS authentication between all clients and servers. You might consider that initial deployment of Istio with strict mTLS enforcement configured is most successfully used within fresh Kubernetes cluster where all workloads will be Istio-enabled. To apply Istio setup with mutual TLS authentication, use the command below:\n</p>\n\n```\n$ kubectl apply -f install/kubernetes/istio-demo-auth.yaml\n```\n<p>\nIstio's control plane is installed in its own istio-system namespace, and it supervises services in all other namespaces with sidecar proxies, or in other words, all other namespaces with services on the mesh. The control plane is deployed in the istio-system namespace act as a cluster-wide, which means that behaves in a single-tenant fashion.\n</p>\n\n```\n$ kubectl get namespaces\nNAME           STATUS   AGE\ndefault        Active   49d\ndocker         Active   49d\nistio-system   Active   2m15s\nkube-public    Active   49d\nkube-system    Active   49d\n```\n<p>Verify installation of the control plane into the <code>istio-system</code> namespace using commands:</p>\n\n```\n$ kubectl get namespaces\nNAME           STATUS   AGE\ndefault        Active   49d\ndocker         Active   49d\nistio-system   Active   2m15s\nkube-public    Active   49d\nkube-system    Active   49d\n\nExample 4.11 - istio-system namespace created to contain Istio control plane components.\n\nVerify installation of the control plane into the istio-system namespace using commands:\n\n$ kubectl get svc -n istio-system\nNAME                     TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                      AGE\ngrafana                  ClusterIP      10.108.237.105   <none>        3000/TCP                                                                                                                                     11d\nistio-citadel            ClusterIP      10.108.165.14    <none>        8060/TCP,15014/TCP                                                                                                                           11d\nistio-egressgateway      ClusterIP      10.107.148.169   <none>        80/TCP,443/TCP,15443/TCP                                                                                                                     11d\n...\n\n$ kubectl get pod -n istio-system\nNAME                                      READY   STATUS      RESTARTS   AGE\ngrafana-57586c685b-jr2pd                  1/1     Running     0          5m45s\nistio-citadel-645ffc4999-8j4v6            1/1     Running     0          5m45s\nistio-cleanup-secrets-1.1.0-4c9pc         0/1     Completed   0          5m48s\nistio-egressgateway-5c7fd57fdb-85g26      1/1     Running     0          5m46s\nistio-galley-978f9447f-mj5xj              1/1     Running     0          5m46s\nistio-grafana-post-install-1.1.0-g49gh    0/1     Completed   0          5m48s\nistio-ingressgateway-8ccdc79bc-8mk4p      1/1     Running     0          5m46s\nistio-pilot-649455846-klc8c               2/2     Running     0          5m45s\nistio-policy-7b7d7f644b-sqsp8             2/2     Running     4          5m45s\nistio-security-post-install-1.1.0-v4ffp   0/1     Completed   0          5m48s\nistio-sidecar-injector-6dcc9d5c64-tklqz   1/1     Running     0          5m45s\nistio-telemetry-6d494cd676-n6pkz          2/2     Running     4          5m45s\nistio-tracing-656f9fc99c-nn9hd            1/1     Running     0          5m44s\nkiali-69d6978b45-7q7ms                    1/1     Running     0          5m45s\nprometheus-66c9f5694-2xzpm                1/1     Running     0          5m45s\n```\n<p>\nWe've only deployed half of the service mesh so far, the control plane. You may not have noticed service proxies prior to deploying the sample application, and thus the data plane, because we have not deployed any services (applications) to run on the mesh. You may believe that no proxies are running, but you would be overlooking the fact that two proxies are already running. Our service proxy is up and operating on both the ingress and egress gateways. Let's have a look.\n</p>\n\n<h4>Deploy Sample Application</h4>\n<p>\nLet's get started by deploying our first set of services (an application) to the service mesh. We'll utilise BookInfo, an Istio sample application that demonstrates many aspects of the value proposition of service meshes. The Kubernetes manifest files for BookInfo may be found in the <code>samples/bookinfo/</code> subdirectory in your release distribution folder.  Let's take a moment to familiarise with this application.\n</p>\n<p>\nTo populate the page, users call the <code>productpage</code> microservice, which then calls the <code>details</code> and <code>reviews</code> microservices. The book information can be found in the <code>details</code> microservice. The <code>reviews</code> microservice contains book reviews and subsequently calls the <code>ratings</code> microservice to retrieve reviews. The <code>ratings</code> microservice contains book ranking in the form of a 1 to 5 star book review.  There are three versions of the <code>reviews</code> microservice:\nEach of the four application services are written in a different language - Python, Ruby, Java, Nodejs, which further demonstrates the value of a service mesh.\n</p>\n<ul>\n<li>reviews v1 has no ratings (does not call the ratings service).</li>\n<li>reviews v2 has ratings of 1 to 5 black stars (calls the ratings service).</li>\n<li>reviews v3 has ratings of 1 to 5 red stars (calls the ratings service).</li>\n</ul>\n\n<p>\nThe application does not need to be changed to run the sample using Istio. Instead, we'll configure and run the services in an Istio-enabled environment, with service proxies injected alongside each service as sidecars. Istio's service proxies can be injected as sidecars to application services either manually or automatically. As we deploy our sample application, let's have a look at how automated sidecar injection works.\n</p>\n\n<h4>Deploying Sample App with Automatic Sidecar Injection</h4>\n<p>\nIstio will deploy a sidecar injector in order to have Envoy deployed as sidecars to each of our services. Let's check for the presence of the sidecar injector deployment and its namespace label, which specifies that pods in a specific namespace will have sidecar injected automatically upon deployment (admission):\n</p>\n\n```\n$ kubectl -n istio-system get deployment -l istio=sidecar-injector\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\nistio-sidecar-injector   1/1     1            1           82m\n```\n<p>\nLabel the default namespace with <code>istio-injection=enabled</code>\n</p>\n\n```\n$ kubectl label namespace default istio-injection=enabled\n```\n<p>And confirm which namespaces have the istio-injection label associated:</p>\n\n```\n$ kubectl get namespace -L istio-injection\nNAME           STATUS    AGE       ISTIO-INJECTION\ndefault        Active    1h        enabled\nDocker         Active    1h        enabled\nistio-system   Active    1h        disabled\nkube-public    Active    1h        \nkube-system    Active    1h\n```\n<p>The <code>istio-demo.yaml</code> deployment we ran has automatic injection configured.</p>\n<p>\nWe can now deploy the sample app after installing the sidecar injector with modifying admission webhook and the namespace designated for automatic sidecar injection.\n</p>\n\n```\n$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n```\n<p>\nWith sample application deployed, you can confirm that automatic sidecar injection is working in your environment by inspecting any one of the BookInfo pods and noting the istio-proxy container as a new addition to the application pod. \n</p>\n\n```\n$ kubectl describe po/productpage-v1-....\n...\nistio-proxy:\n    Container ID:  docker://f28abdf1f0acf92687711488f7fcca8cc5968e2ed39d8275bf57cc46b5ae2257\n    Image:         docker.io/istio/proxyv2:1.1.7\n    Image ID:      docker-pullable://istio/proxyv2@sha256:e6f039115c7d5ef9c8f6b049866fbf9b6f5e2255d3a733bb8756b36927749822\n    Port:          15090/TCP\n    Host Port:     0/TCP\n    Args:\n      proxy\n      sidecar\n...\n```\n<h4>Networking with the Sample App</h4>\n<p>\nAfter the Bookinfo services are up and running, you'll need to make the application accessible from outside your Kubernetes cluster, such as through a browser. This is accomplished through the usage of an Istio Gateway. You'll need to specify the application's ingress gateway:\n</p>\n\n```\n$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml\n```\n\n<p>Confirm the gateway has been created:</p>\n\n```\n$ kubectl get gateway\n\nNAME               AGE\nbookinfo-gateway   7m\n```\n\n<p>\nFind where the <code>productpage</code> has been exposed as a service available to handle requests from outside of the cluster to interact with the freshly deployed application.\n</p>\n\n```\n$ echo \"http://$(kubectl get nodes -o template --template='{{range.items}}{{range.status.addresses}}{{if eq .type \"InternalIP\"}}{{.address}}{{end}}{{end}}{{end}}'):$(kubectl get svc istio-ingressgateway -n istio-system -o jsonpath='{.spec.ports[0].nodePort}')/productpage\"\n\nhttp://x.x.x.x:31380/productpage\n```\n<h4>Uninstall Istio</h4>\n<p>It's a common mistake to assume that deleting the istio-system namespace will uninstall Istio. Deleting the istio-system removes Istio’s control plane components, but leaves CRDs, sidecars and other artifacts resident in your cluster. Uninstalling Istio is as simple as executing this command from within your istio release folder:</p>\n\n```\n$ kubectl delete -f install/kubernetes/istio-demo.yaml\n```\n\n<p>\nThis will not delete all of the Istio custom resource definitions, mesh configuration and sample application, however. In order to delete these, run:\n</p>\n\n```\n$ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl delete -f $i; done\n$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n$ kubectl delete -f samples/bookinfo/networking/bookinfo-gateway.yaml\n```\n<p>\nYou can verify the success of Istio and BookInfo’s removal by running:\n</p>\n\n```\n$ kubectl get crds\n$ kubectl get pods\n```\n\n</ResourcesWrapper>","frontmatter":{"title":"Deploying Istio","type":"Article","technology":"Docker","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/731763d720780a49c2ffdfede8c28f4b/istio.svg"}},"fields":{"slug":"/resources/service-mesh/deploying-istio"}},{"id":"b20bd734-eb5b-5c29-abaa-d2b13d6c327c","body":"\n\n\nimport Library from \"./using-different-microservice-client-libraries.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n  <p>\n    Client libraries (microservices frameworks) became very popular as microservices took a foothold in modern application design to avoid rewriting the same logic in every service. Example frameworks include the following:\n  </p>\n\n  <ul>\n  <li>\n  <h3>Twitter Finagle </h3>\n  <p>\n  An open source remote procedure call (RPC) library built on Netty for engineers that want a strongly-typed language on the Java Virtual Machine (JVM). Finagle is written in Scala.\n  </p>\n  </li>\n\n  <li>\n  <h3>Netflix Hystrix</h3>\n  <p>\n  An open source latency and fault tolerance library designed to isolate points of access to remote systems, services, and third-party libraries; stop cascading failure; and enable resilience. Hystrix is written in Java.\n  </p>\n  </li>\n\n  <li>\n  <h3> Netflix Ribbon</h3>\n  <p>\n  An open source Inter-Process Communication (IPCs) library with built-in software load balancers. Ribbon is written in Java.\n  </p>\n  </li>  \n  <li>\n  <h3> Gokit</h3>\n  <p>\n  An open source toolkit for building microservices (or elegant monoliths) with gRPC as the primary messaging pattern. Gokit is written in Go and comes with pluggable serialization and transport.\n  </p>\n  </li>\n\n  <li><h3>DropWizard, Spring Boot, Akka… and others.</h3></li>\n  </ul>\n\n\n  <div className=\"fact\">\n  <p>\n    See the Layer5 <Link to=\"/landscape\">service mesh landscape</Link> for a comprehensive perspective of and characterizing of all popular client libraries.\n  </p>\n  </div>\n\n  <p>\n  Prior to the availability of service meshes, developers used language-specific microservices frameworks to improve the resiliency, security, and observability of their services. The drawback of client libraries is that they embed infrastructure concerns into your application code. Services that embed the same client library across themselves in the presence of a service mesh incorporate duplicative code. Inconsistency is a concern for services that include different client libraries or different versions of the same client library. In environments with polyglot microservices, different client libraries are used.  \n  </p>\n  <p>\n  Getting teams to update their client libraries can be an arduous process. When these infrastructure concerns are embedded in your service code, you'll need to track down your developers to update and reconfigure these libraries.  It can take a long time to get a consistent configuration with the same and most recent version deployed.  Enforcing consistency is challenging.  As seen in the figure below, these frameworks couple your services with the infrastructure.\n  </p>\n  <div className=\"center\" >\n  <img src={Library} align=\"right\" alt=\"service mesh client libraries\" />\n  <p>Figure 1: Services architecture using client libraries coupled with application logic</p>\n\n  </div>\n\n  <p>\nDifferent services teams must negotiate things like timeouts and retries when infrastructure code is embedded in the application. A service mesh not only decouples infrastructure code from application code, but it also decouples teams. Service meshes are typically implemented as infrastructure that exists outside of your applications, but as their adoption increases, this is changing, and their use for influencing or implementing business logic is becoming more prevalent.\n  </p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Client Libraries","type":"Article","technology":"Docker","product":"Meshery","mesh":"Linkerd","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRi4BAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSFsAAAABYJpt243X+ax9C1hFYgWRAaxiAtUIklH0N9Pf65L8/wQRQTZpE+f2EPyykTyAieQNNCTZ75JOYJb0AK0kjU4tzg3+8ju7zFZJr1nncJSWZZkBcfkBgvITwRcAAFZQOCCsAAAAMAQAnQEqFAAPAD7RVKNLqCSjIbAIAQAaCWcAwoGMRLsm0wASOs234oIAAP6XHNuXBCJ2KQ+ecb3PQ0c5fwSZNvgHm6OoXnjbpxb69DLufGEPdUvlyKFovtxZtq7T5YKEfrAwfrmNDOvM094GU6qVTgZRo3uaELC6VNn1m1jlYWe8PKt9B890YGLcCtNa4BMInybbNJw1i5CJVGJRHTu0yMIrOUbGYRF8ggQAAA=="},"images":{"fallback":{"src":"/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp","srcSet":"/static/c20824e5fc301bc720fc8d9e96c83d9c/66907/using-different-microservice-client-libraries.webp 750w,\n/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.75}},"extension":"webp","publicURL":"/static/c20824e5fc301bc720fc8d9e96c83d9c/using-different-microservice-client-libraries.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRi4BAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSFsAAAABYJpt243X+ax9C1hFYgWRAaxiAtUIklH0N9Pf65L8/wQRQTZpE+f2EPyykTyAieQNNCTZ75JOYJb0AK0kjU4tzg3+8ju7zFZJr1nncJSWZZkBcfkBgvITwRcAAFZQOCCsAAAAMAQAnQEqFAAPAD7RVKNLqCSjIbAIAQAaCWcAwoGMRLsm0wASOs234oIAAP6XHNuXBCJ2KQ+ecb3PQ0c5fwSZNvgHm6OoXnjbpxb69DLufGEPdUvlyKFovtxZtq7T5YKEfrAwfrmNDOvM094GU6qVTgZRo3uaELC6VNn1m1jlYWe8PKt9B890YGLcCtNa4BMInybbNJw1i5CJVGJRHTu0yMIrOUbGYRF8ggQAAA=="},"images":{"fallback":{"src":"/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp","srcSet":"/static/c20824e5fc301bc720fc8d9e96c83d9c/66907/using-different-microservice-client-libraries.webp 750w,\n/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.75}},"extension":"webp","publicURL":"/static/c20824e5fc301bc720fc8d9e96c83d9c/using-different-microservice-client-libraries.webp"}},"fields":{"slug":"/resources/service-mesh/client-libraries"}},{"id":"36d16c3d-7694-5d62-a482-582be4038596","body":"\n\n\nimport Api from \"./citrix-api-security-considerations-by-traffic-direction.svg\";\n\n\n<ResourcesWrapper>\n\n<p>\n    Historically, application delivery controllers were purchased, deployed, and managed by IT professionals most commonly to run enterprise-architected applications. With their distributed systems design and ephemeral infrastructure, cloud native applications require load balancers to be as dynamic as the infrastructure (containers, for example) upon which they run. These are often software load balancers. Because cloud native applications are typically developer-led initiatives in which developers are creating the application — that is, the microservices — and the infrastructure, developers and platform teams are increasingly making, or heavily influencing, decisions for load balancing (and other) infrastructure.\n</p>\n<p>\nSelecting your proxy is one of the most important decision your team will make. A developer’s selection process gives heavier weight to a proxy’s APIs (due to their ability to programmatically configure the proxy) and on a proxy’s cloud native integrations (as previously noted). A top item on the list of demands for proxies is protocol support. Generally, protocol considerations can be broken into two types:\n</p>\n<ul>\n<li>TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing.</li>\n<li>gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.</li> \n</ul>\n\n<div className=\"intro\">\n<h3 style={{textAlign: \"center\"}}>Tip: HTTP2, gRPC, NATS</h3>\n<p>\n    At the heart of many distributed systems architectures are streaming and messaging protocols. When your applications need higher performance than JSON-REST, the application architecture commonly includes use of gRPC or NATS. REST is often found on the perimeter of the services while gRPC is used for service-to-service interactions. gRPC is a universal RPC framework. NATS is a multi-modal messaging system that includes request/reply, pub/sub and load balanced queues. \n</p>\n</div>\n\n<p>\n    The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:\n</p>\n<ul>\n<li>High performance and low latency</li>\n<li>High scalability and small memory footprint</li>\n<li>Deep observability at all layers of the network stack</li>\n<li>Programmatic configuration and ecosystem integration</li>\n</ul>\n\n<p>\n    With a Kubernetes-native control plane, using CRDs and associated controllers enables powerful simplification, easy scaling, and intent-driven infrastructure. It is critical that the proxy has the capability to be intent-driven using Kubernetes CRDs and controllers (preferably an open source proxy like the Citrix Ingress Controller It’s the robustness of a proxy’s cloud native integrations and configuration APIs, like the Citrix Nitro API, that enables this. Not only are the proxy’s configuration APIs a key consideration, but so is the method by which they handle your applications’ APIs, specifically their security.\n</p>\n\n<h3>TCP/UDP Support</h3>\n<p>There are many applications that communicate over TCP/UDP ports. Kubernetes ingress was developed with web traffic in mind. It provides a standard way to control and route HTTP/S traffic into the cluster. However, ingress mechanisms for non-HTTP traffic are inconsistent and can be challenging. </p>\n\nTypical methods are:\n\n<ul>\n<p>Service.Type = Nodeport  \nNodeports use non-standard ports and are awkward and complex to get into production.</p>\n\n<p>Service.Type = LoadBalancer \nTypically offered only in public clouds, LoadBalancers could get expensive depending on the number of services used.</p>\n\n<p>Citrix offers Service.type = Loadbalancer with a built-in IP address manager that is  consistent across clouds and on-premises deployments. This implementation simplifies IP address management and can save on load balancer costs in public clouds. An alternate method, also supported by Citrix, is to use ingress annotations that expose TCP/UDP ports. </p>\n</ul>\n\n<p>\n    All three methods make it much easier for TCP/UDP applications to be used as microservices without extensive code rewrites or protocol changes.\n</p>\n\n<h2>Securing Your Applications and APIs</h2>\n\n  <div className=\"center\" >\n  <img src={Api} align=\"center\" alt=\"API security considerations by traffic direction.\" />\n  <p>API security considerations by traffic direction.</p>\n  </div>\n<p>While traffic direction will dictate your security needs, the reality is that several concerns are shared considerations for both north-south and east-west traffic.</p>\n<p>\nLet’s walk through the API security requirements one by one: \n</p>\n\n<h3>Ingress Security (North-South) </h3>\n<p>\n    As services are exposed outside the cluster, the security considerations remain similar to those of monolithic deployments. In addition to ensuring protections like IP blacklist/whitelist and a robust encryption profile (SSL/TLS), it is imperative that the services are protected against both layer 3-4 and layer 7 DDoS. \n</p>\n<p>\n    Authentication/authorization are equally critical to ensure that the right access controls are established and maintained on data, APIs, and services. At the same time, as attacks are moving to the application layer, web application firewall (WAF) protections like SQL injection (SQLi), buffer overflow, and signature protections are table stakes. As the types of attacks are continuously evolving and because applications and APIs are changing many times a month, it is also critical that the protection mechanisms include behavior-based methods to automate the protection policies and detect potential zero-day attacks.\n</p>\n<h3>API Gateway and Security (North-South)</h3>\n<p>\n    APIs are becoming the currency for digital transformation and for microservices that provide services via API, and therefore routing, security, control, and visibility for APIs is critical. API gateways are a perfect function to achieve these capabilities and typically are combined with the ingress solution. \n</p>\n<p>\n    API gateway solutions offer key functions like authentication, authorization, rate limiting, policy-based routing of APIs, and API versioning. In addition, the traditional controls applicable to a N-S web service are equally applicable and even more important to apply to APIs. API security is not just about authentication but also about ensuring that the content coming in from authenticated sources is not malicious. API gateway functions typically get configured in ingress through configmaps or CRDs. \n</p>\n<h3>Intra-Cluster Security for Service Mesh or Service Mesh-Lite (East-West)</h3>\n<p>\n    Secure application deployment and secure infrastructure best practices dictate security controls in terms of both N-S and E-W service traffic (the former is generally more intuitively understood) because one layer of security isn’t enough, and in-depth defense is needed. \n</p>\n<p>\n    As the number and variety of your microservices expand, the pattern we’ve seen is that services might start as internal use only, but over time end up being exposed externally to customers and partners. The gooey center of your cluster, where you initially intend to have most of your service-to-service interactions, needs to be as secure because service-to-service interactions expand to those outside the cluster. Service meshes are a natural solution here. To obtain this added layer of security (and many other benefits), the adoption of service meshes is on the rise, dramatically. When your application delivery controller integrates with a service mesh, API security is broadly upleveled and guaranteed up to a certain point irrespective of developers' rigor in incorporating secure coding practices. That’s because a service mesh runs as a layer of your infrastructure, relieving developers of a number of (but not all) identity, authentication, and authorization concerns. \n</p>\n<p>\n    For example, inter-services communication should be mutually authenticated via transport layer security (TLS) so that only permitted API connections are allowed. Previously, this may have been implemented with each individual service, but the service mesh enables this functionality to be offloaded to a sidecar ADC, like Citrix CPX, and managed by the service mesh control plane. \n</p>\n<p>\n    Similarly, it should be possible to ensure a faster and more consistent approach to SSL policy in microservices environments through the use of SSL profiles. By defining acceptable SSL settings (for example, ciphers, protocol, and key strength) and binding them to your different entities, developers can quickly deploy consistent encryption policies that meet the appropriate security requirements. After all, isn’t the goal here to facilitate both developer velocity while ensuring that necessary security practices are met? \n</p>\n<p>\n    Another rapidly emerging technology to enable developer velocity is serverless computing. While serverless does indeed involve servers, it leverages infrastructure as code to run backend services as needed, which frees the developer from having to worry about scaling, patching, security, and infrastructure reliability. API gateways are key to applications built with serverless because the developer can simply specify policy such as authentication, authorization, and rate limits without worrying about the form factor, performance, and reliability of the proxy that usually provides these features. \n</p>\n<p>\n    Next, let’s explore aspects of another benefit use of a service mesh provides: traffic control.\n</p>\n\n<h2>Enabling CI/CD and Canary Deployment with Advanced Traffic Steering</h2>\n<p>\nYour application delivery solution should be an enabler of continuous delivery and canary deployments by providing advanced traffic steering. Intelligent proxies are required here. If you’re using a control plane (and not configuring the proxies directly), understand that you will only be able to harness the full power of your proxies to the extent that the control plane exposes their capabilities for configuration. \n</p>\n\n<h3>Canary Deployment  </h3>\n<p>\n    In order to facilitate canary deployments, you need a powerful proxy. Kubernetes facilitates rolling updates to a service deployment, focusing on ensuring that traffic shifting from one version of a service to the next happens gradually over time and with zero downtime. However, Kubernetes on its own doesn’t offer the level of granular control over traffic necessary for simply exposing your canary to a subset of users that you identify. Nor is it convenient for error rate and performance monitoring. Although performance monitoring is integral for canary analysis, many times the solutions for automated canary analysis are cobbled together. \n</p>\n<p>\n    A canary deployment is manual in that you will need to manually check that the canary behaves as you want before doing a full deployment (caution: the difference between canary and baseline isn't always clear). Robust application delivery solutions support <b>automated canary analysis</b> and progressive rollout. With an automated canary analysis, not only are you able to avoid manual administration of the deployment, but you can also rely on an automated statistical analysis to better detect problems in the set of metrics you’ve identified as indicators of a healthy deployment.\n</p>\n<p>\n    <b>A/B testing</b> requires full control over traffic distribution with several versions of your service running in parallel as you run various experimental tests. Experimentations often include measuring differences in conversion rates between versions of a service with the aim of improving a given business metric. To facilitate these experiments, you might want to direct requests based on various criteria like a client’s browser type and version or a user segment based on the presence of a specific cookie or the effect of UI changes on user behavior and the impact on overall performance. \n</p>\n<p>\n    <b>Chaos engineering</b> is akin to A/B testing in that it is an emergent practice that facilitates experimentation. Experimentation here is for purposes of testing and improving application delivery resiliency. Chaos engineering will evolve and expand in use as the complexity and rate of change of large-scale distributed systems demand new tools and techniques for increasing reliability and resiliency. Service-oriented teams (as opposed to infrastructure-oriented platform teams) will push past chaos engineering tools such as Chaos Monkey for inducing machine failures and skip Chaos Kong for evacuating entire regions. Instead they will move to application delivery solutions to perform precise service-level experiments on their path to improving application resiliency via orchestrated chaos. It's through exploration of the impact of increased latency and methodical failure of specific services that service teams will gain confidence in their systems’ capabilities to withstand turbulent conditions in production and begin to sleep more soundly at night. \n</p>\n<p>\n    Savvy cloud native engineers understand the nuances of these delivery methods, and the key role that the proxy plays in enabling these methods. Note, however, that the need for these methods is not restricted to cloud native workloads. These application delivery solution considerations generally apply to microservices and monolithic services in that irrespective of a given service’s architecture, new versions of the service need to be deployed and managed. Because we live in a hybrid world, we encourage you to seek application delivery solutions that do, too. \n</p>\n\n<h2>Achieving Holistic Observability </h2>\n<p>\n    Observability is crucial for effective troubleshooting of microservices environments, but the ephemeral nature and complexity of distributed architecture presents serious challenges. It's incredibly hard to maintain awareness of what's happening in your environment when containers are continuously created and destroyed. Continuous deployment adds to the transient nature of containers because DevOps teams often push many new deployments per day to update their applications. \n</p>\n<p>\n    Similarly, the number of things to monitor — services, containers, users — is enormous, and the fact that everything is distributed makes microservices an incredibly complex environment. While it’s easy to determine if a service is down, troubleshooting slow applications is not? How can you isolate problems among all of the vast telemetry data to find the root cause, especially with inter-microservices (E-W) traffic?\n</p>\n<p>\n    You cannot monitor what you can't see. This is why it is vitally important to have inspection points through which the traffic passes. When they are correctly positioned, proxies/ADCs collect telemetry for an unprecedented view of application traffic — both N-S and E-W traffic across both monolithic and microservices architectures — and they report important data to collection tools.\n</p>\n<p>\n    To overcome the challenge of gaining observability into microservices, you need to build an observability stack. The stack should consist of four pillars: logging, metrics, tracing, and service graphs. However, these should not be viewed as individual, disjointed components but rather as a holistic observability stack that is integrated and can combine data as required.\n</p>\n<strong>Logs</strong>\n<p>\n    Logs are an immutable record of an individual event at a particular time. They are designed into systems, and there tends to be a log record to accompany almost every action. While logs are highly granular, they are limited in their searchability, and it is not usually feasible to process them manually. ADC feeds log data into tools like Elasticsearch for processing and indexing and Kibana for data visualization. \n</p>\n<strong>Metrics</strong>\n<p>\n    Metrics are data points that are measured over time that can be used to monitor trends and set alerts. In addition to the system resources of your individual proxies, the unique position of the proxies means that it sees important information about the use of the application - number of requests, HTTP request rate, errors and more. These metrics can be exported by ADCs to tools like Prometheus where they can be processed and tools like Grafana can visualize them, set alarms create heat maps to help you understand the status of your ADCs.\n</p>\n<strong>Traces</strong>\n<p>\n    The flow of packets through a microservices-based application can be complex spanning multiple services (sometimes multiple times) so identifying why a service is slow can be difficult. Distributed Tracing is a technique that monitors request flow through microservices to build a map of the latency through each microservice hop. Trace is an end-to-end latency graph of a specific request. It represents the entire journey of a request and helps troubleshoot latency issues. Distributed tracing can also be used to understand the application architecture and services not being used. ADC integrates with open source tools like OpenTracing and Zipkin for distributed tracing\n</p>\n<strong>Service Graphs</strong>\n<p>\n    Service graphs are dynamic graphical representations of microservices and their interdependencies. Service graphs, like that of the service graph in the Citrix Application Delivery Manager (ADM) console, provide detail on connectivity among microservices, help you identify issues via simple color coding, and learn composite health scores for each microservice based on throughput, saturation, errors, and latency. More than this, Citrix service graphs also have a built in DVR-like function, which allows you to zero in on the specific time period when an issue occurred.\n</p>\n<p>\n    Given their distillment of complex microservices into a graphical form, service graphs need to provide the ability to tag microservices and to use tags to search, sort , and filter. In this way, you can create custom service graph views of microservices running in production only or you can restrict your view to see details just for canary microservices. \n</p>\n<p>\n    As a complement to the basic pillars of observability (logs, metrics, and traces), service graphs enhance your observability stack. They provide a holistic view of your microservices-based application environments in a single place for an intuitive and convenient way to gain insight and troubleshoot microservices environments faster.\n</p>\n\n<h2>Managing Monoliths and Microservices</h2>\n<p>\n    With hybrid cloud now a reality for many organizations, managing multiple environments with divergent capabilities and management systems is also a reality. Operating with confidence requires reconciling these differences into a uniform operational model and, subsequently, into a uniform understanding with consistent (read: quality) control. For operational consistency, you need a single pane of glass to manage your application delivery infrastructure across:\n</p>\n\n<ul>\n<li>Any application: monolithic and microservices-based applications</li>\n<li>Any environment: on-premises, public, private, and hybrid </li>\n<li>Any ADC form factor: physical, virtual, cloud, containers, sidecars, and more</li>\n</ul>\n\n<p>\n    You need holistic control and monitoring for operational consistency across all your workloads (new microservices and existing monoliths). Ideally, you’ll get such consistency from the proxy you’ve put in place. As you select your proxy, exercise caution when piecing together components from disparate vendors/projects into a solution, because this will not only require integration effort, but also separate specialization to understand and operate. The overhead of integration and specialization can be avoided when your proxy portfolio is robust and supports any application, any environment and form factor with operatonal consistancy. \n</p>\n<p>\n    Moreover, as the large public cloud providers extend their reach on-premises with offerings like Google Anthos, AWS Outposts, and Azure Stack, and as organizations adopt them as simpler paths to cloud migration, it becomes important to use a proxy that works in multiple environments. A battle-tested solution like Citrix ADC that is validated to work in Google Anthos and AWS Outposts environments both in the cloud and on-premises can be invaluable for maintaining operational consistency across your hybrid multi-cloud environment. Because Citrix ADC comes in a variety of form factors (including hardware, software, bare metal, cloud, containers, sidecars, and more) that are built on a single code base, it works across your hybrid workloads in a uniform fashion and prevents a sprawl of heterogenous load balancers across your environment.\n</p>\n\n</ResourcesWrapper>","frontmatter":{"title":"Choosing the Perfect Proxy","type":"Article","technology":"Kubernetes","product":"Meshery","mesh":"Istio","thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"}},"fields":{"slug":"/resources/service-mesh/choosing-the-perfect-proxy"}},{"id":"8df0cdb9-44af-5a21-9ddf-4360ee85b09a","body":"\n\n\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n\n<p>API gateways come in a few forms:</p>\n<ul>\n<li>Traditional (e.g., Kong)</li>\n<li>Cloud-hosted (e.g., Azure Load Balancer)</li>\n<li>L7 proxy used as an API gateway and microservices API gateways (e.g., Traefik, NGINX, HAProxy, or Envoy)</li>\n</ul>\n\n<p>L7 proxies used as API gateways generally can be represented by a collection of microservices-oriented, open source projects, which have taken the approach of wrapping existing L7 proxies with additional features needed for an API gateway.</p>\n\n<h3>NGINX</h3>\n<p>As a stable, efficient, ubiquitous L7 proxy, NGINX is commonly found at the core of API gateways. It may be used on its own or wrapped with additional features to facilitate container orchestrator native integration or additional self-service functionality for developers. Examples of this include:</p>\n<ul>\n<li>APIUmbrella</li>\n<li>Kong</li>\n<li>OpenResty</li>\n</ul>\n\n<h3>Envoy</h3>\n\n<p>The Envoy project also has been used as the foundation for API gateways.</p>\n\n<ul>\n<li>Ambassador: Based on Envoy, Ambassador is an API gateway for microservices functioning stand-alone or as a Kubernetes Ingress Controller. </li>\n<li>Contour: Based on Envoy and deployed as a Kubernetes Ingress Controller. Hosted in the CNCF.</li>\n<li>Enroute: Envoy Route Controller. API Gateway created for Kubernetes ingress controller, and standalone deployments.</li>\n</ul>\n\n<p>\nOther differences between traditional API gateways and microservices API gateways revolve around which team uses the gateway: operators or developers. Operators tend to measure API calls per consumer to meter and disallow API calls when a consumer exceeds its quota. Developers, on the other hand, tend to track L7 latency, throughput, and resilience, limiting API calls when the service is not responding.\n</p>\n\n<p>\nOne of the most important distinctions to make when it comes to service meshes is that API gateways are designed to accept traffic from outside your organization/network and distribute it internally. API gateways expose your services as managed APIs, focused on transiting north/south traffic. They aren’t as well suited for traffic management within the service mesh necessarily, because they require traffic to travel through a central proxy and add a network hop. Service meshes are primarily designed to handle east/west traffic internal to the service mesh.\n</p>\n\n<div className=\"fact-left\">\nTraffic Directions\n<p>North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.</p>\n</div>\n\n<p>\nAPI gateways and service meshes are frequently deployed in combination due to  their complementing nature. Service meshes are on their way to providing much, if not all, of the functionality that API gateways do.\n</p>\n\n<h3>API Management</h3>\n\n<p>\nAPI gateways work with other API management ecosystem components like API marketplaces and API publishing portals, both of which are surfacing in service mesh offerings. Analytics, business data, adjunct provider services like single sign-on, and API versioning control are all provided by API management solutions.  Many API management vendors have migrated their API management systems to a single point of architecture, with API gateways designed to be implemented at the edge.\n</p>\n\n<p>\nAn API gateway can call downstream services via service mesh by offloading application network functions to the service mesh. Some API management capabilities that are oriented toward developer engagement can overlap with service mesh management planes in the following ways:\n</p>\n\n<ul>\n<li>Developers use a portal to discover APIs available for API documentation and discovery,  API testing, and exercising their code.</li>\n<li>API analytics for tracking KPIs, generating reports on usage and adoption trending.</li>\n<li>API lifecycle management to secure APIs (allocate keys) and promote or demote APIs.</li>\n<li>Monetization to tracking payment plans and enforcing quotas.</li>\n</ul>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"API Gateways interplay with service meshes","type":"Article","technology":"API","product":null,"mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg"}},"fields":{"slug":"/resources/service-mesh/api-gateways-interplay-with-service-meshes"}},{"id":"78adbbae-121a-5d8e-9b0f-ccc3ed02d8f5","body":"\n\nimport SMP from \"./smp-light-text_2.webp\";\nimport cover from \"./ieee_bridge_issue3_2021.webp\";\nimport EWtraffic from \"./figure-1.webp\"\nimport Workload from \"./figure-2.webp\"\nimport Archictures from \"./Meshery Architecture - Clients.webp\"\nimport Code from \"./code-snippet.webp\"\nimport NetworkFunction from \"./Comparison of different modes of delivery of service mesh network functions.webp\"\n\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p> \n      Learn more about Service Mesh Performance from this article  \n      <a className=\"blog\" href=\"https://www.nxtbook.com/nxtbooks/ieee/bridge_issue3_2021/index.php#/p/16\"> Analyzing Service Mesh Performance</a> - Published in issue 3 of IEEE Bridge October 2021\n    </p>\n  </div>\n\n<div className=\"right\" >\n<img src={cover} align=\"center\" alt=\"IEEE The Bridge 2021 Issue 3 cover\" />\n</div>\n\n<p>\nAs a forthcoming, ubiquitous layer of cloud native infrastructure, \nservice meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices. \nManaging the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly \nsummarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure \nof choice is a challenge unto its own.\n</p>\n\n<p>\nWe explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties \nof resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance \nanalysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of \nworkloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations.\n</p>\n\n<p>\nWe provide core, memory and I/O combinations based on workload needs with insights into workload analysis which can influence the efficiency of the \nservice mesh and overall performance of the cluster.\n</p>\n\n\n<h2>Characterizing the Complexity of Combinatorial Analysis</h2>\n\n<p>\nConsider that the more value you try to derive from your service mesh, the more work that you will ask it to do. Said another way, \nthat as someone reflects more deeply on the architecture of a service mesh - with its distributed proxies - and the functionality it offers, \nthey will eventually wonder, \"What overhead is running my service mesh incurring?\". This is one of the most common questions engineers have as \nthey initially learn of a service mesh and the value a deployment of one offers. This is not an easy question to answer as the permutations of \nconfiguration between your infrastructure, service mesh, and applications are innumerable and any change to one of them affects their collective performance.\n</p>\n\n<p>\nHow would you describe the performance of your service mesh and that of your clusters and their workloads? Are you imagining a wall of line \ncharts with metrics capturing golden signals? The act of articulating the performance of your service mesh can take anywhere from a minute \nto even a few hours to characterize the state of your systems and the overhead incurred by your infrastructure and what this means to your users.\n</p>\n\n<p>\nMoreover, anytime performance is characterized, analysis is subjective to the specific workload, infrastructure, and instruments used for measurement. \nGiven the variety of this measurement challenge, most service meshes and their data plane proxies (if a third-party component), do not have the tooling \nnecessary or refuse to publish performance data because such tests can be:\n  <ol>\n  <li>arduous to create and sustain a capable harness</li>\n  <li>a point-in-time consideration (none of the elements under measurement are static</li>\n  <li>misinterpreted</li>\n</ol>\n</p>\n\n<p>\nRead on as we identify how to surmount each of these challenges.\n</p>\n\n<h2>Service Mesh Performance Considerations</h2>\n\n<p>\nAs the software defined networking layer of microservices, service mesh encompasses multiple aspects of critical functions of the applications, \nsuch as circuit breaking, health checks, and packet operations. Analyzing the permutations of these configurations is an impossible task without \na suitable test harness. A service mesh management plane can be such a tool. As the multi-mesh manager, <a href=\"https://meshery.io\">Meshery </a> \nis capable of provisioning 10 different service meshes, workloads atop the meshes, generating load using <a href=\"https://getnighthawk.dev\">Nighthawk</a>, \nand analyzing that load. No other tool capable of performing these tasks \nend-to-end exists. Meshery is a Cloud Native Computing Foundation project originally created by Layer5.\n</p>\n\n<h3>How are you measuring?</h3>\n\n<p>\nConsider the simple set of steps to execute performance tests in a simple Kubernetes-based cluster:\n</p>\n\n<ol>\n  <li>Setup your cluster, service mesh, and application under test.</li>\n  <li>Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance.</li>\n  <li>Configure your test setup for performance, doing so in context of other constraints that you might \n  need to uphold (e.g. resiliency characteristics of your service deployment).</li>\n  <li>Choose the protocol of interest: HTTP, HTTPS, HTTP1/2, gRPC, NATS</li>\n  <li>Identify KPIs of interest - Transactions per second (TPS) or percentile latencies, etc.</li>\n  <li>Decide on the test duration: 60s or 5 minutes or 1 hour...</li>\n  <li>Choose the number of requests per second (RPS).</li>\n  <li>Execute the test.</li>\n  <li>Mark down requests per second, latencies, throughput, and any other output provided by benchmarking tools.</li>\n</ol>\n\n<h3>What are you measuring?</h3>\n\n<p>\nPerformance of a service mesh can be described across multiple dimensions covering some or all of these core functionalities \nof a service mesh. So, which dimensions are the linchpins of performance? Which metrics are key indicators of performance? \nOutside of the different types of performance tests, performance management concerns include the need for performance and \noverhead data under a permutation of different workloads (applications) and different types and sizes of infrastructure resources. \n</p>\n\n<div className=\"center\" >\n<a href={EWtraffic}>\n<img src={EWtraffic} align=\"center\" alt=\"EWtraffic\" />\n</a>\n</div>\n\n\n<p>\nHence, it is crucial to understand what is being measured in a service mesh based deployment. Certain critical considerations are \nmissing from the simple methodology previously described. For example, as indicated in Figure 1, but not limited to:\n</p>\n\n<ol>\n  <li>\n    Traffic considerations\n    <ul>\n      <li>\n        East-West traffic\n        <ol>\n          <li>between two pods within the same or two different Virtual Machines (VM).</li>\n          <li>between two pods within the same or two different bare metal nodes.</li>\n          <li>combination of above with choice of user-space or kernel-space networking stack on the host node.</li>\n        </ol>\n      </li>\n      <li>\n        North-South traffic\n        <ol>\n          <li>Throughput and latency of traffic flowing in and out of a single VM or across a single bare metal node.</li>\n        </ol>\n      </li>\n    </ul>\n  </li>\n  <li>\n    Deployment considerations\n    <ul>\n      <li>Number of hops between traffic source and traffic destination with load balancers, API gateways, ingress controllers, \n      security components such as firewall, deep packet inspectors, and so on.</li>\n      <li>Operating system settings.</li>\n      <li>Hardware settings such as BIOS options, power management features, NUMA awareness, platform resource management, hardware \n      accelerators, and so on.</li>\n    </ul>\n  </li>\n  <li>\n    Load generators types\n    <ul>\n      <li>hardware or software based, L2-3,  L4-7, open or closed loop</li>\n    </ul>\n  </li>\n  <li>\n    Service mesh types - the service mesh landscape has over 20 meshes listed. Each share a common architecture, \n    however, their implementation differs and consequently, so does their performance.\n    <ul>\n      <li>Control plane - often a point of contention the larger the service mesh deployment is.</li>\n      <li>Data plane - not only proxies, but filters loaded in those proxies.</li>\n    </ul>\n  </li>\n  <li>\n    Service mesh configuration and number of services on the mesh. To name a few considerations:\n    <ul>\n      <li>\n        Telemetry\n        <ol>\n          <li>Including the three pillars of observability are traces, logs, and metrics.</li>\n          <li>The number of, cardinality of, sampling rate, ingest rate… all bear weight (and bear load on the system).</li>\n        </ol>\n      </li>\n      <li>\n        Policy\n        <ol>\n          <li>Authentication, Authorization - frequency of checks, cache hits vs. cache misses.</li>\n        </ol>\n      </li>\n       <li>\n        Security\n        <ol>\n          <li>Encryption - overhead of handshaking and mutually authenticated TLS.</li>\n        </ol>\n      </li>\n    </ul>\n  </li>\n</ol>\n\n<p>\nUltimately, the goal of any performance tests is to ensure repeatable measurements and obtain consistent results across multiple test runs.\n</p>\n\n<h2>Service Mesh Performance as a Specification</h2>\n\n<p>\nThe need for cross-project, apple-to-apple comparisons are also desired in order to facilitate a comparison of behavioral differences \nbetween service meshes and which one might be best-suited for specific workloads. Individual service mesh projects shy from publishing test \nresults of other, competing service mesh projects. The need for an independent, unbiased, credible, standard measurement is one of the catalysts \nfor the creation of Service Mesh Performance (SMP).\n</p>\n\n<p>\nAmidst performance concerns and the need to measure and manage performance arose the Service Mesh Performance (SMP) standard. Service Mesh \nPerformance as a specification and disseminating insights and research results. Your authors are working toward the definition of MeshMark, \na universal performance index to gauge your mesh’s efficiency against deployments in other organizations’ environments.\n</p>\n\n<p>\nMany performance benchmarks are limited to single instance load generation (single pod load generator). This limits the amount of traffic \nthat can be generated to the output of the single machine that the benchmark tool runs on in or out of a cluster. Overcoming this \nlimitation would allow for more flexible and robust testing. Distributed load testing in parallel poses a challenge when merging \nresults without losing the precision we need to gain insight into the high tail percentiles. Distributed load testing offers insight \ninto system behaviours that arguably more accurately represent real-world behaviours of services under load as that load comes from \nany number of sources.\n</p>\n\n<p>\nThe specification itself provides a standard format for describing and capturing:\n</p>\n\n<ul>\n  <li>performance test configuration</li>\n  <li>Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance.</li>\n  <li>service mesh configuration</li>\n  <li>environment configuration</li>\n  <li>workload configuration</li>\n  <li>performance test results</li>\n  <li>Distributed performance modeling</li>\n  <li>KPIs for service mesh performance</li>\n  <li>Test tool requirements</li>\n</ul>\n\n<p>\nValue from a service mesh is best derived when it's tuned to scale as per the deployment requirements. Given the \ncomplexity of deploying, testing and measuring performance aspects across multiple dimensions, the specification \naims to provide a simple starting point for anyone looking to understand and derive service mesh performance. The \nservice mesh performance standard aims to articulate these complexities in a methodical and automated manner in \norder for anyone to plan the performance scenarios of their deployment and execute relevant tests.\n</p>\n\n<p>\nThe code snippet provides insight on the fact that the specification defines a common collection of statistical analysis \nto be calculated for every performance test.\n</p>\n\n```yaml\nmessage PerformanceTestResult {\n  message Latency {\n    double min = 1;\n    double average = 2;\n    double p50 = 3;\n    double p90 = 4;\n    double p99 = 5;\n    double max = 6;\n  }\n}\n```\n\n<p><i>Snippet of the Service Mesh Performance specification describing how to capture statistical analysis of test results.</i></p>\n\n<h2>Defining Deployments</h2>\n\n<p>\nVirtualized deployments involve deploying microservice orchestration and service mesh stack in virtual machines (VMs). Although bare metal \nusage has performance benefits, customers often use VMs to provide hardware-level isolation between various applications. This deployment \ninvolves two VMs across two nodes, with one acting as a Kubernetes master with the other a worker node. Customers deploy VMs on a single \nNUMA node to avoid cross UPI traffic. Results in virtualized testing have shown that depending on pinning of QEMU threads to a set of \nisolated cores - either sequentially or clustering the threads together to all the cores - tail latencies are heavily impacted.\n</p>\n\n<p>\nMicroservice deployments could use a wide variety of deployment scenarios. The following list provides a sample set of how a service mesh \nperformance could be analyzed either on a same node or in a multi-node cluster:\n</p>\n\n<ul>\n  <li>Pod to pod communication.</li>\n  <li>Pod to service communication.</li>\n  <li>Ingress controller to pod and vice-versa.</li>\n  <li>Load balancer to pod and vice-versa.</li>\n  <li>Pod to Egress Gateway.</li>\n  <li>Mutual TLS termination across any of the above endpoints.</li>\n  <li>Different security rules and policies.</li>\n  <li>Communication protocol.</li>\n</ul>\n\n<p>These considerations are illustrated in a typical workload deployment as shown in <i>Figure 3.</i></p>\n\n<div className=\"center\" >\n<a href={Workload}>\n<img src={Workload} align=\"center\" alt=\"Workload\" />\n</a>\n</div>\n\n<p>\nHere is an example of deployment with Kubernetes as the orchestrator using Calico CNI and deployed in VMs, \nwhile the host infrastructure has OVS-DPDK for switching, which can be extended for VMs to leverage SR-IOV. \nTo understand impact of infrastructure elements and networking elements of microservice software stack, \nperformance impact of a service mesh and its set of data plane proxies with fortio as load generator could be \nunderstood by running the Meshery in two different environments outside the Kubernetes cluster.\n</p>\n\n<ol>\n  <li>First one with load generator running as a process outside of Kubernetes cluster in master-vm</li>\n  <li>Second one with load generator running as a bare metal process on master-host</li>\n</ol>\n\n<h3>Automating Performance Measurements</h3>\n\n<p>\nMeshery is ideal tooling in that it provides lifecycle management of a large number of service meshes and sample \napplications which need to be provisioned, configured, and deprovisioned in the process of analyzing service mesh performance. \nMeshery is capable of generating load, baselining, and comparing performance results. The canonical implementation of this \nspecification is implemented in Meshery.\n</p>\n\n<div className=\"center\" >\n<a href={Archictures}>\n<img src={Archictures} align=\"center\" alt=\"Archictures-client\" />\n</a>\n</div>\n\n<p><i>Figure 4 - Meshery’s load generators can be deployed in the same cluster under test or outside of the cluster under test.</i></p>\n\n<h4>Pipelining performance characterization</h4>\n\n<p>\nAcknowledging the living nature of user deployments, integration of automated performance testing into continuous integration \nsystems helps users deploy new versions of their applications or new configurations of their infrastructure \n(including service mesh configuration) with the assurity  afforded through the act of dry-running the service mesh and application \nconfiguration before production deployment. The Meshery and Service Mesh Performance GitHub Action offers the ability to adaptively \nanalyze application performance as a gate in your continuous delivery pipeline. In this way, the Service Mesh Performance \nspecification facilitates a measurement index that can be referenced when rolling out new versions of a service with this \nadvanced canary technique.\n</p>\n\n<p>\nThrough Meshery, techniques to mirror non-idempotent requests without fear of impacting the current version of your application \nallowing replay of user requests. And use of intelligent network functions, embedded in WebAssembly (WASM) programs, to \nfacilitate real user request reenactments to help you extract the most value out of your pipeline.\n</p>\n\n<ul>\n  <li>Repeatability of test scenarios using performance profiles and cloud native orchestration.</li>\n  <li>Baselining and comparing results.</li>\n</ul>\n\n<h3>Analyzing Performance Measurements</h3>\n\n<p>\nWe have often seen inefficiencies in the ratio of resource usage vs resources applied. Since the mesh \nelements i.e. the ingress and sidecars share resources with one or more of the application containers, \nthere may be more resources left to be utilized. Tail latencies decrease with the increase in number of \ncores for all 1, 10 and 100 clones but increase with the increase in the number of connections. Data for \nvarious connection counts, as shown, indicates that performance degradation with Istio shows up with \ninput RPS more than 1000. In a top down microarchitectural analysis (TMA), when the front proxy is pinned \nto a single core and the sidecar + flask app is pinned to another core and the number of microservices are \nscaled up. It is observed that (Figure 2):\n</p>\n\n<ul>\n  <li>Frontend Bound% decreases with increase in number of microservices​ and Core Bound % increases.</li>\n  <li>Memory Bound % increases with increase in the number of microservices​.</li>\n  <li>L1 and L3 Bound% decreases for both the service cores on which the front –proxy is running as well as the \n  core where the sidecar+flask app is running with number of microservices.</li>\n</ul>\n\n<p>\nIn customer environments, the size of the cluster as well as the amount of incoming traffic will have an impact on the number of \nworkloads and Envoy microservices. The underlying hardware and L4 networking on each node in the cluster will also impact the \nperformance observed. A call stack and cycles spent analysis of a deployment with 1-20 sidecars on a specific  \n40 core system with a 10G NIC shows bottlenecks spread between:\n</p>\n\n<ol>\n  <li>Envoy:TheadLocalStorage-Hashset-Match</li>\n  <li>\n    Linux kernel bottleneck spread between\n      <ol>\n        <li>Libpthreadscheduling</li>\n        <li>Libevent</li>\n      </ol>\n  </li>\n  <li>Envoy buffer slice management and TCP filter, if message sizes or file transfer sizes increase to 1M</li>\n  <li>Crypto operations when TLS is enabled.</li>\n</ol>\n\n<p>\nOur initial studies show that the optimal service mesh setup for the tolerable latencies and the best RPS may include:\n</p>\n\n<ol>\n  <li>Exclusive  threads allocated to Envoy processing</li>\n  <li>Reduced memory contention by allocating more memory bandwidth which can be controlled dynamically</li>\n  <li>Load balancing of worker threads among the among cores which may require</li>\n  <li>Less IO switching</li>\n  <li>Optimized memory copies with signals incorporated in addition to events (libevent)</li>\n</ol>\n\n<h4>Accelerations and Offloads</h4>\n\n<p>\nA number of accelerations and offloads to SMART NIC or other processing elements like IPUs and DPUs are \nbecoming available. How does the service mesh efficiency and performance benefitted from these deployment \noptions needs to be defined and measured. Cycles and cores saved in the host cores vs offload cores which \nmay be of different architectures and/or performance range needs to be quantified and benchmarks and \nindices created to measure.\n</p>\n\n<h3>Being Precise in Performance Studies</h3>\n\n<p>\nWhen measuring sub-millisecond response times, the noise floor of the environment as well as the sensitivity \nof the tooling may become dominant factors in measurements. Noisy neighbours, scheduler fairness, garbage collection, \nand even specifics in the timing of requests being sent as well as connection-reuse patterns may change noise floors \nsuch that similar measurements performed using different systems and tools may diverge an order of magnitude in absolute terms.\n</p>\n\n<p>\nAs a quick survey of load generators by way of those included in Meshery, we find upon close inspection \ntheir differences are noteworthy and justify their use under different circumstances.\n</p>\n\n<p>\nWritten in C, wrk2 supports ignoring coordinated omission. wrk2 lets you test a little more complex scenarios. \nUsers express load generation profiles in terms of RPS. wrk2 shows you what you normally may not see in benchmark \nresults, but what every 1,000th user might see. To see these outliers, you need to run the longer (time) performance \ntests.  Wrk2 tests the scenario where there's a string of services comprising microservices. wrk2 requires you to \nspecify the desired RPS, while wrk does not. Wrk2 is focused on driving the maximum RPS. Meshery’s fork of wrk2 \nenables testing of multiple endpoints and enables the variable rate of load generation. In the future, Meshery \nwill offer the ability to assign a weight to each endpoint for the load to be generated by wrk2.\n</p>\n\n<p>\nWritten in Golang, fortio is extremely fast and usable for testing basic response times on a per request level. \nFortio produces results in JSON on a per request basis and easy to integrate into other Golang-based tooling like Meshery.\n</p>\n\n<p>\nWritten in C++, Nighthawk supports both open- and closed- loop testing, and was designed to offer the right \nsensitivity for benchmarking microservice proxies (sub millisecond latencies). Using an open loop test \nmethodology avoids coordinated omission, and in conjunction with its adaptive load controller one can \nseek answers to questions like “what RPS can my mesh reliably sustain under set latency?”.\n</p>\n\n<h4>Comparing Types of Data Plane Filtering</h4>\n\n<p>\nImportant to note is the power of the service mesh data plane and cost of that power. Envoy is a popular \nproxy of choice for service mesh data planes. Among other features, Envoy provides the ability to \nintegrate custom traffic filters via one of two methods:\n</p>\n\n<ol>\n  <li>\n  Natively by incorporating your custom traffic filter into Envoy’s C++ source code and compiling a new \n  Envoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit \n  being that of your custom filter running at native speed.\n  </li>\n  <li>\n  Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go. \n  The drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically \n  load and reload WASM-based filters in Envoy at runtime.\n  </li>\n</ol>\n\n<p>\nWhether to  integrate your traffic filters natively or as an extension, a tradeoff between the two deployment \nexists primarily in exchanging between service mesh speed and service mesh flexibility as shown in <i>Figure 4.</i>\n</p>\n\n<div className=\"center\" >\n<a href={NetworkFunction}>\n<img src={NetworkFunction} align=\"center\" alt=\"comparison of Network functions\" />\n</a>\n</div>\n\n<p>\n<i>Figure 5 - A comparison of different modes of delivery of service mesh network functions.</i>\n</p>\n\n<p>\nAs an assessment of this tradeoff, an analysis of a series of three tests run across the same rate \nlimit network function implemented as 1) a Golang-based client library, or 2) a Rust-based Envoy \nfilter running in a WebAssembly virtual machine  (or 3) a native Envoy filter) provides some insight \nas to the comparative overhead involved.\n</p>\n\n<ol>\n  <li>\n    Rate limiting with Go client library\n      <ul>\n        <li>At 100 RPS the p50 is 3.19ms.</li>\n        <li>At 500 RPS the p50 is 2.44ms.</li>\n        <li>With unlimited RPS (4,417) the p50 is 0.066ms.</li>\n      </ul>\n  </li>\n   <li>\n    Rate limiting with WASM module (Rust filter)\n      <ul>\n        <li>At 100 RPS the p50 is 2.1ms</li>\n        <li>At 500 RPS the p50 is 2.22ms</li>\n        <li>With unlimited RPS (5,781) the p50 is 0.62ms</li>\n      </ul>\n  </li>\n</ol>\n\n<p>\nUsers not only need to account for the (relatively) easy to quantify system overhead and the operational \noverhead involved in expanding development resources to implement bespoke tooling versus managing off-the-shelf filters.\n</p>\n\n<h3>Summary</h3>\n\n<p>To deploy a service mesh effectively, we need to</p>\n\n<ol>\n  <li>quantify application workload characteristics and how it utilizes a particular microarchitecture.</li>\n  <li>assess how Container Network Interface (CNI) drivers, Open Virtual Switch (OVS), rules processing, match \n  and lookup requirements between Network Address Translated (NAT) and routed networks are required</li>\n  <li> different layers of service mesh to be deployed including layer 4 load balancers, ingress and reverse proxy, \n  number of sidecars and number of microservices to be supported</li>\n  <li>and what hardware baseline performance does the setup have and </li>\n  <li> a quantifiable measure of service mesh deployed with performance measures mapped to KPIs like throughput (RPS) and latency.</li>\n</ol>\n\n\n</ResourcesWrapper>","frontmatter":{"title":"Analyzing Service Mesh Performance","type":"Article","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJQBdgBDdqTIBYAAD+y0sewoyDxaZOxu6BEnH4O26ZDf3HFLQChhSX7W+MuV0QLty3ei6VevV5j7AA"},"images":{"fallback":{"src":"/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp","srcSet":"/static/f1d1d04c93ec2f13adb202acc633bc65/57632/smp-light-text_2.webp 750w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/3fc16/smp-light-text_2.webp 1080w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/b060c/smp-light-text_2.webp 1366w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.616}},"extension":"webp","publicURL":"/static/f1d1d04c93ec2f13adb202acc633bc65/smp-light-text_2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJQBdgBDdqTIBYAAD+y0sewoyDxaZOxu6BEnH4O26ZDf3HFLQChhSX7W+MuV0QLty3ei6VevV5j7AA"},"images":{"fallback":{"src":"/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp","srcSet":"/static/f1d1d04c93ec2f13adb202acc633bc65/57632/smp-light-text_2.webp 750w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/3fc16/smp-light-text_2.webp 1080w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/b060c/smp-light-text_2.webp 1366w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.616}},"extension":"webp","publicURL":"/static/f1d1d04c93ec2f13adb202acc633bc65/smp-light-text_2.webp"}},"fields":{"slug":"/resources/service-mesh-performance/analyzing-service-mesh-performance"}},{"id":"bbdc2982-dc61-5931-ba48-5d1c0650ae6c","body":"\n\n\nimport Traffic from \"./figure1.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<h2>What are practical steps to adopt a service mesh in my enterprise? </h2>\n\n<h3>Piecemeal Adoption</h3>\n<p>\n  Many organisations wish to take advantage of auto-instrumented observability\n  first, taking baby steps toward a full-service mesh after achieving first\n  success and operational comfort, to better understand what's going on across\n  their distributed infrastructure. It's a high-value, relatively safe first\n  step to use a service mesh for its ability to provide enhanced observability.\n  First steps for others might be on a parallel path. For example, a financial\n  organisation might seek improved security with strong identity (per-service\n  certificates) and strong encryption via mutual TLS between each service.\n  Others, on the other hand, may begin with an ingress proxy as a stepping stone\n  to a larger service mesh deployment.\n</p>\n<p>\n  Consider an organisation with hundreds of existing services running on virtual\n  machines (VMs) external to the service mesh that have little to no\n  service-to-service traffic, with practically all traffic flowing from the\n  client to the service and back to the client. Without immediately deploying\n  hundreds of service proxies, this organisation can deploy a service mesh\n  ingress (e.g., Istio Ingress Gateway) to gain granular traffic control (e.g.,\n  path rewrites) and detailed service monitoring.\n</p>\n<div className=\"center\">\n  <img src={Traffic} align=\"center\" alt=\"ingress traffic control\" />\n  <p>\n    Figure 1: Simple service mesh deployment primarily using ingress traffic\n    control.\n  </p>\n</div>\n\n<h3>Practical Steps to Adoption</h3>\n<p>Here are two common paths:</p>\n<ul>\n  <li>\n    Wholesale adoption of a service mesh, commonly while designing a new\n    application (a greenfield project).\n  </li>\n  <li>\n    Piecemeal adoption of some components and capabilities of a service mesh,\n    but not others, commonly while working with an existing application (a\n    brownfield project).\n  </li>\n</ul>\n<p>\n  Let's take a look at how the second path manifests itself, because it's the\n  path that most people will face (those with existing services) and the\n  approach that most organisations take. In this method, incremental steps are\n  taken. When teams are comfortable with their understanding of the deployment,\n  have gained operational expertise, and derived substantial value, another step\n  toward a full mesh is usually accomplished. Since n ot all components of a\n  full service mesh are helpful to teams based on their focus or current pain\n  points, not all teams choose to take another step. This will evolve over time,\n  as full service mesh deployments become ubiquitous. More than this,\n  application developers and service (product) owners will begin to rely on the\n  power of a service mesh to empower and satisfy their requirements as well.\n</p>\n<p>\n  Which applications should be constructed from the ground up or transformed\n  using a new service mesh architecture depends on engineering maturity and\n  skill set. You don't have to use all of the features; use the ones you need.\n  Given that some service meshes provide a path to partial adoption, the best\n  way may be to mitigate risk, baby-step it, and show incremental triumphs. Some\n  service meshes can be deployed and digested in a single step. Even if this is\n  the case, you might find that you enable only a subset of its capabilities.\n  Presence of a service mesh’s capabilities is separate from whether those\n  capabilities are actively engaged.\n</p>\n<p>\n  Observability is at the top of the list of reasons why most organizations\n  deploy a service mesh initially. You usually obtain a service dependency graph\n  in addition to metrics, logs, and traces. These graphs visually identify how\n  much traffic is coming from one service and going to the next.   You'll feel\n  as if you're running blind if you don't have a visible topology or service\n  graph.\n</p>\n<p>\n  Alternatively, it could be your current load balancer that is running blind. \n  Most service mesh proxies will come in handy if you're running gRPC services\n  and have a load balancer ignorant of gRPC and treats this traffic like any\n  other TCP traffic. Modern service proxies will support HTTP/2 and, as such,\n  might provide a gRPC bridge from HTTP/1.1 to HTTP/2.\n</p>\n\n<h3>Security</h3>\n\n<p>\n  Organizations usually prioritise security last.  They may not want strong\n  authentication and encryption when they ultimately do look into security.\n  Although it is best practise to secure everything using strongly authenticated\n  and authorised services, some organisations fail to do so, resulting in soft,\n  gooey centres in their microservices deployments. Some teams are content to\n  secure the edge of their network, but they still want the observability and\n  control that a service mesh can provide.\n</p>\n<div className=\"fact\">\n  <p>\n    Needless to say, it is recommended that you run workloads securely, using a\n    service mesh to provide authentication and authorization between all service\n    requests.\n  </p>\n</div>\n<p>\n  Why aren't certain organizations interested in using Service Mesh's managed\n  certificate authority? Because it is another thing to operate? When\n  connections are established, encryption consumes resources (CPU cycles) and\n  can inject a few microseconds of latency. Given this, and to aid adoption,\n  some service meshes prominently display installation options that include a\n  certificate authority (CA) and installation configurations that do not. Maybe\n  you consider the “gooey center” of your mesh to be secure because there is\n  little to no ingress/egress traffic to/from the cluster and access is provided\n  only via VPN into the cluster. Depending on workload, wallet, and sensitivity\n  to latency, you might find that you don’t want the overhead of running\n  encryption between all of your services.\n</p>\n<p>\n  Maybe you're just searching for authorization checks, and you're deploying\n  monoliths rather than microservices. You don't need any further monitoring\n  integrations because you already have API management. Perhaps you use IP\n  addresses (subnets) for network security zones. Using identities and\n  encryption provided by the service mesh, together with authorization checks\n  enforced by policy you specify, a service mesh can help you get rid of network\n  partitions and firewalling on Layer 3 (L3) boundaries. You can flatten your\n  internal network by policy enforcing, authorization checks across your\n  monoliths, making services broadly reachable while granularly controlling\n  which requests are authorized. The power of service mesh to analyse and reason\n  over details of request traffic much beyond IP addresses and ports (Layer 3/4)\n  provides significantly more flexibility.\n</p>\n<h3>Retrofitting a Deployment</h3>\n<p>\n  Recognize that, while some greenfield projects may have the luxury of starting\n  with a service mesh, most organizations will have existing services (monoliths\n  or otherwise) to onboard to the mesh. These services could run in VMs or\n  bare-metal hosts instead of containers. Fear not! Some service meshes squarely\n  address such environments and help with the modernization of such services,\n  allowing organizations to renovate their services inventory by:\n</p>\n<ul>\n  <li>Not having to rewrite their applications</li>\n  <li>\n    Adapting microservices and existing services using the same infrastructure\n    architecture\n  </li>\n  <li>Facilitating adoption of new languages</li>\n  <li>\n    Facilitating moving to or securely connecting with services in the cloud (or\n    on edge)\n  </li>\n</ul>\n<p>\n  For those organisations who adopt a strangler pattern of building services\n  around a legacy monolith to expose a more developer-friendly set of APIs,\n  service meshes make it easier to insert facade services as a way of breaking\n  down monoliths.\n</p>\n<p>\n  With the adoption of a service mesh, organisations can get observability\n  (e.g., metrics, logs, and traces) as well as dependency or service graphs for\n  all of their services (micro or not). The only change required within the\n  service with respect to tracing is to forward certain HTTP headers. With the\n  least amount of code change, service meshes are effective for retrofitting\n  uniform and ubiquitous observability tracing into existing infrastructures.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Considerations of Adopting a Service Mesh","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAAAQBACdASoUABIAPtFWpkuoJKOhqA1RABoJZwAAMXkxHzbHC1lj/ajugAD+8/kxgzcWpp4uhQloavgkHs7qXUs5nsa3XSfdp4I8OAF4chFSyXoDanAf6Ra3GboYQOdkK00E3XVIdsORLy/ka40fcEjZy30gAAAA"},"images":{"fallback":{"src":"/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp","srcSet":"/static/5ad477e74c5a92fa29a9be876d138224/2f2a6/figure1.webp 750w,\n/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp 901w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8967813540510544}},"extension":"webp","publicURL":"/static/5ad477e74c5a92fa29a9be876d138224/figure1.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAAAQBACdASoUABIAPtFWpkuoJKOhqA1RABoJZwAAMXkxHzbHC1lj/ajugAD+8/kxgzcWpp4uhQloavgkHs7qXUs5nsa3XSfdp4I8OAF4chFSyXoDanAf6Ra3GboYQOdkK00E3XVIdsORLy/ka40fcEjZy30gAAAA"},"images":{"fallback":{"src":"/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp","srcSet":"/static/5ad477e74c5a92fa29a9be876d138224/2f2a6/figure1.webp 750w,\n/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp 901w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8967813540510544}},"extension":"webp","publicURL":"/static/5ad477e74c5a92fa29a9be876d138224/figure1.webp"}},"fields":{"slug":"/resources/service-mesh/considerations-of-adopting-a-service-mesh"}},{"id":"94564ad9-d1c3-5deb-922d-275f845fefa0","body":"\n\n\n<NewsWrapper>\nBoth the Meshery and Service Mesh Performance (SMP) projects joined the Cloud Native Computing Foundation (CNCF) earlier this month at the Sandbox level.\n\nMeshery is a multiservice mesh management plane offering lifecycle, configuration, and performance management of service meshes and their workloads, while SMP is a standard for capturing and characterizing the details of infrastructure capacity, service mesh configuration, and workload metadata.\n\nWhen the projects first applied in April for inclusion, the Technical Oversight Committee (TOC) had one clarifying question for them: should they be combined with or aligned in some manner with the Service Mesh Interface (SMI) project?\n\nLee Calcote, founder of Layer5, the company partly behind both of the projects, explained that it was an alluring prospect for the CNCF, but that, for the time being at least, the projects would continue on their own separate paths.\n\nCalcote, who also serves as the chair of the Network special interest group (SIG) at the CNCF, said he then presented to the CNCF the following diagram, which shows the relation between the three projects. For the time being, he said, both SMI and SMP are “relatively younger projects, both of which still are figuring out what they want to be when they grow up,” and may be considered for consolidation later on down the line, while Meshery has a larger focus than the two projects and will definitely be kept on its own.\n\nWhile the SMI works to define the broadest characteristics that could apply to something defined as a service mesh, looking for the lowest common denominator, Meshery works in the opposite direction, trying to accentuate the differences and strengths of the individual services meshes. SMP, meanwhile, is more of a specification and works to provide a common format for capturing and describing data around the performance of the service mesh itself.\n\nIn comparison to SMI, Calcote said that “SMP essentially just goes a lot deeper. Part of what is trying to address is this long-standing question — and it’s a question that faces the people who are adopting a service mesh today, people who are adopting service mesh tomorrow, people who have already adopted a service mesh — What should I be measuring to consider how efficiently I’m running my service mesh?”\n\nBetween the three projects, then, users have not just a way to interface with any SMI-compatible service mesh via a common API, but also a way to measure the performance of different service meshes, and finally, a method with which to interface with and operate those service meshes while taking advantage of their specific advantages.\n\n“Part of the belief is that service meshes are an inevitable new layer in your cloud native infrastructure that over time will be a ubiquitous component,” said Calcote. “There’s a lot that can be done in the network, a lot of intelligence, and so Meshery, as a management plane, picks off some of those features.”\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Projects Bring Service Mesh Interoperability, Benchmarks","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/1b1b219f5ff2ed23523b02bd172f4c07/The-New-Stack-Logo.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/1b1b219f5ff2ed23523b02bd172f4c07/The-New-Stack-Logo.svg"}},"fields":{"slug":"/company/news/cncf-projects-bring-service-mesh-interoperability-benchmarks"}},{"id":"d5db9e8a-0505-5a0f-8718-60931d1ea9f9","body":"\n\n\n<NewsWrapper>\n\n<div>\nDevOps teams use the right tools to automate deployment plans to minimize risk to the product and customer experience. These service mesh tools also provide synchronization with web communication standards, adapted to varying security protocols, and offer better management.\n\n## Here are some lesser-known Kubernetes service mesh tools:\n\n**Autopilot:** Autopilot is a toolkit and SDK used for deploying and developing service mesh operators. It is developed by Solo.io, a service connectivity company. This service was launched in late-2019. The service allows its users to automate the service mesh interface for chaos experimentation, adaptive security, canary automation, and more.\n\n**Consul:** Consul, a service mesh solution, has a full-featured control plane. It was first released in 2014 and developed by HashiCorp. This service mesh can be installed and configured on an existing Kubernetes cluster. Its latest version is 1.9.5 that was released on April 15, 2021\n\n**OSM:** Open Service Mesh (OSM) is an open-source service mesh created by Microsoft that supports the Kubernetes environment. It is a cloud-native service mesh that allows users to manage and secure service meshes consistently. It also offers out-of-the-box observability features for dynamic microservice environments.\n\n**Layer5:** Layer5 is a service mesh company and a worldwide community that offers a large collection of service mesh projects. The community creates and maintains several projects that focus on the service mesh-centric capabilities in a cloud-based environment.\nThe key projects operating under the Layer5 community include: `Meshery`, `Learn Layer5`, `Service Mesh Landscape`, `Image Hub`, `Meshery Operator`, `Service Mesh Interface Conformance`, and `NightHawk`.\n\n**Kuma:** Kuma is an open-source service mesh that provides support for multiple environments across clouds, such as Kubernetes and virtual machines. It was created by Kong, and it was recently added to CNCF as a Sandbox project. Moreover, Kuma is production-ready, and it is still under active development.\n\n</div>\n\n</NewsWrapper>\n","frontmatter":{"title":"5 Lesser-Known, But Extremely Powerful Kubernetes Service Mesh Tools","type":"News","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAABQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZgCdAB9pIQtJHMb0adr3YHYAAP7tJ1NrnPpDtvGpt7brKer8G134gCRlvCJ7Hiq5yiKFcbg2BqHU0Clqc10JmY4yTR+84sxdcD1YOdAgx4a3nDtOLfW2qE7XFh1g8iqu+AQbOhJYa/oa2/r8yr14MRMAAA=="},"images":{"fallback":{"src":"/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp","srcSet":"/static/43427f194c9f6f161811d46d58e960ba/a66aa/kubernetes-with-mesh-tools.webp 750w,\n/static/43427f194c9f6f161811d46d58e960ba/65dd5/kubernetes-with-mesh-tools.webp 1080w,\n/static/43427f194c9f6f161811d46d58e960ba/4fad6/kubernetes-with-mesh-tools.webp 1366w,\n/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/43427f194c9f6f161811d46d58e960ba/kubernetes-with-mesh-tools.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAABQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZgCdAB9pIQtJHMb0adr3YHYAAP7tJ1NrnPpDtvGpt7brKer8G134gCRlvCJ7Hiq5yiKFcbg2BqHU0Clqc10JmY4yTR+84sxdcD1YOdAgx4a3nDtOLfW2qE7XFh1g8iqu+AQbOhJYa/oa2/r8yr14MRMAAA=="},"images":{"fallback":{"src":"/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp","srcSet":"/static/43427f194c9f6f161811d46d58e960ba/a66aa/kubernetes-with-mesh-tools.webp 750w,\n/static/43427f194c9f6f161811d46d58e960ba/65dd5/kubernetes-with-mesh-tools.webp 1080w,\n/static/43427f194c9f6f161811d46d58e960ba/4fad6/kubernetes-with-mesh-tools.webp 1366w,\n/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/43427f194c9f6f161811d46d58e960ba/kubernetes-with-mesh-tools.webp"}},"fields":{"slug":"/company/news/5-lesser-known-but-extremely-powerful-kubernetes-service-mesh-tools"}},{"id":"2d0498d1-9781-5c5b-a187-6dc25d7c9588","body":"\n\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1GhJH3YF5mBeYX7I7ItEd-EbUmk1cnn3BdK1X230kwII/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\t\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/PBq7mIPnPhM\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n\n</ResourcesWrapper>","frontmatter":{"title":"Working with Meshery Docs and Jekyll","type":"Tutorial","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBYdhghiDMAAAP7qjeX4S8vnJOZ2O8YIJf5D92SY4mvIWq2H5SPwQnrqSs3UrBXFX9Us5D3+HeJD94XG05JPNODc5lErF5oAAA=="},"images":{"fallback":{"src":"/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp","srcSet":"/static/300d26a25901973293e1afa1d7163fd6/06597/docs-jekyll.webp 750w,\n/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5635148042024833}},"extension":"webp","publicURL":"/static/300d26a25901973293e1afa1d7163fd6/docs-jekyll.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBYdhghiDMAAAP7qjeX4S8vnJOZ2O8YIJf5D92SY4mvIWq2H5SPwQnrqSs3UrBXFX9Us5D3+HeJD94XG05JPNODc5lErF5oAAA=="},"images":{"fallback":{"src":"/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp","srcSet":"/static/300d26a25901973293e1afa1d7163fd6/06597/docs-jekyll.webp 750w,\n/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5635148042024833}},"extension":"webp","publicURL":"/static/300d26a25901973293e1afa1d7163fd6/docs-jekyll.webp"}},"fields":{"slug":"/resources/service-mesh/working-with-meshery-docs-and-jekyll"}},{"id":"f41cb63f-c339-58db-973e-da30450bb41d","body":"\n\n<ResourcesWrapper> \n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/ug6yaYC-Kkw\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"A tutorial on Gatsby","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIAAABXRUJQVlA4IFYAAACQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJQBOgBERqlqFce6cAAP7o3Ul65eSgLy7Q2ysf3QFvMd5MVKk1URuZ5T99a5W2gIXHlxaKa0V27sJ1hwpgAA=="},"images":{"fallback":{"src":"/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp","srcSet":"/static/f33532c7d406b7420907a601674bbd29/a66aa/intro-to-gatsby.webp 750w,\n/static/f33532c7d406b7420907a601674bbd29/65dd5/intro-to-gatsby.webp 1080w,\n/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp 1280w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/f33532c7d406b7420907a601674bbd29/intro-to-gatsby.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIAAABXRUJQVlA4IFYAAACQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJQBOgBERqlqFce6cAAP7o3Ul65eSgLy7Q2ysf3QFvMd5MVKk1URuZ5T99a5W2gIXHlxaKa0V27sJ1hwpgAA=="},"images":{"fallback":{"src":"/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp","srcSet":"/static/f33532c7d406b7420907a601674bbd29/a66aa/intro-to-gatsby.webp 750w,\n/static/f33532c7d406b7420907a601674bbd29/65dd5/intro-to-gatsby.webp 1080w,\n/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp 1280w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/f33532c7d406b7420907a601674bbd29/intro-to-gatsby.webp"}},"fields":{"slug":"/resources/service-mesh/a-tutorial-on-gatsby"}},{"id":"5caef945-2e9e-5ee0-b825-7469d162ed54","body":"\n\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1UOlwFtZ-VJhW4RgQoSI_QOGUQ7OBG8NZDWrFUor7eyY/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/O9UZO5g9BvI\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"A tutorial on contributing to Layer5 and working with Git","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJYwCdMoADCoez2MwSD8qu6AD+v8Ru5d7zz+5taxp3ZMdQ8llnTq1XNwe1lipyKC+76r0IDAiqUgfquExjejLHTZqjZ3BMnjMPVA+EI+6sAA=="},"images":{"fallback":{"src":"/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp","srcSet":"/static/ab5d02560ab6edddd3b05e5b68200986/a66aa/layer5-walkthrough.webp 750w,\n/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5628571428571428}},"extension":"webp","publicURL":"/static/ab5d02560ab6edddd3b05e5b68200986/layer5-walkthrough.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJYwCdMoADCoez2MwSD8qu6AD+v8Ru5d7zz+5taxp3ZMdQ8llnTq1XNwe1lipyKC+76r0IDAiqUgfquExjejLHTZqjZ3BMnjMPVA+EI+6sAA=="},"images":{"fallback":{"src":"/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp","srcSet":"/static/ab5d02560ab6edddd3b05e5b68200986/a66aa/layer5-walkthrough.webp 750w,\n/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5628571428571428}},"extension":"webp","publicURL":"/static/ab5d02560ab6edddd3b05e5b68200986/layer5-walkthrough.webp"}},"fields":{"slug":"/resources/service-mesh/a-tutorial-on-contributing-to-layer5-and-working-with-git"}},{"id":"d31448ed-6fc6-5cc9-93b8-b594a85596f9","body":"\n\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1LxhzJhUs9-Hc9mwlKVUMlDAVdH-QWLvU1KWxVuRbSHg/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/wK7Q-zbJ3gQ\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"An Introduction to mesheryctl","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJZQCdAC0H3gN1AAD+61LGcyksda4fQX+hcW28PKI7CGviUbngvM3IveJsmXZPBAo3MZ4e3LLHqIAA"},"images":{"fallback":{"src":"/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp","srcSet":"/static/1945732eb52073c7fc259c43a0c566db/a66aa/golang-meshery-ctl.webp 750w,\n/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp 1048w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5620229007633588}},"extension":"webp","publicURL":"/static/1945732eb52073c7fc259c43a0c566db/golang-meshery-ctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJZQCdAC0H3gN1AAD+61LGcyksda4fQX+hcW28PKI7CGviUbngvM3IveJsmXZPBAo3MZ4e3LLHqIAA"},"images":{"fallback":{"src":"/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp","srcSet":"/static/1945732eb52073c7fc259c43a0c566db/a66aa/golang-meshery-ctl.webp 750w,\n/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp 1048w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5620229007633588}},"extension":"webp","publicURL":"/static/1945732eb52073c7fc259c43a0c566db/golang-meshery-ctl.webp"}},"fields":{"slug":"/resources/service-mesh/an-introduction-to-mesheryctl"}},{"id":"4777de98-5714-58fd-abd4-c083b634a2c1","body":"\n\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1Wc5ALdn-G3fADJ8I6nJlyOGhV2XHVprYPqDvkZ1MEqY/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/67iy2JEp4Ss\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"An Introduction to Contributing to Meshery","type":"Tutorial","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC06CG/jydzPs5oAAD+wD9oJE6Ds2QpzakR61Sp/u8yD0QGv6XIODSgXUC7xMLpwAAA"},"images":{"fallback":{"src":"/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp","srcSet":"/static/432b107d65e54188f665be55b8b337a6/06597/intro-to-meshery.webp 750w,\n/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp 1077w","sizes":"100vw"},"sources":[]},"width":1,"height":0.564531104921077}},"extension":"webp","publicURL":"/static/432b107d65e54188f665be55b8b337a6/intro-to-meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC06CG/jydzPs5oAAD+wD9oJE6Ds2QpzakR61Sp/u8yD0QGv6XIODSgXUC7xMLpwAAA"},"images":{"fallback":{"src":"/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp","srcSet":"/static/432b107d65e54188f665be55b8b337a6/06597/intro-to-meshery.webp 750w,\n/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp 1077w","sizes":"100vw"},"sources":[]},"width":1,"height":0.564531104921077}},"extension":"webp","publicURL":"/static/432b107d65e54188f665be55b8b337a6/intro-to-meshery.webp"}},"fields":{"slug":"/resources/service-mesh/an-introduction-to-contributing-to-meshery"}},{"id":"c6c57869-97d1-5f78-be36-41f667cce46e","body":"\n\nimport  Button  from  \"../../../reusecore/Button\";\n\n<ResourcesWrapper> \n\n<h3> Tutorial Recording </h3>\n<iframe className=\"iframe\" src=\"https://www.youtube.com/embed/Yu03slXrdS0\" loading=\"lazy\"\nframeBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n</iframe>\n<div className=\"Tutorial-btn\"> \n<Button primary url=\"/community/handbook/repository-overview\"> Check out the Layer5 Repository Overview </Button>\n</div>\n     \n</ResourcesWrapper>","frontmatter":{"title":"An introduction to all Layer5 repositories","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCw7CDPyd2ZWd1AAAD+2OvxSMgUO+0MRh6/2bKOqsB8FxmVvDD/qBbE5KbzSZT7gAAA"},"images":{"fallback":{"src":"/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp","srcSet":"/static/98ef543ae405ef027a56c28ec8427b54/06597/all-repos-layer5.webp 750w,\n/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp 869w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5638665132336018}},"extension":"webp","publicURL":"/static/98ef543ae405ef027a56c28ec8427b54/all-repos-layer5.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCw7CDPyd2ZWd1AAAD+2OvxSMgUO+0MRh6/2bKOqsB8FxmVvDD/qBbE5KbzSZT7gAAA"},"images":{"fallback":{"src":"/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp","srcSet":"/static/98ef543ae405ef027a56c28ec8427b54/06597/all-repos-layer5.webp 750w,\n/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp 869w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5638665132336018}},"extension":"webp","publicURL":"/static/98ef543ae405ef027a56c28ec8427b54/all-repos-layer5.webp"}},"fields":{"slug":"/resources/service-mesh/an-introduction-to-all-layer5-repositories"}},{"id":"a95eeac7-cff2-5552-9cfb-6022352a5104","body":"\n\n\n<ResourcesWrapper> \n  <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/PBq7mIPnPhM\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"Contributing to Meshery API Swagger Documentation","type":"Tutorial","technology":"API","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJYgCdG1/AR9xGRrF+XLDQAADfxWTJdzHtgR8N683kc2UdZ6vV/0sOQq+WHV9n4K+L13fp8HYPjJsleFUPx/qv99ZbNgykEeoAAA=="},"images":{"fallback":{"src":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp","srcSet":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.375}},"extension":"webp","publicURL":"/static/c8545d2914fb7562526089838dae61f7/swagger-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJYgCdG1/AR9xGRrF+XLDQAADfxWTJdzHtgR8N683kc2UdZ6vV/0sOQq+WHV9n4K+L13fp8HYPjJsleFUPx/qv99ZbNgykEeoAAA=="},"images":{"fallback":{"src":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp","srcSet":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.375}},"extension":"webp","publicURL":"/static/c8545d2914fb7562526089838dae61f7/swagger-logo.webp"}},"fields":{"slug":"/resources/service-mesh/contributing-to-meshery-api-swagger-documentation"}},{"id":"d75ad6d8-6aa9-583d-ad25-0b5257a08e44","body":"\n\n\n<ResourcesWrapper> \n   <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1oUzWQpFeFbpIs_sejtOPbF9J4nigj9ziEAzoWxmm6ig/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n   <h3> Tutorial Recording </h3>   \n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/hh_kFLZx3G4\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"Beginner's guide to contributing to Meshery and mesheryctl","type":"Tutorial","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlYAAABXRUJQVlA4IEoAAAAwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCdAC0H3spAAP7rq+An2RQM+dpPwh6NSaGNe898ZYovCl1/zVRMex7R7x0znKTQAA=="},"images":{"fallback":{"src":"/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp","srcSet":"/static/57826452d610ee6c68a56e9dcfccdef2/b9516/intro-meshery-ctl.webp 750w,\n/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5616045845272206}},"extension":"webp","publicURL":"/static/57826452d610ee6c68a56e9dcfccdef2/intro-meshery-ctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlYAAABXRUJQVlA4IEoAAAAwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCdAC0H3spAAP7rq+An2RQM+dpPwh6NSaGNe898ZYovCl1/zVRMex7R7x0znKTQAA=="},"images":{"fallback":{"src":"/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp","srcSet":"/static/57826452d610ee6c68a56e9dcfccdef2/b9516/intro-meshery-ctl.webp 750w,\n/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5616045845272206}},"extension":"webp","publicURL":"/static/57826452d610ee6c68a56e9dcfccdef2/intro-meshery-ctl.webp"}},"fields":{"slug":"/resources/service-mesh/beginners-guide-to-contributing-to-meshery-and-mesheryctl"}},{"id":"f3698102-848c-561d-bb18-e29be1e80e1f","body":"\n\n\nimport MesheryOperatorShot from \"./meshery-operator-v0.5.0.webp\";\nimport MesheryOperator from \"./meshery-operator-dark.svg\";\nimport MeshSync from \"./meshsync.svg\";\nimport MesheryDB from \"./meshery-database.svg\";\nimport MesheryAdapterLibrary from \"./meshery-adapter-library.svg\";\nimport Traefik from \"./traefik-mesh.svg\";\nimport MesheryExtensibility from \"./meshery-extensibility.svg\";\nimport NGINXSM from \"./nginx-service-mesh.svg\";\nimport layer5Logo from \"../../../../assets/images/layer5/layer5-only/svg/layer5-no-trim.svg\";\n\n<BlogWrapper>\n\n<p><strong>We're pleased to announce the release of Meshery 0.5.0!</strong> Consisting of a number of significant architectural enhancements with 8 new capabilities entering alpha, Meshery v0.5.0's feature density is impressive. Previewed in the <i>Using Istio</i> workshop delivered at the <Link to=\"/community/events/istiocon-2021\">inaugural IstioCon 2021</Link> earlier this month, Meshery v0.5.0 provides a strong architectural foundation for cloud native application and service mesh management.</p>\n\n\n## Feature Highlights\n- New GraphQL API\n- Meshery Operator with MeshSync inside\n- Meshery Adapter for Traefik Mesh (beta)\n- MeshKit and the Meshery Adapter Library\n- Meshery Adapter for NGINX Service Mesh (alpha)\n- Meshery Remote Provider extensions with dynamic injection\n- New Meshery CLI commands to manage mutiple Meshery deployments\n\n<div className=\"intro\" style={{textAlign: \"center\", display: \"flex\", flexDirection: \"row\", flexWrap: \"wrap\", justifyContent: \"center\", alignItems: \"center\", alignContent: \"center\", margin: \"2rem\"}}>\n  <img src={layer5Logo} style={{maxHeight: \"55px\", height: \"auto\", margin: \"auto\", padding: \".5rem\"}} />\n  <p style={{flexBasis: \"50%\", width: \"100%\", padding: \"0rem\", margin: \"0rem\"}} >Thank you to the wonderful Layer5 community of open source contributors in making this significant release possible.</p>\n</div>\n\n## New Service Mesh Support\n\n<p><span className=\"bigfirstletter\">2</span> new Meshery service mesh adapters are bundled with this latest version of Meshery: The Meshery Adapter for Traefik Mesh and the Meshery Adapter for NGINX Service Mesh.</p>\n\n<h3>Meshery Adapter for Traefik Mesh (beta)</h3>\n<img style={{display: \"inline\", float: \"left\", maxWidth: \"300px\", width: \"80%\", padding: \"1.25rem\"}} src={Traefik} />\n\n<p>Traefik Mesh is a straight-forward, easy to configure, and non-invasive service mesh that allows visibility and management of the traffic flows inside any Kubernetes cluster.</p>\n\n<p>Meshery supports the lifecycle and performance management of Traefik Mesh. Along with support for multiple versions of Traefik Mesh, bundled with this adapter are the Book Info and HttpBin sample applications operations to aid you in familiarizing with the functionality of Traefik Mesh. As a Meshery user, you can apply custom configuration to your instances of Traefik Mesh, managing the onboarding of your own applications onto the service mesh and providing the ability for you as a service mesh manager to customize your service mesh deployment.</p>\n\n<p>Review the <a href=\"https://docs.meshery.io/guides/sample-apps\">sample application guides</a> to familiarize with their differences and learn more about the beta adapter for <a href=\"https://docs.meshery.io/service-meshes\">Meshery Adapter for Traefik Mesh</a>.</p>\n \n\n<h3>Meshery Adapter for NGINX Service Mesh (alpha)</h3>\n<img style={{float: \"left\", maxWidth: \"200px\", display: \"inline\", position: \"relative\", marginRight: \"1.5rem\", padding: \"1.25rem\"}} src={NGINXSM} />\n\n<p>NGINX Service Mesh (NSM) is a fully integrated, lightweight service mesh that leverages a data plane powered by NGINX Plus to manage container traffic in Kubernetes environments. </p>\n\n<p>Meshery supports lifecycle and performance management of NGINX Service Mesh. Bundled with this support are a few sample applications to help users understand the functionality of NGINX Service Mesh. lifecycle management and sample applications operations below:</p>\n\n  <ul>\n    <li>Book Info</li>\n    <li>HTTPBin</li>\n    <li>Emojivoto</li>\n  </ul>\n\n<p>Review the <a href=\"https://docs.meshery.io/guides/sample-apps\">sample application guides</a> to familiarize with their differences. Learn more about the alpha adapter for <a href=\"https://docs.meshery.io/service-meshes\">Meshery Adapter for NGINX Service Mesh</a>.</p>\n\n<h2>Integrating with Meshery: Using extension points</h2>\n\nAs the cloud native manager, Meshery, is an extensible platform offering user and integrators well-crafted, extension points. Extension points allow you to  augment the behavior of Meshery by either adding entirely new capabilities or affecting the behavior of existing functionality, as see in the figure below.\n\n<div className=\"img-center\">\n  <a href={MesheryExtensibility} style={{backgroundColor: \"rgba(255,255,255,0)\"}}><img src={MesheryExtensibility} /></a>\n</div>\n\nAs you can see in the diagram, Meshery offers many types of extension points.\n\n- <strong>Extensible Service Mesh Adapters</strong> - bring your own service mesh.\n- <strong>Extensible APIs</strong> - bring your own GraphQL resolvers and expose new, custom endpoints.\n- <strong>Extensible Load Generators</strong> - Meshery supports three types of load generators, however, you can bring your own and plug it in.\n- <strong>Extensible Providers</strong> - the v0.5.0 release delivers dynamic injection of Remote Provider extensions. Providers are a powerful mechanism for integrating Meshery into your existing tooling and systems.\n\nThere are two types of Providers in Meshery: Local - built into Meshery and Remote - implemented by anyone or any organization that wishes to integrate with Meshery. Remote Provider extensibility includes:\n\n  * Pluggable UI functionality\n  * Pluggable Backend functionality\n  * Pluggable Authentication and Authorization\n  * Long-Term Persistence\n  * Enhanced Visualization\n  * Historical Reporting  \n\nLearn more about the platform Meshery provides to extend its funcionality by exploring its <Link to=\"https://docs.meshery.io/extensibility\">extension points</Link>. If you have or are building your own <Link to=\"https://docs.meshery.io/extensibility/providers\">Remote Provider</Link>, let us know!\n<h2>MeshKit and Meshery Adapter Library</h2>\n\nAs a service mesh toolkit, MeshKit aims to specifically focus on service mesh management and provides broadly useful functionality, it provides a standard policy for error handling and logging across all Meshery components, and implementations for error handling, logging, and tracing.\n\n<ul>\n  <li>MeshKit provides common data models of Service Mesh Interface conformance testing for Meshery.</li>\n  <li>The low-level API abstract by MeshKit to the high-level functions provides out-of-the-box functions.</li>\n</ul>\n\n<h3>Meshery Adapter Library</h3>\n\n<p>The Meshery Adapter Library provides a common and consistent set of functionality for managing the lifecycle of service meshes and their workloads.</p>\n<div className=\"img-center\">\n  <a href={MesheryAdapterLibrary}><img src={MesheryAdapterLibrary} /></a>\n</div>\n\n* The library provides a set of interfaces, some with default implementations like a mini framework implementing the gRPC server that allows plugging in the mesh-specific configuration and operations implemented in the adapters.\n* The default configuration provider we use Viper to reads the adapter specific configuration, and the configuration providers are implementations of an interface, this can be flexible if anyone wants to implement it on their own.\n\n<div className=\"intro\" style={{textAlign: \"center\", margin: \"2rem 4rem\"}}><p>Read <Link to=\"/community/members/michael-gfeller\">Maintainer Michael Gfeller</Link>'s blog post <Link to=\"/blog/meshery/introducing-meshkit-and-the-meshery-adapter-library\">Introduction MeshKit and the Meshery Adapter Library</Link> for more details.</p></div>\n\nWith the increasing the number and diversity of service meshes supported by Meshery, you might find the list of [Supported Service Meshes](https://docs.meshery.io/service-meshes) a helpful, complete list.\n\n<h2>Meshery Operator</h2>\n<img style={{float: \"left\", maxWidth: \"300px\", width: \"20%\", padding: \"1.25rem\"}} src={MesheryOperator} />\n<p style={{display: \"block\", width: \"100%\"}}>\nAs a Kubernetes custom controller, Meshery Operator provides a Kubernetes-native approach to interfacing with Meshery. Kubernetes is where service meshes have gotten their initial foothold, and therefore, important that Meshery interface to Kubernetes natively.\n</p>\n<p>Some service meshes support non-containerized workloads outside of the cluster and will grow in this focus over time. While Meshery Operator is Kubernetes only in the v0.5.0 release, Meshery's arichitecture makes considerations for different workload and platform types.</p>\n\n<div style={{display: \"flex\", width: \"100%\"}}>\n  <div style={{textAlign: \"center\", flex: \"50%\"}}>\n    <a href={MesheryOperatorShot} style={{backgroundColor: \"rgba(255,255,255,0)\"}}><img style={{width: \"100%\"}} src={MesheryOperatorShot} /></a>\n  </div>\n  <ul style={{flex: \"50%\"}}>\n    <li>Meshery Operator is the multi-service mesh operator that runs as a Kubernetes Operator and defines two custom resources: MeshSync and Meshery Broker (NATS)</li>\n    <li>Meshery Operator is provides abilities includes cluster discovery, service mesh discovery, and data streaming via NATS.</li>\n  </ul>\n</div>\n\n<h3>MeshSync</h3>\n<p>MeshSync is available as a Kubernetes custom resource that provides tiered discovery and continual synchronization with Meshery Server as to the state of the Kubernetes cluster, service meshes, and their workloads.</p>\n\n<div style={{display: \"flex\"}}>\n<img style={{maxWidth: \"300px\", width: \"20%\", padding: \"1.25rem\"}} src={MeshSync} />\n<ul>\n\n  <li>MeshSync is one of a family of custom controllers within Meshery Operator and is the <Link to=\"https://docs.meshery.io/concepts/architecture/meshsync\">heartbeat of Meshery</Link>, pumping information about service meshes and their workloads throughout Meshery's components.</li>\n  <li>MeshSync helps Meshery mesh with meshes by helping define a service mesh agnostic object model.</li>\n  <li>It provides ability to detect service meshes and services deployed on the cluster, and snapshot stored in-memory and refreshed periodically; \nmaintain the local snapshot of the cluster and refreshed periodically.</li>\n  <li>MeshSync These abilities above help Meshery operations more resilient.</li>\n</ul>\n\n</div>\n<h4>Relational Database</h4>\n\nMeshery's <a href=\"https://docs.meshery.io/concepts/architecture/database\">relational database</a> serves as a repository for MeshSync data, user preferences, and system settings. This database should be considered ephemeral and given that it operates as a cache. Meshery relational database offers federated datasets for managing multiple Kubernetes cluster and multiple service meshes.\n\n<div className=\"img-center\">\n  <a href={MesheryDB}><img src={MesheryDB} /></a>\n</div>\n\n<p>Learn more and consider <a href=\"https://github.com/layer5io/meshsync\">contributing</a> to MeshSync.</p>\n\n## GraphQL Support\n\nMeshery now supports <a href=\"https://docs.meshery.io/concepts/architecture#meshery-operator-and-meshsync\">GraphQL instances</a> between Meshery UI and Meshery Server offering any GraphQL client the  power to ask for exactly what they need from mesh. This new API sets the stage preparing for  exciting features in upcoming releases. Extension points are also built into Meshery's GraphQL support allowing integrators to bring their own GraphQL resolvers to the Meshery server runtime.\n\n\n<h2>Meshery Command Line Interface Enhancements</h2>\nThe beloved `mesheryctl` introduces new commands in the v0.5.0 release expands the CLI's support of multiple Meshery deployments with the `context` command and control over when Meshery auto-updates with the `channel` command.\n\n<h3>Managing Multiple Meshery Deployments</h3>\nIntroduced in this release is the meshconfig - a configuration file that describes Meshery deployments in separate <i>contexts</i>. A Meshery <i>context</i> describes deployments across Docker hosts and Kubernetes clusters. <code>mesheryctl system context</code> enables user to easy manage multiple deployments of Meshery by quickly switching contexts. \n\n### Subscribing to Meshery Release Channels\n`mesheryctl system channel` allows you to easily set and switch between which Meshery release channel (stable or edge) that you want a particilar Meshery deployment (`context`) to use. Meshery deployments subscribe to one of two release channels and can either automatically self-update the deployment or prompt you to update the deployment. Alternatively, you can pin a given Meshery deployment to a specific release should you want tighter control over when Meshery updates. Read more about <Link to=\"https://docs.meshery.io/project/build-and-release#release-channels\">Meshery's <i>stable</i> and <i>edge</i> release channels</Link>. \n\n\nReview the <Link to=\"https://docs.meshery.io/reference/mesheryctl\">mesheryctl Command Reference</Link> for details on all subcommands, flags, and their behavior.\n\n<h2>On to v0.6.0</h2>\n\nTo get a more comprehensive list of the bug fixes and enhancements packaged in the v0.5.0 release, see the [Meshery Documentation](https://docs.meshery.io/). With v0.6.0 planning complete these signal of the Layer5 community's innovation cycle trending upward sharply. See Meshery's <Link to=\"https://github.com/layer5io/meshery/blob/master/ROADMAP.md\">roadmap</Link> for a prelude of what's yet to come.\n\n<div className=\"intro\"><p>If these topics excite you and you want to explore the wonderful world of service meshes, come and say \"Hi\" on the community <Link to=\"http://slack.layer5.io\">Slack</Link> and you are sure to be warmly welcomed. <span>😀</span></p></div>\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing Meshery v0.5.0","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAAAwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwC7AB6PNYoAAP7ZPPBqgHk9L8Rq4LOZeWzq4QQEHi3NCBc96JkEWIAAAA=="},"images":{"fallback":{"src":"/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp","srcSet":"/static/8817162db307ec6582ad1a1f5aa71201/ee7ce/v0.5.0.webp 750w,\n/static/8817162db307ec6582ad1a1f5aa71201/819dc/v0.5.0.webp 1080w,\n/static/8817162db307ec6582ad1a1f5aa71201/7b8ce/v0.5.0.webp 1366w,\n/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/8817162db307ec6582ad1a1f5aa71201/v0.5.0.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAAAwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwC7AB6PNYoAAP7ZPPBqgHk9L8Rq4LOZeWzq4QQEHi3NCBc96JkEWIAAAA=="},"images":{"fallback":{"src":"/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp","srcSet":"/static/8817162db307ec6582ad1a1f5aa71201/ee7ce/v0.5.0.webp 750w,\n/static/8817162db307ec6582ad1a1f5aa71201/819dc/v0.5.0.webp 1080w,\n/static/8817162db307ec6582ad1a1f5aa71201/7b8ce/v0.5.0.webp 1366w,\n/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/8817162db307ec6582ad1a1f5aa71201/v0.5.0.webp"}},"fields":{"slug":"/blog/announcements/announcing-meshery-v050"}},{"id":"6d660fe4-6dc6-5b5a-80b1-ea41cc92dfff","body":"\n\nimport { MeshkitMesheryAdapterLib } from \"./MeshkitMesheryAdapterLib.style\";\n\n\nimport mesheryAdapterLibrary from \"./meshery-adapter-library.svg\";\nimport malOverview from \"./meshery-adapter-library-overview.webp\";\n\n<BlogWrapper>\n<MeshkitMesheryAdapterLib>\n\n<div className=\"intro\"><p>\nThe Meshery v0.5.0 release includes two new libraries: <span>MeshKit</span> and <span>Meshery Adapter Library</span>.\n\nThese two libraries improve contributor experience and development speed by reducing the burden of sustaining the plethora of Meshery adapters, allowing contributors to focus on exposing a service mesh's differentiated value,\ninstead of having to redundantly implement plumbing for managing service meshes.\n\n</p></div>\n\n## MeshKit\n\nMeshKit was formerly named `gokit` and was renamed recently to align with the other Meshery components' names (and avoid confusion with the `go-kit` project). MeshKit can be considered a derivative of `go-kit` with specific focus on service mesh management.\n\nIn the Meshery v0.5.0 release, MeshKit has been enhanced and expanded substantially. Considering that the MeshKit library provides broadly useful functionality, it is used in a growing number of Meshery components. It is intended to be one of the top level libraries in the Meshery ecosystem. <div className=\"fact\">Meshkit provides functionality useful across all Meshery components.</div>\n\nMeshKit is a toolkit for Layer5’s microservices, and is positioned to become Layer5’s middleware component for Layer5’s microservices, leveraging other libraries like `go-kit/kit`. In complement to functionality provided by a service mesh, its purpose is to provide implementations for common cross-cutting concerns like error handling, logging, and tracing. Uniform error handling and logging across all Meshery components helps to implement efficient tooling for observability, monitoring and troubleshooting. The library provides some common data models for Meshery, notably for <Link to=\"/smi\">Service Mesh Interface conformance testing</Link>, and Kubernetes' `kubeconfig`.\n\nAnother central component in Meshkit is the `utils` package.\n\nThis package provides a Kubernetes and a Helm client that implements functionality based on the Go libraries of these tools. The API exposed by these libraries is quite low-level, and the higher-level functions of the `utils` package simplifies usage of Kubernetes and Helm clients significantly.\nAnother advantage MeshKit that it is not necessary to use the command line versions of these tools, providing a more tailored experience for developers,\nand better logging and error handling integration.\n\n<Link to=\"https://github.com/layer5io/meshkit\">MeshKit</Link> is simple and straight\nforward to use, as the following code example illustrates.{\" \"}\n\n```go\npackage main\n\nimport (\n\t\"os\"\n\n\tmeshkitlogger \"github.com/layer5io/meshkit/logger\"\n\tmeshkitkubernetes \"github.com/layer5io/meshkit/utils/kubernetes\"\n\t\"k8s.io/client-go/kubernetes\"\n)\n\nfunc main() {\n\t// nginx contains the deployment manifest for nginx.\n\tnginx := `apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2 # tells deployment to run 2 pods matching the template\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n`\n\n\t// Create an instance of the meshkit logger handler.\n\tlog, err := meshkitlogger.New(\"ExampleApp\",\n\t\tmeshkitlogger.Options{Format: meshkitlogger.JsonLogFormat, DebugLevel: false})\n\tif err != nil {\n\t\tos.Exit(1)\n\t}\n\tlog.Info(\"successfully instantiated meshkit logger\")\n\n\t// Detect kubeconfig on the local system.\n\tconfig, err := meshkitkubernetes.DetectKubeConfig()\n\tif err != nil {\n\t\tlog.Error(err)\n\t\tos.Exit(1)\n\t}\n\tlog.Info(config.Host)\n\n\t// Create Kubernetes client set for the detected kubeconfig using the Kubernetes Go client library.\n\tclientset, err := kubernetes.NewForConfig(config)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\tos.Exit(1)\n\t}\n\n\t// Create an instance of the meshkit Kubernetes client ...\n\tclient, err := meshkitkubernetes.New(clientset, *config)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\tos.Exit(1)\n\t}\n\n\t// ... and use it to deploy nginx to the cluster.\n\terr2 := client.ApplyManifest([]byte(nginx), meshkitkubernetes.ApplyOptions{\n\t\tNamespace: \"default\",\n\t\tUpdate:    true,\n\t\tDelete:    false,\n\t})\n\tif err2 != nil {\n\t\tlog.Error(err2)\n\t\tos.Exit(1)\n\t}\n\tlog.Info(\"successfully applied the manifest\")\n}\n```\n\n## Meshery Adapters\n\nMeshery adapters are management plane components and manage the lifecycle of service meshes. This includes installation and deletion, configuration, and verification that an installation follows recommended practices. In addition, Meshery adapters can assess to what extent a service mesh complies to the <Link to=\"/blog/announcements/a-standard-interface-for-service-meshes\">Service Mesh Interface standard</Link>. Meshery adapters support management of multiple versions of their respective service mesh and also come bundled with sample applications that can be deployed for easy and quick exploration of service mesh capabilities. <div className=\"fact\">Meshery adapters manage the lifecycle of service meshes.</div>\n\nA Meshery adapter is a gRPC server that exposes the `MeshServiceServer` interface:\n\n```go\n// MeshServiceServer is the server API for MeshService service.\ntype MeshServiceServer interface {\n\tCreateMeshInstance(context.Context, *CreateMeshInstanceRequest) (*CreateMeshInstanceResponse, error)\n\tMeshName(context.Context, *MeshNameRequest) (*MeshNameResponse, error)\n\tApplyOperation(context.Context, *ApplyRuleRequest) (*ApplyRuleResponse, error)\n\tSupportedOperations(context.Context, *SupportedOperationsRequest) (*SupportedOperationsResponse, error)\n\tStreamEvents(*EventsRequest, MeshService_StreamEventsServer) error\n}\n```\n\n- `CreateMeshInstance` sets up the Kubernetes client. It does not, as the name might imply, create an instance of a service mesh.\n- `MeshName` returns the name of the mesh, configured in the adapter.\n- `SupportedOperations` returns all supported operations, configured in the adapter. An operation is e.g. the installation of a service mesh.\n- `ApplyOperation` executes the operation specified in the request. It is one of the supported operations.\n- `StreamEvents` allows sending events from the server to the client.\n\nThis API is one of the extension points of Meshery, making it easy to add support for new service meshes to Meshery. Meshery adapters abstract away differences in installation and configuration of the various service meshes.<div className=\"fact\">Adapters allow Meshery to interface with the different service meshes, exposing their differentiated value to users.</div>\n\nIn general, the various service mesh implementations are installed and configured in their own way. For instance, some service meshes have their own installer, like `istioctl` for Istio, while others use Helm charts, like Consul. One of the purposes of Meshery adapters is to abstract these differences away.\n\n## Meshery Adapter Library\n\nAs can be expected, adapters for the various meshes have a lot of code in common. Initially, this common code was copied from one adapter implementation to the next. The question arose whether common code should be factored out to one or several libraries. After some discussion, the community decided to move some of the more general code to Meshkit, and adapter specific code to a new library.\n\nThus, the Meshery Adapter Library was born.\n\nIt reduces the amount of boilerplate code in the adapters substantially, making adapter code easier to follow. This is especially valuable in an open source community where typically many developers contribute, for varying amounts of time. For the same reasons, it is important such libraries are easily understandable.\n\nAlso, it means new adapters can be implemented quickly, as only configuration and operations that differ between services meshes need to be implemented.\n\n<div className=\"fact\">\n  The Meshery Adapter Library provides a common and consistent set of\n  functionality that Meshery adapters use for managing the lifecycle of\n  service meshes and their workloads.\n</div>\n\nThe initial commit was submitted on October 6th, 2020 based on a refactoring effort in the adapter for the Kuma service mesh. Within a few months, several adapters have been refactored or implemented from scratch based on the Meshery Adapter Library.\n\nThe main purpose of the Meshery Adapter Library is to:\n\n- provide a set of interfaces, some with default implementations, to be used and extended by adapters.\n- implement cross-cutting concerns like logging, error handling, and tracing.\n- provide a mini framework implementing the gRPC server that allows plugging in the mesh specific configuration and operations implemented in the adapters.\n\nThe core interface in the library is the adapter `Handler` interface:\n\n```go\n// Interface Handler is extended by adapters, and used in package api/grpc that implements the MeshServiceServer.\ntype Handler interface {\n\t// GetName returns the name of the adapter.\n\tGetName() string\n\t// CreateInstance instantiates clients used in deploying and managing mesh instances, e.g. Kubernetes clients.\n\tCreateInstance([]byte, string, *chan interface{}) error\n\t// ApplyOperation applies an adapter operation. This is adapter specific and needs to be implemented by each adapter.\n\tApplyOperation(context.Context, OperationRequest) error\n\t// ListOperations list all operations an adapter supports.\n\tListOperations() (Operations, error)\n\n\t// Need not implement this method and can be reused\n\tStreamErr(*Event, error) // Streams an error event, e.g. to a channel\n\tStreamInfo(*Event)       // Streams an informational event, e.g. to a channel\n}\n```\n\nIt corresponds closely to the gRPC API discussed above, and indeed these methods are called in the implementation of the `MeshServiceServer` interface. This implementation is also part of the Meshery Adapter Library.\n\nUsing `struct` embedding, an adapter extends the default implementation `Adapter` of the interface `Handler` from the library.\nUsually, it is sufficient that this adapter handler overrides only the `ApplyOperation` function from the default implementation.\n(There, it is a no-op implementation.)\n\nThe figure below illustrates this and the usage of the library in an adapter.\n\n<img\n  src={mesheryAdapterLibrary}\n  className=\"image-center\"\n  alt=\"meshery adapter library\"\n/>\n\nIn the `main` package of the adapter, the default configuration provider `Viper` from the library is instantiated, and reads the adapter specific configuration. This includes a specification of all available operations. As configuration providers are implementations of an interface, you can choose any of the providers from the library, or implement your own.\n\nNext, an instance of the adapter handler is created. Other components, for instance a logger, may be created depending on needs and requirements, which is symbolize by the three dots in the figure.\n\nThe `service` is a struct that holds all the parameters that specify an adapter service, like the port the gRPC server is running on, and the instance of the adapter handler created in a previous step. This struct is passed to the `Start` function from the library. This `Start` function wraps the gRPC server, wiring up all necessary components, and starts the service. The developer does not need to touch any gRPC code.\n\n### Conclusion\n\nExtracting common code from adapters to the two new libraries has proven to be a worthwhile investment. It led to cleaner code as well as cleaner application architecture, shortened implementation time for new adapters considerably, and upleveled the quality of Meshery's adapters through consistency of implementation.\n\n\n<div className=\"intro\"><p>P.S. If these topics excite you and you want to explore the beautiful realm of service meshes, come and say \"Hi\" on the community <Link to=\"http://slack.layer5.io\">Slack</Link> and you are sure to be warmly welcomed. <span>😀</span></p></div>\n\n</MeshkitMesheryAdapterLib>\n</BlogWrapper>\n","frontmatter":{"title":"Introducing Meshkit and the Meshery Adapter Library","type":"Blog","technology":"API","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIAAABXRUJQVlA4IEYAAABQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZwC06BuZNpYBQAD+y8x8Y+HSd5zjXtkB1x+V98O5YQD2dH+igeMC9cNeLgAA"},"images":{"fallback":{"src":"/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp","srcSet":"/static/f6d05b0291faa22eb65720f319dae9e8/b9516/meshery-adapter-library-overview.webp 750w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a327/meshery-adapter-library-overview.webp 1080w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a401/meshery-adapter-library-overview.webp 1366w,\n/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5614583333333334}},"extension":"webp","publicURL":"/static/f6d05b0291faa22eb65720f319dae9e8/meshery-adapter-library-overview.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIAAABXRUJQVlA4IEYAAABQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZwC06BuZNpYBQAD+y8x8Y+HSd5zjXtkB1x+V98O5YQD2dH+igeMC9cNeLgAA"},"images":{"fallback":{"src":"/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp","srcSet":"/static/f6d05b0291faa22eb65720f319dae9e8/b9516/meshery-adapter-library-overview.webp 750w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a327/meshery-adapter-library-overview.webp 1080w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a401/meshery-adapter-library-overview.webp 1366w,\n/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5614583333333334}},"extension":"webp","publicURL":"/static/f6d05b0291faa22eb65720f319dae9e8/meshery-adapter-library-overview.webp"}},"fields":{"slug":"/blog/meshery/introducing-meshkit-and-the-meshery-adapter-library"}},{"id":"f0be9d0b-f557-56b6-9f99-b2d28864d4ab","body":"\n\nimport bestPracticesSelectingElementsImg from \"./best-practices-selecting-elements.webp\";\nimport cypressTestRunnerImg from \"./cypress-test-runner.webp\";\n\n<BlogWrapper>\n\n<a href=\"https://www.cypress.io\" rel=\"nofollow\">Cypress</a> is the functional test tool used in development of Meshery UI. As a reliably test tool, Cypress  works with <i>ReactJS</i>, <i>VueJS</i>, <i>AngularJS</i> and so on; it is agnostic of the framework you use. You can write all types of tests: <i>end-to-end</i>, <i>integration</i>, and <i>unit tests</i>.\n\nTests allow you to ensure that the new code do not break the current one. They help you to develop and integrate new features faster and ensure everything will work after including your changes. The more tests you have, the more coverage you will have (and less likelihood of issues in production).\n\n### UI tests in Meshery\n\nMeshery has two web projects:\n\n- <b>provider-ui:</b> A <i>ReactJS</i> app that allows you to select the Provider to be used for Meshery\n- <b>ui:</b> Also a <i>ReactJS</i> app where you can do everything related with Meshery. It is the cloud native management plane.\n\nWe create UI tests for both projects using Cypress. Also, we write two types of UI tests at the moment:\n- <b>Integration:</b> Test a specific functionality without backend communication (mocking requests and responses)\n- <b>End-to-end:</b> Test a whole flow like setting up Linkerd Service Mesh or running a SMI Performance Test sending requests and validating the responses from the back-end\n\n### How to write UI tests for Meshery\n\nIf you are writting your first test, you can read and watch the <b><u><a href=\"https://docs.cypress.io/guides/getting-started/writing-your-first-test.html\">great getting started</a></u></b> from Cypress blog.\n\nThen, you have to add your test below `\"provider-ui/cypress/integration\"` or `\"ui/cypress/integration\"` folders (do not forget adding <i>_spec</i> in the filename).\n\nHere is a basic example of a test validating that <b>Provider UI component</b> exists:\n\n```\ndescribe('Provider UI', () => {\n  it('renders provider component', () => {\n    cy\n      .get('[data-cy=root]')\n      .should('exist')\n  })\n})\n```\n\nPlease follow the <b><u><a href=\"https://docs.cypress.io/guides/references/best-practices.html\">best practices recommended</a></u></b> by Cypress.\nOne of the most important is to use or add the `\"data-cy\"` attribute to the element you want to interact to:\n\n<img src={bestPracticesSelectingElementsImg} className=\"image-center\" alt=\"Best Practices selecting elements with Cypress\" />\n<p style={{textAlign: \"center\"}}>Best Practices Selecting Elements</p>\n\n### Run your test!\n\nOnce you have written your test, it is time to execute it locally:\n\n1. First, you have to run the back-end executing this command at the root project folder:\n\n```bash\n$ make run-local\n```\n\n2. Then, run the front-end project (i.e. provider-ui)\n\n```bash\n$ make run-provider-ui-dev\n```\n\n3. Finally, in `\"provider-ui\"` folder, run all the tests with:\n\n```bash\n$ npm run cy:run\n```\n\nIf everything went well, you will see <b>\"All specs passed!\"</b> message. Congrats!\n\nYou can also execute, debug and see in real time your test by executing:\n\n```bash\n$ npm run cy:open\n```\n\nthis will open the <b>Cypress Test Runner:</b>\n\n<img src={cypressTestRunnerImg} className=\"image-center\" alt=\"Cypress Test Runner\" />\n<p style={{textAlign: \"center\"}}>Cypress Test Runner</p>\n\njust double-click on your test and a window browser will be opened and you will see your testing running!\n\n#### What’s next?\n\nTo improve writting better tests, I recommend that you watch:\n\n- Watch the <a href=\"https://www.youtube.com/watch?v=pIFSI7xtwFs\" target=\"_blank\" rel=\"noreferrer\">Meshery Development Meeting (Nov 4th, 2020)</a> where I gave a demo running UI tests on the Meshery project (<a href=\"https://docs.google.com/presentation/d/1QbMEyQgbXMLvvSheAIDruzCFe8SmBrKXUjqP0Hxfqjw\" target=\"_blank\" rel=\"noreferrer\">slides</a>)\n- <a href=\"https://docs.cypress.io/examples/examples/tutorials.html\" rel=\"noreferrer\" target=\"_blank\">Tutorial Videos</a> from Cypress blog.\n- The <a href=\"https://www.youtube.com/watch?v=5XQOK0v_YRE\" target=\"_blank\" rel=\"noreferrer\">Brian Mann – I see your point, but… (Part 1)</a> YouTube video where he gives pro tips writting tests in Cypress.\n\nIf you have questions, do not hesitate to ask to the Meshery community on Slack :)\n\nHappy testing!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Functional Testing with Cypress in Meshery UI","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRvwAAABXRUJQVlA4WAoAAAAQAAAAEwAABQAAQUxQSHkAAAAAAEuqoDAAAAAAAAAAAAAAAAAxEQBQ/v//9CkpLBwlJx4dLxU3AD0VObf/////kbOvpWm3t69rnHwCd4Rvtf////+PtK+lFbxsUslLv2CHg3ZK/f//8TCiIhoBICAgIhkpGxcHMgBDoZcqAhAAAAAAAAAAAAAAAAAAAFZQOCBcAAAAEAMAnQEqFAAGAD7RVKNLqCSjIbAIAQAaCWkAAEmNZx2QAP5J9cl7VPwN7XJEL49/xxssqNFXLSgNmwkZGlgr/sTSa2WP3E3Um5txG6RuWRpO/b5FgZ5pqOnIgAA="},"images":{"fallback":{"src":"/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp","srcSet":"/static/b239a146858aacbc01f39092bd992e6e/2b7d2/cypress-logo.webp 750w,\n/static/b239a146858aacbc01f39092bd992e6e/ab31e/cypress-logo.webp 1080w,\n/static/b239a146858aacbc01f39092bd992e6e/53ea9/cypress-logo.webp 1366w,\n/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.2833333333333333}},"extension":"webp","publicURL":"/static/b239a146858aacbc01f39092bd992e6e/cypress-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRvwAAABXRUJQVlA4WAoAAAAQAAAAEwAABQAAQUxQSHkAAAAAAEuqoDAAAAAAAAAAAAAAAAAxEQBQ/v//9CkpLBwlJx4dLxU3AD0VObf/////kbOvpWm3t69rnHwCd4Rvtf////+PtK+lFbxsUslLv2CHg3ZK/f//8TCiIhoBICAgIhkpGxcHMgBDoZcqAhAAAAAAAAAAAAAAAAAAAFZQOCBcAAAAEAMAnQEqFAAGAD7RVKNLqCSjIbAIAQAaCWkAAEmNZx2QAP5J9cl7VPwN7XJEL49/xxssqNFXLSgNmwkZGlgr/sTSa2WP3E3Um5txG6RuWRpO/b5FgZ5pqOnIgAA="},"images":{"fallback":{"src":"/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp","srcSet":"/static/b239a146858aacbc01f39092bd992e6e/2b7d2/cypress-logo.webp 750w,\n/static/b239a146858aacbc01f39092bd992e6e/ab31e/cypress-logo.webp 1080w,\n/static/b239a146858aacbc01f39092bd992e6e/53ea9/cypress-logo.webp 1366w,\n/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.2833333333333333}},"extension":"webp","publicURL":"/static/b239a146858aacbc01f39092bd992e6e/cypress-logo.webp"}},"fields":{"slug":"/blog/meshery/functional-testing-with-cypress-in-meshery-ui"}},{"id":"459562ad-b96a-5c5e-b19c-6870f3a21187","body":"\n\n\n<NewsWrapper>\n\n<div>\n\n\"Cloud native\" doesn't just mean \"running in the cloud.\" It's a specific deployment paradigm and uses containers and an orchestration system (usually Kubernetes) to help provision, schedule, run and control a production workload in the cloud, or even across multiple clouds. Within cloud native deployments, an increasingly common approach to networking is the service mesh concept. With a service mesh, instead of each individual container requiring a full networking stack, a grouping of containers all benefit from a mesh that provides connectivity and networking with other containers as well as the outside world.\n\nService mesh in the wild\nWhile the concept of a service mesh has applicability beyond just Kubernetes deployments, that's arguably where the vast majority of deployments are today. Among the earliest cloud-native service mesh approaches is the open source Linkerd project, which is backed by Buoyant and began to really ramp up adoption in 2017.\n\nOver the past three years there has been an explosion of open source service mesh technology. Layer5, which develops service mesh aggregation technology, currently tracks over 20 different open and closed source mesh projects. Beyond Linkerd, among the most popular is the Google-backed Istio project, which recently hit its 1.8 milestone release. Cisco has backed the Network Service Mesh (NSM) effort, which works at a lower level in the networking stack than Linkerd, Istio and most others.\n\nEach mesh has its own take on configuration and capabilities, which is a good thing for users. Simply put, there is no shortage of options and there is likely to be a service mesh that already exists to meet just about any need.\n\nService mesh abstraction\nWhile having lots of different service mesh technologies is good for choice, it's not necessarily a good thing for simplicity or interoperability. That's where the concept of service mesh abstraction comes into play.\n\nAt the recent KubeCon NA 2020 virtual event, Lee Calcote, co-chair of the Cloud Native Computing Foundation (CNCF) Networking Special Interest Group (SIG) and founder of Layer5, outlined how the different service mesh abstraction technologies fit together.\n\nThe Service Mesh Interface (SMI) is a way for any compliant service mesh to plug into Kubernetes. The Service Mesh Performance (SMP) abstraction is all about providing visibility into service mesh performance though a common interface. The third key abstraction is known as Hamlet and it provides multi-vendor service interoperation and mesh federation capabilities.\n\nService mesh benefits\nThere are a number of different benefits that service meshes can bring, which are helping to accelerate adoption. Calcote explained that with a service mesh there is a decoupling of developer and operations teams such that each can iterate independently.\n\nAs such, operators can make changes to infrastructure independent of developers. DevOps is supposed to mean developer and operations teams work together, but the reality is often quite different and the ability to build application and infrastructure separately is why service mesh has been such a winning proposition for so many organizations.\n\n\"We live within a software defined network landscape, and service meshes in some respects are sort of a next-gen SDN,\" Calcote said.\n\n</div>\n\n</NewsWrapper>\n","frontmatter":{"title":"Service Mesh Offers Promising Solution for Cloud Native Networking","type":"News","technology":"Cloud","product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC7IDZgmudmGpiGoFX6QKQA/vJjCvgvJkbUF3Y/liMf2Cr8/xo37hrE91bGryC9YOKTJG8D8g1+ChfX6+G1GWpa9O7A7elEBZNUcKzVonLWpxYHA/+hwJ2RWKO+4cLpZL/I4FlFrcEH454AAA=="},"images":{"fallback":{"src":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp","srcSet":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5266666666666667}},"extension":"webp","publicURL":"/static/a2808ac8b497f7848fa6155fba8bb718/service-mesh.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC7IDZgmudmGpiGoFX6QKQA/vJjCvgvJkbUF3Y/liMf2Cr8/xo37hrE91bGryC9YOKTJG8D8g1+ChfX6+G1GWpa9O7A7elEBZNUcKzVonLWpxYHA/+hwJ2RWKO+4cLpZL/I4FlFrcEH454AAA=="},"images":{"fallback":{"src":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp","srcSet":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5266666666666667}},"extension":"webp","publicURL":"/static/a2808ac8b497f7848fa6155fba8bb718/service-mesh.webp"}},"fields":{"slug":"/company/news/service-mesh-offers-promising-solution-for-cloud-native-networking"}},{"id":"fd6ca157-b8fb-5194-9d9f-4ebdc2afca86","body":"\n\nimport serviceMeshAbstractions from \"./service-mesh-abstractions.webp\";\nimport serviceMeshPerformance from \"./service-mesh-performance.webp\";\n\n<NewsWrapper>\n\nAs more organizations implement service meshes, they are finding what works and what needs more work, and they are creating new management practices around this knowledge. A few tried-and-tested best practices were detailed last month during KubeCon+CloudNativeCon.\n\n“There’s a lot to say about each of these service meshes and how they work: their architecture, why they’re made, what they’re focused on, what they do when they came about and why some of them aren’t here anymore and why we’re still seeing new ones,” Lee Calcote, founder of Layer5, explained during his talk entitled “Service Mesh Specifications and Why They Matter in Your Deployment.”\n\nService mesh is increasingly seen as a requirement to manage microservices in Kubernetes environments, offering a central control plane to manage microservices access, testing, metrics and other functionalities. One-third of the respondents in The New Stack survey of our readers said their organizations already use service mesh. Among the numerous service mesh options available; Envoy, Istio, Linkerd and Kuma are but a few on offer.\n\n### Interoperability Is Key as Service Meshes Come and Go\n\nOrganizations will likely look to use at least more than one API service layer and service mesh for their clusters. This is why interoperability, and thus specifications, are critical for control planes as well. During his talk — “Service Mesh Specifications and Why They Matter in Your Deployment” mentioned above — for example, Calcote, asked rhetorically:\n\n“How many specifications, how many standards are there that have come to the rescue, so to speak, for understanding and interoperating with the various service meshes that are out there?” Calcote said.\n\n<a href={serviceMeshAbstractions}><img src={serviceMeshAbstractions} alt=\"service-mesh-abstractions\" width=\"100%\" /></a>\n\nA service mesh can be used for testing router performance, service latency and other variables. However, determining service mesh performance in an apples-to-apples way can be challenging. When studying “published results from some of the service meshes [from providers] that do publish results about performance… what you’ll find is that they’re probably using an environment that isn’t necessarily like yours,” Calcote said. “They’re also using different statistics and metrics to measure [their service meshes] … and it doesn’t help.”\n\n<a href={serviceMeshPerformance}><img src={serviceMeshPerformance} alt=\"service-mesh-performance\" width=\"100%\" /></a>\n\nService mesh performance (SMP) was created in an attempt to establish a way of comparing the performance of different services. “The SMP was born in combination with engaging with a few of those different service mesh maintainers and creating a standard way of articulating a performance of a mesh,” Calcote said.\n\nAmong the variables in consideration, in addition to the service mesh itself, include the number of clusters, workloads, the types of nodes, control plan configuration and the use of client libraries all affect performance.\n\n“What costs more, what’s more efficient and what’s more powerful: These are all open questions that SMP assists in answering in your environment,” Calcote said.\n\n</NewsWrapper>\n","frontmatter":{"title":"KubeCon+CloudNativeCon","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAgAPtFWpEuoJKOhsAgBABoJYgCdMoADf76Io9ukEMKaAAD+0NVX8yrCCYso0t4m+uqXvUNcjspWp5cPsm9igQenys+i4un1qy0qCumd6/zcds2HFNCb9SqZQTZuLg8wT+AA"},"images":{"fallback":{"src":"/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp","srcSet":"/static/3bbaf49e171ac3012bc61c5567dd6aed/b07c1/service-mesh-implementations.webp 750w,\n/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp 1024w","sizes":"100vw"},"sources":[]},"width":1,"height":0.41503906250000006}},"extension":"webp","publicURL":"/static/3bbaf49e171ac3012bc61c5567dd6aed/service-mesh-implementations.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAgAPtFWpEuoJKOhsAgBABoJYgCdMoADf76Io9ukEMKaAAD+0NVX8yrCCYso0t4m+uqXvUNcjspWp5cPsm9igQenys+i4un1qy0qCumd6/zcds2HFNCb9SqZQTZuLg8wT+AA"},"images":{"fallback":{"src":"/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp","srcSet":"/static/3bbaf49e171ac3012bc61c5567dd6aed/b07c1/service-mesh-implementations.webp 750w,\n/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp 1024w","sizes":"100vw"},"sources":[]},"width":1,"height":0.41503906250000006}},"extension":"webp","publicURL":"/static/3bbaf49e171ac3012bc61c5567dd6aed/service-mesh-implementations.webp"}},"fields":{"slug":"/company/news/kubeconcloudnativecon"}},{"id":"f1c49ff8-1bac-5e85-aac8-a2c63d80156e","body":"\nimport kubernetes from \"./kubernetes-platform.webp\";\n\n<img align=\"left\" style={{padding: \"15px\"}} src={kubernetes} alt=\"Kubernetes-platform\" />\n\nA service mesh has become a critical part of platforms based on Kubernetes clusters. It provides both east-west and north-south traffic managementxi, security, observability, and shaping for services implemented by the cluster and supporting components. As clusters have grown in size and platforms have become comprised of many clusters, maintaining a consistent view, management, and policies for network layer 4 – 7 traffic has become increasingly complex.\n\n<p>\nIn response, a number of vendors have extended control planes with a multi-cluster management layer such that they federate and manage service meshes at scale across multiple clouds and on-premises deployments. Both Hashicorp Consul and VMWare Tanzu NSX Service Mesh extend the service mesh control plane past the local service mesh to allow a management layer over multiple clouds and clusters. <u>The open source project <a href=\"/cloud-native-management/meshery\"><b>Meshery</b></a> is also providing a service mesh management plane as separate software that can interact using the Service Mesh Interface or through built-for-purpose adapters for a variety of existing service mesh products and projects.</u>\n</p>\n\nLike Kubernetes control planes, this extension of the service mesh control plane allows for consistent management and policies across clusters in different environments, a situation that is becoming more typical in enterprise IT applications.\n\nService mesh control plane federation is an emerging feature of service mesh products. Unlike Kubernetes control planes, it is not yet commonplace, but Amalgam Insights predicts that we will see service mesh control plane federation become a normal part of the service mesh landscape.\n\n<center>\n<h5 className=\"black-text\">Access the full <a href=\"https://amalgaminsights.com/2018/12/20/the-view-from-kubeconcloudnativecon-seattle/\">research from Amalgam Insights</a></h5>\n</center>\n","frontmatter":{"title":"Meshery Provides the Service Mesh Management Plane and Kubernetes Evolves into an Enterprise Platform","type":"News","technology":"Kubernetes","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRk4AAABXRUJQVlA4IEIAAABwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJaQAAUz7ZZ8qBWQAA/vGd5EmHfVUQRyXKfh9ED+fAbmSNCQRFF7yTAAA="},"images":{"fallback":{"src":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp","srcSet":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp 404w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504950495049505}},"extension":"webp","publicURL":"/static/d5ca72e88de08ce71380ce562f67719c/kubernetes-platform.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRk4AAABXRUJQVlA4IEIAAABwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJaQAAUz7ZZ8qBWQAA/vGd5EmHfVUQRyXKfh9ED+fAbmSNCQRFF7yTAAA="},"images":{"fallback":{"src":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp","srcSet":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp 404w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504950495049505}},"extension":"webp","publicURL":"/static/d5ca72e88de08ce71380ce562f67719c/kubernetes-platform.webp"}},"fields":{"slug":"/company/news/meshery-provides-the-service-mesh-management-plane-and-kubernetes-evolves-into-an-enterprise-platform"}},{"id":"7802e907-ecf2-5e60-93ed-04551ee7687f","body":"\n\nimport smpImg from \"./smp.webp\";\n\n<BlogWrapper>\n\n### What is performance benchmarking and why should you care?\n\nMany of you may remember that the HBO streaming service crashed when the final season of the popular sitcom, Game of Thrones went live on the service. Unable to engage all the user requests, the streaming service and the website broke down and ultimately resulted in DoS (Denial of Service). There are numerous examples of service crashes across different platforms, which has forced developers to take a closer look at performance benchmarking and pre-launch performance checks.\n\nThere are several advantages of preliminary service benchmarking, which may extensively enhance the response time, resolve glitches, enhance the application's robustness, and bring together several other commendable factors, including but not limited to stability and dependability within an application.\n\nThere are several tools for performance benchmarking. A major one is the interconnected relationship between load generators and benchmarks. Some of the well-known load generators in the cloud native realm are:\n\n<ul>\n    <li>Fortio</li>\n    <li>Wrk2/Wrk</li>\n    <li><a href=\"/projects/nighthawk\">Nighthawk</a></li>\n</ul>\n\nThe conclusion can be encapsulated as following, Meshery, the cloud native management plane possesses the ability to generate load and benchmark services in/out of your service mesh using Fortio, Wrk2 and now, Nighthawk too.\n\n### Meshery + Nighthawk = Robust Distributed and Scalable Services\n\nNighthawk, written and maintained by the Envoy Community, is a L7 (HTTP/HTTPS/HTTP2) performance characterization tool that supports performance benchmarking using HTTP or gRPC services.\n\nNighthawk is built using open-source builds and test tool Bazel and supports output formatting to well-known formats, allowing integration with other systems and dashboards. To add more to the list, it will soon support distributed performance benchmarking which is currently under an active development stage.\n\nOn the other hand, Meshery, written and maintainer by Layer5 Community is the multi-service mesh management plane offering lifecycle, configuration and performance management of service meshes and their workloads. With Meshery, you can both, manage your service mesh's lifecycle, and benchmark them with industry-grade tools to let you know how much under or over-utilized your services are.\n\n<img src={smpImg} alt=\"smp-image\" className=\"image-left smp-image\"/>\n\nSoon, Meshery is going to be a canonical implementation for [Service Mesh Performance](https://github.com/layer5io/service-mesh-performance) which is a common and standardised format to describe : - Performance test configuration - Service mesh configuration - Environment configuration - Workload configuration - Performance test results.\n\n### How did we achieve it ?\nThe following project was proposed as a Google Summer of Code Idea, I was selected as a student mentee to draft the design, architecture and code my way from scratch. On my journey, I received guidance from some amazing mentors, colleagues and open-source stake holders. I discussed the design proposal with Envoy Team as well as Layer5 Team and from suggestions from both, I was able to complete my project.\n\nIn the course of the project, I came up with the idea of invoking Nighthawk as a separate container with which Meshery will communicate using a go-lang based middleware.\n\nTo my elation, the project was a huge success and Nighthawk is now invoked as a load-generator in Meshery. Soon, the public release for the new version will be made and users will be able to utilize Nighthawk as a performance-benchamark tool alongside with Fortio and Wrk2.\n\n### What's next?\nThis is just the first relay, in the long run, there are many more milestones to come. The following is a list of projects which will be completed in upcoming months:\n\n- Invoke Nighthawk as an gRPC Service and support gRPC connection between Nighthawk & Meshery.\n- Implement user-profiles for performance benchmarking which may store some preset preferred values according to users.\n- Enhance Nighthawk to support distributed load generation and performance benchmarking.\n- NATS & gRPC Performance Benchmarking for gRPC and NATS services invoked in Meshery.\n\nand many more awesome and bleeding-edge ideas.\n\n### How can I get involved?\nIf any of this sounds remotely exciting, I implore you to give this a chance. You won’t regret it. Head over to our [Slack Channel](http://slack.layer5.io) and join the #performance channel where everything related to performance testing is discussed. We would love to hear your feedback. Stay tuned for more blogs related to Performance Benchmarking, SMI Conformance and all things meshy!!!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Performance benchmarking using Meshery and Nighthawk","type":"Blog","technology":null,"product":"Nighthawk","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp","srcSet":"/static/093f9cfbcb5c36ac072615fe97352342/4a552/mesheryctl.webp 750w,\n/static/093f9cfbcb5c36ac072615fe97352342/571ff/mesheryctl.webp 1080w,\n/static/093f9cfbcb5c36ac072615fe97352342/1866d/mesheryctl.webp 1366w,\n/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/093f9cfbcb5c36ac072615fe97352342/mesheryctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp","srcSet":"/static/093f9cfbcb5c36ac072615fe97352342/4a552/mesheryctl.webp 750w,\n/static/093f9cfbcb5c36ac072615fe97352342/571ff/mesheryctl.webp 1080w,\n/static/093f9cfbcb5c36ac072615fe97352342/1866d/mesheryctl.webp 1366w,\n/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/093f9cfbcb5c36ac072615fe97352342/mesheryctl.webp"}},"fields":{"slug":"/blog/performance/performance-benchmarking-using-meshery-and-nighthawk"}},{"id":"41186fe5-9702-5f79-9115-7013aba6492e","body":"\n\nimport conformance from \"./conformance-results.webp\";\n\n<BlogWrapper>\n\nReleased on August 5th, 2020 by Microsoft, [Open Service Mesh](https://openservicemesh.io/) (OSM) is a lightweight and [Service Mesh Interace conformant](https://layer5.io/smi) (SMI). Open Service Mesh is a contemporary addition to the [service mesh landscape](/service-mesh-landscape). Using Envoy as its data plane proxy component and SMI specifications as it's control plane APIs, OSM draws lessons and code from existing service mesh projects, like Linkerd. The Open Service Mesh project has some miles to go as it is one of a growing list of choices available in the service mesh landscape.\n\nFirst pronounced to be SMI compliant by [Meshery](https://meshery.io/), the cloud native management plane, the first release of OSM supports a myriad of basic\n\n<ul>\n    <li>Securing service to service links</li>\n    <li>Supporting traffic shifting</li>\n    <li>Managing observability for your services</li>\n    <li>Validating and Implementing access control policies</li>\n    <li>Auto addition of applications and services</li>\n</ul>\n\n### Get started with OSM using Meshery\nIn Layer5's effort to support our multi-mesh world, our Meshery project provides an effortless way for Kubernetes operators to install, maintain and run service meshes. [Meshery v0.4.3](https://github.com/layer5io/meshery/releases/tag/v0.4.3) includes the [Meshery Adapter for Open Service Mesh](https://github.com/layer5io/meshery-osm), enabling you to quickly provision OSM, run any number of sample applications, manage its performance using [Service Mesh Performance](https://smp-spec.io/) (SMP), validate OSM's compliance to SMI using a suite of conformance tests. Meshery offers configuraiton management with builtin best practice configuration analysis giving you confidence in applying custom configuration to OSM. Meshery's documenation on the [Open Service Mesh integation](https://docs.meshery.io/service-meshes/adapters/osm) provides a complete walkthrough on how to get set up, install, deploy and configure OSM according to your needs.\n\n<img src={conformance} className=\"\" alt=\"meshery-smi-conformance-results-image\" />\n\nTry Open Service Mesh now, by [getting started with Meshery](/cloud-native-management/meshery/getting-started).\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing the Meshery Adapter for Open Service Mesh","type":"Blog","technology":null,"product":"Meshery","mesh":"Open Service Mesh","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBdgBDvIHyHlAAD+9R5BqQSsiWNeJNqE7PLbzQ9M/Tvb9CSqaIr+n2R5upIraZpU7CzXHZesE7BZyYNioCJXqMKKJGxFbL89G+X6eR3+pLo8zCJoAAAA"},"images":{"fallback":{"src":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp","srcSet":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/280d5/meshery-open-service.webp 750w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/5b49f/meshery-open-service.webp 1080w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/f8bdf/meshery-open-service.webp 1366w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5010416666666666}},"extension":"webp","publicURL":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/meshery-open-service.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBdgBDvIHyHlAAD+9R5BqQSsiWNeJNqE7PLbzQ9M/Tvb9CSqaIr+n2R5upIraZpU7CzXHZesE7BZyYNioCJXqMKKJGxFbL89G+X6eR3+pLo8zCJoAAAA"},"images":{"fallback":{"src":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp","srcSet":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/280d5/meshery-open-service.webp 750w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/5b49f/meshery-open-service.webp 1080w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/f8bdf/meshery-open-service.webp 1366w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5010416666666666}},"extension":"webp","publicURL":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/meshery-open-service.webp"}},"fields":{"slug":"/blog/open-service-mesh/announcing-the-meshery-adapter-for-open-service-mesh"}},{"id":"ea2400da-2d3b-59c7-be79-7831ba9fc7fc","body":"\n\nimport operator from \"./meshery-operator-dark.svg\";\nimport MesheryArchitecture from \"./meshery-architecture.webp\";\n\n<BlogWrapper>\n\n[Meshery](https://meshery.io) is the cloud native management plane offering lifecycle, configuration and performance management of service meshes and their workloads.\n\nLayer5 community members are hard at work providing our users with easy access to any service mesh and myriad management features. New releases for Meshery are published on a frequent cadence with new features and bug fixes. Today, we are announcing version 0.4.0 of Meshery. This summary highlights Meshery's latest developments and elucidates new features.\n\n## What's New?\n\nThe v0.4.0 release of Meshery introduces a plethora of new features and bug fixes across service mesh environments spanning Meshery and it's various adapters.\n\n### Meshery's CLI: `mesheryctl`\n**New Command Structure**<br/>\n`mesheryctl` commands and subcommands have been restructured in v0.4.0 into the categories:\n- Global Commands and Flags\n- Meshery Lifecycle Management\n- Performance Management\n- Service Mesh Lifecycle Management\n- Workload Lifecycle Management\n\nOrganizing commnands [under these categories](https://docs.meshery.io/reference/mesheryctl) is done with both the intention to make `mesheryctl` functions intuitively at your fingertips, but also to make room for forthcoming functionality.\n\n**Exposing Performance Management in the CLI**<br/>\n`perf:` a new `mesheryctl`command. Introduction of new performance sub-commands, now benchmark your service mesh at the tip of your fingers using our new CLI command `perf`.\n\n**Support for Scoop** <br/>\nSupport extended to Scoop Bucket. You can now install mesheryctl on your Windows machine with Scoop Bucket. Visit the [Meshery Scoop Bucket](https://github.com/layer5io/scoop-bucket) to install Meshery on Windows.\n\n**Rename `cleanup` to `reset`**<br/>\nThe `cleanup` is used to reset your Meshery deployment configuration back to its default settings. This command has been renamed to `reset` to more appropriately reflect its purpose.\n\n### MeshSync<br/>\n<img src={operator} className=\"image-right\" alt=\"meshery-operator-dark\" />\n\n-  A component of the [Meshery Operator](https://github.com/layer5io/meshery-operator), MeshSync can scan the environment to get the deployment details of specific types of service meshes and the connected Kubernetes cluster.\n-  MeshSync is a new component addition to Meshery. Meshery needs to be constantly updated given that service meshes and their underlying infrastructure are dynamic, constantly changing.  Meshery operations should be resilient in the face of this change.\n-  MeshSync brings a service mesh agnostic object model that defines relationships between all objects under management.\n\n### Meshery Adapter for Citrix Service Mesh (beta)<br/>\n\n<img src={MesheryArchitecture} className=\"image-right\" alt=\"meshery-architecture\" />\n\n- [Citrix Service Mesh](https://github.com/layer5io/meshery-cpx) is now a supported service mesh. Meshery incorporates support for the Citrix ADC CPX, which is a cloud-ready, container-based application delivery controller that can be provisioned on a Docker host.\n- CPX runs as the Istio Data Plane component, displacing Envoy as the default data plane service proxy.<br/>\n\n### Security & Authentication\n\n- Meshery has moved from using session authentication to JWT authentication. Meshery's JWT authentication is powered by Hydra Auth.\n- You can now opt to authenticate yourself on mesheryctl while performing performance tests using `mesheryctl`, you can authenticate yourself by getting the JWT Token from Meshery UI.\n\n### Meshery Server\n\n- Support provided for [wrk2 as an alternative load generator](https://docs.meshery.io/functionality/performance-management#load-generators).\n- [Providers](https://docs.meshery.io/extensibility) - A new project construct that allows users to select authentication, long-term storage etc.\n- Ad-hoc [connectivity tests for Prometheus and Grafana](https://docs.meshery.io/functionality/performance-management#grafana-and-meshery) are now supported.\n- Extraneous information beyond IP address and port in Grafana and Prometheus endpoints have been stripped off.\n\n### Meshery UI\n\n- ES-Lint has been added to the client side to ensure the quality of code and increase maintainaiblity of code.\n- Cypress has been set-up to enable end-to-end tests and integration tests for Meshery UI.\n\n<center><iframe frameBorder=\"0\" width=\"100%\" height=\"300\" allowFullScreen={true} mozallowFullScreen=\"true\" webkitallowFullScreen=\"true\"frameBorder=\"0\" width=\"100%\" height=\"300\" allowFullScreen={true} mozallowFullScreen=\"true\" webkitallowFullScreen=\"true\" src=\"https://www.youtube.com/embed/ds9D2KgZKxo\" loading=\"lazy\"></iframe></center>\n\n\n### Other notable changes\n\n- From within the [Meshery Continuous Integration Working Group](https://www.youtube.com/watch?v=ds9D2KgZKxo&list=PL3A-A6hPO2IM7rYiKxG4l3eQNc6X3IUex), we have strengthened our continuous integration (CI) actions & tests by introducing new workflows like `static check`, `vet check`, `security check` for our server code.\n- ReleaseDrafter & WelcomeBot has been added to the repository to enable automation of release notes and for welcoming new contributors, respectively.\n\nTo get a more comprehensive list of the bug fixes and enhancements packaged in the v0.4.0 release, see the [Meshery Documentation](https://docs.meshery.io/project/releases)\n\n\n_**P.S.: If these topics excite you and you want to explore the beautiful realm of service meshes, come and say \"Hi\" on our [Slack Channel](http://slack.layer5.io) and one of us will reach out to you!**_\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing Meshery v0.4.0","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsoAAABXRUJQVlA4WAoAAAAQAAAAEwAADAAAQUxQSGYAAAABgCsAgIHqqtHm5JrcZNvWxqvd2GwbYz1u7yf5ARGR4N+JIZRCqIZQBSQ+aIdJPY+dC3seH6nRZlTtfN27zv5n8B0Vs5jm+2qmdSqD7LBa0lUQRfBdDgvPIlGJVCQJR0JTiTjw/wBWUDggPgAAADADAJ0BKhQADQA+0VakS6gko6GwCAEAGglpAAB60b/b/AAA/vAi9+Ax+ANYXYVXicTSFmjmW1J3l211gAAA"},"images":{"fallback":{"src":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp","srcSet":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp 500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.666}},"extension":"webp","publicURL":"/static/af2d9c15a09697b2ad48556b58102cd8/meshery-v040.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsoAAABXRUJQVlA4WAoAAAAQAAAAEwAADAAAQUxQSGYAAAABgCsAgIHqqtHm5JrcZNvWxqvd2GwbYz1u7yf5ARGR4N+JIZRCqIZQBSQ+aIdJPY+dC3seH6nRZlTtfN27zv5n8B0Vs5jm+2qmdSqD7LBa0lUQRfBdDgvPIlGJVCQJR0JTiTjw/wBWUDggPgAAADADAJ0BKhQADQA+0VakS6gko6GwCAEAGglpAAB60b/b/AAA/vAi9+Ax+ANYXYVXicTSFmjmW1J3l211gAAA"},"images":{"fallback":{"src":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp","srcSet":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp 500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.666}},"extension":"webp","publicURL":"/static/af2d9c15a09697b2ad48556b58102cd8/meshery-v040.webp"}},"fields":{"slug":"/blog/announcements/announcing-meshery-v040"}},{"id":"47a58ab5-c67e-52d4-ae1d-1623eeab8aed","body":"\n\nimport listioLayer5 from \"./layer5-and-istio.webp\";\nimport img1 from \"./image1.webp\";\nimport img2 from \"./image2.webp\";\nimport img3 from \"./image3.webp\";\nimport img4 from \"./image4.webp\";\n\n<BlogWrapper>\n\n<img src={listioLayer5} className=\"image-left\" alt=\"Layer5 and Istio\" />\n\nRecently, I started learning on Service Mesh and it was a very interesting journey as I explored the Service Mesh\nlandscape starting with [Layer5 tutorials](https://github.com/layer5io/istio-service-mesh-workshop) and by exploring\nthe blogs at [Istio.io](https://istio.io/).\n\nOur organization decided to use the features of Istio for securing, managing and automating microservices. However, we have to support a multi-tenant environment and that became a challenge due to lack of sufficient documentation and clarity. To give a little bit of background on the problem, we have a single cluster with multiple tenants in different namespaces sharing the same cluster . We do not want to provide each tenant their own separate Kubernetes Cluster because that would be additional provisioning overhead, management overhead and also additional resource overhead on the platform.\n\nIn this blog, I will go over the concepts and visual representation as well as the steps to learn and build your setup.\nNow there are different combinations possible depending on the requirements. These could be :\n\n1. Single Istio Control Plane with its own Ingress-Gateway to ensure traffic for the control plane is coming via the same control plane Ingress-Gateway.\n1. One or more Workspace namespaces for the workload applications and each with its own instance of the ingress gateway\n1. More advanced scenario would be multiple Control Plane and its associated Data Plane or essentially Multiple Service Mesh within a single Kubernetes Cluster. This is presently feasible using the Maistra Istio Operator, but its not fully supported using the upstream Istio at present. I intend to go over this use case in a later article.\n\nHere by Ingress Gateway we mean the Istio Ingress Gateway and not the Kubernetes Ingress Gateway.\nNow, before we get into the steps for building an Istio Multi-tenant setup, lets quickly review the prerequisite :\n\n- Kubernetes setup (in the steps below I am using v1.18 on ubuntu 18.04)\n\n  ```sh\n  $ sudo apt-get install -y docker.io\n  $ sudo sh -c “echo ‘deb http://apt.kubernetes.io/ kubernetes-xenial main’ >> /etc/apt/sources.list.d/kubernetes.list”\n  $ sudo sh -c “curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -”\n  $ sudo apt-get update\n  $ sudo apt-get install -y kubeadm=1.18.1–00 kubelet=1.18.1–00 kubectl=1.18.1–00\n  $ sudo kubeadm init — kubernetes-version 1.18.1 — pod-network-cidr 192.168.0.0/16\n  $ mkdir -p $HOME/.kube\n  $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  $ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n  $ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\n  ```\n\n- Get the latest istioctl binary\n\n  ```sh\n  $ curl -L https://git.io/getLatestIstio | sh -\n  cd istio-*\n  export PATH=$PWD/bin:$PATH\n  istioctl version\n  ```\n\n- Initialize the Istio Operator\n  ```sh\n  $ istioctl operator init\n  Using operator Deployment image: docker.io/istio/operator:1.6.3\n  ✔ Istio operator installed\n  ✔ Installation complete\n  $ kubectl get all -n istio-operator\n  NAME READY STATUS RESTARTS AGE\n  pod/istio-operator-5998f6c744-vrkbk 1/1 Running 1 78m\n  NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n  service/istio-operator ClusterIP 10.107.183.94 <none> 8383/TCP 78m\n  NAME READY UP-TO-DATE AVAILABLE AGE\n  deployment.apps/istio-operator 1/1 1 1 78m\n  NAME DESIRED CURRENT READY AGE\n  replicaset.apps/istio-operator-5998f6c744 1 1 1 78m\n  ```\n\nNext we will look into the details of the multitenancy scenarios; but before that a few word on the Istio operator would be nice. The Istio Operator follows the Kubernetes Controller and Custom Resource Definition mechanism and basically the above steps create an Istio operator controller in the istio-operator namespace and also registers the CRDs in the Kubernetes Registry. Basically, it extends the API for Kubernetes and allows management of a Custom Resource(CR). A word of caution, the existing upstream Istio Operator does not follow any Operator Framework like kubebuilder or Operator SDK. Hence, many of the expected behavior fail like trying to create two Istio Operator Custom Resource(the community mentions it as `iop` instances) in different namespaces or multiple `iop` instances and are under heavy development.\n\nOk, so now lets jump into action. We will build our Istio Setup for the scenario 1 &2 above shown in the diagram below. There are three different instances of Ingress Gateway(and it could be egress gateway as well) :\n\na. Ingress Gateway in Control Plane for traffic entry point to the Control plane Observability Components like `Kiali`(for the Service Mesh Graph), `Prometheus`(for metrics),Grafana(for visual charts of the metrics)and `Jaeger` (for distributed tracing between the services)\nb. Ingress Gateway in the Worskpace 1 namespace for traffic entry point to the workspace 1 microservices.\nc. Ingress Gateway in the Worskpace 2 namespace for traffic entry point to the workspace 2 microservices.\n\n<img src={img1} alt=\"kubernetes-cluster\" />\n<p style={{align: \"center\"}}>\n  Single Control Plane with Multiple Data Plane each with separate Ingress\n  Gateway\n</p>\n\n- Creation of Control Plane CR and Data Plane CR\n  A sample CR for creation of the Control plane and Data Plane CR can be referred below :\n  ```sh\n  $ cat iop-platform.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: platform-istiocontrolplane\n  spec:\n  profile: demo\n  $ cat iop-wk1-gw.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: wk1-gwconfig\n  spec:\n  profile: empty\n  components:\n  ingressGateways:\n  — name: wk1-ingressgw\n  namespace: workspace-1\n  enabled: true\n  label:\n  istio: ingressgateway-1\n  app: istio-ingressgateway-1\n  values:\n  gateways:\n  istio-ingressgateway:\n  debug: error\n  $ cat iop-wk2-gw.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: wk2-gwconfig\n  spec:\n  profile: empty\n  components:\n  ingressGateways:\n  — name: wk2-ingressgw\n  namespace: workspace-2\n  enabled: true\n  label:\n  istio: ingressgateway-2\n  app: istio-ingressgateway-2\n  values:\n  gateways:\n  istio-ingressgateway:\n  debug: error\n  ```\n\nIt is important to make sure the indentation is correct ,otherwise it would lead to errors.\nReference: [Istio Website](https://istio.io/latest/docs/setup/install/)\n\nDeploy the CRs using kubectl:\n\n```sh\n$ kubectl create ns istio-system\n$ kubectl create ns workspace-1\n$ kubectl create ns workspace-2\n$ kubectl apply -f ../iop-platform.yaml\nistiooperator.install.istio.io/platform-istiocontrolplane created\n$ kubectl apply -f ../iop-wk1-gw.yaml\nistiooperator.install.istio.io/wk1-gwconfig configured\n$ kubectl apply -f ../iop-wk2-gw.yaml\nistiooperator.install.istio.io/wk2-gwconfig configured\n```\n\n- Troubleshooting the Istio Operator Controller.\n  Its a good idea to run another window and execute the below command to observe the running logs on the controller pod.\n  ```sh\n  $ kubectl logs -f -n istio-operator\n  $(kubectl get pods -n istio-operator -lname=istio-operator -o jsonpath=’{.items[0].metadata.name}’)\n  ```\n\n<img src={img2} alt=\"image\" />\n\n- Observe the created objects in istio-system and the workspace namespaces for all pods to be in running state.\n\n  ```sh\n  $ kubectl get all -n istio-system\n  NAME READY STATUS RESTARTS AGE\n  pod/grafana-b54bb57b9-k84xf 1/1 Running 0 79s\n  pod/istio-egressgateway-77c7d594c5-fr79j 1/1 Running 0 83s\n  pod/istio-ingressgateway-766c84dfdc-p6g6t 1/1 Running 0 83s\n  pod/istio-tracing-9dd6c4f7c-ndjvn 1/1 Running 0 79s\n  pod/istiod-7b69ff6f8c-9gwp8 1/1 Running 0 94s\n  pod/kiali-d45468dc4–4sww2 1/1 Running 0 79s\n  pod/prometheus-5fdfc44fb7–67khx 2/2 Running 0 78s\n  <truncated>\n  esudbat@istio:~/istio$ kubectl get all -n workspace-1\n  NAME READY STATUS RESTARTS AGE\n  pod/wk1-ingressgw-5674488c8b-fg2w5 1/1 Running 0 21s\n  <truncated>\n  esudbat@istio:~/istio$ kubectl get all -n workspace-2\n  ```\n\n- Now we will label the namespaces for istio-injection\n\n  ```sh\n  $kubectl label namespace workspace-1 istio-injection=enabled\n  $kubectl label namespace workspace-2 istio-injection=enabled\n  ```\n\n- Now we will deploy the bookinfo sample application in both namespaces but before that we need to make sure that the Gateway resource is updated with the correct label selector as below :\n\n  ```sh\n  $ cat istio/bookinfo-gateway-1.yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: Gateway\n  metadata:\n  name: bookinfo-gateway\n  spec:\n  selector:\n  istio: ingressgateway-1 # use istio gateway-1 controller in workspace-1\n  servers:\n  — port:\n  number: 80\n  name: http\n  protocol: HTTP\n  hosts:\n  — “*”\n  $ cat istio/bookinfo-gateway-2.yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: Gateway\n  metadata:\n  name: bookinfo-gateway\n  spec:\n  selector:\n  istio: ingressgateway-2 # use istio gateway-2 controller in workspace-1\n  servers:\n  — port:\n  number: 80\n  name: http\n  protocol: HTTP\n  hosts:\n  — “*”\n  ```\n\nDeploy the applications in workspace-1 and workspace-2 and deploy the Gateway,VirtualService and DestinationRules.\n\n```sh\n$kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n workspace-2\n$kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml -n workspace-2\n$kubectl apply -f samples/bookinfo/networking/destination-rule-all-mtls.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/networking/destination-rule-all-mtls.yaml -n workspace-2\n```\n\nEssentially what is happening is the Gateway CR is configuring the traffic to come via the ingress-gateway, it specifies the label selector based on which the ingress-gateway is selected and the host from where the traffic is allowed and port on which the traffic is allowed. It is important to ensure the label maps the label on the ingress-gateway.\nOnce this is done the traffic will start flowing the intended gateway and it could be observed on the Kiali dashboard.\nPlease note that in this scenario the Kiali is also accessed via the default control plane ingress-gateway running in the istio-system control plane namespace.\n\n<img src={img3} alt=\"image\" />\n<p style={{align: \"center\"}}>Kiali view for Workspace-1</p>\n\n<img src={img4} alt=\"image\" />\n<p style={{align: \"center\"}}>Kiali view for Workspace-2</p>\n\nShortly, we will go over the 3rd scenario which is to run multiple Istio Control Planes (Multiple Service Meshes) within the same Kubernetes Cluster. For that, we will need to build an open-shift setup and deploy the Maistra Istio Operator.\nSpecial thanks to the [Istio Community](https://istio.slack.com/) for helping me understand the concepts and also answering my queries and of course to [Lee Calcote](https://calcotestudios.com/talks/), who helped me embark on my Istio journey.\n\n<div>\n  <b>\n    Connect with Sudeep Batra on\n    <a href=\"https://www.linkedin.com/in/sudeep-batra\"> LinkedIn</a>,<a href=\"https://github.com/sb1975\">\n      {\" \"}GitHub</a>, or\n    <a href=\"https://twitter.com/sudeepbatra\"> Twitter</a>.\n  </b>\n</div>\n\n</BlogWrapper>\n","frontmatter":{"title":"Service Mesh (Istio) patterns for Multitenancy","type":"Blog","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAAAwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJaQAAetGLLsAAAP7vhDiT/XpMBU3mvncWVJalRVYSIAAA"},"images":{"fallback":{"src":"/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp","srcSet":"/static/6126014dd6a4c684993008406f28dae0/1f1d0/image2.webp 750w,\n/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.638095238095238}},"extension":"webp","publicURL":"/static/6126014dd6a4c684993008406f28dae0/image2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAAAwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJaQAAetGLLsAAAP7vhDiT/XpMBU3mvncWVJalRVYSIAAA"},"images":{"fallback":{"src":"/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp","srcSet":"/static/6126014dd6a4c684993008406f28dae0/1f1d0/image2.webp 750w,\n/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.638095238095238}},"extension":"webp","publicURL":"/static/6126014dd6a4c684993008406f28dae0/image2.webp"}},"fields":{"slug":"/blog/istio/service-mesh-istio-patterns-for-multitenancy"}},{"id":"933fdd2b-b2a4-5371-bb9a-f047b72e3e23","body":"\n\nimport smilogo from \"./smi-logo.webp\";\nimport checklist from \"./checklist.svg\"\n\n<BlogWrapper>\n\n<img src={smilogo} align=\"right\" alt=\"smilogo\" width=\"200px\" style={{margin: \"1rem 2rem\"}} />\n\n### About SMI\n\nThe Service Mesh Interface (SMI) is a specification for service meshes that run on Kubernetes. It utilizes CRDs to modify the behavior of service meshes. The project is under development at [SMI Github Repository](https://github.com/servicemeshinterface/smi-spec). Please visit the github repository page to know the latest advancements in the characteristics. The complete spec can be found [here](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md).\n\n### APIs in SMI\n\nCurrently SMI supports 4 set of APIs:\n\n- [Traffic Specs](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-specs) - Used to define traffic, currently only supports TCP, HTTP traffic.\n- [Traffic Access Control](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-access-control) - Used to specify whether a particular form of traffic is allowed or not\n- [Traffic Split](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-split) - Used to redirect/divide a request for a resource between 2 or more resources. Useful in canary testing\n- [Traffic Metrics](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-metrics) - Used to expose common traffic metrics like p99 in a specific format that can be utilized by single dashboard for all the service meshes.\n\n### About SMI Conformance Tests\n\n**SMI Conformance Tests** check whether the service mesh that is installed in the kubernetes cluster, conforms to SMI specs or not. This involves asking some major questions. Does it have the required CRDs? Do these CRDs perform as they should when applied or not applied? Are we able to get metrics in a proper format?\n\nAll these questions will be answered by SMI conformance tests. The biggest benefit of your service mesh conforming to SMI is that it makes building tools an easier process.Also, one time development of any tool would in turn support all the meshes that conform to SMI.\n\nSounds fun, right? Let's dig deeper into the SMI conformance project and find out.\n\n### Meshery'ing with Conformance Tests\n\n<img src={checklist} align=\"left\" alt=\"checklist\" width=\"250px\"/>\n\n<Link to=\"/cloud-native-management/meshery\">Meshery</Link>  is _the cloud native management plane__. It supports all the popular meshes, teaches you how to manage them, assists you in applying custom or recommended configurations, tests for  compatibility, performs performance tests for meshes and a lot more. The SMI conformance testing requires performance testing capabilities, load generation (Meshery is about to support distributed load generation as well), and other functionalities such that these conformance tests can be easily used in the pipelines of all the popular service meshes. mesheryctl does have a perf command that can be used in the pipelines of service meshes. I aim at making such capabilities for SMI conformance as well.\n\nAs you have made your way halfway through the post (thank you for your patience), you should now be aware of SMI, its conformance practices and how Meshery’s incredible engineering can be utilized for conformance tests. We can now tackle the larger questions and hope to see the bigger picture.\n\n### The Bigger Picture\n\nDo you know that almost all of the test cases that we would write in this project would be  raw YAML files? To those doing traditional unit and integration tests, we might sound unhinged at this point. We assure you that we are completely sober and serious (if you don’t count the temporary euphoria from geeky jokes).\n\n#### Forking [kuttl](https://kuttl.dev/)\n\n`kuttl` is a tool for writing tests against Kubernetes operators and controllers. It can ascertain whether any kind of resources exist or not in the Kubernetes cluster, spring up a kind cluster and do other convenient things. Another plus is that It's entirely declarative. Consider a scenario in which we have a special use case where we wanted to run some go code  after each individual step in the test case was executed. To accomplish this, we forked `kuttl` and modified it a little. You can see our modified version [here](https://github.com/kanishkarj/kuttl).\n\n\nWe are planning to use `kuttl` for all the APIs in SMI. We are also planning to use the Meshery load generator with the modified version of `kuttl`.\n\n#### [Learn Layer5](https://github.com/layer5io/learn-layer5/)\n\nLearn Layer5 is a sample app which is very lightweight and simple to deploy. It is a simple sample app for learning about service meshes. We are planning to use the same app for testing for SMI conformance. The app is deployed when we test for SMI conformance and traffic is generated from one service/deployment/pod to another. This is a great tool for playing around with service meshes and the tools provided by Layer5 and its projects without investing any personal resources.\n\nThis is where all the test cases along with the code will be placed. Currently, there is a large overlap in the learn-layer5 and `smi-conformance` testing files. All those changes will be transferred here.\n\nIf any of this sounds remotely exciting, I implore you to give this a chance. You won’t regret it.\nHead over to our [Slack Channel](http://slack.layer5.io) and join the #smi channel where everything related to conformance testing is discussed. We would love to hear your feedback. Stay tuned for more blogs related to SMI Conformance and all things meshy!!!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Starting SMI Conformance Testing with Meshery","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/d0daea53e35a8641bb6bf51dfd650543/smi-conformance.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/d0daea53e35a8641bb6bf51dfd650543/smi-conformance.svg"}},"fields":{"slug":"/blog/programs/starting-smi-conformance-testing-with-meshery"}},{"id":"bbc29500-fde1-5510-8899-cab604e7f720","body":"\n\n\n<NewsWrapper>\n\nMeshery took its first steps into the Cloud Native world in July of 2019 with the vision to ease the adoption and operation of any service mesh. Since then, Meshery as a project and Layer5 as an open source community has grown by leaps and bounds. Now, right at a year later, we are bursting with pride in announcement of:\n\n<h3 style={{textAlign: \"center\"}}>Meshery is officially accepted into the Cloud Native Computing Foundation's Landscape!</h3>\n\n<br/>\nRead about our journey in the words of one of our valued contributors and proud Meshery user, Anton Weiss: <br/>\n<i>\n\"Open source contributions are a must-do for becoming a true cloud native hero. Cloud native is all about the community and one can't be a part of a community by only taking and never giving back. So, if you were looking for a promising and welcoming project to join - look no further! <br/> Hop on to Layer5 Slack and we'll happily embrace you and help you get started. And it's not only coding! Documentation, testing, UI design, logos, blogs, videos - you decide where to apply your talent.\"\n</i>\n<br/>\n\n</NewsWrapper>\n","frontmatter":{"title":"Meshery accepted into the CNCF Landscape","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/3c4752fd98e56b683603598033f1c84b/cncf-landscape-horizontal-color.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/3c4752fd98e56b683603598033f1c84b/cncf-landscape-horizontal-color.svg"}},"fields":{"slug":"/company/news/meshery-accepted-into-the-cncf-landscape"}},{"id":"fbdb0105-a11c-58b8-b99e-f59449dd09f9","body":"\n\nimport cncf from \"./cncf-landscape-stacked-color.svg\"\nimport cncfmeshery from \"./cncf-meshery-landscape.webp\"\n\n<BlogWrapper>\n\n<img src={cncf} className=\"image-right\" alt=\"cncf-landscape-stacked-color\" />\n\n### Digging into Service Meshes\n\nAbout a year and a half ago I got interested in service mesh technology. A customer needed some advanced routing capabilities and we started looking at Envoy and Istio. Then - invitations to talk about Istio at meetups and conferences started flowing in. That's when I got excited about progressive delivery capabilities that service meshes enable. I even wrote a Kubernetes Istio canary controller - BirdWatch.\n\n### Finding Meshery\n\nDigging deeper into what service meshes had to offer I discovered Meshery - the universal service mesh management plane. And immediately joined Layer5 - the great, welcoming open-source community that created it.\n\n### Community Matters\n\nBeing a member of Layer5 was one of the nicest community experiences I've ever had. Mainly thanks to community's founder and captain - Lee Calcote. He always makes sure everybody feels significant, included and motivated to participate. And this spirit spreads out to all community activities.\n\nIn no time, I had my first commits approved and merged and started joining weekly community and development video calls.\n\n### We're on CNCF Landscape!\n\nNow - I won't be reviewing Meshery in this post. I've spoken about it in this video and some great introductory articles by community members can be found here and here. This post is more of a celebration, because last week...\n\n<h5 style={{textAlign: \"center\"}}><i>Meshery now featured in the CNCF Landscape!</i></h5>\n\n<img src={cncfmeshery} className=\"image-center\" alt=\"cncf-meshery-landscape\" />\n\nAnd this is only the first step - there's already an application filed for Meshery to become a full-fledged CNCF sandbox project. I had a chance to collaborate on the sandbox proposal and am so eager for this to happen.\n\n### Getting Meshy\n\nThis is also an invitation to participate - Meshery is a young, ambitious project - it requires a ton of work to make it what it aims to become. Integrating with all of the leading service mesh solutions asks for extensive expertise. In many areas Meshery's functionality is still young. But these are normal growth stages, aren't they? To put it simple - the community and the project need more hands! And these should be your hands!\n\n<p style={{textAlign: \"center\"}}><i>As already mentioned - Layer5 is a very welcoming bunch!</i></p>\n\nOpen source contributions are a must-do for becoming a true cloud native hero. Cloud native is all about the community and one can't be a part of a community by only taking and never giving back. So if you were looking for a promising and welcoming project to join - look no further! Hop on to Layer5 Slack and we'll happily embrace you and help you get started.\n\nAnd it's not only coding! Documentation, testing, UI design, logos, blogs, videos - you decide where to apply your talent.\n\nFor example - I sometimes wish I had more time and motivation to code new Meshery features or fix existing bugs. But instead I'm writing this post. Because lately I enjoy writing texts more than coding. Coding for longer than a couple of days at a time throws me into a coding fatigue… Actually also many other activities do. I'm just not very good at keeping a routine. But I'm sure many of you out there aren't like me. So why not join forces?\n\n### Join the cloud native community!\n\n* Meshery is an exciting opportunity to learn more about service meshes.\n* We're already on CNCF Landscape and are headed for the sandbox.\n* Now is a great time to hop on board. Are you ready? Get into the mesh pit!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Meshery lands in the CNCF Landscape","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQBACdASoUAAoAPtFUo0uoJKMhsAgBABoJZACdMoADgO9k6qEL53yk2sYAAP7Abw4XvX2jHGD89BNjRpE70cE2XMKPwIVX+4lLfd3o20v5GElRvyyyUrRwSFT2h/RDZdLxUwq/W4DautwG0qJ1AAAA"},"images":{"fallback":{"src":"/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp","srcSet":"/static/c201715de532db5e6e35ab46bb613fee/678bf/cncf-meshery.webp 750w,\n/static/c201715de532db5e6e35ab46bb613fee/00510/cncf-meshery.webp 1080w,\n/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp 1250w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504}},"extension":"webp","publicURL":"/static/c201715de532db5e6e35ab46bb613fee/cncf-meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQBACdASoUAAoAPtFUo0uoJKMhsAgBABoJZACdMoADgO9k6qEL53yk2sYAAP7Abw4XvX2jHGD89BNjRpE70cE2XMKPwIVX+4lLfd3o20v5GElRvyyyUrRwSFT2h/RDZdLxUwq/W4DautwG0qJ1AAAA"},"images":{"fallback":{"src":"/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp","srcSet":"/static/c201715de532db5e6e35ab46bb613fee/678bf/cncf-meshery.webp 750w,\n/static/c201715de532db5e6e35ab46bb613fee/00510/cncf-meshery.webp 1080w,\n/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp 1250w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504}},"extension":"webp","publicURL":"/static/c201715de532db5e6e35ab46bb613fee/cncf-meshery.webp"}},"fields":{"slug":"/blog/announcements/meshery-lands-in-the-cncf-landscape"}},{"id":"251537a7-cdcc-51ce-81cf-50a9e792197f","body":"\n\nimport layer5_hashicorp_partnership from \"./Layer5-HashiCorp-Service-Mesh-Partnership.webp\";\nimport layer5_image_hub from \"./layer5-image-hub-on-hashicorp-consul.webp\";\n\n<NewsWrapper>\n<link rel=\"canonical\" href=\"/company/news/layer5-and-hashicorp-launch-service-mesh-partnership\" />\n\n_Announced on May 28th, 2020 at DockerCon Live 2020._\n\n## Meshery Announces Native Support for Consul Service Mesh\n\nToday, we are pleased to announce the technology partnership of Layer5 and HashiCorp. Layer5’s [Meshery](https://layer5.io/cloud-native-management/meshery), the cloud native management plane, and HashiCorp’s [Consul](https://consul.io) integrate to provide advanced, cloud native infrastructure solutions for containerized and non-containerized workloads - strengths of Consul. The marriage of these technologies forms a layering of network planes: data, control, and management.\n\n<a href={layer5_hashicorp_partnership}><img src={layer5_hashicorp_partnership} alt=\"layer5-hashicorp-partnership\" width=\"100%\" /></a>\n\n_Service Mesh Planes: Consul and Meshery. Learn more about service mesh planes in [The Enterprise Path to Service Mesh Architectures](https://layer5.io/books/the-enterprise-path-to-service-mesh-architectures)._\n\nConsul’s broad and prevalent use across [any runtime or infrastructure](https://learn.hashicorp.com/consul/datacenter-deploy/reference-architecture) (bare metal servers, virtual machines, Kubernetes clusters, and any cloud) is a key facilitator of the modernization of IT infrastructure - a significant attractant for Layer5 to focus on this integration; to meet customers where they’re at. The lynchpin of the integration of Consul and Meshery is the Meshery Adapter for Consul. Through this adapter, Meshery facilitates lifecycle management of Consul service mesh deployments, evaluates and espouses configuration best practices published by HashiCorp. Meshery provides users with an interface to apply custom configuration to their Consul service mesh in an ad hoc fashion.\n\n### Lifecycle management of sample applications\n\nThe [Meshery Adapter for Consul](https://docs.meshery.io/service-meshes/adapters/consul) comes bundled with a handful of sample applications for evaluating, exploring, and learning how to operate Consul service mesh. Many operators are new to the ongoing administrative tasks of running a healthy and optimized Consul service mesh deployment. In advance of their production deployments, operators may utilize Meshery to quickly deploy Consul with sample applications to gain familiarity with the many features of Consul.\n\nDemonstrated at DockerCon 2020, is the “[Image Hub](https://github.com/layer5io/image-hub)”, a sample application built to allow users to explore Consul’s feature set, and specifically, an experimental area of Consul’s data plane: Envoy’s impending support for WebAssembly.\n\n### Performance management of Consul and it’s workloads\n\nIn order to assess the overall performance of the service mesh, and the overhead of individual, fine-grained traffic control mechanisms defined in Consul’s control plane and enforced through Consul’s intelligent data plane, Meshery provides users with statistical analysis of the responsiveness of their services and performance of the service mesh. As highlighted by Docker Captain, [Luc Juggery](https://twitter.com/lucjuggery), performance is an ongoing concern:\n\n<div style={{margin: \"20px\"}}>\nRunning a performance test is not a one shot thing. Tests should be run on a regular basis to (re)establish baselines and evaluate configuration changes:\n<ul>\n<li>- for each new release of the chosen service mesh</li>\n<li>- for each change of the configuration of your service mesh</li>\n<li>- for each new release of the application\"</li>\n</ul>\n</div>\n\nMeshery’s ability to connect to Prometheus instances to retrieve and account for cluster and application-level metrics is popularly used during Meshery’s service mesh performance tests. Likewise, Meshery’s ability to connect to and import existing dashboards, panels, and charts from Grafana is instrumental in allowing users to retain their existing investment in dashboards and metrics they have curated over time.\n\n## Meshery Announces Experimental Support for WebAssembly using Consul\n\nToday, at [DockerCon 2020](https://docker.events.cube365.net/docker/dockercon/content/Videos/63TCCNpzDC7Xxnm8b), we demonstrate technology leadership in advanced data plane engineering for near-native performance of fine-grained traffic control facilitated by Meshery and Consul with the use of Envoy and WebAssembly.\n\n<a href={layer5_image_hub}><img src={layer5_image_hub} alt=\"layer5-hashicorp-imagehub\" width=\"100%\" /></a>\n\n_In this demonstration, Meshery takes advantage of Consul’s use of Envoy. Envoy support for WebAssembly is impending._\n\n### WebAssembly’s near-native performance\n\nWebAssembly, or WASM, is an open standard that defines a binary format for executable programs. Through WebAssembly System Interface (WASI), it also defines interfaces for facilitating interaction with host environments. The initial focus of these host environments was browsers and large web applications with the intention of securely running programs to improve performance. As an open standard, WASM is maintained by the W3C, and has been adopted by all modern browsers. After HTML, CSS, and Javascript, WebAssembly is the fourth language to natively run in web browsers.\n\nWebAssembly is exciting because of its performance characteristics, running between 10% to 20% overhead as compared to natively executed code for network filtering use cases. WebAssembly bears some resemblance to Docker given its high degree of portability. Like the Java Virtual Machine (JVM), WASM’s virtual stack machine is becoming a write once, run anywhere (WORA). WASM executables are precompiled with a healthy variety of languages supporting it as a compilation target - currently about 40 languages.\n\nWASM support is coming to Envoy through the efforts of Google, and Envoy maintainers embedding Google's open source high-performance JavaScript and WebAssembly engine, V8, into Envoy. Through the WebAssembly System Interface, Envoy exposes an Application Binary Interface (ABI) to WASM modules, so that they can operate as Envoy filters. The way WASI works is straight-forward. You write your application in your favourite languages like Rust, C or C++. Then, build and compile them into a WebAssembly binary targeting the host environment. The generated binary requires the WebAssembly runtime to provide the necessary interfaces to system calls for the binary to execute. Conceptually, this is similar to JVM. If you have a JVM installed then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary.\n\n## Learn more\n\nThis integration of management, control, and data planes is a powerful combination. See Meshery and Consul in-action at [DockerCon 2020](https://docker.events.cube365.net/docker/dockercon/content/Videos/63TCCNpzDC7Xxnm8b). Learn more about [Layer5 and HashiCorp’s partnership](https://www.hashicorp.com/integrations/layer5-io/consul/).\n\n**About Consul**\n\nFor more information about Consul, please visit: [https://www.consul.io](https://www.consul.io).\n\n**About HashiCorp**\n\nFor more information about HashiCorp, please visit: [https://hashicorp.com](https://hashicorp.com)\n\n**About Meshery**\n\nFor more information about Meshery, please visit: [https://meshery.io](https://meshery.io)\n\n**About Layer5**\n\nFor more information about Layer5, please visit: [https://layer5.io](https://layer5.io)\n\n</NewsWrapper>\n","frontmatter":{"title":"Layer5 and HashiCorp Launch Service Mesh Partnership","type":"News","technology":"WebAssembly","product":"Meshery","mesh":"Consul","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpQAAABXRUJQVlA4IIgAAADwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJaQAD4coOltM3zZ3rJcoAAP7qVt1qgj75t4tSHc71Vn+D2BXmrz/efUjPU+mokWbpyHp9/p5q0ywR6Lv2yZZ0kDFBb8d0hb0HH6GF3sGgq02ng+tLemIT+URQs5nV3CV0rtFdBp7tNRXpaWaJKgAA"},"images":{"fallback":{"src":"/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp","srcSet":"/static/a36abfe42e42455496b77e017dce4822/ca8ed/layer5-hashicorp.webp 750w,\n/static/a36abfe42e42455496b77e017dce4822/8b691/layer5-hashicorp.webp 1080w,\n/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5275}},"extension":"webp","publicURL":"/static/a36abfe42e42455496b77e017dce4822/layer5-hashicorp.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpQAAABXRUJQVlA4IIgAAADwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJaQAD4coOltM3zZ3rJcoAAP7qVt1qgj75t4tSHc71Vn+D2BXmrz/efUjPU+mokWbpyHp9/p5q0ywR6Lv2yZZ0kDFBb8d0hb0HH6GF3sGgq02ng+tLemIT+URQs5nV3CV0rtFdBp7tNRXpaWaJKgAA"},"images":{"fallback":{"src":"/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp","srcSet":"/static/a36abfe42e42455496b77e017dce4822/ca8ed/layer5-hashicorp.webp 750w,\n/static/a36abfe42e42455496b77e017dce4822/8b691/layer5-hashicorp.webp 1080w,\n/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5275}},"extension":"webp","publicURL":"/static/a36abfe42e42455496b77e017dce4822/layer5-hashicorp.webp"}},"fields":{"slug":"/company/news/layer5-and-hashicorp-launch-service-mesh-partnership"}},{"id":"58ae43e0-f0b0-5c61-ab4f-b71e722508cc","body":"\n\n\n\n\n<BlogWrapper>\n\n### Introduction to Meshery\n\nFor all those who are unaware of <a href=\"/meshery\">Meshery</a>, Meshery is a multi-service mesh management plane which provides users with service mesh operational best practices, lifecycle and configuration management, but also interoperates between various service meshes, while enabling you with the tools and knowledge to glean the most of out your service mesh performance, while keeping your overhead to a minimum.\n\nMeshery's vision is to make the operating of any service mesh layer of cloud infrastructure simplified, and to hasten the inevitable, eventual, ubiquituous adoption service meshes as a pervasively present layer of any the way that any modern workload is designed and deployed. Meshery is created by the <Link to=\"/community\">Layer5</Link>.\n\nLayer5 is a community-first, service mesh company which has technology <Link to=\"/partners\">partnerships</Link> with various tech giants like Microsoft, HashiCorp, CNCF, RedHat and many more to enlist. The community consists of open source leaders like maintainers of trending open-source projects, Google SoCers, Docker Captains, service mesh maintainers, Cloud Native Ambassadors and many more (<a href=\"http://slack.layer5.io\">join in!</a>).\n\n\n### What is mesheryctl?\n\nMeshery provides you with a clean, robust, streamlined command-line interface to manage and benchmark your service meshes, `mesheryctl`. With `mesheryctl`, not only you can manage your adapters & containers but you can also benchmark your mesh using the command line. `mesheryctl` provides support to a number of platforms so that we never miss out users. `mesheryctl` can be installed with a single bash command by simply executing:\n\n```bash\n$ curl -L https://meshery.io/install | PLATFORM=kubernetes bash -\n````\n\nin your terminal. You will see Meshery getting installed & fired up on port: 9081.\nYou will see the output as\n\n\n```\nExtracting mesheryctl-v0.3.14...\nArchive:  /Users/user/meshery.zip\n  inflating: LICENSE\n  inflating: README.md\n  inflating: mesheryctl\n\nInstalling mesheryctl in /usr/local/bin.\nmesheryctl installed.\npermissions moved to user\nRemoving installation files and opening Meshery...Updating Meshery now...\nPulling meshery          ... download complete\nPulling meshery-istio    ... done\nPulling meshery-linkerd  ... done\nPulling meshery-consul   ... done\nPulling meshery-octarine ... done\nPulling meshery-nsm      ... done\nPulling meshery-cpx      ... done\nPulling watchtower       ... done\n```\n\nand you will be able to see the Meshery UI on `https://localhost:9081`.\n\nIf you are wondering if bash is only way to get `mesheryctl`, then here is the list of platforms which you can get `mesheryctl describing all the different ways to get it.\n\n<table className=\"table-1\" align=\"center\">\n<thead>\n    <tr>\n    <th align=\"left\">Platform</th>\n    <th >Supported?</th>\n    </tr>\n</thead>\n<tbody>\n    <tr>\n    <td ><a href=\"https://docs.meshery.io/installation/platforms/docker\">Docker</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/docker\">Docker - Docker App</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/platforms/kubernetes\">Kubernetes</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/aks\">Kubernetes - AKS</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/quick-start\">Kubernetes - Docker Desktop</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/eks\">Kubernetes - EKS</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/gke\">Kubernetes - GKE</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/kubernetes#helm\">Kubernetes - Helm</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/minikube\">Kubernetes - Minikube</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - Kubernetes - OpenShift</td>\n    <td className=\"text-centre\">In Progress</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/quick-start\">Linux</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/quick-start\">Mac</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/mesheryctl#homebrew\">Mac - Homebrew</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/platforms/windows\">Windows</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/mesheryctl#scoop\">Scoop</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/windows#wsl\">WSL2</a></td>\n    <td className=\"text-centre\">✔️</td>\n    </tr>\n    <tr>\n    <td>Raspberry Pi</td>\n    <td className=\"text-centre\">In Progress</td>\n    </tr>\n</tbody>\n</table>\n\n<br/>\nWe believe we have not missed any of the popular platforms for what it’s worth, we will be rolling out support for RaspberryPi and OpenShift soon 🎉🎉🎉.\n\nIf you are thinking about the requirements you would have to run `mesheryctl`, so to your surprise, to successfully run `mesheryctl` you will only need :\n\n<table align=\"center\" className=\"table-box\"><tbody><tr><td className=\"text-centre\">a running Docker daemon</td></tr></tbody></table>\n\n### Into the MesheryCTL\n\nOnce you have successfully installed, you will be having the power of a new CLI Command MesheryCTL. As you type `mesheryctl` into your terminal, you will be shown with the various sub-commands and flags `mesheryctl` can support.\n\n```\nMeshery is the cloud native management plane, providing lifecycle, performance, and configuration management of service meshes and their workloads.\n\nUsage:\n  mesheryctl [command]\n\nAvailable Commands:\n  help        Help about any command\n  perf        Performance Management\n  system      Meshery Lifecyle Management\n  version     Print mesheryctl version\n\n\nFlags:\n      --config string    config file (default location is: $HOME/.meshery//meshery.yaml)\n  -h, --help            help for mesheryctl\n  -v, --version         Version of mesheryctl\n\nUse \"mesheryctl [command] --help\" for more information about a command.\n```\n\nOnce you do `mesheryctl system start`, Meshery will pull its adapters and latest docker images. Meshery will also detect your Kubernetes configuration and will let you know if Kubernetes is running. Meshery will run it’s web-based user interface on localhost port `9081` and will let you select your choice of <a href=\"https://docs.meshery.io/extensibility#providers\">Provider</a> before you can start managing your service meshes with this powerful utility.\n\n<table align=\"center\" className=\"table-box\"><tbody><tr><td className=\"text-centre\">One of the most interesting sub-commands of <code>mesheryctl</code> is <strong><code>perf</code></strong>.</td></tr></tbody></table>\n\nThe `perf` subcommand enables you to being managing the performance of your service mesh deployment and your workloads running atop of them. It lets you benchmark your service mesh without using the Meshery UI from the command line interface itself. Once you type `mesheryctl perf`, it will present you with all the powerful flags you can control with CLI, including providing it with a `--file` flag that points to any of a number of performance test profiles that you may have saved.\n\n```\nPerformance Management and Benchmarking using Meshery CLI.\n\nUsage:\n  mesheryctl perf --[flags]\n\nAvailable Flags for Performance Command:\n  name[string]                  (optional) A short descriptor to serve as reference for this test. If not provided, a random name will be generate.\n  url[string]                   (required) URL endpoint to send requests.\n  duration[string]              (required) Length of time to perform test (e.g 30s, 15m, 1hr). See standard notation https://golang.org/pkg/time/#ParseDuration\n  load-generator[string]        (optional) Name of load generator to be used to perform test (default: \"fortio\")\n  mesh[string]                  (optional) Name of the service mesh to be tested (default: \"None\")\n  provider[string]              (required) Choice of Provider (default: \"Meshery\")\n  concurrent-requests[string]   (optional) Number of parallel requests to be sent (default: \"1\")\n  qps[string]                   (required) Queries per second (default: \"0\")\n  file[string]                  (optional) file containing SMPS-compatible test configuration. See https://github.com/layer5io/service-mesh-performance-specification\n  help                          Help for perf subcommand\n\nurl, duration, concurrent-requests, and qps can be considered optional flags if specified through an SMPS compatible yaml file using --file\n```\n\nAn example usage of `mesheryctl perf --[flags]` can be\n\n```bash\n mesheryctl perf --name \"a quick stress test\" --url http://192.168.1.15/productpage --qps 300 --concurrent-requests 2 --duration 30s --token \"provider=Meshery\"\n```\n\nYou can also provide a SMPS Configuration file with `perf` subcommand, with this file provided you will not have to specify url, duration, concurrent-requests & qps. However, if specified the value provided through file will be over-rided by value through CLI. For more info about file configuration, see [here](https://github.com/service-mesh-performance/service-mesh-performance/blob/master/docs/assets/spec/readme/service%20mesh%20performance%20specification%20result.yaml).\n\n```bash\n mesheryctl perf --name \"a quick stress test\" --file {path}/smps.yaml --token \"provider=Meshery\"\n```\n\n### What's next?\n\nMeshery is an ever-growing community with attracting contributors from across the globe. We always have a role for everyone whether to be a code-writer, a community manager or a marketer. Layer5 community is always open to welcome you warmly.\n\nIf this makes you excited, [join the Layer5 community](http://slack.layer5.io) with just a click & someone will be there to make sure you do not get missed.\n\nStay meshy and happy meshing!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Getting started with mesheryctl","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp","srcSet":"/static/9cfe96da1edeb15d9314d201d6f225a0/4a552/mesheryctl.webp 750w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/571ff/mesheryctl.webp 1080w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/1866d/mesheryctl.webp 1366w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/9cfe96da1edeb15d9314d201d6f225a0/mesheryctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp","srcSet":"/static/9cfe96da1edeb15d9314d201d6f225a0/4a552/mesheryctl.webp 750w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/571ff/mesheryctl.webp 1080w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/1866d/mesheryctl.webp 1366w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/9cfe96da1edeb15d9314d201d6f225a0/mesheryctl.webp"}},"fields":{"slug":"/blog/meshery/getting-started-with-mesheryctl"}},{"id":"64df8149-6294-5076-9c8d-f16dfd23e718","body":"\n\n\n<NewsWrapper>\nService mesh technologies have emerged as a reliable way to manage observability, security and traffic management in microservices environments, typically with the use of Kubernetes for container orchestration. Specific use cases and needs for service meshes also vary.\n<br/><br/>\nThe New Stack recently completed a survey about service mesh use cases. While one third of those surveyed said their organizations already use service meshes to control traffic between microservices and Kubernetes environments, adoption rates and use varied significantly among the respondents. Sixteen percent of respondents said that their organization broadly uses service mesh in production environments and 17% said service meshes have limited use in production environments, for example.\n<br/><br/>\nIn this latest episode of The New Stack Analysts podcast, <a href=\"https://www.linkedin.com/in/leecalcote\">Lee Calcote</a>, an analyst and founder of service mesh provider <a href=\"https://layer5.io/\">Layer5</a>, and <a href=\"https://www.linkedin.com/in/brianredbeard/\">Brian “Redbeard” Harrington</a>, a principal product manager for OpenShift service mesh at Red Hat, discussed the many nuances of what the survey numbers really mean.\n<br/><br/>\n<iframe height=\"200px\" width=\"100%\" frameBorder=\"no\" scrolling=\"no\" seamless src=\"https://player.simplecast.com/79d9b8d2-9e6d-4b35-80d0-c14d8fa81f0f?dark=false\"></iframe>\n<br/><br/>\nCalcote notes how traffic management is seen as a key feature among the many different service mesh capabilities, but it’s most useful to advanced users. Speaking about the use of traffic management functionalities, Calcote said: “Folks tend to be a little more advanced as they get into that because they’re at that point they’re actually affecting traffic and then routing requests differently, as opposed to something like just purely observing or getting a ‘read-only’ view in their environment.”\n<br/><br/>\n\n</NewsWrapper>\n\n\n","frontmatter":{"title":"The New Stack: What the Numbers Say about How Service Meshes Are Used Today","type":"News","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAACQBACdASoUABEAPtFcpU6oJSMiKAqpABoJaTcAAADheslpkcZR0v8TjFjJzAAA/vCjjd7ZN/+hiZMLVyqN5EDUMLtP25EUQ4dbE8BqzJoC++39ZzdWJEUqFLlNAGLiRcfoB2AuwCvh2CIg09W3O7i88d/Ao2wc29oCC/vc0Oq/kC5lDgpihv3T4AAAAA=="},"images":{"fallback":{"src":"/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp","srcSet":"/static/1d413ecd41b509f9ab80fce27e78f284/1e798/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 750w,\n/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 761w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8554533508541393}},"extension":"webp","publicURL":"/static/1d413ecd41b509f9ab80fce27e78f284/what-the-numbers-say-about-how-service-meshes-are-used-today.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAACQBACdASoUABEAPtFcpU6oJSMiKAqpABoJaTcAAADheslpkcZR0v8TjFjJzAAA/vCjjd7ZN/+hiZMLVyqN5EDUMLtP25EUQ4dbE8BqzJoC++39ZzdWJEUqFLlNAGLiRcfoB2AuwCvh2CIg09W3O7i88d/Ao2wc29oCC/vc0Oq/kC5lDgpihv3T4AAAAA=="},"images":{"fallback":{"src":"/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp","srcSet":"/static/1d413ecd41b509f9ab80fce27e78f284/1e798/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 750w,\n/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 761w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8554533508541393}},"extension":"webp","publicURL":"/static/1d413ecd41b509f9ab80fce27e78f284/what-the-numbers-say-about-how-service-meshes-are-used-today.webp"}},"fields":{"slug":"/company/news/the-new-stack-what-the-numbers-say-about-how-service-meshes-are-used-today"}},{"id":"ee99e5c3-8e43-5eed-b3e0-a64947d39a71","body":"\n\nimport awsappmesh from \"../../../../assets/images/service-mesh-icons/aws-app-mesh.webp\";\nimport consul from \"../../../../assets/images/service-mesh-icons/consul.svg\";\nimport istio from \"../../../../assets/images/service-mesh-icons/istio.svg\";\nimport linkerd from \"../../../../assets/images/service-mesh-icons/linkerd.svg\";\nimport maesh from \"../../../../assets/images/service-mesh-icons/maesh.webp\";\nimport nsm from \"../../../../assets/images/service-mesh-icons/nsm.svg\";\nimport octarine from \"../../../../assets/images/service-mesh-icons/octarine.svg\";\nimport kuma from \"../../../../assets/images/service-mesh-icons/kuma.svg\";\n\n\n<BlogWrapper>\n\n<span className=\"starting-letter\">I</span>t’s no secret that service mesh tech is boiling hot. Microservice architectures brought on as many challenges as they have advantages. With operational complexity being one of the most acute pains. Service meshes do offer solutions to a number of these operational concerns. Including but not limited to: resilience, improved observability, security and advanced service discovery.\n<div>\n  <div>\n\n<iframe width=\"100%\" src=\"https://www.youtube.com/embed/MXQV-i-Hkf8\" loading=\"lazy\" frameBorder=\"0\"\n    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n    style={{minHeight: \"315px\", minWidth: \"280px\"}}></iframe>\n</div>\nBut with so many mesh options around - how do we choose, evaluate and compare them? And once we’ve chosen a solution - how do we make it accessible to all our engineers? It is to provide an answer to these questions that the Layer5 community has created <Link to=\"/cloud-native-management/meshery\">Meshery</Link>, the open-source, service mesh management plane. Meshery already supports a number of leading mesh providers with adapters for additional meshes on the way. In today’s video, I’ll show how to use Meshery for rolling out and evaluating Linkerd.\n\n Linkerd is a system that comes from the service mesh pioneers - the company called Buoyant. They were the first to realise the need for a distributed network of smart, centrally configured proxies and coin the term “service mesh” back in 2016. Today, we’ll be looking at Linkerd 2.x - the second generation of this now CNCF project.\n</div>\n<div>\n<h5>Meshery Adapters</h5>\n    <table className=\"table-adapters\">\n        <thead className=\"hidden\">\n            <th>Status</th>\n            <th>Adapter</th>\n        </thead>\n        <tbody>\n        <tr>\n            <td rowSpan=\"7\" className=\"stable-adapters\">stable</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-istio\">\n                <img src={istio} alt=\"Istio Service Mesh adapter\" className=\"adapter-logo\" />Meshery adapter for Istio\n                </a>\n            </td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-linkerd\"><img src={linkerd} alt=\"Linkerd\" className=\"adapter-logo\" />Meshery adapter for Linkerd</a></td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-consul\"><img src={consul} alt=\"Consul Connect\" className=\"adapter-logo\" />Meshery adapter for Consul</a></td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-octarine\"><img src={octarine} alt=\"Octarine Service Mesh\" className=\"adapter-logo\" />Meshery adapter for Octarine</a></td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-nsm\"><img src={nsm} alt=\"Network Mesh\" className=\"adapter-logo\" />Meshery adapter for Network Service Mesh</a></td>\n        </tr>\n        <tr><td className=\"stable-adapters\"/></tr>\n        <tr>\n            <td rowSpan=\"2\" className=\"beta-adapters\">beta</td>\n            <td><a href=\"https://github.com/layer5io/meshery-cpx\">\n                <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQksHj15DkID308qQw3cmkQrRULPxyzbVquSZVev-9dj1L6sPs-rQ&s\" alt=\"Citrix CPX Service Mesh\" className=\"adapter-logo\" />Meshery adapter for Citrix CPX\n                </a>\n            </td>\n        </tr>\n        <tr><td className=\"beta-adapters\"/></tr>\n        <tr>\n            <td rowSpan=\"6\" className=\"alpha-adapters\">alpha</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-maesh\">\n                <img src={maesh} alt=\"Maesh Service Mesh\" className=\"adapter-logo\" />Meshery adapter for Maesh\n                </a>\n            </td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-app-mesh\">\n                <img src={awsappmesh} alt=\"AWS App Mesh Service Mesh\" className=\"adapter-logo\" />Meshery adapter for App Mesh \n                </a>\n            </td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/layer5io/meshery-kuma\">\n                <img src={kuma} alt=\"Kuma Service Mesh\" className=\"adapter-logo\" />Meshery adapter for Kuma\n                </a>\n            </td>\n        </tr><tr>\n        </tr>\n        <tr><td className=\"alpha-adapters\"/></tr>\n        </tbody>\n    </table>\n</div>\n\nSome things that Linkerd is known for:\n\n<li>Purpose-built for Kubernetes</li>\n<li>Featuring custom-built, highly performant proxies written in Rust</li>\n<li>Zero-config option (works out-of-the-box)</li>\n<li>Network telemetry built-in (includes a pre-configured, optimised Prometheus instance)</li>\n<li>Low-overhead control-plane</li>\n<li>Operational simplicity (when compared to Istio, for example, even though Istio is getting better in this regard)</li>\n\nSo what is covered in the video? More or less the following:\n\n<li>What service mesh tech allows us to do</li>\n<li>What a typical service mesh architecture looks like</li>\n<li>What Layer5 is about (<i>Lookout - it may surprise you!</i> 😯)</li>\n<li>What Meshery is. What Linkerd is.</li>\n<li>How easy it is to install Meshery on your PC (be it Linux, Mac or Windows)</li>\n<ul>\n<li>\nAll it takes is:\n\n```sh\n$ curl -L https://meshery.io/install | PLATFORM=kubernetes bash -\n```\n\n</li></ul>\n<li>How Meshery connects to your Kubernetes cluster (nothing to be done if it’s in your <code>kubectl config current-context</code>)</li>\n<li>How to correctly install and remove Linkerd on your Kubernetes cluster using Meshery</li>\n<li>How to install one of included Linkerd sample applications and verify the installation</li>\n\nThat’s quite a lot of content for a 20 minute clip. In the follow-up videos, we’ll dive deeper into many of these concepts. And also show how to use Meshery with other service mesh providers.\n\nThis video is also the opening shot of Layer5's [Learn to Service Mesh](https://www.youtube.com/playlist?list=PL3A-A6hPO2IN_HSU0pSfijBboiHggs5mC) playlist, which is specifically dedicated to tutorials and webinars. If service mesh tech interests you and you’re willing to learn more about it, then make sure to [subscribe to the channel](https://www.youtube.com/channel/UCFL1af7_wdnhHXL1InzaMvA?sub_confirmation=1) and watch for updates.\n\nAnd let us know if there’s any specific content you want us to create. Or maybe anything you’ve created yourself and would like to share? Layer5 is all about knowledge sharing and we want to talk to you, so please [join the cloud native community](http://slack.layer5.io)!\n\nHappy meshing!\n<br />\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Deploying Linkerd with Meshery","type":"Blog","technology":null,"product":"Meshery","mesh":"Linkerd","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgAAW41+EMeuRS5kAAD+zRR30B7IZkwg5DLpIC/9Ldd+oO3jEdv9tbLd+qeOIGpIzE1i+iJaKAAA"},"images":{"fallback":{"src":"/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp","srcSet":"/static/af48ad5b31a3b12f8d571eea1a4f863f/a66aa/Linkerd-with-Meshery.webp 750w,\n/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/af48ad5b31a3b12f8d571eea1a4f863f/Linkerd-with-Meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgAAW41+EMeuRS5kAAD+zRR30B7IZkwg5DLpIC/9Ldd+oO3jEdv9tbLd+qeOIGpIzE1i+iJaKAAA"},"images":{"fallback":{"src":"/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp","srcSet":"/static/af48ad5b31a3b12f8d571eea1a4f863f/a66aa/Linkerd-with-Meshery.webp 750w,\n/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/af48ad5b31a3b12f8d571eea1a4f863f/Linkerd-with-Meshery.webp"}},"fields":{"slug":"/blog/meshery/deploying-linkerd-with-meshery"}},{"id":"617e3e58-0541-5058-8d5c-8cbd1b69c619","body":"\n\n\n<NewsWrapper>\n\nWhen an organization is forced to manage distributed service-to-service communication over a large network, service mesh provides a dedicated layer where separate parts of an application can communicate with each other. This way, software teams can centralize communication, rather than monitor each individual service message exchange independently.\n\nWhen service mesh emerged in 2018, many saw this technology as a way to tackle the complexity of container deployment at production scale. They also saw it as a way to address unsustainable manual traffic management processes.\n\nIn 2019, the success of service mesh implementation inspired a rush of vendors that hoped to cash in on the need to manage services at scale. The industry saw a booming sub-ecosystem around two major service mesh options, Google's Istio and the open source Envoy, plus many à la carte tools, such as Tetrate and Meshery. A handful of newcomers jumped into the fray, such as HashiCorp, Kong, Containous, Aspen Mesh and Layer5. Despite the competition, Istio and Envoy led the pack.\n\nThe service mesh market saw two significant events in 2019. First, Envoy Project Authors fine-tuned its increasingly popular sidecar proxy design pattern. Second, Google kept its service mesh technology, and Istio, out of the open source Cloud Native Computing Foundation (CNCF), and thereby retained proprietary control.\n\n</NewsWrapper>\n","frontmatter":{"title":"Vendors make a splash in 2019 service mesh implementation rush","type":"News","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAABQBACdASoUAAYAPtFWpEuoJKOhsAgBABoJZQCdH8G6A5/8B5Pd7JAOdIsAAP7Hfg7V6Cw+lBvPBuF5PLewMAEGH3x14wTH6pKuiqCh/pETb+DWCdaMnSQXMD8R1kSMqbBP+Ao0ZoAAAA=="},"images":{"fallback":{"src":"/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp","srcSet":"/static/34068b4bb8760d9d00922b48df09397b/440b4/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 750w,\n/static/34068b4bb8760d9d00922b48df09397b/4dabe/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1080w,\n/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1274w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3021978021978022}},"extension":"webp","publicURL":"/static/34068b4bb8760d9d00922b48df09397b/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAABQBACdASoUAAYAPtFWpEuoJKOhsAgBABoJZQCdH8G6A5/8B5Pd7JAOdIsAAP7Hfg7V6Cw+lBvPBuF5PLewMAEGH3x14wTH6pKuiqCh/pETb+DWCdaMnSQXMD8R1kSMqbBP+Ao0ZoAAAA=="},"images":{"fallback":{"src":"/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp","srcSet":"/static/34068b4bb8760d9d00922b48df09397b/440b4/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 750w,\n/static/34068b4bb8760d9d00922b48df09397b/4dabe/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1080w,\n/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1274w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3021978021978022}},"extension":"webp","publicURL":"/static/34068b4bb8760d9d00922b48df09397b/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp"}},"fields":{"slug":"/company/news/vendors-make-a-splash-in-2019-service-mesh-implementation-rush"}},{"id":"d54999fc-e89f-5c6b-935a-5af585bf53eb","body":"\n\n\n<NewsWrapper>\n\nIn 2019, we saw service mesh move beyond an experimental technology and into a solution that organizations are beginning to learn is an elemental building block for any successful Kubernetes deployment. Adoption of service mesh at scale, across companies large and small, began to gain steam. As the second wave of adopters watched the cutting edge adopters trial and succeed with service mesh technology, they too began to evaluate service mesh to address the challenges Kubernetes leaves on the table.\n<br/>\n\nIn tandem with growing adoption of service mesh, 2019 offered a burgeoning service mesh market. Istio and Linkerd keep chugging along, and the tooling and vendor ecosystem around Istio almost tripled throughout the year. But there were also many new players that entered the market providing alternative approaches to solving layer seven networking challenges. Meshes, such as those Kuma and Maesh offer, have emerged to provide different approaches to service mesh in order to address various edge use cases. We also saw the introduction of tools like [Service Mesh Interface](https://smi-spec.io/) spec and [Meshery](https://layer5.io/meshery/) attempt to engage an early market that is flourishing due to immense opportunity, but has yet to contract while key players are waiting for the market to choose the winners first. Adjacent projects like [Network Service Mesh](https://networkservicemesh.io/) bring service mesh principles to lower layers of the stack.\n<br/>\n\n\n</NewsWrapper>\n","frontmatter":{"title":"Meshery in top 3 service mesh developments in 2020","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRr4AAABXRUJQVlA4ILIAAABQBQCdASoUABIAPtFcok4oJSKiKA1RABoJZAC1Gy/lvQwDPxKvEGRfFu90PUVDp1QXgAAA/ufjO56dRxtwAdARiX21W2xYHKwFys8WfnpU3Q8u912iDFv4Yyhpmy0BSZ1fpQ+ikh9JSGSXilJufNsKum3VfZPJAXJeWKrKdBX1RLkiM9SDJKoyFAzgdj3y76yFQiTlVbANwJsHp45bR+OKeWis0LDrCQe9jcPYAs3WCAAA"},"images":{"fallback":{"src":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp","srcSet":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp 649w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8921417565485361}},"extension":"webp","publicURL":"/static/b8151b980f351e8733505acaa801c470/Meshery_top3_servish_mesh_development.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRr4AAABXRUJQVlA4ILIAAABQBQCdASoUABIAPtFcok4oJSKiKA1RABoJZAC1Gy/lvQwDPxKvEGRfFu90PUVDp1QXgAAA/ufjO56dRxtwAdARiX21W2xYHKwFys8WfnpU3Q8u912iDFv4Yyhpmy0BSZ1fpQ+ikh9JSGSXilJufNsKum3VfZPJAXJeWKrKdBX1RLkiM9SDJKoyFAzgdj3y76yFQiTlVbANwJsHp45bR+OKeWis0LDrCQe9jcPYAs3WCAAA"},"images":{"fallback":{"src":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp","srcSet":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp 649w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8921417565485361}},"extension":"webp","publicURL":"/static/b8151b980f351e8733505acaa801c470/Meshery_top3_servish_mesh_development.webp"}},"fields":{"slug":"/company/news/meshery-in-top-3-service-mesh-developments-in-2020"}},{"id":"c95858c2-6e7f-5a8e-a41e-c069bc89b90b","body":"\n\nimport issueImage from \"./issue.webp\";\n\n<BlogWrapper>\n\nSeveral weeks ago, I wrote [a blog post](https://raungar.wordpress.com/2019/11/15/introducing-comparative-spectrums-to-the-layer5-landscape/) about introducing \"comparative spectrum\" tools to [the Layer5 landscape](https://layer5.io/landscape)—a webpage which I have transformed multiple times, now!\n\nUp until now, the contents of each blog post I have written were centered upon a freshly-opened pull request. Shortly before writing my last post, I did open [one such pull request (layer5#238)](https://github.com/layer5io/layer5/pull/238). However, since my PR remains open, and since I am still working on the same issue my PR addresses, I have opted to instead push [a new commit](https://github.com/layer5io/layer5/pull/238/commits/4d396aaa6d3ca46add71531daedc8c0e2a5d2495) to the aformentioned (but, now, renamed) PR instead of creating a whole new one. This newest commit introduces a major step towards resolving the issue at hand, and will be the subject of this blog post!\n\n<img src={issueImage} alt=\"Issue\"/>\n\nThe issue at hand: [layer5#211](https://github.com/layer5io/layer5/issues/211) - add comparative spectrums to the Landscape page\n\n* * *\n\n_**Note:** this blog post will frequently reference [the update and documentation comment that I made](https://github.com/layer5io/layer5/pull/238#issuecomment-561613644) to accompany my last commit to my PR. I consider this hefty comment to be an extension of this blog post, so I strongly recommend giving it a read!_\n\n* * *\n\nMy initial commit towards introducing comparative spectrum tooling did not represent a full solution. Thinking about what might constitute a full solution for the issue at hand, I came up with three criteria:\n\n## What was still needed:\n\n#### 1\\. A complete toolset\n\nWithin [Issue #211](https://github.com/layer5io/layer5/issues/211), Layer5 lead developer Lee indicates [four slides](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6) upon which comparative spectrum graphics may be based upon. During my initial commit, I created graphics that emulated those found within the first three of those four slides, but I had yet to implement the graphic found in [the fourth](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p12): a table. I was also less-than-satisfied with the 'grid' design I had implemented in response to [slide 7](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p10).\n\n#### 2\\. A modular design\n\nThe designs I am implementing are meant to be used to present opinionated information. As I am not nearly knowledgeable to form opinionated comparisons between service meshes and related technologies, I have instead made my goal to make it as easy as possible for other Layer5 contributors to utilize the graphics (\"\\[comparative\\] spectrums\") that I am designing. Doing so would require encapsulating (templating) the spectrums I design (new and old), within their own HTML files, and providing a means to easily invoke (and customize) instances of those templates into the Landscape page.\n\n#### 3\\. Documentation\n\nBecause the templates I design are intended to be implemented and customized by other contributors, it is _especially_ critical that those contributors have access to complete and thorough documentation detailing the intended use of each templated design.\n\n* * *\n\n## What I delivered:\n\n#### 1\\. A complete toolset\n\nAs documented in my [update comment](https://github.com/layer5io/layer5/pull/238#issuecomment-561613644), I designed a table that very closely resembles that of Lee's slides. Implementing the table was interesting, as it ended up requiring [quite a few nested Liquid for-loops](https://github.com/layer5io/layer5/blob/4d396aaa6d3ca46add71531daedc8c0e2a5d2495/_includes/partials/spectrum/table.html#L23). Also as documented, I revamped the grid-based tooling and am quite pleased with the improvements made. The end result of these efforts is a complete set of comparative spectrums.\n\n#### 2, 3. A modular design and documentation\n\nThe bulk of the documentation I wrote details how to deal with the modular solution that I designed and implemented to enable comparative spectrums to be included into the Landscape page (through the use of Liquid `include` tags). The documentation speaks for itself; [check it out!](https://github.com/layer5io/layer5/pull/238#issuecomment-561613644)\n\n## What's next?\n\nI would not have considered the documentation I delivered to be complete if I did not report on the issues still present in the work I delivered. I denoted these as 'Current issues' in the documentation, and they represent work that still remains to be done. I know that I can count on the Layer5 community to assist me with small issues like these, and, once this pull request receives some forward motion, I hope to start zeroing in on its smaller issues. Fortunately, I have made plans to continue working with open source well into the new year!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Layer5: Landscape Spectrums Revisited","type":"Blog","technology":null,"product":"Service Mesh Landscape","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/e1337065d328292a21fe09e154fd04d8/landscape_green.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/e1337065d328292a21fe09e154fd04d8/landscape_green.svg"}},"fields":{"slug":"/blog/landscape/layer5-landscape-spectrums-revisited"}},{"id":"94ec3b54-c4c3-53cd-ad1b-e5a628ad968e","body":"\n\nimport pr211 from \"./PR-211.webp\";\nimport pr2112 from \"./PR-211-2.webp\";\nimport card1 from \"./card1.webp\";\nimport card2 from \"./card2.webp\";\nimport arrow from \"./arrow.webp\";\nimport gtable from \"./graphical-table.webp\";\nimport gcomp from \"./graph-compare.webp\";\nimport image21 from \"./image.webp\";\nimport comment from \"./comment.webp\";\n\n<BlogWrapper>\n\nDuring [Hacktoberfest 2019](https://raungar.wordpress.com/tag/layer5/), I worked on the website of [Layer5](https://layer5.io/), open source community. More specifically, my contributions concerned one specific page of that website: its [Service Mesh Landscape page](https://layer5.io/landscape).\n\nShortly after making these contributions, I was graciously welcomed into the Layer5 community by its lead developer [Lee Calcote](https://twitter.com/lcalcote?lang=en), who later directly approached me to assist him in furthering his vision for the Landscape page by implementing \"comparative spectrums\". Wishing to focus on my remaining two Hacktoberfest contributions at the time, I suggested surveying the interest of other potential contributors for this project. As such, an informative issue was opened:\n\n<img src={pr211} alt=\"PR 211\"/>\n\nIssue [layer5#211](https://github.com/layer5io/layer5/issues/211): add comparative spectrums to the Landscape page\n\nA month later, I fortunately found time enough to make some major progress into this issue.\n\n* * *\n\nThis issue is quite highly conceptual, much moreso than any other issue I have thus far worked on. I decided that the best way to approach this issue would be to focus on establishing a set of tools that could be used by more-knowledgeable contributors to later construct comparative spectrums—opinionated data visualizations. As such, my first step was to build a set of responsive graphical elements that resembled [those provided as examples](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6). These include:\n\n#### (1) _Sleek information cards:_\n\n<table>\n    <tbody>\n    <tr>\n    <td><img src={card1} alt=\"Card\"/></td>\n    <td> or this </td>\n    <td><img src={card2} alt=\"Card\"/></td>\n    </tr>\n    </tbody>\n</table>\n\n_(Source: [ONIF Container Networking Panel, slides 5 and 6](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6))_\n\n#### (2) _Gradiented, labelable double-arrow banners:_\n\n<img src={arrow} alt=\"Arrow\"/>\n\n_(Source: [ONIF Container Networking Panel, slide 5](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6))_\n\n#### (3) _Graphically-augmented tables:_\n\n<img src={gtable} alt=\"Table\"/>\n\n_(Source: [ONIF Container Networking Panel, slide 8](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p12))_\n\n#### (4) _Spectrum-like graphical comparisons:_\n\n<img src={gcomp} alt=\"Comparison\"/>\n\n_(Source: [ONIF Container Networking Panel, slide 7](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6))_\n\n* * *\n\n(1) Although there may exist libraries that may help construct such graphical elements, I did not want to introduce additional libraries to accomplish my work. Instead, I wanted to make good use of Layer5io's preexisting [Materialize](https://materializecss.com/) library. Fortunately, Materialize strongly supports the design of card-like structures, allowing me to more easily [implement some](https://github.com/layer5io/layer5/pull/238/files#diff-20fc098534d6aab31ad8e5c9db51bde0R10).\n\n(2) Unfortunately, it does not seem that Materialize supports the creation of graphical arrows, so I just ended up [styling my own](https://github.com/layer5io/layer5/pull/238/files#diff-1d5fe92e61759723c94b009b32e9e1b7R2).\n\n(3) These tables can be quite easily implemented and styled with or without the use of `<table>` tags. I anticipate these will be given a proper fleshing out after the other graphical elements are further developed.\n\n(4) These unique spectrum graphics present the most challenging, of all the comparison tools, to implement. Snaking spectrum bar aside, I needed to develop a _responsive_ solution that (a) allowed contributors to programmatically place image thumbnails at preset horizontal positions, while (b) ensuring those thumbnails placed at the same position do not overlap with one another (and instead align vertically atop each other).\n\nThis presented a problem to solve: I required a means to 'float' elements toward a horizontal line; to 'stack' thumbnails atop one another, without overlap, if they are given the same horizontal position. After researching quite deeply into potential solutions to this problem, I ended up stumbling across some CSS property-value pairings that I had never heard of before: [`display: grid`](https://www.w3schools.com/css/css_grid.asp) and [`grid-auto-flow: row dense`](https://www.w3schools.com/cssref/pr_grid-auto-flow.asp). Miraculously, I discovered that these could actually function as [a basis for a solution](https://github.com/layer5io/layer5/pull/238/files#diff-1d5fe92e61759723c94b009b32e9e1b7R76).\n\n* * *\n\nAfter styling the graphical elements, I continued the website's trend of using [Liquid](https://help.shopify.com/en/themes/liquid) tags (e.g. [`for`](https://help.shopify.com/en/themes/liquid/tags/iteration-tags#for)) and [YAML lists](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html) to help modularize my solutions, which should aid future contributors in generalizing them.\n\n* * *\n\nI opened [a pull request](https://github.com/layer5io/layer5/pull/238) to share my work as well as invite collaboration:\n\n<img src={pr2112} alt=\"PR 211-2\"/>\n\nPull request [layer5#238](https://github.com/layer5io/layer5/pull/238): description of tooling introduced\n\n<img src={image21} alt=\"Image\"/>\n\nPull request [layer5#238](https://github.com/layer5io/layer5/pull/238): example images of tooling introduced\n\nThe pull request was quite well-recieved:\n\n<img src={comment} alt=\"Comment\"/>\n\n[Comment](https://github.com/layer5io/layer5/pull/238#issuecomment-554181763) by Layer5 team lead on pull request [layer5#238](https://github.com/layer5io/layer5/pull/238)\n\nAs I mentioned in a recent Layer5 community meeting, I am very excited to continue working with Layer5; to refine and expand upon this set of new, visionary tooling for their landscape!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Introducing Comparative Spectrums to the Layer5 Landscape","type":"Blog","technology":null,"product":"Service Mesh Landscape","mesh":null,"thumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/e1337065d328292a21fe09e154fd04d8/landscape_green.svg"},"darkthumbnail":{"childImageSharp":null,"extension":"svg","publicURL":"/static/e1337065d328292a21fe09e154fd04d8/landscape_green.svg"}},"fields":{"slug":"/blog/landscape/introducing-comparative-spectrums-to-the-layer5-landscape"}},{"id":"cac9ddb8-17d6-5815-b6a0-3a849328003b","body":"\n\nimport wsldockerstart from \"./wsl-docker-start.webp\";\nimport wslgrafanalogin from \"./wsl-grafana-login.webp\";\nimport wslgrafanaloginsuccess from \"./wsl-grafana-login-success.webp\";\nimport wslgrafanastart from \"./wsl-grafana-start.webp\";\nimport wslk3dstart from \"./wsl-k3d-start.webp\";\nimport wslmesherycomplete from \"./wsl-meshery-complete.webp\";\nimport wslmesherylogin from \"./wsl-meshery-login.webp\";\nimport wslmesheryloginsuccess from \"./wsl-meshery-login-success.webp\";\nimport wslmesherystart from \"./wsl-meshery-start.webp\";\n\n<BlogWrapper>\n\nDuring KubeCon EU 2019, I had the chance to discover two new softwares that simply amazed me:\n1. [Meshery](https://layer5.io/cloud-native-management/meshery), which is the multi-service mesh management plane.\n2. [k3d](https://github.com/rancher/k3d), which is used to create a dockerized [k3s](https://k3s.io) server.\n\nAnd, what really appealed to me about both of them is that everything from the installation to the usage was just *simple!*\nAnd cream on the top, both softwares are used with or inside containers, making each ideal for a create/try/delete workflow.\n\n<h4>Environment Setup</h4>\n\nBefore we start having *real* fun with Meshery, I will quickly list the different components I used for this blog post and ensure I define what could be optional for your own setup:\n1. [Meshery](https://layer5.io/cloud-native-management/meshery)\n2. [Docker](https://docs.docker.com/install/)\n    - Docker is of course mandatory and as Meshery is based on a Compose file, which means that [docker-compose](https://docs.docker.com/compose/install/) is also mandatory.\n3. [k3d](https://github.com/rancher/k3d)\n    - k3d or any k3s/K8s cluster that you might have already configured.\n4. [WSL2](https://devblogs.microsoft.com/commandline/wsl-2-is-now-available-in-windows-insiders/)\n    - For the (few) ones who know me, my \"OS base\" is WSL2, which means that without much/any change, it should run fine for any Linux/MacOS setup.\n5. [Grafana](https://grafana.com/) *(optional)*\n    - Grafana is not mandatory however is strongly recommend. We will setup a dockerized instance, but feel free to plug Meshery with your existing instance.\n\n<h4> Nothing is taken for granted </h4>\n\nFor the sake of making the blog post around Meshery, I won't explain how to install each component and will focus only on getting k3d and Meshery working.\n\nThat said, I do not take anything for granted and as Scott Hanselman once taught me: there is no \"just have to ...\" or \"by simply doing ...\".\n\nIf you face any issue with your setup (hopefully WSL2), just let me know on [Twitter](https://twitter.com/nunixtech) or on the [Layer5 Slack channel](http://slack.layer5.io).\n\n<h4>Meshery Installation</h4>\n\nFor the following steps, I will use the Ubuntu 18.04 WSL2 distro:\n\n- Start docker and confirm it's running:\n\n```bash\nsudo service docker start\ndocker version\n```\n\n- Using Docker, install Meshery on your local machine by running the following:\n\n```bash\ncurl -L https://meshery.io/install | PLATFORM=kubernetes bash -\n```\n<a href={wsldockerstart}>\n    <img src={wsldockerstart} className=\"thumbnail\" alt=\"wsl-docker-start\" />\n</a>\n\n- Create a new k3d cluster with the <code> WSL2 IP </code>\n\n```bash\nexport mainIP=`hostname -I | awk '{ print $1 }'`\nk3d list\nk3d create --workers 3 --api-port ${mainIP}:6443\nexport KUBECONFIG=\"$(k3d get-kubeconfig --name='k3s-default')\"\nkubectl cluster-info\n```\n\n<a href={wslk3dstart}>\n    <img src={wslk3dstart} className=\"thumbnail\" alt=\"wslk3dstart\" />\n</a>\n<br/>\n- Start Meshery on the newly created cluster\n\n```bash\nmesheryctl system start\n```\n\n<a href={wslmesherystart}>\n    <img src={wslmesherystart} className=\"thumbnail\" alt=\"wslmesherystart\" />\n</a>\n- Once Meshery is fully started, login in your preferred browser using the <code>WSL2 IP</code> instead of <code>localhost</code>\n\n```bash\nexport BROWSER=/mnt/c/Firefox/firefox.exe\n$BROWSER $mainIP:9081 &\n```\n\n<a href={wslmesherylogin}>\n        <img src={wslmesherylogin} alt=\"wslmesherylogin\" />\n</a>\n<a href={wslmesheryloginsuccess}>\n    <img src={wslmesheryloginsuccess} alt=\"wslmesheryloginsuccess\" />\n</a>\n\n\n#### [Optional] More analytics with Grafana\nAs stated above, Meshery can leverage the analytics provided by Grafana. For this blog post, as everything is built from scratch. Here is the setup for a new Grafana dockerized instance.\n\nStart a new Grafana on docker instance\n\n```bash\ndocker run \\\n-d \\\n-p 3000:3000 \\\n--name=grafana \\\n-e \"GF_SERVER_ROOT_URL=http://$mainIP\" \\\n-e \"GF_SECURITY_ADMIN_PASSWORD=MesheryInstance\" \\\ngrafana/grafana\n```\n\n<a href={wslgrafanastart}>\n    <img src={wslgrafanastart} className=\"thumbnail\" alt=\"wslgrafanastart\" />\n</a>\n\n- Access the new instance with the admin password that you set in the docker environment variable\n```bash\n$BROWSER $mainIP:3000 &\n```\n\n<a href={wslgrafanalogin}>\n    <img src={wslgrafanalogin} className=\"thumbnail\" alt=\"wslgrafanalogin\" />\n</a>\n<br />\n<a href={wslgrafanaloginsuccess}>\n    <img src={wslgrafanaloginsuccess} className=\"thumbnail\" alt=\"wslgrafanaloginsuccess\" />\n</a>\n\n### An inside look\nWhile everything should run fine, it's always good to have a look at what has been deployed.\n\nIn this case, we are almost exclusively working with Docker and the \"inside look\" should look something like this:\n\n<a href={wslmesherycomplete}>\n    <img src={wslmesherycomplete}className=\"thumbnail\" alt=\"wslmesherycomplete\" />\n</a>\n\n#### Conclusion\nAs [Lee Calcote](https://twitter.com/lcalcote) put it, this is a lot of buzz words: Meshery > k3s (deployed via k3d) > Docker > WSL2 > Windows 10. And he's totally right, still the \"beauty\" here, is that it \"simply works\".\n\nSince the begin of the Docker era, new tooling has appeard for simplifying complex workflows.\nEven Kubernetes (K8s) as a much lighter version with k3s by Rancher.\n\nAnd of course, Meshery which integrates and simplifies the installation and benchmarking of different service meshes. Hope you had fun assembling all these pieces and stay tunned for the \"Bonuses\", more fun to come!\n\n<span> > > > <i>Nunix out</i></span>\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Getting started with Meshery, WSL2 and k3d","type":"Blog","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRrgAAABXRUJQVlA4IKwAAAAwBQCdASoUABQAPtFgqU+oJSOiKAgBABoJagDHMywTmwXkh8XuWw62pPgeLa6iGOkYAAD+9R4SKH1oL6udrBkwr5rrkLRIeudVijKFQQi4NBpAgn1GqiLKGll7/coQQQ8X2m4ARFICZ1eH4EKwlMH79KOgYAEP9qeZU1fXG+Jmj3mSYoA/SF+9X/WI4UZXzEZSPBXefiBldNQhjxeWdjq9FujdEnATM/mAAAAA"},"images":{"fallback":{"src":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp","srcSet":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp 400w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/4c732e28e50f90fde2ff41201d6d0743/cnab-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRrgAAABXRUJQVlA4IKwAAAAwBQCdASoUABQAPtFgqU+oJSOiKAgBABoJagDHMywTmwXkh8XuWw62pPgeLa6iGOkYAAD+9R4SKH1oL6udrBkwr5rrkLRIeudVijKFQQi4NBpAgn1GqiLKGll7/coQQQ8X2m4ARFICZ1eH4EKwlMH79KOgYAEP9qeZU1fXG+Jmj3mSYoA/SF+9X/WI4UZXzEZSPBXefiBldNQhjxeWdjq9FujdEnATM/mAAAAA"},"images":{"fallback":{"src":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp","srcSet":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp 400w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/4c732e28e50f90fde2ff41201d6d0743/cnab-logo.webp"}},"fields":{"slug":"/blog/meshery/getting-started-with-meshery-wsl2-and-k3d"}},{"id":"fbc0a4e6-e2df-5139-835a-843d390eaa13","body":"\n\nimport SmiLogo from \"./smi-logo.webp\";\n\n<BlogWrapper>\n\n<img className=\"image-left\" src={SmiLogo} alt=\"SMI Logo\"/>\n\nMost began their cloud native journey with their first step being use of containers, and taking a second step, moved into container orchestration as their workloads grew. Now, waves and waves of organizations are considering service meshes as their third significant step in their cloud native journey. As they invest into service meshes as their next layer of key infrastructure, users will continue to look for the same assurances sought from other commonly accepted (standard) interfaces for container runtimes (e.g. CRI), container storage (e.g. CSI), container networking (e.g. CNI) and they will look for a commonly accepted service mesh interface.\n\nAs a prominent supporter of management software for multiple service meshes, Layer5 is pleased to partner with Microsoft in support of the [Service Mesh Interface](https://smi-spec.io) (SMI). The Service Mesh Interface is a specification for service meshes that run on Kubernetes. As such, SMI defines a common standard that can be implemented by a variety of service mesh projects and vendors.\n\nLike standards before SMI, consistent APIs inspire confidence in infrastructure stability, community-managed APIs assuage technology and vendor lock-in concerns, and steward the resounding of core use cases, resulting in streamlining the smaller, but critical-to-users, subset of capabilities offered across the [service mesh landscape](https://layer5.io/landscape).\n\nMeshery and SMI are aligned on common goals of getting users started quickly, understanding that users want service mesh technology, but have questions as to which service mesh use, how, and when to get started through a common interface. Meshery’s playground capabilities quick provision a variety of service meshes and reduce time to value and time to understanding for those adopting a service mesh.\n\nAs a multi-mesh manager, Meshery, understands that each service mesh has it own strengths. SMI intends to allow for differentiation by service mesh providers, at the same time providing interoperability between service meshes and their surrounding tooling. As a management plane, Meshery enhances networking intelligence in a multi-mesh way, encouraging users to expect more from their infrastructure. Meshery exposes each service mesh’s differentiated capabilities.\n\nSMI’s aim for consistent APIs facilitates Meshery’s same goals, allowing for users and tools to flourish. As SMI unveils today, so does Meshery’s compatibility. Try out [Meshery and SMI](https://layer5.io/meshery) today!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"A Standard Interface for Service Meshes","type":"Blog","technology":null,"product":"Service Mesh Landscape","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRigCAABXRUJQVlA4WAoAAAAQAAAAEwAAFQAAQUxQSPAAAAABkCvbtmlb/VqxbSOyrejWjWwbL7Nt27Zt27Zt+81g6xciYgIwWHbj780KDFaIsqqqSMWibwxwU+XOx0cq/WQ58Evlb3iQoq9sdADOqJxHOVjWWACWexS/sxQjZLk5YLVZJq6/siEOMBkri8wA6+3/e6FuMknmmgK2u/93oG46Q2aaAnb7/zejeUwmmwAuz//VAeS/yYV9MlHhdKs3QPT7zxlgOkummaAZ//GxH4DJVJltqpb0+YEPqiYTZIGZIu3rXU+0R8mD69evX/9xyw29p0U1DfWoSOCQWgLYFNrApycGmqUNigoM2PdxQF2PXkNWUDggEgEAALAGAJ0BKhQAFgA+0VikTSglI6IoDVEAGglsALsvsXoFytSAuzn9ZiQA9nb1UH773JB1ZQmv/+DfOndma9wAAPWKbXfbscu7ED8PNnaio58XsbOOx256LmPVRADnEPF+551VhKdW8r+iWIf2dL6oQLxgUOFBuAuFZfQ14oFo5CDsfZzHKMRan9atM8e5a09UzuBGXaFacdxsJ+X+HLb5fQSlSqpgKCtxzljACQCnWgckQVt863w//zUWqAi28GMv+MPKRx/YyAKGyI/UbWDadMOGwB1bHShhhupziJrW1skC4BbbgSmFR+9b9tjvTQwxiwWMLGwyPKtnui1LQUa/DziIq9WLCOvg++O9V9Uk1OsQAAA="},"images":{"fallback":{"src":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp","srcSet":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp 515w","sizes":"100vw"},"sources":[]},"width":1,"height":1.1242718446601943}},"extension":"webp","publicURL":"/static/8b3b9d5daf662a9f37debc294ba46cf2/smi-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRigCAABXRUJQVlA4WAoAAAAQAAAAEwAAFQAAQUxQSPAAAAABkCvbtmlb/VqxbSOyrejWjWwbL7Nt27Zt27Zt+81g6xciYgIwWHbj780KDFaIsqqqSMWibwxwU+XOx0cq/WQ58Evlb3iQoq9sdADOqJxHOVjWWACWexS/sxQjZLk5YLVZJq6/siEOMBkri8wA6+3/e6FuMknmmgK2u/93oG46Q2aaAnb7/zejeUwmmwAuz//VAeS/yYV9MlHhdKs3QPT7zxlgOkummaAZ//GxH4DJVJltqpb0+YEPqiYTZIGZIu3rXU+0R8mD69evX/9xyw29p0U1DfWoSOCQWgLYFNrApycGmqUNigoM2PdxQF2PXkNWUDggEgEAALAGAJ0BKhQAFgA+0VikTSglI6IoDVEAGglsALsvsXoFytSAuzn9ZiQA9nb1UH773JB1ZQmv/+DfOndma9wAAPWKbXfbscu7ED8PNnaio58XsbOOx256LmPVRADnEPF+551VhKdW8r+iWIf2dL6oQLxgUOFBuAuFZfQ14oFo5CDsfZzHKMRan9atM8e5a09UzuBGXaFacdxsJ+X+HLb5fQSlSqpgKCtxzljACQCnWgckQVt863w//zUWqAi28GMv+MPKRx/YyAKGyI/UbWDadMOGwB1bHShhhupziJrW1skC4BbbgSmFR+9b9tjvTQwxiwWMLGwyPKtnui1LQUa/DziIq9WLCOvg++O9V9Uk1OsQAAA="},"images":{"fallback":{"src":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp","srcSet":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp 515w","sizes":"100vw"},"sources":[]},"width":1,"height":1.1242718446601943}},"extension":"webp","publicURL":"/static/8b3b9d5daf662a9f37debc294ba46cf2/smi-logo.webp"}},"fields":{"slug":"/blog/announcements/a-standard-interface-for-service-meshes"}}]}}}