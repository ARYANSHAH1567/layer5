(self.webpackChunkLayer5=self.webpackChunkLayer5||[]).push([[35502],{78705:function(e,n,t){var r=t(15301).w_;e.exports.O=function(e){return r({tag:"svg",attr:{viewBox:"0 0 512 512"},child:[{tag:"path",attr:{d:"M256 48C141.1 48 48 141.1 48 256s93.1 208 208 208 208-93.1 208-208S370.9 48 256 48zm43.4 289.1c7.5 7.5 7.5 19.8 0 27.3-3.8 3.8-8.7 5.6-13.6 5.6s-9.9-1.9-13.7-5.7l-94-94.3c-6.9-7.6-6.7-19.3.6-26.6l95.4-95.7c7.5-7.5 19.7-7.6 27.3 0 7.5 7.5 7.6 19.7 0 27.3l-81.9 81 79.9 81.1z"}}]})(e)}},56969:function(e,n,t){"use strict";t.r(n),t.d(n,{Head:function(){return g},default:function(){return p}});var r=t(39626),a=t(67294),o=(t.p,t.p+"static/ieee_bridge_issue3_2021-c6d713aa19776fb6230d12d6ff10a529.webp"),i=t.p+"static/figure-1-b900f15c0cfa4a851ed51e64f058b16a.webp",l=t.p+"static/figure-2-8c152993c0bd68905a977ea9059dde17.webp",s=t.p+"static/Meshery Architecture - Clients-e354ed1b192168b5efc4f451331854be.webp",c=t.p+"static/Comparison of different modes of delivery of service mesh network functions-9a5dcf1713efc459827d9c165d2c4886.webp";function u(e){var n=Object.assign({p:"p",br:"br",pre:"pre",code:"code"},(0,r.ah)(),e.components),t=n.ResourcesWrapper;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("ResourcesWrapper",!0),a.createElement(t,null,a.createElement("div",{className:"intro"},a.createElement("p",null,a.createElement(n.p,null,"Learn more about Service Mesh Performance from this article",a.createElement(n.br),"\n",a.createElement("a",{className:"blog",href:"https://www.nxtbook.com/nxtbooks/ieee/bridge_issue3_2021/index.php#/p/16"}," Analyzing Service Mesh Performance")," - Published in issue 3 of IEEE Bridge October 2021"))),a.createElement("div",{className:"right"},a.createElement("img",{src:o,align:"center",alt:"IEEE The Bridge 2021 Issue 3 cover"})),a.createElement("p",null,a.createElement(n.p,null,"As a forthcoming, ubiquitous layer of cloud native infrastructure,\nservice meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices.\nManaging the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly\nsummarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure\nof choice is a challenge unto its own.")),a.createElement("p",null,a.createElement(n.p,null,"We explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties\nof resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance\nanalysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of\nworkloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations.")),a.createElement("p",null,a.createElement(n.p,null,"We provide core, memory and I/O combinations based on workload needs with insights into workload analysis which can influence the efficiency of the\nservice mesh and overall performance of the cluster.")),a.createElement("h2",null,"Characterizing the Complexity of Combinatorial Analysis"),a.createElement("p",null,a.createElement(n.p,null,'Consider that the more value you try to derive from your service mesh, the more work that you will ask it to do. Said another way,\nthat as someone reflects more deeply on the architecture of a service mesh - with its distributed proxies - and the functionality it offers,\nthey will eventually wonder, "What overhead is running my service mesh incurring?". This is one of the most common questions engineers have as\nthey initially learn of a service mesh and the value a deployment of one offers. This is not an easy question to answer as the permutations of\nconfiguration between your infrastructure, service mesh, and applications are innumerable and any change to one of them affects their collective performance.')),a.createElement("p",null,a.createElement(n.p,null,"How would you describe the performance of your service mesh and that of your clusters and their workloads? Are you imagining a wall of line\ncharts with metrics capturing golden signals? The act of articulating the performance of your service mesh can take anywhere from a minute\nto even a few hours to characterize the state of your systems and the overhead incurred by your infrastructure and what this means to your users.")),a.createElement("p",null,a.createElement(n.p,null,"Moreover, anytime performance is characterized, analysis is subjective to the specific workload, infrastructure, and instruments used for measurement.\nGiven the variety of this measurement challenge, most service meshes and their data plane proxies (if a third-party component), do not have the tooling\nnecessary or refuse to publish performance data because such tests can be:"),a.createElement("ol",null,a.createElement("li",null,"arduous to create and sustain a capable harness"),a.createElement("li",null,"a point-in-time consideration (none of the elements under measurement are static"),a.createElement("li",null,"misinterpreted"))),a.createElement("p",null,a.createElement(n.p,null,"Read on as we identify how to surmount each of these challenges.")),a.createElement("h2",null,"Service Mesh Performance Considerations"),a.createElement("p",null,a.createElement(n.p,null,"As the software defined networking layer of microservices, service mesh encompasses multiple aspects of critical functions of the applications,\nsuch as circuit breaking, health checks, and packet operations. Analyzing the permutations of these configurations is an impossible task without\na suitable test harness. A service mesh management plane can be such a tool. As the multi-mesh manager, ",a.createElement("a",{href:"https://meshery.io"},"Meshery "),"\nis capable of provisioning 10 different service meshes, workloads atop the meshes, generating load using ",a.createElement("a",{href:"https://getnighthawk.dev"},"Nighthawk"),",\nand analyzing that load. No other tool capable of performing these tasks\nend-to-end exists. Meshery is a Cloud Native Computing Foundation project originally created by Layer5.")),a.createElement("h3",null,"How are you measuring?"),a.createElement("p",null,a.createElement(n.p,null,"Consider the simple set of steps to execute performance tests in a simple Kubernetes-based cluster:")),a.createElement("ol",null,a.createElement("li",null,"Setup your cluster, service mesh, and application under test."),a.createElement("li",null,"Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance."),a.createElement("li",null,"Configure your test setup for performance, doing so in context of other constraints that you might\nneed to uphold (e.g. resiliency characteristics of your service deployment)."),a.createElement("li",null,"Choose the protocol of interest: HTTP, HTTPS, HTTP1/2, gRPC, NATS"),a.createElement("li",null,"Identify KPIs of interest - Transactions per second (TPS) or percentile latencies, etc."),a.createElement("li",null,"Decide on the test duration: 60s or 5 minutes or 1 hour..."),a.createElement("li",null,"Choose the number of requests per second (RPS)."),a.createElement("li",null,"Execute the test."),a.createElement("li",null,"Mark down requests per second, latencies, throughput, and any other output provided by benchmarking tools.")),a.createElement("h3",null,"What are you measuring?"),a.createElement("p",null,a.createElement(n.p,null,"Performance of a service mesh can be described across multiple dimensions covering some or all of these core functionalities\nof a service mesh. So, which dimensions are the linchpins of performance? Which metrics are key indicators of performance?\nOutside of the different types of performance tests, performance management concerns include the need for performance and\noverhead data under a permutation of different workloads (applications) and different types and sizes of infrastructure resources.")),a.createElement("div",{className:"center"},a.createElement("a",{href:i},a.createElement("img",{src:i,align:"center",alt:"EWtraffic"}))),a.createElement("p",null,a.createElement(n.p,null,"Hence, it is crucial to understand what is being measured in a service mesh based deployment. Certain critical considerations are\nmissing from the simple methodology previously described. For example, as indicated in Figure 1, but not limited to:")),a.createElement("ol",null,a.createElement("li",null,a.createElement(n.p,null,"Traffic considerations"),a.createElement("ul",null,a.createElement("li",null,a.createElement(n.p,null,"East-West traffic"),a.createElement("ol",null,a.createElement("li",null,"between two pods within the same or two different Virtual Machines (VM)."),a.createElement("li",null,"between two pods within the same or two different bare metal nodes."),a.createElement("li",null,"combination of above with choice of user-space or kernel-space networking stack on the host node."))),a.createElement("li",null,a.createElement(n.p,null,"North-South traffic"),a.createElement("ol",null,a.createElement("li",null,"Throughput and latency of traffic flowing in and out of a single VM or across a single bare metal node."))))),a.createElement("li",null,a.createElement(n.p,null,"Deployment considerations"),a.createElement("ul",null,a.createElement("li",null,"Number of hops between traffic source and traffic destination with load balancers, API gateways, ingress controllers,\nsecurity components such as firewall, deep packet inspectors, and so on."),a.createElement("li",null,"Operating system settings."),a.createElement("li",null,"Hardware settings such as BIOS options, power management features, NUMA awareness, platform resource management, hardware\naccelerators, and so on."))),a.createElement("li",null,a.createElement(n.p,null,"Load generators types"),a.createElement("ul",null,a.createElement("li",null,"hardware or software based, L2-3,  L4-7, open or closed loop"))),a.createElement("li",null,a.createElement(n.p,null,"Service mesh types - the service mesh landscape has over 20 meshes listed. Each share a common architecture,\nhowever, their implementation differs and consequently, so does their performance."),a.createElement("ul",null,a.createElement("li",null,"Control plane - often a point of contention the larger the service mesh deployment is."),a.createElement("li",null,"Data plane - not only proxies, but filters loaded in those proxies."))),a.createElement("li",null,a.createElement(n.p,null,"Service mesh configuration and number of services on the mesh. To name a few considerations:"),a.createElement("ul",null,a.createElement("li",null,a.createElement(n.p,null,"Telemetry"),a.createElement("ol",null,a.createElement("li",null,"Including the three pillars of observability are traces, logs, and metrics."),a.createElement("li",null,"The number of, cardinality of, sampling rate, ingest rate… all bear weight (and bear load on the system)."))),a.createElement("li",null,a.createElement(n.p,null,"Policy"),a.createElement("ol",null,a.createElement("li",null,"Authentication, Authorization - frequency of checks, cache hits vs. cache misses."))),a.createElement("li",null,a.createElement(n.p,null,"Security"),a.createElement("ol",null,a.createElement("li",null,"Encryption - overhead of handshaking and mutually authenticated TLS.")))))),a.createElement("p",null,a.createElement(n.p,null,"Ultimately, the goal of any performance tests is to ensure repeatable measurements and obtain consistent results across multiple test runs.")),a.createElement("h2",null,"Service Mesh Performance as a Specification"),a.createElement("p",null,a.createElement(n.p,null,"The need for cross-project, apple-to-apple comparisons are also desired in order to facilitate a comparison of behavioral differences\nbetween service meshes and which one might be best-suited for specific workloads. Individual service mesh projects shy from publishing test\nresults of other, competing service mesh projects. The need for an independent, unbiased, credible, standard measurement is one of the catalysts\nfor the creation of Service Mesh Performance (SMP).")),a.createElement("p",null,a.createElement(n.p,null,"Amidst performance concerns and the need to measure and manage performance arose the Service Mesh Performance (SMP) standard. Service Mesh\nPerformance as a specification and disseminating insights and research results. Your authors are working toward the definition of MeshMark,\na universal performance index to gauge your mesh’s efficiency against deployments in other organizations’ environments.")),a.createElement("p",null,a.createElement(n.p,null,"Many performance benchmarks are limited to single instance load generation (single pod load generator). This limits the amount of traffic\nthat can be generated to the output of the single machine that the benchmark tool runs on in or out of a cluster. Overcoming this\nlimitation would allow for more flexible and robust testing. Distributed load testing in parallel poses a challenge when merging\nresults without losing the precision we need to gain insight into the high tail percentiles. Distributed load testing offers insight\ninto system behaviours that arguably more accurately represent real-world behaviours of services under load as that load comes from\nany number of sources.")),a.createElement("p",null,a.createElement(n.p,null,"The specification itself provides a standard format for describing and capturing:")),a.createElement("ul",null,a.createElement("li",null,"performance test configuration"),a.createElement("li",null,"Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance."),a.createElement("li",null,"service mesh configuration"),a.createElement("li",null,"environment configuration"),a.createElement("li",null,"workload configuration"),a.createElement("li",null,"performance test results"),a.createElement("li",null,"Distributed performance modeling"),a.createElement("li",null,"KPIs for service mesh performance"),a.createElement("li",null,"Test tool requirements")),a.createElement("p",null,a.createElement(n.p,null,"Value from a service mesh is best derived when it's tuned to scale as per the deployment requirements. Given the\ncomplexity of deploying, testing and measuring performance aspects across multiple dimensions, the specification\naims to provide a simple starting point for anyone looking to understand and derive service mesh performance. The\nservice mesh performance standard aims to articulate these complexities in a methodical and automated manner in\norder for anyone to plan the performance scenarios of their deployment and execute relevant tests.")),a.createElement("p",null,a.createElement(n.p,null,"The code snippet provides insight on the fact that the specification defines a common collection of statistical analysis\nto be calculated for every performance test.")),a.createElement(n.pre,null,a.createElement(n.code,{className:"language-yaml"},"message PerformanceTestResult {\n  message Latency {\n    double min = 1;\n    double average = 2;\n    double p50 = 3;\n    double p90 = 4;\n    double p99 = 5;\n    double max = 6;\n  }\n}\n")),a.createElement("p",null,a.createElement("i",null,"Snippet of the Service Mesh Performance specification describing how to capture statistical analysis of test results.")),a.createElement("h2",null,"Defining Deployments"),a.createElement("p",null,a.createElement(n.p,null,"Virtualized deployments involve deploying microservice orchestration and service mesh stack in virtual machines (VMs). Although bare metal\nusage has performance benefits, customers often use VMs to provide hardware-level isolation between various applications. This deployment\ninvolves two VMs across two nodes, with one acting as a Kubernetes master with the other a worker node. Customers deploy VMs on a single\nNUMA node to avoid cross UPI traffic. Results in virtualized testing have shown that depending on pinning of QEMU threads to a set of\nisolated cores - either sequentially or clustering the threads together to all the cores - tail latencies are heavily impacted.")),a.createElement("p",null,a.createElement(n.p,null,"Microservice deployments could use a wide variety of deployment scenarios. The following list provides a sample set of how a service mesh\nperformance could be analyzed either on a same node or in a multi-node cluster:")),a.createElement("ul",null,a.createElement("li",null,"Pod to pod communication."),a.createElement("li",null,"Pod to service communication."),a.createElement("li",null,"Ingress controller to pod and vice-versa."),a.createElement("li",null,"Load balancer to pod and vice-versa."),a.createElement("li",null,"Pod to Egress Gateway."),a.createElement("li",null,"Mutual TLS termination across any of the above endpoints."),a.createElement("li",null,"Different security rules and policies."),a.createElement("li",null,"Communication protocol.")),a.createElement("p",null,"These considerations are illustrated in a typical workload deployment as shown in ",a.createElement("i",null,"Figure 3.")),a.createElement("div",{className:"center"},a.createElement("a",{href:l},a.createElement("img",{src:l,align:"center",alt:"Workload"}))),a.createElement("p",null,a.createElement(n.p,null,"Here is an example of deployment with Kubernetes as the orchestrator using Calico CNI and deployed in VMs,\nwhile the host infrastructure has OVS-DPDK for switching, which can be extended for VMs to leverage SR-IOV.\nTo understand impact of infrastructure elements and networking elements of microservice software stack,\nperformance impact of a service mesh and its set of data plane proxies with fortio as load generator could be\nunderstood by running the Meshery in two different environments outside the Kubernetes cluster.")),a.createElement("ol",null,a.createElement("li",null,"First one with load generator running as a process outside of Kubernetes cluster in master-vm"),a.createElement("li",null,"Second one with load generator running as a bare metal process on master-host")),a.createElement("h3",null,"Automating Performance Measurements"),a.createElement("p",null,a.createElement(n.p,null,"Meshery is ideal tooling in that it provides lifecycle management of a large number of service meshes and sample\napplications which need to be provisioned, configured, and deprovisioned in the process of analyzing service mesh performance.\nMeshery is capable of generating load, baselining, and comparing performance results. The canonical implementation of this\nspecification is implemented in Meshery.")),a.createElement("div",{className:"center"},a.createElement("a",{href:s},a.createElement("img",{src:s,align:"center",alt:"Archictures-client"}))),a.createElement("p",null,a.createElement("i",null,"Figure 4 - Meshery’s load generators can be deployed in the same cluster under test or outside of the cluster under test.")),a.createElement("h4",null,"Pipelining performance characterization"),a.createElement("p",null,a.createElement(n.p,null,"Acknowledging the living nature of user deployments, integration of automated performance testing into continuous integration\nsystems helps users deploy new versions of their applications or new configurations of their infrastructure\n(including service mesh configuration) with the assurity  afforded through the act of dry-running the service mesh and application\nconfiguration before production deployment. The Meshery and Service Mesh Performance GitHub Action offers the ability to adaptively\nanalyze application performance as a gate in your continuous delivery pipeline. In this way, the Service Mesh Performance\nspecification facilitates a measurement index that can be referenced when rolling out new versions of a service with this\nadvanced canary technique.")),a.createElement("p",null,a.createElement(n.p,null,"Through Meshery, techniques to mirror non-idempotent requests without fear of impacting the current version of your application\nallowing replay of user requests. And use of intelligent network functions, embedded in WebAssembly (WASM) programs, to\nfacilitate real user request reenactments to help you extract the most value out of your pipeline.")),a.createElement("ul",null,a.createElement("li",null,"Repeatability of test scenarios using performance profiles and cloud native orchestration."),a.createElement("li",null,"Baselining and comparing results.")),a.createElement("h3",null,"Analyzing Performance Measurements"),a.createElement("p",null,a.createElement(n.p,null,"We have often seen inefficiencies in the ratio of resource usage vs resources applied. Since the mesh\nelements i.e. the ingress and sidecars share resources with one or more of the application containers,\nthere may be more resources left to be utilized. Tail latencies decrease with the increase in number of\ncores for all 1, 10 and 100 clones but increase with the increase in the number of connections. Data for\nvarious connection counts, as shown, indicates that performance degradation with Istio shows up with\ninput RPS more than 1000. In a top down microarchitectural analysis (TMA), when the front proxy is pinned\nto a single core and the sidecar + flask app is pinned to another core and the number of microservices are\nscaled up. It is observed that (Figure 2):")),a.createElement("ul",null,a.createElement("li",null,"Frontend Bound% decreases with increase in number of microservices​ and Core Bound % increases."),a.createElement("li",null,"Memory Bound % increases with increase in the number of microservices​."),a.createElement("li",null,"L1 and L3 Bound% decreases for both the service cores on which the front –proxy is running as well as the\ncore where the sidecar+flask app is running with number of microservices.")),a.createElement("p",null,a.createElement(n.p,null,"In customer environments, the size of the cluster as well as the amount of incoming traffic will have an impact on the number of\nworkloads and Envoy microservices. The underlying hardware and L4 networking on each node in the cluster will also impact the\nperformance observed. A call stack and cycles spent analysis of a deployment with 1-20 sidecars on a specific",a.createElement(n.br),"\n","40 core system with a 10G NIC shows bottlenecks spread between:")),a.createElement("ol",null,a.createElement("li",null,"Envoy:TheadLocalStorage-Hashset-Match"),a.createElement("li",null,a.createElement(n.p,null,"Linux kernel bottleneck spread between"),a.createElement("ol",null,a.createElement("li",null,"Libpthreadscheduling"),a.createElement("li",null,"Libevent"))),a.createElement("li",null,"Envoy buffer slice management and TCP filter, if message sizes or file transfer sizes increase to 1M"),a.createElement("li",null,"Crypto operations when TLS is enabled.")),a.createElement("p",null,a.createElement(n.p,null,"Our initial studies show that the optimal service mesh setup for the tolerable latencies and the best RPS may include:")),a.createElement("ol",null,a.createElement("li",null,"Exclusive  threads allocated to Envoy processing"),a.createElement("li",null,"Reduced memory contention by allocating more memory bandwidth which can be controlled dynamically"),a.createElement("li",null,"Load balancing of worker threads among the among cores which may require"),a.createElement("li",null,"Less IO switching"),a.createElement("li",null,"Optimized memory copies with signals incorporated in addition to events (libevent)")),a.createElement("h4",null,"Accelerations and Offloads"),a.createElement("p",null,a.createElement(n.p,null,"A number of accelerations and offloads to SMART NIC or other processing elements like IPUs and DPUs are\nbecoming available. How does the service mesh efficiency and performance benefitted from these deployment\noptions needs to be defined and measured. Cycles and cores saved in the host cores vs offload cores which\nmay be of different architectures and/or performance range needs to be quantified and benchmarks and\nindices created to measure.")),a.createElement("h3",null,"Being Precise in Performance Studies"),a.createElement("p",null,a.createElement(n.p,null,"When measuring sub-millisecond response times, the noise floor of the environment as well as the sensitivity\nof the tooling may become dominant factors in measurements. Noisy neighbours, scheduler fairness, garbage collection,\nand even specifics in the timing of requests being sent as well as connection-reuse patterns may change noise floors\nsuch that similar measurements performed using different systems and tools may diverge an order of magnitude in absolute terms.")),a.createElement("p",null,a.createElement(n.p,null,"As a quick survey of load generators by way of those included in Meshery, we find upon close inspection\ntheir differences are noteworthy and justify their use under different circumstances.")),a.createElement("p",null,a.createElement(n.p,null,"Written in C, wrk2 supports ignoring coordinated omission. wrk2 lets you test a little more complex scenarios.\nUsers express load generation profiles in terms of RPS. wrk2 shows you what you normally may not see in benchmark\nresults, but what every 1,000th user might see. To see these outliers, you need to run the longer (time) performance\ntests.  Wrk2 tests the scenario where there's a string of services comprising microservices. wrk2 requires you to\nspecify the desired RPS, while wrk does not. Wrk2 is focused on driving the maximum RPS. Meshery’s fork of wrk2\nenables testing of multiple endpoints and enables the variable rate of load generation. In the future, Meshery\nwill offer the ability to assign a weight to each endpoint for the load to be generated by wrk2.")),a.createElement("p",null,a.createElement(n.p,null,"Written in Golang, fortio is extremely fast and usable for testing basic response times on a per request level.\nFortio produces results in JSON on a per request basis and easy to integrate into other Golang-based tooling like Meshery.")),a.createElement("p",null,a.createElement(n.p,null,"Written in C++, Nighthawk supports both open- and closed- loop testing, and was designed to offer the right\nsensitivity for benchmarking microservice proxies (sub millisecond latencies). Using an open loop test\nmethodology avoids coordinated omission, and in conjunction with its adaptive load controller one can\nseek answers to questions like “what RPS can my mesh reliably sustain under set latency?”.")),a.createElement("h4",null,"Comparing Types of Data Plane Filtering"),a.createElement("p",null,a.createElement(n.p,null,"Important to note is the power of the service mesh data plane and cost of that power. Envoy is a popular\nproxy of choice for service mesh data planes. Among other features, Envoy provides the ability to\nintegrate custom traffic filters via one of two methods:")),a.createElement("ol",null,a.createElement("li",null,a.createElement(n.p,null,"Natively by incorporating your custom traffic filter into Envoy’s C++ source code and compiling a new\nEnvoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit\nbeing that of your custom filter running at native speed.")),a.createElement("li",null,a.createElement(n.p,null,"Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go.\nThe drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically\nload and reload WASM-based filters in Envoy at runtime."))),a.createElement("p",null,a.createElement(n.p,null,"Whether to  integrate your traffic filters natively or as an extension, a tradeoff between the two deployment\nexists primarily in exchanging between service mesh speed and service mesh flexibility as shown in ",a.createElement("i",null,"Figure 4."))),a.createElement("div",{className:"center"},a.createElement("a",{href:c},a.createElement("img",{src:c,align:"center",alt:"comparison of Network functions"}))),a.createElement("p",null,a.createElement("i",null,"Figure 5 - A comparison of different modes of delivery of service mesh network functions.")),a.createElement("p",null,a.createElement(n.p,null,"As an assessment of this tradeoff, an analysis of a series of three tests run across the same rate\nlimit network function implemented as 1) a Golang-based client library, or 2) a Rust-based Envoy\nfilter running in a WebAssembly virtual machine  (or 3) a native Envoy filter) provides some insight\nas to the comparative overhead involved.")),a.createElement("ol",null,a.createElement("li",null,a.createElement(n.p,null,"Rate limiting with Go client library"),a.createElement("ul",null,a.createElement("li",null,"At 100 RPS the p50 is 3.19ms."),a.createElement("li",null,"At 500 RPS the p50 is 2.44ms."),a.createElement("li",null,"With unlimited RPS (4,417) the p50 is 0.066ms."))),a.createElement("li",null,a.createElement(n.p,null,"Rate limiting with WASM module (Rust filter)"),a.createElement("ul",null,a.createElement("li",null,"At 100 RPS the p50 is 2.1ms"),a.createElement("li",null,"At 500 RPS the p50 is 2.22ms"),a.createElement("li",null,"With unlimited RPS (5,781) the p50 is 0.62ms")))),a.createElement("p",null,a.createElement(n.p,null,"Users not only need to account for the (relatively) easy to quantify system overhead and the operational\noverhead involved in expanding development resources to implement bespoke tooling versus managing off-the-shelf filters.")),a.createElement("h3",null,"Summary"),a.createElement("p",null,"To deploy a service mesh effectively, we need to"),a.createElement("ol",null,a.createElement("li",null,"quantify application workload characteristics and how it utilizes a particular microarchitecture."),a.createElement("li",null,"assess how Container Network Interface (CNI) drivers, Open Virtual Switch (OVS), rules processing, match\nand lookup requirements between Network Address Translated (NAT) and routed networks are required"),a.createElement("li",null," different layers of service mesh to be deployed including layer 4 load balancers, ingress and reverse proxy,\nnumber of sidecars and number of microservices to be supported"),a.createElement("li",null,"and what hardware baseline performance does the setup have and "),a.createElement("li",null," a quantifiable measure of service mesh deployed with performance measures mapped to KPIs like throughput (RPS) and latency.")))}var m=function(e){void 0===e&&(e={});var n=Object.assign({},(0,r.ah)(),e.components).wrapper;return n?a.createElement(n,e,a.createElement(u,e)):u(e)};var d=t(17875),h=t(72417),f=function(e){var n=e.data,t=e.children;return a.createElement(a.Fragment,null,a.createElement(h.Z,{data:n},t))};function p(e){return a.createElement(f,e,a.createElement(m,e))}var g=function(e){var n=e.data;return a.createElement(d.Z,{title:n.mdx.frontmatter.title,image:n.mdx.frontmatter.thumbnail.publicURL})}},72417:function(e,n,t){"use strict";t.d(n,{Z:function(){return v}});var r=t(67294),a=t(71082),o=t(40156),i=t(6652),l=t(33754),s=t(85313).default.div.withConfig({displayName:"resourceSinglestyle__ResourcePageWrapper",componentId:"sc-gfz8rr-0"})(["\n    color: ",";\n    .single-resource-wrapper{\n        margin-bottom: 4rem;\n\n        h3 {\n            text-align: center;\n        }\n    }\n\n    .resource-info-block{\n        margin-top: 3rem;\n        border-bottom: 1px solid ",";\n        padding-bottom: 2rem;\n    }\n    p {\n        color: ",";\n    }\n    li {\n        color: ",";\n    }\n    .backBtn {\n        margin: 3rem auto;\n        font-weight: 600;\n        z-index: 2;\n\n        @media screen and (max-width: 62rem) {\n            display: none;\n        }\n        a{\n            display: flex;\n            color: ",";\n            &:hover{\n                color: ",";\n            }\n\n            h4 {\n                line-height: 1.75rem;\n                margin-left: 0.5rem;\n            }\n            svg {\n                font-size: 1.75rem;\n            }\n        }\n    }\n\n    .tags{\n        display: flex;\n        span{\n            font-size: 1.2rem;\n            align-self: center;\n        }\n        a{\n            color: ",";\n            margin: 0.2rem;\n            display: inline-block;\n            padding: 0.3rem 0.8rem;\n            border-radius: 0.2rem;\n            background: #F0F0F0;\n            transition: all 0.3s linear;\n            &:hover{\n                background: ",";\n                color: ",";\n            }\n        }\n        div{\n            display: inline-flex;\n            flex-wrap: wrap;\n        }\n    }\n    @media screen and (max-width: 360px){\n        .tags{\n            span{\n                position: relative;\n                top: 0.5rem;\n                align-self: flex-start;\n            }\n        }\n    }\n"],(function(e){return e.theme.text}),(function(e){return e.theme.text}),(function(e){return e.theme.text}),(function(e){return e.theme.text}),(function(e){return e.theme.primaryColor}),(function(e){return e.theme.linkColor}),(function(e){return e.theme.black}),(function(e){return e.theme.secondaryColor}),(function(e){return e.theme.white})),c=t(75472),u=t.n(c),m=t(64721),d=t.n(m);function h(e,n){var t="undefined"!=typeof Symbol&&e[Symbol.iterator]||e["@@iterator"];if(t)return(t=t.call(e)).next.bind(t);if(Array.isArray(e)||(t=function(e,n){if(!e)return;if("string"==typeof e)return f(e,n);var t=Object.prototype.toString.call(e).slice(8,-1);"Object"===t&&e.constructor&&(t=e.constructor.name);if("Map"===t||"Set"===t)return Array.from(e);if("Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t))return f(e,n)}(e))||n&&e&&"number"==typeof e.length){t&&(e=t);var r=0;return function(){return r>=e.length?{done:!0}:{done:!1,value:e[r++]}}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}function f(e,n){(null==n||n>e.length)&&(n=e.length);for(var t=0,r=new Array(n);t<n;t++)r[t]=e[t];return r}var p=function(){function e(e,n){this.resources=e.filter((function(e){return e.fields.slug!==n})),this.currentResourceSlug=n,this.maxResources=6,this.category=null,this.tags=[]}var n=e.prototype;return n.setMaxResources=function(e){return this.maxResources=e,this},n.setCategory=function(e){return this.category=e,this},n.setTags=function(e){return this.tags=e,this},n.getResources=function(){var e=this.category,n=this.tags,t=this.resources,r=this.maxResources,a={};if(!1==!!n||0===n.length)return console.error("RelatedResourcesFactory: Tags not provided, use setTags()."),[];if(!1==!!e)return console.error("RelatedResourcesFactory: Category not provided, use setCategory()."),[];for(var o,i=function(e){return e.fields.slug},l=function(e){var n=i(e);Object.prototype.hasOwnProperty.call(a,n)||(a[n]={resource:e,points:0})},s=function(e,n){var t=i(e);e.frontmatter.category===n&&(a[t].points+=2)},c=function(e,n){var t=i(e);e.frontmatter.tags.forEach((function(e){d()(n,e)&&(a[t].points+=1)}))},m=h(t);!(o=m()).done;){var f=o.value;l(f),s(f,e),c(f,n)}var p=Object.keys(a).map((function(e){return a[e]}));return u()(p,["points"],["desc"]).splice(0,r)},e}(),g=t(78705),y=(0,o.ZP)((function(){return t.e(35575).then(t.bind(t,59434))})),E=(0,o.ZP)((function(){return Promise.all([t.e(40532),t.e(67326),t.e(18514)]).then(t.bind(t,24210))})),v=function(e){var n=e.data,t=e.children,o=n.mdx,c=o.frontmatter,u=o.fields,m=(0,a.useStaticQuery)("2848499768").allMdx.nodes,d=new p(m,u.slug).setMaxResources(6).setCategory(c.category).setTags(c.tags).getResources();return r.createElement(s,null,r.createElement(l.Z,{title:c.title,subtitle:c.subtitle,thumbnail:c.thumbnail}),r.createElement("div",{className:"single-resource-wrapper"},r.createElement(i.W2,null,t,r.createElement(y,{category:"MeshMap"}),r.createElement("div",{className:"backBtn"},r.createElement(a.Link,{to:"/resources"},r.createElement(g.O,null),r.createElement("h4",null,"All Resources"))),r.createElement(E,{resourceType:"resources",relatedResources:d,mainHead:"Related Resources",lastCardHead:"All Resources",linkToAllItems:"/resources"}))))}}}]);